{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# polite API usage\n",
    "headers = {\n",
    "    'User-Agent': 'LitScapeExperiments/1.0 (mailto:10133433@mackenzista.com.br)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_article_count(issn):\n",
    "    \"\"\"Fetches the count of articles available for a specific ISSN.\"\"\"\n",
    "    url = f\"https://api.crossref.org/journals/{issn}/works\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "    # Extract total number of works available\n",
    "    if 'message' in data and 'total-results' in data['message']:\n",
    "        return data['message']['total-results']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def list_journals(query):\n",
    "    url = f\"https://api.crossref.org/journals?query={query}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "\n",
    "    journals = []\n",
    "    for item in data.get('message', {}).get('items', []):\n",
    "        journal_title = item.get('title', 'No title available')\n",
    "        issn_list = item.get('ISSN', [])\n",
    "        current_dois = item.get('counts', {}).get('current-dois', 0)\n",
    "\n",
    "        # Skip if no current DOIs or list is empty\n",
    "        if not current_dois or not issn_list:\n",
    "            continue\n",
    "\n",
    "        abstract_fill_rate = item.get('coverage', {}).get('abstracts-current', 0.0)\n",
    "\n",
    "        if abstract_fill_rate < 0.5 or current_dois < 100:\n",
    "            continue\n",
    "\n",
    "        article_count = fetch_article_count(issn_list[0])\n",
    "\n",
    "        journal_info = {\n",
    "            'title': journal_title,\n",
    "            'ISSN': issn_list,\n",
    "            'article_count': article_count,\n",
    "            'current_dois': current_dois,\n",
    "            'abstract_fill_rate': abstract_fill_rate\n",
    "        }\n",
    "        journals.append(journal_info)\n",
    "\n",
    "    # Save the journals list to a JSON file, if not empty\n",
    "    if journals:\n",
    "        with open(f'journal_queries/{query}.json', 'w') as f:\n",
    "            json.dump(journals, f, indent=4)\n",
    "\n",
    "        df_journals = pd.DataFrame(journals)\n",
    "        if not df_journals.empty:\n",
    "            return df_journals.sort_values(['abstract_fill_rate', 'current_dois'], ascending=False)\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def fetch_journal_articles(issn, journal_name, rows=150):\n",
    "    \"\"\"Fetches articles and saves them as JSON.\"\"\"\n",
    "    url = f\"https://api.crossref.org/journals/{issn}/works?rows={rows}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "    \n",
    "    articles = []\n",
    "    if 'message' in data:\n",
    "        for item in data['message']['items']:\n",
    "            #print(item)\n",
    "            article = {\n",
    "                'title': item.get('title', [None])[0],\n",
    "                'doi': item.get('DOI', None),\n",
    "                'year': item.get('created', {}).get('date-parts', [None])[0][0],\n",
    "                'abstract': item.get('abstract', '').strip(),\n",
    "                'is_referenced_by_count': item.get('is-referenced-by-count', None)\n",
    "            }\n",
    "\n",
    "            # only append if it has a title and abstract\n",
    "            if article['title'] is not None and article['abstract'] != '':\n",
    "                articles.append(article)\n",
    "\n",
    "    valid_rows = len(articles)\n",
    "\n",
    "    # Save the articles to a JSON file\n",
    "    with open(f\"article_metadata/{journal_name}_ISSN{issn}_sample{valid_rows}.json\", 'w') as f:\n",
    "        json.dump(articles, f, indent=4)  # Pretty print the JSON for readability\n",
    "\n",
    "    df_articles = pd.DataFrame(articles)\n",
    "\n",
    "    return df_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['quantum', 'complexity', 'biology', 'psychology', 'chemistry', 'medical physics', 'machine learning']\n",
    "\n",
    "for query in queries:\n",
    "\n",
    "    # check if it has already been fetched\n",
    "    try:\n",
    "        with open(f'journal_queries/{query}.json', 'r') as f:\n",
    "            journals = json.load(f)\n",
    "        df_journals = pd.DataFrame(journals)\n",
    "        print(f\"Found existing data for {query}.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Fetching data for query:\", query)\n",
    "        df_journals = list_journals(query)\n",
    "        if df_journals.empty:\n",
    "            print(f\"No journals found for {query}.\")\n",
    "\n",
    "    # Select the primary ISSN and corresponding journal name\n",
    "    primary_issn = df_journals.iloc[0]['ISSN'][0]\n",
    "    primary_journal = df_journals[df_journals['ISSN'].apply(lambda x: primary_issn in x)]['title'].iloc[0]\n",
    "    print(f\"Selected journal: {primary_journal} (ISSN: {primary_issn})\")\n",
    "\n",
    "    # Normalize the journal name for file naming\n",
    "    normalized_name = primary_journal.replace(' ', '_').replace('/', '_').lower()\n",
    "    \n",
    "    # Attempt to fetch articles from the primary ISSN\n",
    "    df_articles = fetch_journal_articles(primary_issn, journal_name=normalized_name, rows=200)\n",
    "    if len(df_articles) >= 100:\n",
    "        print(f\"Successfully fetched {len(df_articles)} articles from {primary_journal} (ISSN: {primary_issn}).\")\n",
    "        continue\n",
    "\n",
    "    # If the primary ISSN fails, try the secondary ISSN if available\n",
    "    if len(df_journals.iloc[0]['ISSN']) > 1:\n",
    "        secondary_issn = df_journals.iloc[0]['ISSN'][1]\n",
    "        print(\"Trying secondary ISSN:\", secondary_issn)\n",
    "        secondary_journal = df_journals[df_journals['ISSN'].apply(lambda x: secondary_issn in x)]['title'].iloc[0]\n",
    "        normalized_name = secondary_journal.replace(' ', '_').replace('/', '_').lower()\n",
    "        \n",
    "        df_articles = fetch_journal_articles(secondary_issn, journal_name=normalized_name, rows=200)\n",
    "        if len(df_articles) >= 100:\n",
    "            print(f\"Successfully fetched {len(df_articles)} articles from {secondary_journal} (ISSN: {secondary_issn}).\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch enough articles from {secondary_journal}.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch articles from {primary_journal} and no secondary ISSN available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_metadata = os.listdir('article_metadata')\n",
    "article_metadata = [file for file in article_metadata if file.endswith('.json')]\n",
    "\n",
    "# Combine all article metadata into a single DataFrame, where a column should be the journal name\n",
    "dfs = []\n",
    "for file in article_metadata:\n",
    "    with open(f'article_metadata/{file}', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "        df['journal'] = file.split('_ISSN')[0]\n",
    "        dfs.append(df)\n",
    "\n",
    "df_all_articles_raw = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "df_all_articles_raw.to_csv('all_articles_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "df_all_articles = df_all_articles_raw.copy()\n",
    "\n",
    "df_all_articles['abstract'] = df_all_articles['abstract'].apply(remove_tags)\n",
    "\n",
    "# Remove leading \"Abstract\" from abstracts\n",
    "df_all_articles['abstract'] = df_all_articles['abstract'].str.replace(r'^Abstract', '', regex=True)\n",
    "df_all_articles['abstract'] = df_all_articles['abstract'].str.replace(r'^Abstract: ', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_articles['abstract_length'] = df_all_articles['abstract'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "hovertemplate": "journal=%{label}<br>count=%{value}<extra></extra>",
         "labels": [
          "medical_physics",
          "chemistry",
          "quantum",
          "journal_of_physics_complexity",
          "machine_learning_science_and_technology",
          "biology",
          "complexity",
          "culture_&_psychology",
          "chemistryopen",
          "apl_machine_learning"
         ],
         "legendgroup": "",
         "name": "",
         "showlegend": true,
         "textinfo": "percent+label",
         "textposition": "inside",
         "type": "pie",
         "values": [
          285,
          200,
          200,
          199,
          193,
          184,
          170,
          168,
          136,
          105
         ]
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Periódico"
         },
         "tracegroupgap": 0
        },
        "piecolorway": [
         "rgb(103,0,31)",
         "rgb(178,24,43)",
         "rgb(214,96,77)",
         "rgb(244,165,130)",
         "rgb(253,219,199)",
         "rgb(247,247,247)",
         "rgb(209,229,240)",
         "rgb(146,197,222)",
         "rgb(67,147,195)",
         "rgb(33,102,172)",
         "rgb(5,48,97)"
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribuição de Artigos por Periódico"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "journal_counts = df_all_articles['journal'].value_counts().reset_index()\n",
    "journal_counts.columns = ['journal', 'count']\n",
    "\n",
    "# Create the pie chart\n",
    "fig = px.pie(journal_counts, values='count', names='journal',\n",
    "             title='Distribuição de Artigos por Periódico',\n",
    "             color_discrete_sequence=px.colors.sequential.RdBu)\n",
    "\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "fig.update_layout(legend_title_text='Periódico')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "Tamanho do Abstract=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "nbinsx": 50,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          1165,
          1151,
          1532,
          1402,
          1395,
          1458,
          1800,
          1463,
          2486,
          1164,
          1268,
          1814,
          1199,
          1403,
          847,
          1006,
          768,
          1831,
          1347,
          1186,
          1673,
          1203,
          1725,
          1509,
          1072,
          1322,
          1364,
          1765,
          1457,
          1648,
          1099,
          1183,
          724,
          1422,
          866,
          1689,
          1045,
          1551,
          1492,
          966,
          813,
          1294,
          1189,
          729,
          1787,
          1073,
          1471,
          1507,
          1281,
          1118,
          1326,
          577,
          1100,
          1462,
          1568,
          1615,
          1360,
          1379,
          1040,
          1598,
          1751,
          1134,
          1130,
          1608,
          993,
          1012,
          1518,
          1379,
          1793,
          1398,
          1487,
          1788,
          1912,
          1646,
          2191,
          1179,
          1760,
          1056,
          1288,
          1873,
          1171,
          1193,
          1361,
          1168,
          1072,
          1631,
          1258,
          1698,
          1167,
          1475,
          1169,
          1409,
          1164,
          1449,
          1409,
          696,
          1222,
          1393,
          1258,
          1164,
          1844,
          1377,
          1404,
          1197,
          1288,
          1423,
          851,
          77,
          1886,
          1272,
          1258,
          1422,
          1353,
          1631,
          1140,
          1024,
          1493,
          1647,
          1347,
          1308,
          1904,
          1341,
          1060,
          1640,
          1433,
          1561,
          1435,
          1638,
          1267,
          948,
          1435,
          1443,
          1764,
          84,
          2068,
          1618,
          1635,
          1698,
          1354,
          1392,
          596,
          1418,
          1156,
          1636,
          1790,
          1062,
          1374,
          1134,
          145,
          1049,
          1310,
          1537,
          1673,
          1461,
          1462,
          1388,
          984,
          1503,
          1130,
          79,
          1372,
          1432,
          1370,
          1773,
          1480,
          1316,
          1798,
          1478,
          1908,
          1276,
          1468,
          2148,
          1866,
          1333,
          1304,
          1439,
          1745,
          705,
          50,
          1339,
          1148,
          1248,
          172,
          33,
          1259,
          1079,
          1185,
          131,
          1251,
          1666,
          1298,
          1415,
          1519,
          1051,
          1517,
          1408,
          1291,
          1315,
          1405,
          1751,
          1667,
          1174,
          1321,
          2085,
          1151,
          1163,
          1306,
          1402,
          1374,
          1107,
          2013,
          1671,
          1430,
          1491,
          1046,
          1561,
          1837,
          1439,
          1595,
          2047,
          1470,
          1886,
          2080,
          1906,
          1332,
          1532,
          1333,
          1882,
          1588,
          1489,
          1418,
          1366,
          1197,
          1161,
          1256,
          1966,
          2332,
          1648,
          1332,
          1267,
          265,
          1406,
          1259,
          1281,
          1533,
          1193,
          1281,
          1601,
          1668,
          1127,
          1353,
          1298,
          1353,
          1460,
          1103,
          1356,
          1569,
          1395,
          1741,
          1534,
          2015,
          2232,
          1466,
          1668,
          1483,
          1444,
          1459,
          1036,
          1512,
          1477,
          1949,
          1327,
          1437,
          1549,
          1907,
          2079,
          2445,
          1424,
          1952,
          1501,
          1729,
          1283,
          1376,
          2840,
          1692,
          1422,
          1936,
          1421,
          885,
          1060,
          11,
          569,
          11,
          586,
          538,
          344,
          445,
          1061,
          1479,
          837,
          596,
          1060,
          795,
          571,
          506,
          1470,
          537,
          665,
          1068,
          1116,
          948,
          855,
          1139,
          937,
          1365,
          1477,
          988,
          661,
          969,
          1208,
          1649,
          708,
          1025,
          1324,
          924,
          1412,
          1266,
          464,
          545,
          794,
          1134,
          694,
          1262,
          1141,
          868,
          593,
          897,
          1114,
          604,
          1296,
          1465,
          524,
          450,
          700,
          656,
          1142,
          1384,
          403,
          907,
          1011,
          1142,
          1210,
          902,
          746,
          1187,
          1382,
          989,
          534,
          1453,
          822,
          800,
          566,
          761,
          1340,
          1481,
          956,
          958,
          965,
          496,
          866,
          1057,
          328,
          11,
          1191,
          677,
          933,
          1144,
          937,
          796,
          1851,
          1098,
          898,
          420,
          359,
          765,
          1089,
          396,
          1391,
          994,
          795,
          951,
          928,
          849,
          561,
          994,
          1006,
          852,
          927,
          1299,
          579,
          1267,
          1060,
          307,
          897,
          652,
          985,
          794,
          1426,
          851,
          547,
          572,
          1405,
          798,
          1504,
          1446,
          982,
          1167,
          955,
          990,
          1169,
          567,
          607,
          1008,
          1091,
          1495,
          1190,
          1268,
          807,
          1328,
          1462,
          613,
          1328,
          591,
          1408,
          300,
          929,
          1379,
          1323,
          914,
          977,
          1105,
          1370,
          1272,
          598,
          1058,
          1468,
          1068,
          1048,
          375,
          1526,
          1275,
          987,
          793,
          1450,
          1012,
          977,
          909,
          1083,
          1455,
          1232,
          1032,
          632,
          1707,
          1372,
          940,
          812,
          1372,
          937,
          1255,
          1450,
          786,
          994,
          1235,
          508,
          1097,
          1781,
          423,
          588,
          1247,
          1138,
          1533,
          1375,
          314,
          1066,
          893,
          1338,
          1768,
          646,
          525,
          714,
          1518,
          1248,
          2124,
          1765,
          1304,
          1303,
          959,
          369,
          1535,
          1105,
          1299,
          2300,
          1376,
          1746,
          1437,
          1330,
          720,
          1283,
          596,
          1252,
          453,
          1915,
          2461,
          1854,
          1068,
          1291,
          470,
          863,
          1627,
          1894,
          911,
          545,
          984,
          925,
          735,
          1400,
          498,
          913,
          975,
          1484,
          2036,
          933,
          1229,
          829,
          499,
          1234,
          995,
          1138,
          1771,
          885,
          246,
          1780,
          1311,
          1277,
          686,
          1303,
          1057,
          1416,
          1286,
          1166,
          949,
          2015,
          448,
          972,
          946,
          1440,
          1361,
          1461,
          1622,
          624,
          1096,
          1228,
          1710,
          637,
          1260,
          1585,
          661,
          665,
          739,
          1485,
          1786,
          815,
          989,
          584,
          1272,
          904,
          1600,
          58,
          640,
          1225,
          1416,
          1084,
          1470,
          1265,
          961,
          1049,
          821,
          1098,
          229,
          269,
          1522,
          698,
          832,
          1365,
          659,
          1577,
          759,
          1742,
          1252,
          187,
          1283,
          1094,
          857,
          1167,
          1118,
          833,
          1126,
          1349,
          1047,
          944,
          763,
          1137,
          1396,
          992,
          1593,
          1845,
          1223,
          1407,
          1571,
          1551,
          1657,
          863,
          1666,
          855,
          1466,
          1158,
          1057,
          1466,
          869,
          373,
          1493,
          1056,
          856,
          1658,
          382,
          554,
          888,
          1189,
          1360,
          1092,
          924,
          1234,
          1790,
          1145,
          979,
          1235,
          501,
          1254,
          1128,
          631,
          1272,
          1389,
          944,
          979,
          1546,
          1125,
          1128,
          1334,
          1075,
          829,
          1206,
          1246,
          1419,
          1074,
          1602,
          1354,
          1530,
          889,
          470,
          1301,
          655,
          1507,
          1013,
          1641,
          1342,
          2915,
          1554,
          848,
          1621,
          1589,
          1240,
          1159,
          903,
          1045,
          654,
          1293,
          444,
          1346,
          805,
          1199,
          1445,
          650,
          1565,
          1547,
          996,
          1161,
          867,
          709,
          1167,
          1203,
          1426,
          965,
          591,
          1742,
          1120,
          1333,
          1169,
          1384,
          1463,
          1336,
          354,
          1205,
          1418,
          1307,
          703,
          1369,
          539,
          470,
          2147,
          1353,
          582,
          1242,
          1621,
          1090,
          669,
          1117,
          1816,
          626,
          1422,
          1040,
          415,
          1729,
          908,
          686,
          914,
          1682,
          1535,
          871,
          1322,
          1159,
          921,
          983,
          619,
          622,
          1010,
          642,
          1053,
          1672,
          1035,
          511,
          1198,
          580,
          1087,
          998,
          1079,
          336,
          586,
          1641,
          940,
          373,
          1263,
          1058,
          1073,
          1075,
          1753,
          1266,
          1346,
          1039,
          996,
          1337,
          776,
          469,
          846,
          311,
          774,
          2518,
          599,
          1438,
          1053,
          1154,
          1088,
          998,
          720,
          616,
          1324,
          1278,
          1718,
          1754,
          1829,
          1271,
          1233,
          1876,
          1227,
          1493,
          1182,
          1066,
          985,
          816,
          1067,
          1018,
          1158,
          1114,
          754,
          381,
          1414,
          1211,
          1409,
          935,
          1048,
          772,
          1364,
          908,
          1058,
          624,
          1301,
          1427,
          1190,
          447,
          1040,
          659,
          522,
          1479,
          1314,
          1279,
          707,
          1096,
          496,
          1248,
          763,
          1301,
          390,
          725,
          1163,
          1044,
          1128,
          661,
          879,
          665,
          1166,
          1472,
          1249,
          922,
          877,
          555,
          616,
          1447,
          904,
          916,
          308,
          959,
          1155,
          1041,
          1179,
          726,
          1165,
          2516,
          766,
          1003,
          1143,
          689,
          688,
          636,
          353,
          540,
          1419,
          1576,
          1003,
          1391,
          1113,
          464,
          1420,
          1014,
          874,
          771,
          929,
          1173,
          635,
          1741,
          850,
          1047,
          1174,
          1596,
          1040,
          1391,
          1201,
          1627,
          1548,
          853,
          1001,
          1592,
          1471,
          1118,
          818,
          1207,
          1164,
          1208,
          1642,
          1677,
          979,
          716,
          893,
          941,
          1163,
          1291,
          1413,
          1163,
          1023,
          553,
          1118,
          1178,
          1098,
          831,
          1746,
          880,
          847,
          1701,
          1232,
          1202,
          1439,
          930,
          709,
          413,
          719,
          707,
          912,
          820,
          1455,
          1182,
          1065,
          1291,
          984,
          548,
          1601,
          599,
          835,
          1222,
          1477,
          1642,
          1090,
          1087,
          1258,
          742,
          1814,
          951,
          949,
          850,
          1082,
          1841,
          1104,
          1207,
          433,
          682,
          743,
          1011,
          1017,
          975,
          1009,
          991,
          1173,
          813,
          793,
          411,
          758,
          757,
          278,
          543,
          1239,
          957,
          1557,
          1730,
          912,
          241,
          1422,
          1922,
          1648,
          1703,
          1288,
          878,
          1632,
          1279,
          555,
          1247,
          1146,
          1470,
          335,
          1091,
          1038,
          1223,
          1184,
          1425,
          1061,
          1916,
          1929,
          1758,
          1236,
          1487,
          1462,
          1859,
          1799,
          1524,
          1166,
          825,
          898,
          1237,
          1296,
          1515,
          1052,
          1364,
          1022,
          1134,
          1342,
          1122,
          1101,
          1224,
          1408,
          1079,
          597,
          811,
          1902,
          589,
          830,
          1757,
          1049,
          1921,
          1181,
          1093,
          847,
          995,
          1112,
          1046,
          1599,
          856,
          1041,
          456,
          1346,
          1889,
          1892,
          1182,
          1333,
          1271,
          1165,
          890,
          1109,
          1147,
          748,
          1003,
          1365,
          1801,
          749,
          1312,
          1570,
          1238,
          2566,
          1255,
          1218,
          888,
          588,
          1364,
          993,
          1543,
          1237,
          643,
          1199,
          832,
          1368,
          1136,
          1640,
          780,
          1229,
          855,
          1677,
          1674,
          890,
          1079,
          2009,
          1441,
          1391,
          1428,
          947,
          969,
          1023,
          1626,
          983,
          986,
          1191,
          1430,
          1190,
          998,
          1243,
          918,
          906,
          1567,
          1791,
          1228,
          853,
          1664,
          1309,
          1105,
          1358,
          661,
          1080,
          1323,
          875,
          1409,
          1218,
          965,
          958,
          1291,
          930,
          1313,
          1471,
          206,
          1065,
          1080,
          686,
          1942,
          1121,
          979,
          730,
          1896,
          1051,
          846,
          1241,
          1618,
          1075,
          1328,
          1486,
          1538,
          1137,
          1143,
          868,
          1326,
          971,
          699,
          1026,
          870,
          1196,
          1819,
          996,
          1811,
          1863,
          899,
          876,
          1082,
          790,
          1731,
          2014,
          1379,
          1758,
          1091,
          577,
          961,
          1097,
          938,
          1081,
          1114,
          963,
          812,
          1110,
          951,
          1425,
          1769,
          1785,
          1104,
          1594,
          1205,
          1236,
          1099,
          1636,
          1559,
          1126,
          1111,
          1387,
          1377,
          1205,
          2282,
          1185,
          1516,
          1062,
          1088,
          1640,
          1040,
          834,
          1394,
          1638,
          1419,
          1081,
          1454,
          1141,
          1926,
          1469,
          1094,
          1854,
          549,
          1346,
          1973,
          1666,
          1462,
          798,
          1106,
          913,
          1087,
          1507,
          1047,
          1148,
          2285,
          1925,
          793,
          1252,
          1291,
          862,
          1425,
          1586,
          1110,
          1653,
          1328,
          1186,
          1231,
          1157,
          2001,
          1497,
          1416,
          1108,
          1602,
          1183,
          1653,
          990,
          994,
          889,
          1917,
          1736,
          1199,
          1307,
          1116,
          1741,
          1223,
          1279,
          806,
          1647,
          756,
          1252,
          1195,
          644,
          807,
          1205,
          1470,
          1929,
          1868,
          1208,
          1334,
          1400,
          1182,
          1773,
          891,
          1391,
          502,
          896,
          850,
          1422,
          868,
          1429,
          1477,
          1041,
          1520,
          1419,
          1370,
          1279,
          1509,
          841,
          1395,
          1174,
          1070,
          1196,
          1150,
          900,
          1247,
          1376,
          1190,
          982,
          954,
          1405,
          1698,
          1065,
          1242,
          871,
          1403,
          1827,
          935,
          1077,
          920,
          1073,
          1954,
          1590,
          1344,
          861,
          2747,
          1939,
          1298,
          724,
          1449,
          1554,
          1218,
          990,
          1444,
          1547,
          1256,
          1156,
          900,
          2033,
          1024,
          1690,
          1220,
          1773,
          1294,
          1741,
          1776,
          1527,
          1681,
          1024,
          947,
          1499,
          1211,
          2074,
          1058,
          1141,
          1530,
          1102,
          1007,
          1515,
          1138,
          2029,
          1374,
          1233,
          1099,
          1269,
          1387,
          1237,
          856,
          1365,
          1295,
          1535,
          938,
          1176,
          819,
          882,
          1746,
          930,
          951,
          1239,
          1515,
          895,
          1868,
          2052,
          1820,
          998,
          1615,
          1045,
          1217,
          2019,
          2924,
          1863,
          1300,
          1007,
          1417,
          2232,
          1269,
          1814,
          990,
          1526,
          2559,
          288,
          1608,
          1652,
          1784,
          833,
          633,
          1414,
          772,
          1574,
          1367,
          2248,
          2488,
          2652,
          1710,
          2226,
          1707,
          2955,
          2196,
          1452,
          2203,
          826,
          1972,
          786,
          1675,
          551,
          1197,
          1301,
          2696,
          2170,
          2403,
          2903,
          1516,
          2684,
          2903,
          2601,
          2193,
          1544,
          1713,
          1898,
          2389,
          243,
          1747,
          1458,
          871,
          1528,
          691,
          2497,
          262,
          1826,
          1992,
          1750,
          2560,
          1760,
          2235,
          2083,
          2263,
          1992,
          1312,
          1880,
          1395,
          705,
          1684,
          1932,
          2152,
          2067,
          1536,
          1076,
          1477,
          1976,
          1803,
          2043,
          1379,
          1337,
          1677,
          2014,
          2068,
          1605,
          1975,
          1360,
          1396,
          1293,
          838,
          2551,
          1768,
          1649,
          2596,
          998,
          1615,
          1045,
          1217,
          2019,
          2924,
          1863,
          1300,
          1007,
          1417,
          2232,
          1269,
          1814,
          990,
          1526,
          2559,
          288,
          1608,
          1652,
          1784,
          833,
          633,
          1414,
          772,
          1574,
          1367,
          2248,
          2488,
          2652,
          1710,
          2226,
          1707,
          2955,
          2196,
          1452,
          2203,
          826,
          1972,
          786,
          1675,
          551,
          1197,
          1301,
          2696,
          2170,
          2403,
          2903,
          1516,
          2684,
          2903,
          2601,
          2193,
          1544,
          1713,
          1898,
          2389,
          243,
          1747,
          1458,
          871,
          1528,
          691,
          2497,
          262,
          1826,
          1992,
          1750,
          2560,
          1760,
          2235,
          2083,
          2263,
          1992,
          1312,
          1880,
          1395,
          705,
          1684,
          1932,
          2152,
          2067,
          1536,
          1076,
          1477,
          1976,
          1803,
          2043,
          1379,
          1337,
          1677,
          2014,
          2068,
          1605,
          1975,
          1360,
          1396,
          1293,
          838,
          2551,
          1768,
          1649,
          2596,
          1920,
          2894,
          2192,
          2199,
          1640,
          1932,
          2355,
          1616,
          1348,
          919,
          892,
          974,
          1317,
          2014,
          2820,
          2858,
          1908,
          2714,
          2385,
          2023,
          2881,
          2930,
          1986,
          1519,
          2222,
          2535,
          2362,
          2343,
          1835,
          2275,
          2311,
          2047,
          2575,
          2625,
          2523,
          2532,
          1778,
          1797,
          2666,
          1355,
          144,
          2450,
          2574,
          2125,
          1525,
          2932,
          976,
          429,
          642,
          489,
          534,
          784,
          991,
          814,
          466,
          425,
          1086,
          658,
          2994,
          483,
          903,
          600,
          1215,
          626,
          897,
          2477,
          1132,
          1705,
          1077,
          1918,
          1102,
          1236,
          1221,
          1245,
          769,
          1897,
          1071,
          1075,
          1161,
          999,
          666,
          783,
          1947,
          886,
          782,
          1625,
          1755,
          1807,
          946,
          928,
          1685,
          1042,
          1622,
          1150,
          1425,
          1178,
          912,
          901,
          1220,
          952,
          1142,
          1133,
          1566,
          1025,
          1181,
          1058,
          1287,
          1653,
          627,
          1544,
          1031,
          1128,
          1211,
          1254,
          724,
          928,
          1179,
          1810,
          1247,
          1002,
          1343,
          624,
          1364,
          963,
          884,
          777,
          1381,
          1315,
          1129,
          922,
          1042,
          1104,
          909,
          832,
          963,
          1141,
          1285,
          1240,
          986,
          1259,
          1349,
          1160,
          1197,
          768,
          1366,
          1383,
          1428,
          1090,
          1224,
          1132,
          1003,
          1132,
          1199,
          624,
          802,
          1614,
          1292,
          466,
          1514,
          1133,
          1045,
          1170,
          1136,
          998,
          1382,
          419,
          1084,
          1172,
          1036,
          892,
          994,
          1797,
          615,
          925,
          1549,
          1491,
          1062,
          1134,
          554,
          1021,
          700,
          764,
          662,
          1535,
          1666,
          650,
          664,
          665,
          1601,
          1576,
          747,
          943,
          851,
          1222,
          1707,
          1154,
          2354,
          1573,
          1061,
          874,
          1195,
          1678,
          1320,
          916,
          1025,
          1160,
          479,
          794,
          1033,
          1006,
          1429,
          1226,
          1398,
          690,
          1111,
          992,
          751,
          1192,
          1432,
          789,
          884,
          2032,
          1490,
          1505,
          1045,
          870,
          1868,
          1025,
          917,
          1092,
          796,
          847,
          1068,
          1920,
          2068,
          1754,
          1353,
          1170,
          525,
          1092,
          1286,
          1268,
          1023,
          1125,
          709,
          1119,
          1903,
          1077,
          1384,
          155,
          1362,
          1595,
          1200,
          672,
          1077,
          875,
          1123,
          1492,
          616,
          1466,
          1579,
          1230
         ],
         "xaxis": "x",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "customdata": [
          [
           "Pair distribution function analysis for oxide defect identification through feature extraction and supervised learning",
           "10.1063/5.0130681",
           2023,
           "Feature extraction and a neural network model are applied to predict defect types and concentrations in experimental anatase TiO2 samples. A dataset of TiO2 structures with vacancies and interstitials of oxygen and titanium is built, and the structures are relaxed using energy minimization. The features of the calculated pair distribution functions (PDFs) of these defected structures are extracted using linear methods (principal component analysis and non-negative matrix factorization) and non-linear methods (autoencoder and convolutional neural network). The extracted features are used as inputs to a neural network that maps feature weights to the concentration of each defect type. The performance of this machine learning pipeline is validated by predicting defect concentrations based on experimentally measured TiO2 PDFs and comparing the results to brute-force predictions. A physics-based initialization of the autoencoder has the highest accuracy in predicting defect concentrations. This model incorporates physical interpretability and predictability of material structures, enabling a more efficient characterization process with scattering data.",
           1,
           "apl_machine_learning"
          ],
          [
           "Leveraging graph neural networks and neural operator techniques for high-fidelity mesh-based physics simulations",
           "10.1063/5.0167014",
           2023,
           "Developing fast and accurate computational models to simulate intricate physical phenomena has been a persistent research challenge. Recent studies have demonstrated remarkable capabilities in predicting various physical outcomes through machine learning-assisted approaches. However, it remains challenging to generalize current methods, usually crafted for a specific problem, to other more complex or broader scenarios. To address this challenge, we developed graph neural network (GNN) models with enhanced generalizability derived from the distinct GNN architecture and neural operator techniques. As a proof of concept, we employ our GNN models to predict finite element (FE) simulation results for three-dimensional solid mechanics problems with varying boundary conditions. Results show that our GNN model achieves accurate and robust performance in predicting the stress and deformation profiles of structures compared with FE simulations. Furthermore, the neural operator embedded GNN approach enables learning and predicting various solid mechanics problems in a generalizable fashion, making it a promising approach for surrogate modeling.",
           0,
           "apl_machine_learning"
          ],
          [
           "Random forests for detecting weak signals and extracting physical information: A case study of magnetic navigation",
           "10.1063/5.0189564",
           2024,
           "It has been recently demonstrated that two machine-learning architectures, reservoir computing and time-delayed feed-forward neural networks, can be exploited for detecting the Earth’s anomaly magnetic field immersed in overwhelming complex signals for magnetic navigation in a GPS-denied environment. The accuracy of the detected anomaly field corresponds to a positioning accuracy in the range of 10–40 m. To increase the accuracy and reduce the uncertainty of weak signal detection as well as to directly obtain the position information, we exploit the machine-learning model of random forests that combines the output of multiple decision trees to give optimal values of the physical quantities of interest. In particular, from time-series data gathered from the cockpit of a flying airplane during various maneuvering stages, where strong background complex signals are caused by other elements of the Earth’s magnetic field and the fields produced by the electronic systems in the cockpit, we demonstrate that the random-forest algorithm performs remarkably well in detecting the weak anomaly field and in filtering the position of the aircraft. With the aid of the conventional inertial navigation system, the positioning error can be reduced to less than 10 m. We also find that, contrary to the conventional wisdom, the classic Tolles–Lawson model for calibrating and removing the magnetic field generated by the body of the aircraft is not necessary and may even be detrimental for the success of the random-forest method.",
           0,
           "apl_machine_learning"
          ],
          [
           "Experimental realization of a quantum classification: Bell state measurement via machine learning",
           "10.1063/5.0149414",
           2023,
           "The Bell state is a crucial resource for the realization of quantum information tasks, and when combined with orbital angular momentum (OAM), it enables a high-dimensional Hilbert space, which is essential for high-capacity quantum communication. In this study, we demonstrate the recognition of OAM Bell states using interference patterns generated by a classical light source and a single-photon source from a Sagnac interferometer-based OAM Bell state evolution device. The interference patterns exhibit a one-to-one correspondence with the input Bell states, providing conclusive evidence for the full recognition of OAM Bell states. Furthermore, we introduce machine learning to the field of Bell state recognition by proposing a neural network model capable of accurately recognizing higher order single-photon OAM Bell states, even in the undersampling case. In particular, the model’s training set includes interference patterns of OAM Bell states generated by classical light sources, yet it is able to recognize single-photon OAM Bell states with high accuracy, without relying on quantum resources during training. Our innovative application of neural networks to the recognition of single-photon OAM Bell states not only circumvents the resource consumption and experimental difficulties associated with quantum light sources but also facilitates the study of OAM-based quantum information.",
           0,
           "apl_machine_learning"
          ],
          [
           "Analysis of VMM computation strategies to implement BNN applications on RRAM arrays",
           "10.1063/5.0139583",
           2023,
           "The growing interest in edge-AI solutions and advances in the field of quantized neural networks have led to hardware efficient binary neural networks (BNNs). Extreme BNNs utilize only binary weights and activations, making them more memory efficient. Such networks can be realized using exclusive-NOR (XNOR) gates and popcount circuits. The analog in-memory realization of BNNs utilizing emerging non-volatile memory devices has been widely explored recently. However, most realizations typically use 2T-2R synapses, resulting in sub-optimal area utilization. In this study, we investigate alternate computation mapping strategies to realize BNN using selectorless resistive random access memory arrays. A new differential computation scheme that shows a comparable performance with the well-established XNOR computation strategy is proposed. Through extensive experimental characterization, BNN implementation using a non-filamentary bipolar oxide-based random access memory device-based crossbar is demonstrated for two datasets: (i) experimental characterization was performed on a thermal-image based Rock-Paper-Scissors dataset to analyze the impact of sneak-paths with real-hardware experiments. (ii) Large-scale BNN simulations on the Fashion-MNIST dataset with multi-level cell characteristics of non-filamentary devices are performed to demonstrate the impact of device non-idealities.",
           0,
           "apl_machine_learning"
          ],
          [
           "Noise tailoring, noise annealing, and external perturbation injection strategies in memristive Hopfield neural networks",
           "10.1063/5.0173662",
           2024,
           "The commercial introduction of a novel electronic device is often preceded by a lengthy material optimization phase devoted to the suppression of device noise as much as possible. The emergence of novel computing architectures, however, triggers a paradigm shift in noise engineering, demonstrating that non-suppressed but properly tailored noise can be harvested as a computational resource in probabilistic computing schemes. Such a strategy was recently realized on the hardware level in memristive Hopfield neural networks, delivering fast and highly energy efficient optimization performance. Inspired by these achievements, we perform a thorough analysis of simulated memristive Hopfield neural networks relying on realistic noise characteristics acquired on various memristive devices. These characteristics highlight the possibility of orders of magnitude variations in the noise level depending on the material choice as well as on the resistance state (and the corresponding active region volume) of the devices. Our simulations separate the effects of various device non-idealities on the operation of the Hopfield neural network by investigating the role of the programming accuracy as well as the noise-type and noise amplitude of the ON and OFF states. Relying on these results, we propose optimized noise tailoring and noise annealing strategies, comparing the impact of internal noise to the effect of external perturbation injection schemes.",
           0,
           "apl_machine_learning"
          ],
          [
           "Machine learning based hybrid ensemble models for prediction of organic dyes photophysical properties: Absorption wavelengths, emission wavelengths, and quantum yields",
           "10.1063/5.0181294",
           2024,
           "Fluorescent organic dyes are extensively used in the design and discovery of new materials, photovoltaic cells, light sensors, imaging applications, medicinal chemistry, drug design, energy harvesting technologies, dye and pigment industries, and pharmaceutical industries, among other things. However, designing and synthesizing new fluorescent organic dyes with desirable properties for specific applications requires knowledge of the chemical and physical properties of previously studied molecules. It is a difficult task for experimentalists to identify the photophysical properties of the required chemical molecule at negligible time and financial cost. For this purpose, machine learning-based models are a highly demanding technique for estimating photophysical properties and may be an alternative approach to density functional theory. In this study, we used 15 single models and proposed three different hybrid models to assess a dataset of 3066 organic materials for predicting photophysical properties. The performance of these models was evaluated using three evaluation parameters: mean absolute error, root mean squared error, and the coefficient of determination (R2) on the test-size data. All the proposed hybrid models achieved the highest accuracy (R2) of 97.28%, 95.19%, and 74.01% for predicting the absorption wavelengths, emission wavelengths, and quantum yields, respectively. These resultant outcomes of the proposed hybrid models are ∼1.9%, ∼2.7%, and ∼2.4% higher than the recently reported best models’ values in the same dataset for absorption wavelengths, emission wavelengths, and quantum yields, respectively. This research promotes the quick and accurate production of new fluorescent organic dyes with desirable photophysical properties for specific applications.",
           0,
           "apl_machine_learning"
          ],
          [
           "A physics-based predictive model for pulse design to realize high-performance memristive neural networks",
           "10.1063/5.0180346",
           2023,
           "Memristive neural networks have extensively been investigated for their capability in handling various artificial intelligence tasks. The training performance of memristive neural networks depends on the pulse scheme applied to the constituent memristors. However, the design of the pulse scheme in most previous studies was approached in an empirical manner or through a trial-and-error method. Here, we choose ferroelectric tunnel junction (FTJ) as a model memristor and demonstrate a physics-based predictive model for the pulse design to achieve high training performance. This predictive model comprises a physical model for FTJ that can adequately describe the polarization switching and memristive switching behaviors of the FTJ and an FTJ-based neural network that uses the long-term potentiation (LTP)/long-term depression (LTD) characteristics of the FTJ for the weight update. Simulation results based on the predictive model demonstrate that the LTP/LTD characteristics with a good trade-off between ON/OFF ratio, nonlinearity, and asymmetry can lead to high training accuracies for the FTJ-based neural network. Moreover, it is revealed that an amplitude-increasing pulse scheme may be the most favorable pulse scheme as it offers the widest ranges of pulse amplitudes and widths for achieving high accuracies. This study may provide useful guidance for the pulse design in the experimental development of high-performance memristive neural networks.",
           1,
           "apl_machine_learning"
          ],
          [
           "Accelerating defect predictions in semiconductors using graph neural networks",
           "10.1063/5.0176333",
           2024,
           "First-principles computations reliably predict the energetics of point defects in semiconductors but are constrained by the expense of using large supercells and advanced levels of theory. Machine learning models trained on computational data, especially ones that sufficiently encode defect coordination environments, can be used to accelerate defect predictions. Here, we develop a framework for the prediction and screening of native defects and functional impurities in a chemical space of group IV, III–V, and II–VI zinc blende semiconductors, powered by crystal Graph-based Neural Networks (GNNs) trained on high-throughput density functional theory (DFT) data. Using an innovative approach of sampling partially optimized defect configurations from DFT calculations, we generate one of the largest computational defect datasets to date, containing many types of vacancies, self-interstitials, anti-site substitutions, impurity interstitials and substitutions, as well as some defect complexes. We applied three types of established GNN techniques, namely crystal graph convolutional neural network, materials graph network, and Atomistic Line Graph Neural Network (ALIGNN), to rigorously train models for predicting defect formation energy (DFE) in multiple charge states and chemical potential conditions. We find that ALIGNN yields the best DFE predictions with root mean square errors around 0.3 eV, which represents a prediction accuracy of 98% given the range of values within the dataset, improving significantly on the state-of-the-art. We further show that GNN-based defective structure optimization can take us close to DFT-optimized geometries at a fraction of the cost of full DFT. The current models are based on the semi-local generalized gradient approximation-Perdew–Burke–Ernzerhof (PBE) functional but are highly promising because of the correlation of computed energetics and defect levels with higher levels of theory and experimental data, the accuracy and necessity of discovering novel metastable and low energy defect structures at the PBE level of theory before advanced methods could be applied, and the ability to train multi-fidelity models in the future with new data from non-local functionals. The DFT-GNN models enable prediction and screening across thousands of hypothetical defects based on both unoptimized and partially optimized defective structures, helping identify electronically active defects in technologically important semiconductors.",
           0,
           "apl_machine_learning"
          ],
          [
           "Deep learning-enabled probing of irradiation-induced defects in time-series micrographs",
           "10.1063/5.0186046",
           2024,
           "Modeling time-series data with convolutional neural networks (CNNs) requires building a model to learn in batches as opposed to training sequentially. Coupling CNNs with in situ or operando techniques opens the possibility of accurately segmenting dynamic reactions and mass transport phenomena to understand how materials behave under the conditions in which they are used. In this article, in situ ion irradiation transmission electron microscopy (TEM) images are used as inputs into the CNN to assess the defect generation rate, defect cluster density, and saturation of defects. We then use the output segmentation maps to correlate with conventional TEM micrographs to assess the model’s ability to detail nanoscale interactions. Next, we discuss the implications of preprocessing and hyperparameters on model variability, accuracy when expanded to other datasets, and the role of regularization when controlling model variance. Ultimately, we eliminate human bias when extrapolating physical metrics, speed up analysis time, decouple reactions that happen at 100 ms intervals, and deploy models that are both accurate and transferable to similar experiments.",
           0,
           "apl_machine_learning"
          ],
          [
           "Discovery of structure–property relations for molecules via hypothesis-driven active learning over the chemical space",
           "10.1063/5.0157644",
           2023,
           "The discovery of the molecular candidates for application in drug targets, biomolecular systems, catalysts, photovoltaics, organic electronics, and batteries necessitates the development of machine learning algorithms capable of rapid exploration of chemical spaces targeting the desired functionalities. Here, we introduce a novel approach for active learning over the chemical spaces based on hypothesis learning. We construct the hypotheses on the possible relationships between structures and functionalities of interest based on a small subset of data followed by introducing them as (probabilistic) mean functions for the Gaussian process. This approach combines the elements from the symbolic regression methods, such as SISSO and active learning, into a single framework. The primary focus of constructing this framework is to approximate physical laws in an active learning regime toward a more robust predictive performance, as traditional evaluation on hold-out sets in machine learning does not account for out-of-distribution effects which may lead to a complete failure on unseen chemical space. Here, we demonstrate it for the QM9 dataset, but it can be applied more broadly to datasets from both domains of molecular and solid-state materials sciences.",
           2,
           "apl_machine_learning"
          ],
          [
           "Deep language models for interpretative and predictive materials science",
           "10.1063/5.0134317",
           2023,
           "Machine learning (ML) has emerged as an indispensable methodology to describe, discover, and predict complex physical phenomena that efficiently help us learn underlying functional rules, especially in cases when conventional modeling approaches cannot be applied. While conventional feedforward neural networks are typically limited to performing tasks related to static patterns in data, recursive models can both work iteratively based on a changing input and discover complex dynamical relationships in the data. Deep language models can model flexible modalities of data and are capable of learning rich dynamical behaviors as they operate on discrete or continuous symbols that define the states of a physical system, yielding great potential toward end-to-end predictions. Similar to how words form a sentence, materials can be considered as a self-assembly of physically interacted building blocks, where the emerging functions of materials are analogous to the meaning of sentences. While discovering the fundamental relationships between building blocks and function emergence can be challenging, language models, such as recurrent neural networks and long-short term memory networks, and, in particular, attention models, such as the transformer architecture, can solve many such complex problems. Application areas of such models include protein folding, molecular property prediction, prediction of material failure of complex nonlinear architected materials, and also generative strategies for materials discovery. We outline challenges and opportunities, especially focusing on extending the deep-rooted kinship of humans with symbolism toward generalizable artificial intelligence (AI) systems using neuro-symbolic AI, and outline how tools such as ChatGPT and DALL·E can drive materials discovery.",
           24,
           "apl_machine_learning"
          ],
          [
           "Stoichiometric growth of SrTiO3 films via Bayesian optimization with adaptive prior mean",
           "10.1063/5.0132768",
           2023,
           "Perovskite insulator SrTiO3 (STO) is expected to be applied to the next generation of electronic and photonic devices as high-k capacitors and photocatalysts. However, reproducible growth of highly insulating stoichiometric (STO) films remains challenging due to the difficulty of precise stoichiometry control in perovskite oxide films. Here, to grow stoichiometric (STO) thin films by fine-tuning multiple growth conditions, we developed a new Bayesian optimization (BO)-based machine learning method that encourages exploration of the search space by varying the prior mean to get out of suboptimal growth condition parameters. Using simulated data, we demonstrate the efficacy of the new BO method, which reproducibly reaches the global best conditions. With the BO method implemented in machine-learning-assisted molecular beam epitaxy (ML-MBE), a highly insulating stoichiometric (STO) film with no absorption in the bandgap was developed in only 44 MBE growth runs. The proposed algorithm provides an efficient experimental design platform that is not as dependent on the experience of individual researchers and will accelerate not only oxide electronics but also various material syntheses.",
           1,
           "apl_machine_learning"
          ],
          [
           "Hyena neural operator for partial differential equations",
           "10.1063/5.0177276",
           2023,
           "Numerically solving partial differential equations typically requires fine discretization to resolve necessary spatiotemporal scales, which can be computationally expensive. Recent advances in deep learning have provided a new approach to solving partial differential equations that involves the use of neural operators. Neural operators are neural network architectures that learn mappings between function spaces and have the capability to solve partial differential equations based on data. This study utilizes a novel neural operator called Hyena, which employs a long convolutional filter that is parameterized by a multilayer perceptron. The Hyena operator is an operation that enjoys sub-quadratic complexity and enjoys a global receptive field at the meantime. This mechanism enhances the model’s comprehension of the input’s context and enables data-dependent weight for different partial differential equation instances. To measure how effective the layers are in solving partial differential equations, we conduct experiments on the diffusion–reaction equation and Navier–Stokes equation and compare it with the Fourier neural operator. Our findings indicate that the Hyena neural operator can serve as an efficient and accurate model for learning the partial differential equation solution operator. The data and code used can be found at https://github.com/Saupatil07/Hyena-Neural-Operator.",
           0,
           "apl_machine_learning"
          ],
          [
           "AnalogVNN: A fully modular framework for modeling and optimizing photonic neural networks",
           "10.1063/5.0134156",
           2023,
           "In this paper, we present AnalogVNN, a simulation framework built on PyTorch that can simulate the effects of optoelectronic noise, limited precision, and signal normalization present in photonic neural network accelerators. We use this framework to train and optimize linear and convolutional neural networks with up to nine layers and ∼1.7 × 106 parameters, while gaining insights into how normalization, activation function, reduced precision, and noise influence accuracy in analog photonic neural networks. By following the same layer structure design present in PyTorch, the AnalogVNN framework allows users to convert most digital neural network models to their analog counterparts with just a few lines of code, taking full advantage of the open-source optimization, deep learning, and GPU acceleration libraries available through PyTorch.",
           0,
           "apl_machine_learning"
          ],
          [
           "Automatic identification of edge localized modes in the DIII-D tokamak",
           "10.1063/5.0134001",
           2023,
           "Fusion power production in tokamaks uses discharge configurations that risk producing strong type I edge localized modes. The largest of these modes will likely increase impurities in the plasma and potentially damage plasma facing components, such as the protective heat and particle divertor. Machine learning-based prediction and control may provide for the automatic detection and mitigation of these damaging modes before they grow too large to suppress. To that end, large labeled datasets are required for the supervised training of machine learning models. We present an algorithm that achieves 97.7% precision when automatically labeling edge localized modes in the large DIII-D tokamak discharge database. The algorithm has no user controlled parameters and is largely robust to tokamak and plasma configuration changes. This automatically labeled database of events can subsequently feed future training of machine learning models aimed at autonomous edge localized mode control and suppression.",
           0,
           "apl_machine_learning"
          ],
          [
           "High-speed CMOS-free purely spintronic asynchronous recurrent neural network",
           "10.1063/5.0129006",
           2023,
           "The exceptional capabilities of the human brain provide inspiration for artificially intelligent hardware that mimics both the function and the structure of neurobiology. In particular, the recent development of nanodevices with biomimetic characteristics promises to enable the development of neuromorphic architectures with exceptional computational efficiency. In this work, we propose biomimetic neurons comprised of domain wall-magnetic tunnel junctions that can be integrated into the first trainable CMOS-free recurrent neural network with biomimetic components. This paper demonstrates the computational effectiveness of this system for benchmark tasks and its superior computational efficiency relative to alternative approaches for recurrent neural networks.",
           1,
           "apl_machine_learning"
          ],
          [
           "Long-term forecasts of residential energy profiles based on Conv2D and LSTM models (electricity- and gas-based households)",
           "10.1063/5.0137443",
           2023,
           "For power system operation and expansion of grid-import systems, an accurate forecast model plays an essential role in the better management of household electricity demands. With the aim of finding an accurate forecast model in the proper representation of various household energy profiles, our research objective is centered on the development of a reliable forecast system for a group of 24-household energy consumers. In this energy study, we proposed long-term forecasts of (1) residential energy profiles within the multi-classification framework and (2) energy costing of the household demands using the Keras two-dimensional convolutional neural network (Conv2D) model and long short-term memory (LSTM) models. These high-level Keras neural networks are built to extract multivariate features for household energy consumption modeling and forecasting. The proposed forecast systems utilized a similar model hyperparameter configuration, while the forecast skills are validated with spatial–temporal variation datasets of ten remote locations. The actual costs of household demand and supply are estimated and compared with Conv2D predictions. The finding results (hourly and seasonal predictions and model evaluation) revealed that Conv2D and LSTM forecast systems are promising for household energy forecast solutions. Experimental results of the Conv2D predictive system achieved better forecast skills [correlation coefficient (0.727–0.994) and root mean square error (0.190–0.868)] than LSTM forecasts (0.308–0.987 and 0.278–1.212). However, experimental findings revealed that forecast skills of the predictive systems in residential energy demand predictions are highly influenced by the (1) quality of input datasets, (2) model hyperparameter tuning approach, and (3) learning rate of selected network optimizer(s).",
           0,
           "apl_machine_learning"
          ],
          [
           "A deep learning approach for gas sensor data regression: Incorporating surface state model and GRU-based model",
           "10.1063/5.0160983",
           2024,
           "Metal–oxide–semiconductor (MOS) gas sensors are widely used for gas detection and monitoring. However, MOS gas sensors have always suffered from instability in the link between gas sensor data and the measured gas concentration. In this paper, we propose a novel deep learning approach that combines the surface state model and a Gated Recurrent Unit (GRU)-based regression to enhance the analysis of gas sensor data. The surface state model provides valuable insights into the microscopic surface processes underlying the conductivity response to pulse heating, while the GRU model effectively captures the temporal dependencies present in time-series data. The experimental results demonstrate that the theory guided model GRU+β outperforms the elementary GRU algorithm in terms of accuracy and astringent speed. The incorporation of the surface state model and the parameter rate enhances the model’s accuracy and provides valuable information for learning pulse-heated regression tasks with better generalization. This research exhibits superiority of integrating domain knowledge and deep learning techniques in the field of gas sensor data analysis. The proposed approach offers a practical framework for improving the understanding and prediction of gas concentrations, facilitating better decision-making in various practical applications.",
           0,
           "apl_machine_learning"
          ],
          [
           "Pulse-stream impact on recognition accuracy of reservoir computing from SiO2-based low power memory devices",
           "10.1063/5.0131524",
           2023,
           "Reservoir computing (RC)-based neuromorphic applications exhibit extremely low power consumption, thus challenging the use of deep neural networks in terms of both consumption requirements and integration density. Under this perspective, this work focuses on the basic principles of RC systems. The ability of self-selective conductive-bridging random access memory devices to operate in two modes, namely, volatile and non-volatile, by regulating the applied voltage is first presented. We then investigate the relaxation time of these devices as a function of the applied amplitude and pulse duration, a critical step in determining the desired non-linearity by the reservoir. Moreover, we present an in-depth study of the impact of selecting the appropriate pulse-stream and its final effects on the total power consumption and recognition accuracy in a handwritten digit recognition application from the National Institute of Standards and Technology dataset. Finally, we conclude at the optimal pulse-stream of 3-bit, through the minimization of two cost criteria, with the total power remaining at 287 µW and simultaneously achieving 82.58% recognition accuracy upon the test set.",
           1,
           "apl_machine_learning"
          ],
          [
           "VERI-D: A new dataset and method for multi-camera vehicle re-identification of damaged cars under varying lighting conditions",
           "10.1063/5.0183408",
           2024,
           "Vehicle re-identification (V-ReID) is a critical task that aims to match the same vehicle across images from different camera viewpoints. The previous studies have leveraged attribute clues, such as color, model, and license plate, to enhance the V-ReID performance. However, these methods often lack effective interaction between the global–local features and the final V-ReID objective. Moreover, they do not address the challenging issues in real-world scenarios, such as high viewpoint variations, extreme illumination conditions, and car appearance changes (e.g., due to damage or wrong driving). We propose a novel framework to tackle these problems and advance the research in V-ReID, which can handle various types of car appearance changes and achieve robust V-ReID under varying lighting conditions. Our main contributions are as follows: (i) we propose a new Re-ID architecture named global–local self-attention network, which integrates local information into the feature learning process and enhances the feature representation for V-ReID and (ii) we introduce a novel damaged vehicle Re-ID dataset called VERI-D, which is the first publicly available dataset that focuses on this challenging yet practical scenario. The dataset contains both natural and synthetic images of damaged vehicles captured from multiple camera viewpoints and under different lighting conditions. (iii) We conduct extensive experiments on the VERI-D dataset and demonstrate the effectiveness of our approach in addressing the challenges associated with damaged vehicle re-identification. We also compare our method to several state-of-the-art V-ReID methods and show its superiority.",
           0,
           "apl_machine_learning"
          ],
          [
           "Impact of analog memory device failure on in-memory computing inference accuracy",
           "10.1063/5.0131797",
           2023,
           "In-memory computing using analog non-volatile memory (NVM) devices can improve the speed and reduce the latency of deep neural network (DNN) inference. It has been recently shown that neuromorphic crossbar arrays, where each weight is implemented using analog conductance values of phase-change memory devices, achieve competitive accuracy and high power efficiency. However, due to the large amount of NVMs needed and the challenge for making analog NVM devices, these chips typically include some failed devices from fabrication or developed over time. We study the impact of these failed devices on the analog in-memory computing accuracy for various networks. We show that larger networks with fewer reused layers are more tolerable to failed devices. Devices stuck at high resistance states are more tolerable than devices stuck at low resistance states. To improve the robustness of DNNs to defective devices, we develop training methods that add noise and corrupt devices in the weight matrices during network training and show that this can increase the network accuracy in the presence of the failed devices. We also provide estimated maximum defective device tolerance of some common networks.",
           1,
           "apl_machine_learning"
          ],
          [
           "Rotationally equivariant super-resolution of velocity fields in two-dimensional flows using convolutional neural networks",
           "10.1063/5.0132326",
           2023,
           "This paper investigates the super-resolution of velocity fields in two-dimensional flows from the viewpoint of rotational equivariance. Super-resolution refers to techniques that enhance the resolution of an image from low to high resolution, and it has recently been applied in fluid mechanics. Rotational equivariance of super-resolution models is defined as the property by which the super-resolved velocity field is rotated according to a rotation of the input, leading to inferences that are covariant with the orientation of fluid systems. In physics, covariance is often related to symmetries. To better understand the connection with symmetries, the notion of rotational consistency of datasets is introduced within the framework of supervised learning, which is defined as the invariance of pairs of low- and high-resolution velocity fields with respect to rotation. This consistency is sufficient and necessary for super-resolution models to learn rotational equivariance from large datasets. Such a large dataset is not required when rotational equivariance is imposed on super-resolution models through the use of prior knowledge in the form of equivariant kernel patterns. Nonetheless, even if a fluid system has rotational symmetry, this symmetry may not carry over to a velocity dataset, which is not rotationally consistent. This inconsistency can arise when the rotation does not commute with the generation of low-resolution velocity fields. These theoretical assertions are supported by the results of numerical experiments, where two existing convolutional neural networks (CNNs) are converted into rotationally equivariant CNNs and the inferences of these CNNs are compared after the supervised training.",
           1,
           "apl_machine_learning"
          ],
          [
           "A unifying perspective on non-stationary kernels for deeper Gaussian processes",
           "10.1063/5.0176963",
           2024,
           "The Gaussian process (GP) is a popular statistical technique for stochastic function approximation and uncertainty quantification from data. GPs have been adopted into the realm of machine learning (ML) in the last two decades because of their superior prediction abilities, especially in data-sparse scenarios, and their inherent ability to provide robust uncertainty estimates. Even so, their performance highly depends on intricate customizations of the core methodology, which often leads to dissatisfaction among practitioners when standard setups and off-the-shelf software tools are being deployed. Arguably, the most important building block of a GP is the kernel function, which assumes the role of a covariance operator. Stationary kernels of the Matérn class are used in the vast majority of applied studies; poor prediction performance and unrealistic uncertainty quantification are often the consequences. Non-stationary kernels show improved performance but are rarely used due to their more complicated functional form and the associated effort and expertise needed to define and tune them optimally. In this perspective, we want to help ML practitioners make sense of some of the most common forms of non-stationarity for Gaussian processes. We show a variety of kernels in action using representative datasets, carefully study their properties, and compare their performances. Based on our findings, we propose a new kernel that combines some of the identified advantages of existing kernels.",
           0,
           "apl_machine_learning"
          ],
          [
           "Bring memristive in-memory computing into general-purpose machine learning: A perspective",
           "10.1063/5.0167743",
           2023,
           "In-memory computing (IMC) using emerging nonvolatile devices has received considerable attention due to its great potential for accelerating artificial neural networks and machine learning tasks. As the basic concept and operation modes of IMC are now well established, there is growing interest in employing its wide and general application. In this perspective, the path that leads memristive IMC to general-purpose machine learning is discussed in detail. First, we reviewed the development timeline of machine learning algorithms that employ memristive devices, such as resistive random-access memory and phase-change memory. Then we summarized two typical aspects of realizing IMC-based general-purpose machine learning. One involves a heterogeneous computing system for algorithmic completeness. The other is to obtain the configurable precision techniques for the compromise of the precision-efficiency dilemma. Finally, the major directions and challenges of memristive IMC-based general-purpose machine learning are proposed from a cross-level design perspective.",
           1,
           "apl_machine_learning"
          ],
          [
           "Deep ensemble inverse model for image-based estimation of solar cell parameters",
           "10.1063/5.0139707",
           2023,
           "Physical models can help improve solar cell efficiency during the design phase and for quality control after the fabrication process. We present a data-driven approach to inverse modeling that can predict the underlying parameters of a finite element method solar cell model based on an electroluminescence (EL) image of a solar cell with known cell geometry and laser scribed defects. For training the inverse model, 75 000 synthetic EL images were generated with randomized parameters of the physical cell model. We combine 17 deep convolutional neural networks based on a modified VGG19 architecture into a deep ensemble to add uncertainty estimates. Using the silicon solar cell model, we show that such a novel approach to data-driven statistical inverse modeling can help apply recent developments in deep learning to new engineering applications that require real-time parameterizations of physical models augmented by confidence intervals. The trained network was tested on four different physical solar cell samples, and the estimated parameters were used to create the corresponding model representations. Resimulations of the measurements yielded relative deviations of the calculated and the measured junction voltage values of 0.2% on average with a maximum of 10%, demonstrating the validity of the approach.",
           1,
           "apl_machine_learning"
          ],
          [
           "Study of the adsorption sites of high entropy alloys for CO2 reduction using graph convolutional network",
           "10.1063/5.0198043",
           2024,
           "Carbon dioxide reduction is a major step toward building a cleaner and safer environment. There is a surge of interest in exploring high-entropy alloys (HEAs) as active catalysts for CO2 reduction; however, so far, it is mainly limited to quinary HEAs. Inspired by the successful synthesis of octonary and denary HEAs, herein, the CO2 reduction reaction (CO2RR) performance of an HEA composed of Ag, Au, Cu, Pd, Pt, Co, Ga, Ni, and Zn is studied by developing a high-fidelity graph neural network (GNN) framework. Within this framework, the adsorption site geometry and physics are employed through the featurization of elements. Particularly, featurization is performed using various intrinsic properties, such as electronegativity and atomic radius, to enable not only the supervised learning of CO2RR performance descriptors, namely, CO and H adsorption energies, but also the learning of adsorption physics and generalization to unseen metals and alloys. The developed model evaluates the adsorption strength of ∼3.5 and ∼0.4 billion possible sites for CO and H, respectively. Despite the enormous space of the AgAuCuPdPtCoGaNiZn alloy and the rather small size of the training data, the GNN framework demonstrated high accuracy and good robustness. This study paves the way for the rapid screening and intelligent synthesis of CO2RR-active and selective HEAs.",
           0,
           "apl_machine_learning"
          ],
          [
           "Learning thermodynamically constrained equations of state with uncertainty",
           "10.1063/5.0165298",
           2024,
           "Numerical simulations of high energy-density experiments require equation of state (EOS) models that relate a material’s thermodynamic state variables—specifically pressure, volume/density, energy, and temperature. EOS models are typically constructed using a semi-empirical parametric methodology, which assumes a physics-informed functional form with many tunable parameters calibrated using experimental/simulation data. Since there are inherent uncertainties in the calibration data (parametric uncertainty) and the assumed functional EOS form (model uncertainty), it is essential to perform uncertainty quantification (UQ) to improve confidence in EOS predictions. Model uncertainty is challenging for UQ studies since it requires exploring the space of all possible physically consistent functional forms. Thus, it is often neglected in favor of parametric uncertainty, which is easier to quantify without violating thermodynamic laws. This work presents a data-driven machine learning approach to constructing EOS models that naturally captures model uncertainty while satisfying the necessary thermodynamic consistency and stability constraints. We propose a novel framework based on physics-informed Gaussian process regression (GPR) that automatically captures total uncertainty in the EOS and can be jointly trained on both simulation and experimental data sources. A GPR model for the shock Hugoniot is derived, and its uncertainties are quantified using the proposed framework. We apply the proposed model to learn the EOS for the diamond solid state of carbon using both density functional theory data and experimental shock Hugoniot data to train the model and show that the prediction uncertainty is reduced by considering thermodynamic constraints.",
           0,
           "apl_machine_learning"
          ],
          [
           "Accelerating the design and development of polymeric materials via deep learning: Current status and future challenges",
           "10.1063/5.0131067",
           2023,
           "The design and development of polymeric materials have been a hot domain for decades. However, traditional experiments and molecular simulations are time-consuming and labor-intensive, which no longer meet the requirements of new materials development. With the rapid advances of artificial intelligence and materials informatics, machine learning algorithms are increasingly applied in materials science, aiming to shorten the development period of new materials. With the evolution of polymeric materials, the structure of polymers has become more and more complex. Traditional machine learning algorithms often do not perform satisfactorily when dealing with complex data. Presently, deep learning algorithms, including deep neural networks, convolutional neural networks, generative adversarial networks, recurrent neural networks, and graph neural networks, show their uniquely excellent learning capabilities for large and complex data, which will be a powerful tool for the design and development of polymeric materials. This Review introduces principles of several currently popular deep learning algorithms and discusses their multiple applications in the materials field. Applications range from property prediction and molecular generation at the molecular level to structure identification and material synthesis in polymers. Finally, future challenges and opportunities for the application of deep learning in polymeric materials are discussed.",
           2,
           "apl_machine_learning"
          ],
          [
           "Simulation-free determination of microstructure representative volume element size via Fisher scores",
           "10.1063/5.0195232",
           2024,
           "A representative volume element (RVE) is a reasonably small unit of microstructure that can be simulated to obtain the same effective properties as the entire microstructure sample. Finite element (FE) simulation of RVEs, as opposed to much larger samples, saves computational expenses, especially in multiscale modeling. Therefore, it is desirable to have a framework that determines the RVE size prior to FE simulations. Existing methods select the RVE size based on when the FE-simulated properties of samples of increasing sizes converge with insignificant statistical variations, with the drawback being that many samples must be simulated. We propose a simulation-free alternative that determines the RVE size based only on a micrograph. The approach utilizes a machine learning model trained to implicitly characterize the stochastic nature of the input micrograph. The underlying rationale is to view RVE size as the smallest moving window size for which the stochastic nature of the microstructure within the window is stationary as the window moves across a large micrograph. For this purpose, we adapt a recently developed Fisher score-based framework for microstructure nonstationarity monitoring. Because the resulting RVE size is based solely on the micrograph and does not involve any FE simulation of specific properties, it constitutes an RVE for any property of interest that solely depends on the microstructure characteristics. Through numerical experiments of simple and complex microstructures, we validate our approach and show that our selected RVE sizes are consistent with when the chosen FE-simulated properties converge.",
           0,
           "apl_machine_learning"
          ],
          [
           "Deep learning of nonlinear flame fronts development due to Darrieus–Landau instability",
           "10.1063/5.0139857",
           2023,
           "The Darrieus–Landau instability is studied using a data-driven, deep neural network approach. The task is set up to learn a time-advancement operator mapping any given flame front to a future time. A recurrent application of such an operator rolls out a long sequence of predicted flame fronts, and a learned operator is required to not only make accurate short-term predictions but also reproduce characteristic nonlinear behavior, such as fractal front structures and detached flame pockets. Using two datasets of flame front solutions obtained from a heavy-duty direct numerical simulation and a light-duty modeling equation, we compare the performance of three state-of-art operator-regression network methods: convolutional neural networks, Fourier neural operator (FNO), and deep operator network. We show that, for learning complicated front evolution, FNO gives the best recurrent predictions in both the short and long term. A consistent extension allowing the operator-regression networks to handle complicated flame front shape is achieved by representing the latter as an implicit curve.",
           1,
           "apl_machine_learning"
          ],
          [
           "A machine learning framework for elastic constants predictions in multi-principal element alloys",
           "10.1063/5.0129928",
           2023,
           "On the one hand, multi-principal element alloys (MPEAs) have created a paradigm shift in alloy design due to large compositional space, whereas on the other, they have presented enormous computational challenges for theory-based materials design, especially density functional theory (DFT), which is inherently computationally expensive even for traditional dilute alloys. In this paper, we present a machine learning framework, namely PREDICT (PRedict properties from Existing Database In Complex alloys Territory), that opens a pathway to predict elastic constants in large compositional space with little computational expense. The framework only relies on the DFT database of binary alloys and predicts Voigt–Reuss–Hill Young’s modulus, shear modulus, bulk modulus, elastic constants, and Poisson’s ratio in MPEAs. We show that the key descriptors of elastic constants are the A–B bond length and cohesive energy. The framework can predict elastic constants in hypothetical compositions as long as the constituent elements are present in the database, thereby enabling property exploration in multi-compositional systems. We illustrate predictions in a FCC Ni-Cu-Au-Pd-Pt system.",
           9,
           "apl_machine_learning"
          ],
          [
           "Optimization of a quantum cascade laser cavity for single-spatial-mode operation via machine learning",
           "10.1063/5.0158204",
           2023,
           "Neural networks, trained with the ADAM algorithm followed by a globally convergent modification to Newton’s method, are developed to predict the threshold gain of the fundamental and first higher-order modes as functions of the refractive-index profile in a quantum cascade laser cavity. The networks are used to optimize the design of a refractive-index profile that provides essentially single-spatial-mode performance in a nominally multi-moded cavity by maximizing the threshold-gain differential between the modes. The use of neural networks allows the optimization to be performed in seconds, instead of days or weeks which would be required if Maxwell’s equations were repeatedly solved to obtain the threshold gains.",
           0,
           "apl_machine_learning"
          ],
          [
           "Asymmetric CycleGANs for inverse design of photonic metastructures",
           "10.1063/5.0159264",
           2023,
           "Using deep learning to develop nanophotonic structures has been an active field of research in recent years to reduce the time intensive iterative solutions found in finite-difference time-domain simulations. Existing work has primarily used a specific type of generative network: conditional deep convolutional generative adversarial networks. However, these networks have issues with producing clear optical structures in image files; for example, a large number of images show speckled noise, which often results in non-manufacturable structures. Here, we report the first use of cycle-consistent generative adversarial networks to design nanophotonic structures. This approach significantly reduces the amount of speckled noise present in generated geometric structures and allows shapes to have clear edges. We demonstrate that for a given input reflectance spectra, the system generates designs in the form of images, and a complementary network generates reflectance spectra if an image containing a shape is provided as an input. The results show a higher Frechet Inception Distance score than previous approaches, which indicates that the generated structures are of higher quality and are able to learn nonlinear relationships between both datasets. This method of designing nanophotonics provides alternative avenues for development that are more noise robust while still adhering to desired optical properties.",
           0,
           "apl_machine_learning"
          ],
          [
           "Robust design of semi-automated clustering models for 4D-STEM datasets",
           "10.1063/5.0130546",
           2023,
           "Materials discovery and design require characterizing material structures at the nanometer and sub-nanometer scale. Four-Dimensional Scanning Transmission Electron Microscopy (4D-STEM) resolves the crystal structure of materials, but many 4D-STEM data analysis pipelines are not suited for the identification of anomalous and unexpected structures. This work introduces improvements to the iterative Non-Negative Matrix Factorization (NMF) method by implementing consensus clustering for ensemble learning. We evaluate the performance of models during parameter tuning and find that consensus clustering improves performance in all cases and is able to recover specific grains missed by the best performing model in the ensemble. The methods introduced in this work can be applied broadly to materials characterization datasets to aid in the design of new materials.",
           0,
           "apl_machine_learning"
          ],
          [
           "DyFraNet: Forecasting and backcasting dynamic fracture mechanics in space and time using a 2D-to-3D deep neural network",
           "10.1063/5.0135015",
           2023,
           "The dynamics of material failure is a critical phenomenon relevant to a range of scientific and engineering fields, from healthcare to structural materials. We propose a specially designed deep neural network, DyFraNet, which can predict dynamic fracture behaviors by identifying a complete history of fracture propagation—from the onset of cracking, as a crack grows through the material, modeled as a series of frames evolving over time and dependent on each other. Furthermore, the model can not only forecast future fracture processes but also backcast to elucidate past fracture histories. In this scenario, once provided with the outcome of a fracture event, the model will reveal past events that led to this state and can also predict future evolutions of the failure process. By comparing the predicted results with atomistic-level simulations and theory, we show that DyFraNet can capture dynamic fracture mechanics by accurately predicting how cracks develop over time, including measures such as the crack speed, as well as when cracks become unstable. We use Gradient-weighted Class Activation Mapping, Grad-CAM, to interpret how DyFraNet perceives the relationship between geometric conditions and fracture dynamics, and we find that DyFraNet pays special attention to the areas around crack tips that have a critical influence in the early stage of fracture propagation. In later stages, the model pays increased attention to the existing or newly formed damaged regions in the material. The proposed approach offers the potential to accelerate the exploration of dynamical processes in material design against failure and can be adapted for all kinds of dynamical problems.",
           5,
           "apl_machine_learning"
          ],
          [
           "Scalable wavelength-multiplexing photonic reservoir computing",
           "10.1063/5.0158939",
           2023,
           "Photonic reservoir computing (PRC) is a special hardware recurrent neural network, which is featured with fast training speed and low training cost. This work shows a wavelength-multiplexing PRC architecture, taking advantage of the numerous longitudinal modes in a Fabry–Perot (FP) semiconductor laser. These modes construct connected physical neurons in parallel, while an optical feedback loop provides interactive virtual neurons in series. We experimentally demonstrate a four-channel wavelength-multiplexing PRC architecture with a total of 80 neurons. The clock rate of the multiplexing PRC reaches as high as 1.0 GHz, which is four times higher than that of the single-channel case. In addition, it is proved that the multiplexing PRC exhibits a superior performance on the task of signal equalization in an optical fiber communication link. This improved performance is owing to the rich neuron interconnections both in parallel and in series. In particular, this scheme is highly scalable owing to the rich mode resources in FP lasers.",
           4,
           "apl_machine_learning"
          ],
          [
           "Completeness of atomic structure representations",
           "10.1063/5.0160740",
           2024,
           "In this paper, we address the challenge of obtaining a comprehensive and symmetric representation of point particle groups, such as atoms in a molecule, which is crucial in physics and theoretical chemistry. The problem has become even more important with the widespread adoption of machine-learning techniques in science, as it underpins the capacity of models to accurately reproduce physical relationships while being consistent with fundamental symmetries and conservation laws. However, some of the descriptors that are commonly used to represent point clouds— notably those based on discretized correlations of the neighbor density that power most of the existing ML models of matter at the atomic scale—are unable to distinguish between special arrangements of particles in three dimensions. This makes it impossible to machine learn their properties. Atom-density correlations are provably complete in the limit in which they simultaneously describe the mutual relationship between all atoms, which is impractical. We present a novel approach to construct descriptors of finite correlations based on the relative arrangement of particle triplets, which can be employed to create symmetry-adapted models with universal approximation capabilities, and have the resolution of the neighbor discretization as the sole convergence parameter. Our strategy is demonstrated on a class of atomic arrangements that are specifically built to defy a broad class of conventional symmetric descriptors, showing its potential for addressing their limitations.",
           0,
           "apl_machine_learning"
          ],
          [
           "A machine learning-based prediction of crystal orientations for multicrystalline materials",
           "10.1063/5.0138099",
           2023,
           "We established a rapid, low-cost, and accurate technique to measure crystallographic orientations in multicrystalline materials by optical images and machine learning. A long short-term memory neural network was trained with pairs of light reflection patterns and the correct orientations of each grain, successfully predicting orientation with an error median of 8.61°. The model was improved by diverse data taken from various incident light angles and by data augmentation. When trained on different incident angles, the model was capable of estimating different orientations. This is related to the geometrical configuration of the incident light angles and surface facets of the crystal. The failure in certain orientations is thought to be complemented by supplementary data taken from different incident angles. Combining data from multiple incident angles, we acquired an error median of 4.35°. Data augmentation was successfully performed, reducing error by an additional 35%. This technique can provide the crystallographic orientations of a 15 × 15 cm2 sized wafer in less than 8 min, while baseline techniques such as electron backscatter diffraction and Laue scanner may take more than 10 h. The rapid and accurate measurement can accelerate data collection for full-sized ingots, helping us gain a comprehensive understanding of crystal growth. We believe that our technique will contribute to controlling crystalline structure for the fabrication of high-performance materials.",
           2,
           "apl_machine_learning"
          ],
          [
           "Materials cartography: A forward-looking perspective on materials representation and devising better maps",
           "10.1063/5.0149804",
           2023,
           "Machine learning (ML) is gaining popularity as a tool for materials scientists to accelerate computation, automate data analysis, and predict materials properties. The representation of input material features is critical to the accuracy, interpretability, and generalizability of data-driven models for scientific research. In this Perspective, we discuss a few central challenges faced by ML practitioners in developing meaningful representations, including handling the complexity of real-world industry-relevant materials, combining theory and experimental data sources, and describing scientific phenomena across timescales and length scales. We present several promising directions for future research: devising representations of varied experimental conditions and observations, the need to find ways to integrate machine learning into laboratory practices, and making multi-scale informatics toolkits to bridge the gaps between atoms, materials, and devices.",
           2,
           "apl_machine_learning"
          ],
          [
           "Computational synthesis of a new generation of 2D-based perovskite quantum materials",
           "10.1063/5.0189497",
           2024,
           "Perovskite-based optoelectronic devices have emerged as a promising energy source due to their potential for scalable production. This study introduces “perovskene,” a novel class of 2D materials derived from the ABC3-like perovskites, synthesized via a data-driven, high-throughput computational strategy. We harness machine learning and multitarget deep neural networks to systematically investigate the structure–property relations, paving the way for targeted material design and optimization in fields such as renewable energy, electronics, and catalysis. The characterization of over 1500 synthesized structures shows that more than 500 structures are stable, revealing properties such as ultra-low work function and large magnetic moment, underscoring the potential for advanced technological applications.",
           0,
           "apl_machine_learning"
          ],
          [
           "Machine learning guided optimal composition selection of niobium alloys for high temperature applications",
           "10.1063/5.0129528",
           2023,
           "Nickel- and cobalt-based superalloys are commonly used as turbine materials for high-temperature applications. However, their maximum operating temperature is limited to about 1100 °C. Therefore, to improve turbine efficiency, current research is focused on designing materials that can withstand higher temperatures. Niobium-based alloys can be considered as promising candidates because of their exceptional properties at elevated temperatures. The conventional approach to alloy design relies on phase diagrams and structure–property data of limited alloys and extrapolates this information into unexplored compositional space. In this work, we harness machine learning and provide an efficient design strategy for finding promising niobium-based alloy compositions with high yield and ultimate tensile strength. Unlike standard composition-based features, we use domain knowledge-based custom features and achieve higher prediction accuracy. We apply Bayesian optimization to screen out novel Nb-based quaternary and quinary alloy compositions and find these compositions have superior predicted strength over a range of temperatures. We develop a detailed design flow and include Python programming code, which could be helpful for accelerating alloy design in a limited alloy data regime.",
           5,
           "apl_machine_learning"
          ],
          [
           "Multivariate Gaussian process surrogates for predicting basic structural parameters of refractory non-dilute random alloys",
           "10.1063/5.0186045",
           2024,
           "Refractory non-dilute random alloys consist of two or more principal refractory metals with complex interactions that modify their basic structural properties such as lattice parameters and elastic constants. Atomistic simulations (ASs) are an effective method to compute such basic structural parameters. However, accurate predictions from ASs are computationally expensive due to the size and number of atomistic structures required. To reduce the computational burden, multivariate Gaussian process regression (MVGPR) is proposed as a surrogate model that only requires computing a small number of configurations for training. The elemental atom percentage in the hyper-spherical coordinates is demonstrated to be an effective feature for surrogate modeling. An additive approximation of the full MVGPR model is also proposed to further reduce computations. To improve surrogate accuracy, active learning is used to select a small number of alloys to simulate. Numerical studies based on AS data show the accuracy of the surrogate methodology and the additive approximation, as well as the effectiveness and robustness of the active learning for selecting new alloy designs to simulate.",
           0,
           "apl_machine_learning"
          ],
          [
           "Classification of multi-frequency RF signals by extreme learning, using magnetic tunnel junctions as neurons and synapses",
           "10.1063/5.0155447",
           2023,
           "Extracting information from radio-frequency (RF) signals using artificial neural networks at low energy cost is a critical need for a wide range of applications from radars to health. These RF inputs are composed of multiple frequencies. Here, we show that magnetic tunnel junctions can process analog RF inputs with multiple frequencies in parallel and perform synaptic operations. Using a backpropagation-free method called extreme learning, we classify noisy images encoded by RF signals, using experimental data from magnetic tunnel junctions functioning as both synapses and neurons. We achieve the same accuracy as an equivalent software neural network. These results are a key step for embedded RF artificial intelligence.",
           2,
           "apl_machine_learning"
          ],
          [
           "Label free identification of different cancer cells using deep learning-based image analysis",
           "10.1063/5.0141730",
           2023,
           "Cancer diagnostics is an important field of cancer recovery and survival with many expensive procedures needed to administer the correct treatment. Machine Learning (ML) approaches can help with the diagnostic prediction from circulating tumor cells in liquid biopsy or from a primary tumor in solid biopsy. After predicting the metastatic potential from a deep learning model, doctors in a clinical setting can administer a safe and correct treatment for a specific patient. This paper investigates the use of deep convolutional neural networks for predicting a specific cancer cell line as a tool for label free identification. Specifically, deep learning strategies for weight initialization and performance metrics are described, with transfer learning and the accuracy metric utilized in this work. The equipment used for prediction involves brightfield microscopy without the use of chemical labels, advanced instruments, or time-consuming biological techniques, giving an advantage over current diagnostic methods. In the procedure, three different binary datasets of well-known cancer cell lines were collected, each having a difference in metastatic potential. Two different classification models were adopted (EfficientNetV2 and ResNet-50) with the analysis given for each stage in the ML architecture. The training results for each model and dataset are provided and systematically compared. We found that the test set accuracy showed favorable performance for both ML models with EfficientNetV2 accuracy reaching up to 99%. These test results allowed EfficientNetV2 to outperform ResNet-50 at an average percent increase of 3.5% for each dataset. The high accuracy obtained from the predictions demonstrates that the system can be retrained on a large-scale clinical dataset.",
           0,
           "apl_machine_learning"
          ],
          [
           "Machine learning assisted interpretation of creep and fatigue life in titanium alloys",
           "10.1063/5.0129037",
           2023,
           "Making reliable predictions of the mechanical behavior of alloys with a prolonged service life is beneficial for many structural applications. In this work, we propose an interpretable machine learning (ML) approach to predict fatigue life cycles (Nf) and creep rupture life (tr) in titanium-based alloys. Chemical compositions, experimental parameters, and alloy processing conditions are employed as descriptors for the development of gradient boost regression models for log-scaled Nf and tr. The models are trained on an extensive experimental dataset, predicting log-scaled Nf and tr with a very small root mean squared error of 0.17 and 0.15, respectively. An intuitive interpretation of the ML models is carried out via SHapley Additive exPlanations (SHAP) to understand the complex interplay of various features with Nf and tr. The SHAP interpretation of the ML models reveals close agreement with the general creep equation and Wöhler curve of fatigue. The approach proposed in this study can accelerate the design of novel Ti-based alloys with desired properties.",
           1,
           "apl_machine_learning"
          ],
          [
           "Quantifying the impact of uninformative features on the performance of supervised classification and dimensionality reduction algorithms",
           "10.1063/5.0170229",
           2023,
           "Machine learning approaches have become critical tools in data mining and knowledge discovery, especially when attempting to uncover relationships in high-dimensional data. However, researchers have noticed that a large fraction of features in high-dimensional datasets are commonly uninformative (too noisy or irrelevant). Because optimal feature selection is an NP-hard task, it is essential to understand how uninformative features impact the performance of machine learning algorithms. Here, we conduct systematic experiments on algorithms from a wide range of taxonomy families using synthetic datasets with different numbers of uninformative features and different numbers of patterns to be learned. Upon visual inspection, we classify these algorithms into four groups with varying robustness against uninformative features. For the algorithms in three of the groups, we find that when the number of uninformative features exceeds the number of data instances per pattern to be learned, the algorithms fail to learn the patterns. Finally, we investigate whether increasing the distinguishability of patterns or adding training instances can mitigate the effect of uninformative features. Surprisingly, we find that uninformative features still cause algorithms to suffer big losses in performance, even when patterns should be easily distinguishable. Analyses of real-world data show that our conclusions hold beyond the synthetic datasets we study systematically.",
           0,
           "apl_machine_learning"
          ],
          [
           "A tutorial on the Bayesian statistical approach to inverse problems",
           "10.1063/5.0154773",
           2023,
           "Inverse problems are ubiquitous in science and engineering. Two categories of inverse problems concerning a physical system are (1) estimate parameters in a model of the system from observed input–output pairs and (2) given a model of the system, reconstruct the input to it that caused some observed output. Applied inverse problems are challenging because a solution may (i) not exist, (ii) not be unique, or (iii) be sensitive to measurement noise contaminating the data. Bayesian statistical inversion (BSI) is an approach to tackle ill-posed and/or ill-conditioned inverse problems. Advantageously, BSI provides a “solution” that (i) quantifies uncertainty by assigning a probability to each possible value of the unknown parameter/input and (ii) incorporates prior information and beliefs about the parameter/input. Herein, we provide a tutorial of BSI for inverse problems by way of illustrative examples dealing with heat transfer from ambient air to a cold lime fruit. First, we use BSI to infer a parameter in a dynamic model of the lime temperature from measurements of the lime temperature over time. Second, we use BSI to reconstruct the initial condition of the lime from a measurement of its temperature later in time. We demonstrate the incorporation of prior information, visualize the posterior distributions of the parameter/initial condition, and show posterior samples of lime temperature trajectories from the model. Our Tutorial aims to reach a wide range of scientists and engineers.",
           1,
           "apl_machine_learning"
          ],
          [
           "Spontaneous muscle activity classification with delay-based reservoir computing",
           "10.1063/5.0160927",
           2023,
           "Neuromuscular disorders (NMDs) affect various parts of a motor unit, such as the motor neuron, neuromuscular junction, and muscle fibers. Abnormal spontaneous activity (SA) is detected with electromyography (EMG) as an essential hallmark in diagnosing NMD, which causes fatigue, pain, and muscle weakness. Monitoring the effects of NMD calls for new smart devices to collect and classify EMG. Delay-based Reservoir Computing (DRC) is a neuromorphic algorithm with high efficiency in classifying sequential data. This work proposes a new DRC-based algorithm that provides a reference for medical education and training and a second opinion to clinicians to verify NMD diagnoses by detecting SA in muscles. With a sampling frequency of Fs = 64 kHz, we have classified SA with EMG signals of 1 s of muscle recordings. Furthermore, the DRC model of size N = 600 nodes has successfully detected SA signals against normal muscle activity with an accuracy of up to 90.7%. The potential of using neuromorphic processing approaches in point-of-care diagnostics, alongside the supervision of a clinician, provides a more comprehensive and reliable clinical profile. Our developed model benefits from the potential to be implemented in physical hardware to provide near-sensor edge computing.",
           0,
           "apl_machine_learning"
          ],
          [
           "Unsupervised machine learning to analyze corneal tissue surfaces",
           "10.1063/5.0159502",
           2023,
           "Identifying/classifying damage features on soft materials, such as tissues, is much more challenging than on classical, hard materials—but nevertheless important, especially in the field of bio-tribology. For instance, cartilage samples from osteoarthritic patients exhibit surface damage even at early stages of tissue degeneration, and corneal tissues can be damaged by contact lenses when the ocular lubrication system fails. Here, we employ unsupervised machine learning (ML) methods to assess the surface condition of a soft tissue by detecting and classifying different wear morphologies as well as the severity of surface damage they represent. We show that different clustering methods, especially a k-means clustering algorithm, can indeed achieve a—from a material science point of view—meaningful classification of those tissue samples. Our study pinpoints the ability of unsupervised ML models to guide or even replace human decision processes for the analysis of complex surfaces and topographical datasets that—either owing to their complexity or the sample size—exceed the capability of the human brain.",
           0,
           "apl_machine_learning"
          ],
          [
           "Benchmarking energy consumption and latency for neuromorphic computing in condensed matter and particle physics",
           "10.1063/5.0116699",
           2023,
           "The massive use of artificial neural networks (ANNs), increasingly popular in many areas of scientific computing, rapidly increases the energy consumption of modern high-performance computing systems. An appealing and possibly more sustainable alternative is provided by novel neuromorphic paradigms, which directly implement ANNs in hardware. However, little is known about the actual benefits of running ANNs on neuromorphic hardware for use cases in scientific computing. Here, we present a methodology for measuring the energy cost and compute time for inference tasks with ANNs on conventional hardware. In addition, we have designed an architecture for these tasks and estimate the same metrics based on a state-of-the-art analog in-memory computing (AIMC) platform, one of the key paradigms in neuromorphic computing. Both methodologies are compared for a use case in quantum many-body physics in two-dimensional condensed matter systems and for anomaly detection at 40 MHz rates at the Large Hadron Collider in particle physics. We find that AIMC can achieve up to one order of magnitude shorter computation times than conventional hardware at an energy cost that is up to three orders of magnitude smaller. This suggests great potential for faster and more sustainable scientific computing with neuromorphic hardware.",
           3,
           "apl_machine_learning"
          ],
          [
           "Physics-constrained 3D convolutional neural networks for electrodynamics",
           "10.1063/5.0132433",
           2023,
           "We present a physics-constrained neural network (PCNN) approach to solving Maxwell’s equations for the electromagnetic fields of intense relativistic charged particle beams. We create a 3D convolutional PCNN to map time-varying current and charge densities J(r, t) and ρ(r, t) to vector and scalar potentials A(r, t) and φ(r, t) from which we generate electromagnetic fields according to Maxwell’s equations: B = ∇ × A and E = −∇φ − ∂A/∂t. Our PCNNs satisfy hard constraints, such as ∇ · B = 0, by construction. Soft constraints push A and φ toward satisfying the Lorenz gauge.",
           4,
           "apl_machine_learning"
          ],
          [
           "Visual explanations of machine learning model estimating charge states in quantum dots",
           "10.1063/5.0193621",
           2024,
           "Charge state recognition in quantum dot devices is important in the preparation of quantum bits for quantum information processing. Toward auto-tuning of larger-scale quantum devices, automatic charge state recognition by machine learning has been demonstrated. For further development of this technology, an understanding of the operation of the machine learning model, which is usually a black box, will be useful. In this study, we analyze the explainability of the machine learning model estimating charge states in quantum dots by gradient weighted class activation mapping. This technique highlights the important regions in the image for predicting the class. The model predicts the state based on the change transition lines, indicating that human-like recognition is realized. We also demonstrate improvements of the model by utilizing feedback from the mapping results. Due to the simplicity of our simulation and pre-processing methods, our approach offers scalability without significant additional simulation costs, demonstrating its suitability for future quantum dot system expansions.",
           0,
           "apl_machine_learning"
          ],
          [
           "Digitizing images of electrical-circuit schematics",
           "10.1063/5.0177755",
           2024,
           "Electrical-circuit schematics are a foundational tool in electrical engineering. A method that can automatically digitalize them is desirable since a knowledge base of such schematics could preserve their functional information as well as provide a database that one can mine to predict more operationally efficient electrical circuits using data analytics and machine learning. We present a workflow that contains a novel pattern-recognition methodology and a custom-trained Optical Character Recognition (OCR) model that can digitalize images of electrical-circuit schematics with minimal configuration. The pattern-recognition and OCR stages of the workflow yield 86.4% and 99.6% success rates, respectively. We also present an extendable option toward predictive circuit-design efficiencies, subject to a large database of images being available. Thereby, data gathered from our pattern-recognition workflow are used to draw network graphs, which are in turn employed to form matrix equations that contain the voltages and currents for all nodes in the circuit in terms of component values. These equations could be applied to a database of electrical-circuit schematics to predict new circuit designs or circuit modifications that offer greater operational efficiency. Alternatively, these network graphs could be converted into simulation programs with integrated circuit emphasis netlists to afford more accurate and computationally automated simulations.",
           0,
           "apl_machine_learning"
          ],
          [
           "Machine learning for rapid discovery of laminar flow channel wall modifications that enhance heat transfer",
           "10.1063/5.0187783",
           2024,
           "Numerical simulation of fluid flow plays an essential role in modeling many physical phenomena, which enables technological advancements, contributes to sustainable practices, and expands our understanding of various natural and engineered systems. The calculation of heat transfer in fluid flow in simple flat channels is a relatively easy task for various simulation methods. However, once the channel geometry becomes more complex, numerical simulations become a bottleneck in optimizing wall geometries. We present a combination of accurate numerical simulations of arbitrary, flat, and non-flat channels as well as machine learning models trained on simulated data to predict the drag coefficient and Stanton number. We show that convolutional neural networks (CNNs) can accurately predict target properties at a fraction of the computational cost of numerical simulations. We use CNN models in a virtual high-throughput screening approach to explore a large number of possible, randomly generated wall architectures. Data augmentation techniques are incorporated to enforce physical invariances toward shifting and flipping, contributing to precise prediction for fluid flow and heat transfer characteristics. Moreover, we approach the interpretation of the trained model to better understand relevant channel structures and their influence on heat transfer. The general approach is not only applicable to simple flow setups as presented here but can be extended to more complex tasks, such as multiphase or even reactive unit operations in chemical engineering.",
           0,
           "apl_machine_learning"
          ],
          [
           "M3ICRO: Machine learning-enabled compact photonic tensor core based on programmable multi-operand multimode interference",
           "10.1063/5.0170965",
           2024,
           "Photonic computing shows promise for transformative advancements in machine learning (ML) acceleration, offering ultrafast speed, massive parallelism, and high energy efficiency. However, current photonic tensor core (PTC) designs based on standard optical components hinder scalability and compute density due to their large spatial footprint. To address this, we propose an ultracompact PTC using customized programmable multi-operand multimode interference (MOMMI) devices, named M3ICRO. The programmable MOMMI leverages the intrinsic light propagation principle, providing a single-device programmable matrix unit beyond the conventional computing paradigm of one multiply-accumulate operation per device. To overcome the optimization difficulty of customized devices that often requires time-consuming simulation, we apply ML for optics to predict the device behavior and enable differentiable optimization flow. We thoroughly investigate the reconfigurability and matrix expressivity of our customized PTC and introduce a novel block unfolding method to fully exploit the computing capabilities of a complex-valued PTC for near-universal real-valued linear transformations. Extensive evaluations demonstrate that M3ICRO achieves a 3.5–8.9× smaller footprint, 1.6–4.4× higher speed, 9.9–38.5× higher compute density, 3.7–12× higher system throughput, and superior noise robustness compared to state-of-the-art coherent PTC designs. It also outperforms electronic digital A100 graphics processing unit by 34.8–403× higher throughput while maintaining close-to-digital task accuracy across various ML benchmarks.",
           0,
           "apl_machine_learning"
          ],
          [
           "In-memory computing with emerging memory devices: Status and outlook",
           "10.1063/5.0136403",
           2023,
           "In-memory computing (IMC) has emerged as a new computing paradigm able to alleviate or suppress the memory bottleneck, which is the major concern for energy efficiency and latency in modern digital computing. While the IMC concept is simple and promising, the details of its implementation cover a broad range of problems and solutions, including various memory technologies, circuit topologies, and programming/processing algorithms. This Perspective aims at providing an orientation map across the wide topic of IMC. First, the memory technologies will be presented, including both conventional complementary metal-oxide-semiconductor-based and emerging resistive/memristive devices. Then, circuit architectures will be considered, describing their aim and application. Circuits include both popular crosspoint arrays and other more advanced structures, such as closed-loop memory arrays and ternary content-addressable memory. The same circuit might serve completely different applications, e.g., a crosspoint array can be used for accelerating matrix-vector multiplication for forward propagation in a neural network and outer product for backpropagation training. The different algorithms and memory properties to enable such diversification of circuit functions will be discussed. Finally, the main challenges and opportunities for IMC will be presented.",
           18,
           "apl_machine_learning"
          ],
          [
           "Sparse subnetwork inference for neural network epistemic uncertainty estimation with improved Hessian approximation",
           "10.1063/5.0193951",
           2024,
           "Despite significant advances in deep neural networks across diverse domains, challenges persist in safety-critical contexts, including domain shift sensitivity and unreliable uncertainty estimation. To address these issues, this study investigates Bayesian learning for uncertainty handling in modern neural networks. However, the high-dimensional, non-convex nature of the posterior distribution poses practical limitations for epistemic uncertainty estimation. The Laplace approximation, as a cost-efficient Bayesian method, offers a practical solution by approximating the posterior as a multivariate normal distribution but faces computational bottlenecks in precise covariance matrix computation and storage. This research employs subnetwork inference, utilizing only a subset of the parameter space for Bayesian inference. In addition, a Kronecker-factored and low-rank representation is explored to reduce space complexity and computational costs. Several corrections are introduced to converge the approximated curvature to the exact Hessian matrix. Numerical results demonstrate the effectiveness and competitiveness of this method, whereas qualitative experiments highlight the impact of Hessian approximation granularity and parameter space utilization in Bayesian inference on mitigating overconfidence in predictions and obtaining high-quality uncertainty estimates.",
           0,
           "apl_machine_learning"
          ],
          [
           "Physics-agnostic inverse design using transfer matrices",
           "10.1063/5.0179457",
           2024,
           "Inverse design is an application of machine learning to device design, giving the computer maximal latitude in generating novel structures, learning from their performance, and optimizing them to suit the designer’s needs. Gradient-based optimizers, augmented by the adjoint method to efficiently compute the gradient, are particularly attractive for this approach and have proven highly successful with finite-element and finite-difference physics simulators. Here, we extend adjoint optimization to the transfer matrix method, an accurate and efficient simulator for a wide variety of quasi-1D physical phenomena. We leverage this versatility to develop a physics-agnostic inverse design framework and apply it to three distinct problems, each presenting a substantial challenge for conventional design methods: optics, designing a multivariate optical element for compressive sensing; acoustics, designing a high-performance anti-sonar submarine coating; and quantum mechanics, designing a tunable double-bandpass electron energy filter.",
           0,
           "apl_machine_learning"
          ],
          [
           "Imaging in double-casing wells with convolutional neural network based on inception module",
           "10.1063/5.0191452",
           2024,
           "The evaluation of well integrity in double-casing wells is critical for ensuring well stability, preventing oil and gas leaks, avoiding pollution, and ensuring safety throughout well development and production. However, the current predominant method of assessing cementing quality primarily focuses on single-casing wells, with limited work conducted on double-casing wells. This study introduces a novel approach for evaluating the cementing quality using the Inception module of convolutional neural networks. First, the finite-difference method is employed to generate borehole sonic data corresponding to a variety of model configurations, which are used to train a neural network that learns spatial features from the borehole sonic data to reconstruct the slowness model. By adjusting the network architecture and parameters, it is discovered that a neural network with two blocks and 4096 nodes in the fully connected layer demonstrated the best imaging results and exhibited strong anti-noise capabilities. The proposed method is validated using practical wellbore size models, demonstrating excellent results and offering a more effective means of evaluating wellbore integrity in double-casing wells. In addition, dipole acoustic logging data are used to conduct slowness model imaging of the compressional (P-) wave and shear (S-) wave in double-casing wells to verify the feasibility of cementing quality evaluation. The developed method contributes to more accurate evaluations of wellbore integrity for the oil and gas industry, leading to improved safety and environmental outcomes.",
           0,
           "apl_machine_learning"
          ],
          [
           "Artificial neural network-based streamline tracing strategy applied to hypersonic waverider design",
           "10.1063/5.0127034",
           2023,
           "Streamline tracing in hypersonic flows is essential for designing a high-performance waverider and intake. Conventionally, the streamline equations are solved after obtaining the velocity field over a basic flow field from simplified flow differential equations or three-dimensional computational fluid dynamics. The hypersonic waverider shape is generated by repeatedly applying the streamline tracing approach along several planes. This approach is computationally expensive for iterative waverider optimization. We provide a novel strategy where an Artificial Neural Network (ANN) is trained to directly predict the streamlines without solving the differential equations. We consider the standard simple cone-derived waverider using Taylor–Maccoll equations for the conical flow field as a template for the study. First, the streamlines from the shock are solved for a wide range of cone angle and Mach number conditions resulting in an extensive database. The streamlines are parameterized by a third-order polynomial, and an ANN is trained to predict the coefficients of the polynomial for arbitrary inputs of Mach number, cone angle, and streamline originating locations. We apply this strategy to design a cone-derived waverider and compare the geometry obtained with the standard conical waverider design method and the simplified waverider design method. The ANN technique is highly accurate, with a difference of 0.68% from the standard method in the coordinates of the waverider. The performance of the three waveriders is compared using Reynolds averaged Navier–Stokes simulations. The ANN-derived waverider does not indicate severe flow spillage at the leading edge. The new ANN-based approach is 20 times faster than the standard method.",
           0,
           "apl_machine_learning"
          ],
          [
           "Designing composition ratio of magnetic alloy multilayer for transverse thermoelectric conversion by Bayesian optimization",
           "10.1063/5.0140332",
           2023,
           "We demonstrated the effectiveness of the machine learning method combined with first-principles calculations for the enhancement of the anomalous Nernst effect (ANE) of multilayers. The composition ratio of CoNi homogeneous alloy superlattices was optimized by Bayesian optimization so as to maximize the transverse thermoelectric conductivity (αxy). The nonintuitive optimal composition with a large αxy of ∼10 A K−1 m−1 was identified through the two-step Bayesian optimization using rough and fine candidate pools. The Berry curvature and band dispersion analyses revealed that αxy is enhanced by the appearance of the flat band near the Fermi level due to the multilayer formation. The magnitude of the energy derivative of the anomalous Hall conductivity increases owing to the large Berry curvature near the flat band along the R-M high symmetry line, which emerges only in the optimized superlattice, leading to the αxy enhancement. The effective method verified here will broaden the choices of ANE materials to more complex systems and, therefore, lead to the development of transverse thermoelectric conversion technologies.",
           2,
           "apl_machine_learning"
          ],
          [
           "Learning the stable and metastable phase diagram to accelerate the discovery of metastable phases of boron",
           "10.1063/5.0175994",
           2024,
           "Boron, an element of captivating chemical intricacy, has been surrounded by controversies ever since its discovery in 1808. The complexities of boron stem from its unique position between metals and insulators in the Periodic Table. Recent computational studies have shed light on some of the stable boron allotropes. However, the demand for multifunctionality necessitates the need to go beyond the stable phases into the realm of metastability and explore the potentially vast but elusive metastable phases of boron. Traditional search for stable phases of materials has focused on identifying materials with the lowest enthalpy. Here, we introduce a workflow that uses reinforcement learning coupled with decision trees, such as Monte Carlo tree search, to search for stable and metastable boron phases, with enthalpy as the objective. We discover new boron metastable phases and construct a phase diagram that locates their phase space (T, P) at different levels of metastability (ΔG) from the ground state and provides useful information on the domains of relative stability of the various stable and metastable boron phases.",
           1,
           "apl_machine_learning"
          ],
          [
           "Simulation of the effect of material properties on yttrium oxide memristor-based artificial neural networks",
           "10.1063/5.0143926",
           2023,
           "This paper reports a simulation study concerning the effect of yttrium oxide stoichiometry on output features of a memristor-based single layer perceptron neural network. To carry out this investigation, a material-oriented behavioral compact model for bipolar-type memristive devices was developed and tested. The model is written for the SPICE (Simulation Program with Integrated Circuits Emphasis) simulator and considers as one of its inputs a measure of the oxygen flow used during the deposition of the switching layer. After a thorough statistical calibration of the model parameters using experimental current–voltage characteristics associated with different fabrication conditions, the corresponding curves were simulated and the results were compared with the original data. In this way, the average switching behavior of the structures (low and high current states, set and reset voltages, etc.) as a function of the oxygen content can be forecasted. In a subsequent phase, the collective response of the devices when used in a neural network was investigated in terms of the output features of the network (mainly power dissipation and power efficiency). The role played by parasitic elements, such as the line resistance and the read voltage influence on the inference accuracy, was also explored. Since a similar strategy can be applied to any other material-related fabrication parameter, the proposed approach opens up a new dimension for circuit designers, as the behavior of complex circuits employing devices with specific characteristics can be realistically assessed before fabrication.",
           0,
           "apl_machine_learning"
          ],
          [
           "Calibration in machine learning uncertainty quantification: Beyond consistency to target adaptivity",
           "10.1063/5.0174943",
           2023,
           "Reliable uncertainty quantification (UQ) in machine learning (ML) regression tasks is becoming the focus of many studies in materials and chemical science. It is now well understood that average calibration is insufficient, and most studies implement additional methods for testing the conditional calibration with respect to uncertainty, i.e., consistency. Consistency is assessed mostly by so-called reliability diagrams. There exists, however, another way beyond average calibration, which is conditional calibration with respect to input features, i.e., adaptivity. In practice, adaptivity is the main concern of the final users of the ML-UQ method, seeking the reliability of predictions and uncertainties for any point in the feature space. This article aims to show that consistency and adaptivity are complementary validation targets and that good consistency does not imply good adaptivity. An integrated validation framework is proposed and illustrated with a representative example.",
           0,
           "apl_machine_learning"
          ],
          [
           "Seizure detection using dynamic memristor-based reservoir computing and leaky integrate-and-fire neuron for post-processing",
           "10.1063/5.0171274",
           2023,
           "Epilepsy is a prevalent neurological disorder, rendering the development of automated seizure detection systems imperative. While complex machine learning models are powerful, their training and hardware deployment remain challenging. The reservoir computing system offers a low-cost solution in terms of both hardware requirements and training. In this paper, we introduce a compact reservoir computing system for seizure detection, based on the α-In2Se3 dynamic memristors. Leaky integrate-and-fire neurons are used for post-processing the output of the system, and experimental results indicate their effectiveness in suppressing erroneous outputs, where both accuracy and specificity are enhanced by over 2.5%. The optimized compact reservoir system achieves 96.40% accuracy, 86.34% sensitivity, and 96.56% specificity in seizure detection tasks. This work demonstrates the feasibility of using reservoir computing for seizure detection and shows its potential for future application in extreme edge devices.",
           0,
           "apl_machine_learning"
          ],
          [
           "Advancing magnetic material discovery through machine learning: Unveiling new manganese-based materials",
           "10.1063/5.0171320",
           2023,
           "Magnetic materials are used in a variety of applications, such as electric generators, speakers, hard drives, MRI machines, etc. Discovery of new magnetic materials with desirable properties is essential for advancement in these applications. In this research article, we describe the development and validation of a machine-learning model to discover new manganese-based stable magnetic materials. The machine learning model is trained on the input data from the Materials Project database to predict the magnetization and formation energy of the materials. New hypothetical structures are made using the substitution method, and the properties are predicted using the machine learning model to select the materials with desired properties. Harnessing the power of machine learning allows us to intelligently narrow down the vast pool of potential candidates. By doing so, we deftly reduce the number of materials that warrant in-depth examination using density functional theory, rendering the task more manageable and efficient. The selected materials, seemingly promising with their magnetic potential, undergo a meticulous validation process using the Vienna Ab initio Simulation Package, grounded in density functional theory. Our results underscore the paramount significance of input data in the efficacy of the machine learning model. Particularly in the realm of magnetic materials, the proper initialization of atomic magnetic spins holds the key to converging upon the true magnetic state of each material.",
           1,
           "apl_machine_learning"
          ],
          [
           "Using the IBM analog in-memory hardware acceleration kit for neural network training and inference",
           "10.1063/5.0168089",
           2023,
           "Analog In-Memory Computing (AIMC) is a promising approach to reduce the latency and energy consumption of Deep Neural Network (DNN) inference and training. However, the noisy and non-linear device characteristics and the non-ideal peripheral circuitry in AIMC chips require adapting DNNs to be deployed on such hardware to achieve equivalent accuracy to digital computing. In this Tutorial, we provide a deep dive into how such adaptations can be achieved and evaluated using the recently released IBM Analog Hardware Acceleration Kit (AIHWKit), freely available at https://github.com/IBM/aihwkit. AIHWKit is a Python library that simulates inference and training of DNNs using AIMC. We present an in-depth description of the AIHWKit design, functionality, and best practices to properly perform inference and training. We also present an overview of the Analog AI Cloud Composer, a platform that provides the benefits of using the AIHWKit simulation in a fully managed cloud setting along with physical AIMC hardware access, freely available at https://aihw-composer.draco.res.ibm.com. Finally, we show examples of how users can expand and customize AIHWKit for their own needs. This Tutorial is accompanied by comprehensive Jupyter Notebook code examples that can be run using AIHWKit, which can be downloaded from https://github.com/IBM/aihwkit/tree/master/notebooks/tutorial.",
           3,
           "apl_machine_learning"
          ],
          [
           "Measuring thermal profiles in high explosives using neural networks",
           "10.1063/5.0183886",
           2024,
           "We present a new method for calculating the temperature profile of high explosive (HE) material using a Convolutional Neural Network (CNN). To train/test the CNN, we have developed a hybrid experiment/simulation method for collecting acoustic and temperature data. We experimentally heat cylindrical containers of HE material until detonation/deflagration, where we continuously measure the acoustic bursts through the HE using multiple acoustic transducers lined around the exterior container circumference. However, measuring the temperature profile in the HE in an experiment would require inserting a large number of thermal probes, which would disrupt the heating process. Thus, we use two thermal probes, one at the HE center and one at the wall. We then use numerical simulation of the heating process to calculate the temperature distribution and correct the simulated temperatures based on the experimental center and wall temperatures. We calculate temperature errors on the order of 15 °C, which is ∼12% of the range of temperatures in the experiment. We also investigate how the algorithm’s accuracy is affected by the number of acoustic receivers used to collect each measurement and the resolution of the temperature prediction. This work provides a means of assessing the safety status of HE material, which cannot be achieved using existing temperature measurement methods. In addition, it has implications for a range of other applications where internal temperature profile measurements would provide critical information. These applications include detecting chemical reactions, observing thermodynamic processes such as combustion, monitoring metal or plastic casting, determining the energy density in thermal storage capsules, and identifying abnormal battery operations.",
           0,
           "apl_machine_learning"
          ],
          [
           "LiNLNet: Gauging required nonlinearity in deep neural networks",
           "10.1063/5.0134713",
           2023,
           "Feedforward deep neural networks (DNNs) commonly involve layer-wise linear operations and subsequent nonlinear operations, which are repeated through all layers. The nonlinear operations by nonlinear activations in each layer remarkably enhance the expressiveness of DNNs, resulting in the great success in a variety of application domains. Although the necessity of layer-wise nonlinear operations is agreed, the optimal nonlinearity for each layer in a given DNN is not clear. In this regard, we propose an easy-to-use method to layer-wise measure the optimal nonlinearity for a given DNN using its replica termed a linear-nonlinear network (LiNLNet). The key to the LiNLNet is the use of linear-nonlinear units (LiNLUs) whose degree of nonlinearity is parameterized by a trainable parameter p. The parameter p is shared among all LiNLUs in a given layer, thus indicating the layer-wise optimal nonlinearity. This method allows layer-level pruning such that the layers that do not require nonlinearity are merged into the subsequent layers, reducing computational complexity. For proofs of concept, we applied the proposed method to a MLP, AlexNet, VGG16, and ResNet18 on CIFAR-10 and ImageNet. The results commonly indicate the last hidden layer as a linear layer that may be merged into the output layer, reducing memory usage by 27% while maintaining the accuracy for LiNL-AlexNet on ImageNet.",
           0,
           "apl_machine_learning"
          ],
          [
           "An efficiency-driven, correlation-based feature elimination strategy for small datasets",
           "10.1063/5.0118207",
           2023,
           "With big datasets and highly efficient algorithms becoming increasingly available for many problem sets, rapid advancements and recent breakthroughs achieved in the field of machine learning encourage more and more scientific fields to make use of such a computational data analysis. Still, for many research problems, the amount of data available for training a machine learning (ML) model is very limited. An important strategy to combat the problems arising from data sparsity is feature elimination—a method that aims at reducing the dimensionality of an input feature space. Most such strategies exclusively focus on analyzing pairwise correlations, or they eliminate features based on their relation to a selected output label or by optimizing performance measures of a certain ML model. However, those strategies do not necessarily remove redundant information from datasets and cannot be applied to certain situations, e.g., to unsupervised learning models. Neither of these limitations applies to the network-based, correlation-driven redundancy elimination (NETCORE) algorithm introduced here, where the size of a feature vector is reduced by considering both redundancy and elimination efficiency. The NETCORE algorithm is model-independent, does not require an output label, and is applicable to all kinds of correlation topographies within a dataset. Thus, this algorithm has the potential to be a highly beneficial preprocessing tool for various machine learning pipelines.",
           2,
           "apl_machine_learning"
          ],
          [
           "Multi-objective generative design of three-dimensional material structures",
           "10.1063/5.0169432",
           2023,
           "Generative design for materials has recently gained significant attention due to the rapid evolution of generative deep learning models. There have been a few successful generative design demonstrations of molecular-level structures with the help of graph neural networks. However, in the realm of macroscale material structures, most of the works are targeting two-dimensional, ungoverned structure generations. Hindered by the complexity of 3D structures, it is hard to extract customized structures with multiple desired properties from a large, unexplored design space. Here we report a novel framework, a multi-objective driven Wasserstein generative adversarial network (WGAN), to implement inverse designs of 3D structures according to given geometrical, structural, and mechanical requirements. Our framework consists of a WGAN-based network that generates 3D structures possessing geometrical and structural features learned from the target dataset. Besides, multiple objectives are introduced to our framework for the control of mechanical property and isotropy of the structures. An accurate surrogate model is incorporated into the framework to perform efficient prediction on the properties of generated structures in training iterations. With multiple objectives combined by their weight and the 3D WGAN acting as a soft constraint to regulate features that are hard to define by the traditional method, our framework has proven to be capable of tuning the properties of the generated structures in multiple aspects while keeping the selected structural features. The feasibility of a small dataset and the scalability of the objectives of other properties make our work an effective approach to provide fast and automated structure designs for various functional materials.",
           0,
           "apl_machine_learning"
          ],
          [
           "Automatic graph representation algorithm for heterogeneous catalysis",
           "10.1063/5.0140487",
           2023,
           "One of the most appealing aspects of machine learning for material design is its high throughput exploration of chemical spaces, but to reach the ceiling of machine learning-aided exploration, more than current model architectures and processing algorithms are required. New architectures such as graph neural networks have seen significant research investments recently. For heterogeneous catalysis, defining substrate intramolecular bonds and adsorbate/substrate intermolecular bonds is a time-consuming and challenging process. Before applying a model, dataset pre-processing, node/bond descriptor design, and specific model constraints have to be considered. In this work, a framework designed to solve these issues is presented in the form of an automatic graph representation algorithm (AGRA) tool to extract the local chemical environment of metallic surface adsorption sites. This tool is able to gather multiple adsorption geometry datasets composed of different systems and combine them into a single model. To show AGRA’s excellent transferability and reduced computational cost compared to other graph representation methods, it was applied to five different catalytic reaction datasets and benchmarked against the Open Catalyst Projects graph representation method. The two oxygen reduction reaction (ORR) datasets with O/OH adsorbates obtained 0.053 eV root-mean-square deviation (RMSD) when combined together, whereas the three carbon dioxide reduction reaction datasets with CHO/CO/COOH obtained an average performance of 0.088 eV RMSD. To further display the algorithm’s versatility and extrapolation ability, a model was trained on a subset combination of all five datasets with an RMSD of 0.105 eV. This universal model was then used to predict a wide range of adsorption energies and an entirely new ORR catalyst system, which was then verified through density functional theory calculations.",
           1,
           "apl_machine_learning"
          ],
          [
           "Analysis of Brownian motion trajectories of non-spherical nanoparticles using deep learning",
           "10.1063/5.0160979",
           2023,
           "As nanoparticles are being put to practical use as useful materials in the medical, pharmaceutical, and industrial fields, the importance of technologies that can evaluate not only nanoparticle populations of homogeneous size and density but also those of rich diversity is increasing. Nano-tracking analysis (NTA) has been commercialized and widely used as a method to measure individual nanoparticles in liquids and evaluate their size distribution by analyzing Brownian motion. We have combined deep learning (DL) for NTA to extract more property information and explored a methodology to achieve an evaluation for individual particles to understand their diversity. Practical NTA always assumes spherical shape when quantifying particle size using the Stokes–Einstein equation, but it is not possible to verify whether the measured particles are truly spherical. We developed a DL model that predicts the shape of nanoparticles using time series trajectory data of BM obtained from NTA measurements to address this problem. As a result, we were able to discriminate with ∼80% accuracy between spherical and rod-shaped gold nanoparticles of different shapes, which are evaluated to have nearly equal particle size without any discrimination by conventional NTA. Furthermore, we demonstrated that the mixing ratio of spherical and rod-shaped nanoparticles can be quantitatively estimated from measured data of mixed samples of nanoparticles. This result suggests that it is possible to evaluate particle shape by applying DL analysis to NTA measurements, which was previously considered impossible, and opens the way to further value-added NTA.",
           1,
           "apl_machine_learning"
          ],
          [
           "Data-driven design for enhanced efficiency of Sn-based perovskite solar cells using machine learning",
           "10.1063/5.0177271",
           2023,
           "In this study, a novel three-step learning-based machine learning (ML) methodology is developed utilizing 26 000 experimental records from The Perovskite Database Project. A comprehensive set of 29 features encompassing both categorical and numerical data was utilized to train various ML models for various solar cell performance metrics, including open-circuit voltage (VOC), short-circuit current (JSC), fill factor (FF), and power conversion efficiency (PCE). The model accuracy was assessed using four key metrics: mean absolute error, mean square error, root mean square error, and R2 score. Among the constructed models, random forest (RF) emerged as the standout performer, boasting an R2 score of 0.70 for PCE. This RF model was then used for prediction on the large, optimized design pool of Sn-based perovskite data with intent to probe a viable non-toxic substitute to the standard Pb-based absorber. A three-step algorithm was tailored, which led to the discovery of a new set of feature combinations, showcasing a PCE improvement over the existing peak performance of Sn-based devices. The key aspects identified were device architecture, dimensionality, and deposition procedures for essential layers, including the electron transport layer, the hole transport layer, the perovskite absorber layer, and the back-contact. Through consideration of these features, an impressive increase in PCE was achieved. There was a 28.35% increase in PCE from 12.24% to 15.71% for architecture optimization and a 24.6% increase in PCE from 12.24% to 15.25% for deposition method optimization. This study additionally addresses the effective implementation of target encoding applied to a diverse set of categorical feature labels. The data-driven methodology proposed in this study allows scientists to efficiently identify an optimal architecture and deposition parameters for non-toxic Sn-based perovskite materials with a much higher anticipated device PCE compared to traditional trial-and-error analyses. Further exploration and exploitation of the current investigation is expected to lead to successful and sustainable development of highly efficient Sn-based perovskite solar cells.",
           0,
           "apl_machine_learning"
          ],
          [
           "Improving the mechanical properties of Cantor-like alloys with Bayesian optimization",
           "10.1063/5.0179844",
           2024,
           "The search for better compositions in high entropy alloys is a formidable challenge in materials science. Here, we demonstrate a systematic Bayesian optimization method to enhance the mechanical properties of the paradigmatic five-element Cantor alloy in silico. This method utilizes an automated loop with an online database, a Bayesian optimization algorithm, thermodynamic modeling, and molecular dynamics simulations. Starting from the equiatomic Cantor composition, our approach optimizes the relative fractions of its constituent elements, searching for better compositions while maintaining the thermodynamic phase stability. With 24 steps, we find Fe21Cr20Mn5Co20Ni34 with a yield stress improvement of 58%, and with 72 steps, we find Fe6Cr22Mn5Co32Ni35 where the yield stress has improved by 74%. These optimized compositions correspond to Ni-rich medium entropy alloys with enhanced mechanical properties and superior face-centered-cubic phase stability compared to the traditional equiatomic Cantor alloy. The automatic approach devised here paves the way for designing high entropy alloys with tailored properties, opening avenues for numerous potential applications.",
           0,
           "apl_machine_learning"
          ],
          [
           "Predicting wind farm wake losses with deep convolutional hierarchical encoder–decoder neural networks",
           "10.1063/5.0168973",
           2024,
           "Wind turbine wakes are the most significant factor affecting wind farm performance, decreasing energy production and increasing fatigue loads in downstream turbines. Wind farm turbine layouts are designed to minimize wake interactions using a suite of predictive models, including analytical wake models and computational fluid dynamics simulations (CFD). CFD simulations of wind farms are time-consuming and computationally expensive, which hinder their use in optimization studies that require hundreds of simulations to converge to an optimal turbine layout. In this work, we propose DeepWFLO, a deep convolutional hierarchical encoder–decoder neural network architecture, as an image-to-image surrogate model for predicting the wind velocity field for Wind Farm Layout Optimization (WFLO). We generate a dataset composed of image representations of the turbine layout and undisturbed flow field in the wind farm, as well as images of the corresponding wind velocity field, including wake effects generated with both analytical models and CFD simulations. The proposed DeepWFLO architecture is then trained and optimized through supervised learning with an application-tailored loss function that considers prediction errors in both wind velocity and energy production. Results on a commonly used test case show median velocity errors of 1.0%–8.0% for DeepWFLO networks trained with analytical and CFD data, respectively. We also propose a model-fusion strategy that uses analytical wake models to generate an additional input channel for the network, resulting in median velocity errors below 1.8%. Spearman rank correlations between predictions and data, which evidence the suitability of DeepWFLO for optimization purposes, range between 92.3% and 99.9%.",
           0,
           "apl_machine_learning"
          ],
          [
           "Autonomous convergence of STM control parameters using Bayesian optimization",
           "10.1063/5.0185362",
           2024,
           "Scanning tunneling microscopy (STM) is a widely used tool for atomic imaging of novel materials and their surface energetics. However, the optimization of the imaging conditions is a tedious process due to the extremely sensitive tip–surface interaction, thus limiting the throughput efficiency. In this paper, we deploy a machine learning (ML)-based framework to achieve optimal atomically resolved imaging conditions in real time. The experimental workflow leverages the Bayesian optimization (BO) method to rapidly improve the image quality, defined by the peak intensity in the Fourier space. The outcome of the BO prediction is incorporated into the microscope controls, i.e., the current setpoint and the tip bias, to dynamically improve the STM scan conditions. We present strategies to either selectively explore or exploit across the parameter space. As a result, suitable policies are developed for autonomous convergence of the control parameters. The ML-based framework serves as a general workflow methodology across a wide range of materials.",
           0,
           "apl_machine_learning"
          ],
          [
           "Estimation of TbCo composition from local-minimum-energy magnetic images taken by magneto-optical Kerr effect microscope by using machine learning",
           "10.1063/5.0160970",
           2023,
           "Recently, the incorporation of machine learning (ML) has heralded significant advancements in materials science. For instance, in spintronics, it has been shown that magnetic parameters, such as the Dzyaloshinskii–Moriya interaction, can be estimated from magnetic domain images using ML. Magnetic materials exhibit hysteresis, leading to numerous magnetic states with locally minimized energy (LME) even within a single sample. However, it remains uncertain whether these parameters can be derived from LME states. In our research, we explored the estimation of material parameters from an LME magnetic state using a convolutional neural network. We introduced a technique to manipulate LME magnetic states, combining the ac demagnetizing method with the magneto-optical Kerr effect. By applying this method, we generated multiple LME magnetic states from a single sample and successfully estimated its material composition. Our findings suggest that ML emphasizes not the global domain structures that are readily perceived by humans but the more subtle local domain structures that are often overlooked. Adopting this approach could potentially facilitate the estimation of magnetic parameters from any state observed in experiments, streamlining experimental processes in spintronics.",
           1,
           "apl_machine_learning"
          ],
          [
           "On-device edge-learning for cardiac abnormality detection using a bio-inspired and spiking shallow network",
           "10.1063/5.0191571",
           2024,
           "This work introduces on-device edge learning for cardiac abnormality detection by merging spiking 2D Convolutional Long-Short-Term Memory (ConvLSTM2D) with a bio-inspired shallow neural network, referred to as Closed-form Continuous-time (CfC), to form the sCCfC model. The model achieves an F1 score and AUROC of 0.82 and 0.91 in cardiac abnormalities detection. These results are comparable to the non-spiking ConvLSTM2D–CfC (ConvCfC) model [Huang et al., J. Cardiovasc. Transl. Res. (published online, 2024)]. Notably, the sCCfC model demonstrates a significantly higher energy efficiency with an estimated power consumption of 4.68 μJ/Inf (per inference) on an emulated Loihi’s neuromorphic chip architecture, in contrast to ConvCfC model’s consumption of 450 μJ/Inf on a conventional processor. In addition, as a proof-of-concept, we deployed the sCCfC model on the conventional and relatively resource-constrained Radxa Zero, which is equipped with an Amlogic S905Y2 processor for on-device training, which resulted in performance improvements. After initial training of two epochs on a conventional Graphics Processing Unit, the F1 score and AUROC improved from 0.46 and 0.65 to 0.56 and 0.73, respectively, with five additional epochs of on-device training. Furthermore, when presented with a new dataset, the sCCfC model showcases strong out-of-sample generalization capabilities that can constitute a pseudo-perspective test, achieving an F1 score and AUROC of 0.71 and 0.86, respectively. The spiking sCCfC also outperforms the non-spiking ConvCfC model in robustness regarding effectively handling missing electrocardiogram (ECG) channels during inference. The model’s efficacy extends to single-lead ECG analysis, demonstrating reasonable accuracy in this context, while the focus of our work has been on the computational and memory complexities of the model.",
           0,
           "apl_machine_learning"
          ],
          [
           "Scanning probe microscopy in the age of machine learning",
           "10.1063/5.0160568",
           2023,
           "Scanning probe microscopy (SPM) has revolutionized our ability to explore the nanoscale world, enabling the imaging, manipulation, and characterization of materials at the atomic and molecular level. However, conventional SPM techniques suffer from limitations, such as slow data acquisition, low signal-to-noise ratio, and complex data analysis. In recent years, the field of machine learning (ML) has emerged as a powerful tool for analyzing complex datasets and extracting meaningful patterns and features in multiple fields. The combination of ML with SPM techniques has the potential to overcome many of the limitations of conventional SPM methods and unlock new opportunities for nanoscale research. In this review article, we will provide an overview of the recent developments in ML-based SPM, including its applications in topography imaging, surface characterization, and secondary imaging modes, such as electrical, spectroscopic, and mechanical datasets. We will also discuss the challenges and opportunities of integrating ML with SPM techniques and highlight the potential impact of this interdisciplinary field on various fields of science and engineering.",
           2,
           "apl_machine_learning"
          ],
          [
           "Self-supervised learning of shedding droplet dynamics during steam condensation",
           "10.1063/5.0188620",
           2024,
           "Knowledge of condensate shedding droplet dynamics provides important information for the characterization of two-phase heat and mass transfer phenomena. Detecting and segmenting the droplets during shedding requires considerable time and effort if performed manually. Here, we developed a self-supervised deep learning model for segmenting shedding droplets from a variety of dropwise and filmwise condensing surfaces. The model eliminates the need for image annotation by humans in the training step and, therefore, reduces labor significantly. The trained model achieved an average accuracy greater than 0.9 on a new unseen test dataset. After extracting the shedding droplet size and speed, we developed a data-driven model for shedding droplet dynamics based on condensation heat flux and surface properties such as wettability and tube diameter. Our results demonstrate that condensate droplet departure size is both heat flux and tube size dependent and follows different trends based on the condensation mode. The results of this work provide an annotation-free methodology for falling droplet segmentation as well as a statistical understanding of droplet dynamics during condensation.",
           0,
           "apl_machine_learning"
          ],
          [
           "Glass transition of amorphous polymeric materials informed by machine learning",
           "10.1063/5.0137357",
           2023,
           "The glass transition temperature (Tg) is used to determine thermophysical properties of polymer materials and is often considered one of the most important descriptors. Methods for predicting various physical properties of materials based on machine learning algorithms and key molecular descriptors are efficient and accurate. However, it still needs improvements because an overly complex model is less practical and difficult to generalize. In addition, obtaining a large number of samples to achieve accurate predictions remains a challenge due to the complex and lengthy experimental process. In this work, based on Tg of 100 polymers, we use a feature selection algorithm combining FeatureWiz and the least absolute shrinkage and selection operator to quickly select molecular descriptors that are minimally redundant and maximally relevant to Tg. The processed dataset is interpolated from the original dataset using the nearest neighbor interpolation algorithm to solve the data deficiency problem. Finally, the synthetic minority oversampling technique algorithm is used to solve the data imbalance problem. The augmented dataset is used to construct the extreme gradient boosting prediction model to achieve good prediction accuracy. The experimental results demonstrate the robustness of the proposed model and the accuracy of its prediction results.",
           1,
           "apl_machine_learning"
          ],
          [
           "Flexible optoelectronic synaptic transistors for neuromorphic visual systems",
           "10.1063/5.0163926",
           2023,
           "Neuromorphic visual systems that integrate the functionalities of sensing, memory, and processing are expected to overcome the shortcomings of conventional artificial visual systems, such as data redundancy, data access delay, and high-energy consumption. Neuromorphic visual systems based on emerging flexible optoelectronic synaptic devices have recently opened up innovative applications, such as robot visual perception, visual prosthetics, and artificial intelligence. Various flexible optoelectronic synaptic devices have been fabricated, which are either two-terminal memristors or three-terminal transistors. In flexible optoelectronic synaptic transistors (FOSTs), the synaptic weight can be modulated by the electricity and light synergistically, which endows the neuromorphic visual systems with versatile functionalities. In this Review, we present an overview of the working mechanisms, device structures, and active materials of FOSTs. Their applications in neuromorphic visual systems for color recognition, image recognition and memory, motion detection, and pain perception are presented. Perspectives on the development of FOSTs are finally outlined.",
           2,
           "apl_machine_learning"
          ],
          [
           "Training self-learning circuits for power-efficient solutions",
           "10.1063/5.0181382",
           2024,
           "As the size and ubiquity of artificial intelligence and computational machine learning models grow, the energy required to train and use them is rapidly becoming economically and environmentally unsustainable. Recent laboratory prototypes of self-learning electronic circuits, such as “physical learning machines,” open the door to analog hardware that directly employs physics to learn desired functions from examples at a low energy cost. In this work, we show that this hardware platform allows for an even further reduction in energy consumption by using good initial conditions and a new learning algorithm. Using analytical calculations, simulations, and experiments, we show that a trade-off emerges when learning dynamics attempt to minimize both the error and the power consumption of the solution—greater power reductions can be achieved at the cost of decreasing solution accuracy. Finally, we demonstrate a practical procedure to weigh the relative importance of error and power minimization, improving the power efficiency given a specific tolerance to error.",
           0,
           "apl_machine_learning"
          ],
          [
           "3D CNN and grad-CAM based visualization for predicting generation of dislocation clusters in multicrystalline silicon",
           "10.1063/5.0156044",
           2023,
           "We propose a machine learning-based technique to address the crystallographic characteristics responsible for the generation of crystal defects. A convolutional neural network was trained with pairs of optical images that display the characteristics of the crystal and photoluminescence images that show the distributions of crystal defects. The model was trained to predict the existence of crystal defects at the center pixel of the given image from its optical features. Prediction accuracy and separability were enhanced by feeding three-dimensional data and data augmentation. The prediction was successful with a high area under the curve of over 0.9 in a receiver operating characteristic curve. Likelihood maps showing the distributions of the predicted defects are in good resemblance with the correct distributions. Using the trained model, we visualized the most important regions to the predicted class by gradient-based class activation mapping. The extracted regions were found to contain mostly particular grains where the grain boundaries changed greatly due to crystal growth and clusters of small grains. This technique is beneficial in providing a rapid and statistical analysis of various crystal characteristics because the features of optical images are often complex and difficult to interpret. The interpretations can help us understand the physics of crystal growth and the effects of crystallographic characteristics on the generation of detrimental defects. We believe that this technique will contribute to the development of a better fabrication process for high-performance multicrystalline materials.",
           1,
           "apl_machine_learning"
          ],
          [
           "Intelligent performance inference: A graph neural network approach to modeling maximum achievable throughput in optical networks",
           "10.1063/5.0137426",
           2023,
           "One of the key performance metrics for optical networks is the maximum achievable throughput for a given network. Determining it, however, is a nondeterministic polynomial time (NP) hard optimization problem, often solved via computationally expensive integer linear programming (ILP) formulations. These are infeasible to implement as objectives, even on very small node scales of a few tens of nodes. Alternatively, heuristics are used although these, too, require considerable computation time for a large number of networks. There is, thus, a need for an ultra-fast and accurate performance evaluation of optical networks. For the first time, we propose the use of a geometric deep learning model, message passing neural networks (MPNNs), to learn the relationship between node and edge features, the network structure, and the maximum achievable network throughput. We demonstrate that MPNNs can accurately predict the maximum achievable throughput while reducing the computational time by up to five-orders of magnitude compared to the ILP for small networks (10–15 nodes) and compared to a heuristic for large networks (25–100 nodes)—proving their suitability for the design and optimization of optical networks on different time- and distance-scales.",
           0,
           "apl_machine_learning"
          ],
          [
           "Attention hybrid variational net for accelerated MRI reconstruction",
           "10.1063/5.0165485",
           2023,
           "The application of compressed sensing (CS)-enabled data reconstruction for accelerating magnetic resonance imaging (MRI) remains a challenging problem. This is due to the fact that the information lost in k-space from the acceleration mask makes it difficult to reconstruct an image similar to the quality of a fully sampled image. Multiple deep learning-based structures have been proposed for MRI reconstruction using CS, in both the k-space and image domains, and using unrolled optimization methods. However, the drawback of these structures is that they are not fully utilizing the information from both domains (k-space and image). Herein, we propose a deep learning-based attention hybrid variational network that performs learning in both the k-space and image domains. We evaluate our method on a well-known open-source MRI dataset (652 brain cases and 1172 knee cases) and a clinical MRI dataset of 243 patients diagnosed with strokes from our institution to demonstrate the performance of our network. Our model achieves an overall peak signal-to-noise ratio/structural similarity of 40.92 ± 0.29/0.9577 ± 0.0025 (fourfold) and 37.03 ± 0.25/0.9365 ± 0.0029 (eightfold) for the brain dataset, 31.09 ± 0.25/0.6901 ± 0.0094 (fourfold) and 29.49 ± 0.22/0.6197 ± 0.0106 (eightfold) for the knee dataset, and 36.32 ± 0.16/0.9199 ± 0.0029 (20-fold) and 33.70 ± 0.15/0.8882 ± 0.0035 (30-fold) for the stroke dataset. In addition to quantitative evaluation, we undertook a blinded comparison of image quality across networks performed by a subspecialty trained radiologist. Overall, we demonstrate that our network achieves a superior performance among others under multiple reconstruction tasks.",
           1,
           "apl_machine_learning"
          ],
          [
           "A cloud platform for sharing and automated analysis of raw data from high throughput polymer MD simulations",
           "10.1063/5.0160937",
           2023,
           "Open material databases storing thousands of material structures and their properties have become the cornerstone of modern computational materials science. Yet, the raw simulation outputs are generally not shared due to their huge size. In this work, we describe a cloud-based platform to enable fast post-processing of the trajectories and to facilitate sharing of the raw data. As an initial demonstration, our database includes 6286 molecular dynamics trajectories for amorphous polymer electrolytes (5.7 terabytes of data). We create a public analysis library at https://github.com/TRI-AMDD/htp_md to extract ion transport properties from the raw data using expert-designed functions and machine learning models. The analysis is run automatically on the cloud, and the results are uploaded onto an open database. Our platform encourages users to contribute both new trajectory data and analysis functions via public interfaces. Finally, we create a front-end user interface at https://www.htpmd.matr.io/ for browsing and visualization of our data. We envision the platform to be a new way of sharing raw data and new insights for the materials science community.",
           1,
           "apl_machine_learning"
          ],
          [
           "KoopmanLab: Machine learning for solving complex physics equations",
           "10.1063/5.0157763",
           2023,
           "Numerous physics theories are rooted in partial differential equations (PDEs). However, the increasingly intricate physics equations, especially those that lack analytic solutions or closed forms, have impeded the further development of physics. Computationally solving PDEs by classic numerical approaches suffers from the trade-off between accuracy and efficiency and is not applicable to the empirical data generated by unknown latent PDEs. To overcome this challenge, we present KoopmanLab, an efficient module of the Koopman neural operator (KNO) family, for learning PDEs without analytic solutions or closed forms. Our module consists of multiple variants of the KNO, a kind of mesh-independent neural-network-based PDE solvers developed following the dynamic system theory. The compact variants of KNO can accurately solve PDEs with small model sizes, while the large variants of KNO are more competitive in predicting highly complicated dynamic systems govern by unknown, high-dimensional, and non-linear PDEs. All variants are validated by mesh-independent and long-term prediction experiments implemented on representative PDEs (e.g., the Navier–Stokes equation and the Bateman–Burgers equation in fluid mechanics) and ERA5 (i.e., one of the largest high-resolution global-scale climate datasets in earth physics). These demonstrations suggest the potential of KoopmanLab to be a fundamental tool in diverse physics studies related to equations or dynamic systems.",
           0,
           "apl_machine_learning"
          ],
          [
           "Integrating uncertainty into deep learning models for enhanced prediction of nanocomposite materials’ mechanical properties",
           "10.1063/5.0177062",
           2024,
           "In this paper, we present a novel deep-learning framework that incorporates quantified uncertainty for predicting the mechanical properties of nanocomposite materials, specifically taking into account their morphology and composition. Due to the intricate microstructures of nanocomposites and their dynamic changes under diverse conditions, traditional methods, such as molecular dynamics simulations, often impose significant computational burdens. Our machine learning models, trained on comprehensive material datasets, provide a lower computational cost alternative, facilitating rapid exploration of design spaces and more reliable predictions. We employ both convolutional neural networks and feedforward neural networks for our predictions, training separate models for yield strength and ultimate tensile strength. Furthermore, we integrate uncertainty quantification into our models, thereby providing confidence intervals for our predictions and making them more reliable. This study paves the way for advancements in predicting the properties of nanocomposite materials and could potentially be expanded to cover a broad spectrum of materials in the future.",
           0,
           "apl_machine_learning"
          ],
          [
           "Accelerated and interpretable prediction of local properties in composites",
           "10.1063/5.0156517",
           2023,
           "The localized stress and strain field simulation results are critical for understanding the mechanical properties of materials, such as strength and toughness. However, applying off-the-shelf machine learning or deep learning methods to a digitized microstructure restricts the image samples to be of a fixed size and also lacks interpretability. Additionally, existing methods that utilize deep learning models to solve boundary value problems require retraining the model for each set of boundary conditions. To address these limitations, we propose a customized Pixel-Wise Convolutional Neural Network (PWCNN) to make fast predictions of stress and strain fields pixel-by-pixel under different loading conditions and for a wide range of composite microstructures of any size (e.g., much larger or smaller than the sample on which the PWCNN is trained). Through numerical experiments, we show that our PWCNN model serves as an alternative approach to numerical solution methods, such as finite element analysis, but is computationally more efficient, and the prediction errors on the test microstructure are around 5%. Moreover, we also propose an interpretable machine learning framework to facilitate the scientific discovery of why certain microstructures have better or worse performance than others, which has important implications in the design of composite microstructures in advanced manufacturing.",
           0,
           "apl_machine_learning"
          ],
          [
           "Experiment-based deep learning approach for power allocation with a programmable metasurface",
           "10.1063/5.0184328",
           2023,
           "Metasurfaces designed with deep learning approaches have emerged as efficient tools for manipulating electromagnetic waves to achieve beam steering and power allocation objectives. However, the effects of complex environmental factors like obstacle blocking and other unavoidable scattering need to be sufficiently considered for practical applications. In this work, we employ an experiment-based deep learning approach for programmable metasurface design to control powers delivered to specific locations generally with obstacle blocking. Without prior physical knowledge of the complex system, large sets of experimental data can be efficiently collected with a programmable metasurface to train a deep neural network (DNN). The experimental data can inherently incorporate complex factors that are difficult to include if only simulation data are used for training. Moreover, the DNN can be updated by collecting new experimental data on-site to adapt to changes in the environment. Our proposed experiment-based DNN demonstrates significant potential for intelligent wireless communication, imaging, sensing, and quiet-zone control for practical applications.",
           0,
           "apl_machine_learning"
          ],
          [
           "Bayesian optimization approach to quantify the effect of input parameter uncertainty on predictions of numerical physics simulations",
           "10.1063/5.0151747",
           2023,
           "An understanding of how input parameter uncertainty in the numerical simulation of physical models leads to simulation output uncertainty is a challenging task. Common methods for quantifying output uncertainty, such as performing a grid or random search over the model input space, are computationally intractable for a large number of input parameters represented by a high-dimensional input space. It is, therefore, generally unclear as to whether a numerical simulation can reproduce a particular outcome (e.g., a set of experimental results) with a plausible set of model input parameters. Here, we present a method for efficiently searching the input space using Bayesian optimization to minimize the difference between the simulation output and a set of experimental results. Our method allows explicit evaluation of the probability that the simulation can reproduce the measured experimental results in the region of input space defined by the uncertainty in each input parameter. We apply this method to the simulation of charge-carrier dynamics in the perovskite semiconductor methyl-ammonium lead iodide (MAPbI3), which has attracted attention as a light harvesting material in solar cells. From our analysis, we conclude that the formation of large polarons, quasiparticles created by the coupling of excess electrons or holes with ionic vibrations, cannot explain the experimentally observed temperature dependence of electron mobility.",
           0,
           "apl_machine_learning"
          ],
          [
           "Autoregressive transformers for data-driven spatiotemporal learning of turbulent flows",
           "10.1063/5.0152212",
           2023,
           "A convolutional encoder–decoder-based transformer model is proposed for autoregressively training on spatiotemporal data of turbulent flows. The prediction of future fluid flow fields is based on the previously predicted fluid flow field to ensure long-term predictions without diverging. A combination of convolutional neural networks and transformer architecture is utilized to handle both the spatial and temporal dimensions of the data. To assess the performance of the model, a priori assessments are conducted, and significant agreements are found with the ground truth data. The a posteriori predictions, which are generated after a considerable number of simulation steps, exhibit predicted variances. The autoregressive training and prediction of a posteriori states are deemed crucial steps toward the development of more complex data-driven turbulence models and simulations. The highly nonlinear and chaotic dynamics of turbulent flows can be handled by the proposed model, and accurate predictions over long time horizons can be generated. Overall, the potential of using deep learning techniques to improve the accuracy and efficiency of turbulence modeling and simulation is demonstrated by this approach. The proposed model can be further optimized and extended to incorporate additional physics and boundary conditions, paving the way for more realistic simulations of complex fluid dynamics.",
           2,
           "apl_machine_learning"
          ],
          [
           "Prediction and control of spatiotemporal chaos by <i>learning</i> conjugate tubular neighborhoods",
           "10.1063/5.0181022",
           2024,
           "I present a data-driven predictive modeling tool that is applicable to high-dimensional chaotic systems with unstable periodic orbits. The basic idea is using deep neural networks to learn coordinate transformations between the trajectories in the periodic orbits’ neighborhoods and those of low-dimensional linear systems in a latent space. I argue that the resulting models are partially interpretable since their latent-space dynamics is fully understood. To illustrate the method, I apply it to the numerical solutions of the Kuramoto–Sivashinsky partial differential equation in one dimension. Besides the forward-time predictions, I also show that these models can be leveraged for control.",
           0,
           "apl_machine_learning"
          ],
          [
           "Multiplexed gradient descent: Fast online training of modern datasets on hardware neural networks without backpropagation",
           "10.1063/5.0157645",
           2023,
           "We present multiplexed gradient descent (MGD), a gradient descent framework designed to easily train analog or digital neural networks in hardware. MGD utilizes zero-order optimization techniques for online training of hardware neural networks. We demonstrate its ability to train neural networks on modern machine learning datasets, including CIFAR-10 and Fashion-MNIST, and compare its performance to backpropagation. Assuming realistic timescales and hardware parameters, our results indicate that these optimization techniques can train a network on emerging hardware platforms orders of magnitude faster than the wall-clock time of training via backpropagation on a standard GPU, even in the presence of imperfect weight updates or device-to-device variations in the hardware. We additionally describe how it can be applied to existing hardware as part of chip-in-the-loop training or integrated directly at the hardware level. Crucially, because the MGD framework is model-free it can be applied to nearly any hardware platform with tunable parameters, and its gradient descent process can be optimized to compensate for specific hardware limitations, such as slow parameter-update speeds or limited input bandwidth.",
           1,
           "apl_machine_learning"
          ],
          [
           "Improved prediction for failure time of multilayer ceramic capacitors (MLCCs): A physics-based machine learning approach",
           "10.1063/5.0158360",
           2023,
           "Multilayer ceramic capacitors (MLCC) play a vital role in electronic systems, and their reliability is of critical importance. The ongoing advancement in MLCC manufacturing has improved capacitive volumetric density for both low and high voltage devices; however, concerns about long-term stability under higher fields and temperatures are always a concern, which impact their reliability and lifespan. Consequently, predicting the mean time to failure (MTTF) for MLCCs remains a challenge due to the limitations of existing models. In this study, we develop a physics-based machine learning approach using the eXtreme Gradient Boosting method to predict the MTTF of X7R MLCCs under various temperature and voltage conditions. We employ a transfer learning framework to improve prediction accuracy for test conditions with limited data and to provide predictions for test conditions where no experimental data exists. We compare our model with the conventional Eyring model (EM) and, more recently, the tipping point model (TPM) in terms of accuracy and performance. Our results show that the machine learning model consistently outperforms both the EM and TPM, demonstrating superior accuracy and stability across different conditions. Our model also exhibits a reliable performance for untested voltage and temperature conditions, making it a promising approach for predicting MTTF in MLCCs.",
           1,
           "apl_machine_learning"
          ],
          [
           "Manifold projection image segmentation for nano-XANES imaging",
           "10.1063/5.0167584",
           2023,
           "As spectral imaging techniques are becoming more prominent in science, advanced image segmentation algorithms are required to identify appropriate domains in these images. We present a version of image segmentation called manifold projection image segmentation (MPIS) that is generally applicable to a broad range of systems without the need for training because MPIS uses unsupervised machine learning with a few physically motivated hyperparameters. We apply MPIS to nanoscale x-ray absorption near edge structure (XANES) imaging, where XANES spectra are collected with nanometer spatial resolution. We show the superiority of manifold projection over linear transformations, such as the commonly used principal component analysis (PCA). Moreover, MPIS maintains accuracy while reducing computation time and sensitivity to noise compared to the standard nano-XANES imaging analysis procedure. Finally, we demonstrate how multimodal information, such as x-ray fluorescence data and spatial location of pixels, can be incorporated into the MPIS framework. We propose that MPIS is adaptable for any spectral imaging technique, including scanning transmission x-ray microscopy, where the length scale of domains is larger than the resolution of the experiment.",
           2,
           "apl_machine_learning"
          ],
          [
           "Identification of novel organic polar materials: A machine learning study with importance sampling",
           "10.1063/5.0162380",
           2023,
           "Recent advances in the synthesis of polar molecular materials have produced practical alternatives to ferroelectric ceramics, opening up exciting new avenues for their incorporation into modern electronic devices. However, in order to realize the full potential of polar polymer and molecular crystals for modern technological applications, it is paramount to assemble and evaluate all the available data for such compounds, identifying descriptors that could be associated with an emergence of ferroelectricity. In this paper, we utilized data-driven approaches to judiciously shortlist candidate materials from a wide chemical space that could possess ferroelectric functionalities. A machine learning study with importance sampling was employed to address the challenge of having a limited amount of available data on already-known organic ferroelectrics. Sets of molecular- and crystal-level descriptors were combined with a Random Forest Regression algorithm in order to predict the spontaneous polarization of the shortlisted compounds. First-principles simulations were performed to further validate the predictions obtained from the machine learning model.",
           1,
           "apl_machine_learning"
          ],
          [
           "Contextual beamforming: Exploiting location and AI for enhanced wireless telecommunication performance",
           "10.1063/5.0176422",
           2024,
           "Beamforming, an integral component of modern mobile networks, enables spatial selectivity and improves network quality. However, many beamforming techniques are iterative, introducing unwanted latency to the system. In recent times, there has been a growing interest in leveraging mobile users’ location information to expedite beamforming processes. This paper explores the concept of contextual beamforming, discussing its advantages, disadvantages, and implications. Notably, we demonstrate an impressive 53% improvement in the signal-to-interference-plus-noise ratio by implementing the adaptive beamforming maximum ratio transmission (MRT) algorithm compared to scenarios without beamforming. It further elucidates how MRT contributes to contextual beamforming. The importance of localization in implementing contextual beamforming is also examined. Additionally, the paper delves into the use of artificial intelligence (AI) schemes, including machine learning and deep learning, in implementing contextual beamforming techniques that leverage user location information. Based on the comprehensive review, the results suggest that the combination of MRT and zero-forcing techniques, alongside deep neural networks employing Bayesian optimization, represents the most promising approach for contextual beamforming. Furthermore, the study discusses the future potential of programmable switches, such as Tofino—an innovative switch developed by Barefoot Networks (now a part of Intel)—in enabling location-aware beamforming. This paper highlights the significance of contextual beamforming for improving wireless telecommunications performance. By capitalizing on location information and employing advanced AI techniques, the field can overcome challenges and unlock new possibilities for delivering reliable and efficient mobile networks.",
           1,
           "apl_machine_learning"
          ],
          [
           "Harnessing nonlinear conductive characteristic of TiO2/HfO2 memristor crossbar for implementing parallel vector–matrix multiplication",
           "10.1063/5.0195190",
           2024,
           "Memristor crossbar arrays are expected to achieve highly energy-efficient neuromorphic computing via implementing parallel vector–matrix multiplication (VMM) in situ. The similarities between memristors and neural synapses offer opportunities for realizing hardware-based brain-inspired computing, such as spike neural networks. However, the nonlinear I–V characteristics of the memristors limit the implementation of parallel VMM on passive memristor crossbar arrays. In our work, we propose to utilize differential conductance as a synaptic weight to implement linear VMM operations on a passive memristor array in parallel. We fabricated a TiO2/HfO2 memristor crossbar array, in which differential-conductance-based synaptic weight exhibits plasticity, nonvolatility, multi-states, and tunable ON/OFF ratio. The noise-dependent accuracy performance of VMM operations based on the proposed approach was evaluated, offering an optimization guideline. Furthermore, we demonstrated a spike neural network circuit capable of processing small spiking signals through the differential-conductance-based synapses. The experimental results showcase effective space-coded and time-coded spike pattern recognition. Importantly, our work opens up new possibilities for the development of passive memristor arrays, leading to increased energy and area efficiency in brain-inspired chips.",
           0,
           "apl_machine_learning"
          ],
          [
           "Unsupervised machine learning discovery of structural units and transformation pathways from imaging data",
           "10.1063/5.0147316",
           2023,
           "We show that unsupervised machine learning can be used to learn chemical transformation pathways from observational Scanning Transmission Electron Microscopy (STEM) data. To enable this analysis, we assumed the existence of atoms, a discreteness of atomic classes, and the presence of an explicit relationship between the observed STEM contrast and the presence of atomic units. With only these postulates, we developed a machine learning method leveraging a rotationally invariant variational autoencoder (VAE) that can identify the existing molecular fragments observed within a material. The approach encodes the information contained in STEM image sequences using a small number of latent variables, allowing the exploration of chemical transformation pathways by tracing the evolution of atoms in the latent space of the system. The results suggest that atomically resolved STEM data can be used to derive fundamental physical and chemical mechanisms involved, by providing encodings of the observed structures that act as bottom-up equivalents of structural order parameters. The approach also demonstrates the potential of variational (i.e., Bayesian) methods in the physical sciences and will stimulate the development of more sophisticated ways to encode physical constraints in the encoder–decoder architectures and generative physical laws and causal relationships in the latent space of VAEs.",
           2,
           "apl_machine_learning"
          ],
          [
           "In-memory and in-sensor reservoir computing with memristive devices",
           "10.1063/5.0174863",
           2024,
           "Despite the significant progress made in deep learning on digital computers, their energy consumption and computational speed still fall short of meeting the standards for brain-like computing. To address these limitations, reservoir computing (RC) has been gaining increasing attention across communities of electronic devices, computing systems, and machine learning, notably with its in-memory or in-sensor implementation on the hardware–software co-design. Hardware regarded, in-memory or in-sensor computers leverage emerging electronic and optoelectronic devices for data processing right where the data are stored or sensed. This technology dramatically reduces the energy consumption from frequent data transfers between sensing, storage, and computational units. Software regarded, RC enables real-time edge learning thanks to its brain-inspired dynamic system with massive training complexity reduction. From this perspective, we survey recent advancements in in-memory/in-sensor RC, including algorithm designs, material and device development, and downstream applications in classification and regression problems, and discuss challenges and opportunities ahead in this emerging field.",
           1,
           "apl_machine_learning"
          ],
          [
           "Resistance transient dynamics in switchable perovskite memristors",
           "10.1063/5.0153289",
           2023,
           "Memristor devices have been investigated for their properties of resistive modulation that can be used in data storage and brain-like computation elements as artificial synapses and neurons. Memristors are characterized by an onset of high current values under applied voltage that produces a transition to a low resistance state or successively to different stable states of increasing conductivity that implement synaptic weights. Here, we develop a nonlinear model to explain the variation with time of the voltage and the resistance and compare it to experimental results on ionic–electronic halide perovskite memristors. We find separate experimental signatures of the capacitive discharge and inductive current increase. We show that the capacitor produces an increase step of the resistance due to the influence of the series resistance. In contrast, the inductor feature associated with inverted hysteresis causes a decrease of the resistance, as observed experimentally. The chemical inductor feature dominates the potentiation effect in which the conductivity increases with the voltage stimulus. Our results enable a quantitative characterization of highly nonlinear electronic devices using a combination of techniques such as time transient decays and impedance spectroscopy.",
           9,
           "apl_machine_learning"
          ],
          [
           "Long-Term Outcomes of Dose-Escalated Hypofractionated Radiotherapy in Localized Prostate Cancer",
           "10.3390/biology11030435",
           2022,
           "This retrospective study aimed to provide some clinical outcomes regarding effectiveness, toxicity, and quality of life in PCa patients treated with dose-escalated moderately hypofractionated radiation therapy (HFRT). Patients received HFRT to a total dose of 66 Gy in 22 fractions (3 Gy/fraction) delivered via volume modulated arc therapy (VMAT) in 2011–2016. Treatment effectiveness was measured by the biochemical failure-free survival rate. Toxicity was assessed according to the criteria of the Radiation Therapy Oncology Group (RTOG) and quality of life according to the criteria of the European Organization for Research and Treatment of Cancer (EORTC). In this regard, quality of life (QoL) was measured longitudinally, at a median of 2 and 5 years after RT. Enrolled patients had low-risk (40.2%), intermediate-risk (47.5%), and high-risk (12.3%) PCa. Median follow-up was 75 months. The biochemical failure-free survival rate was 94.2%. The incidence of acute grade 2 or higher gastrointestinal (GI) and genitourinary (GU) toxicity was 9.84% and 28.69%, respectively. The incidence rate of late grade 2 or higher GI and GU toxicity was 1.64% and 4.10%, respectively. Expanded Prostate Cancer Index Composite (EPIC) scores showed that the majority of patients maintained their QoL. HFRT to 66 Gy with VMAT was associated with adequate biochemical control, low toxicity and good reported GU and GI quality of life.",
           0,
           "biology"
          ],
          [
           "Rational Design of an Orthogonal Pair of Bimolecular RNase P Ribozymes through Heterologous Assembly of Their Modular Domains",
           "10.3390/biology8030065",
           2019,
           "The modular structural domains of multidomain RNA enzymes can often be dissected into separate domain RNAs and their noncovalent assembly can often reconstitute active enzymes. These properties are important to understand their basic characteristics and are useful for their application to RNA-based nanostructures. Bimolecular forms of bacterial RNase P ribozymes consisting of S-domain and C-domain RNAs are attractive as platforms for catalytic RNA nanostructures, but their S-domain/C-domain assembly was not optimized for this purpose. Through analysis and engineering of bimolecular forms of the two bacterial RNase P ribozymes, we constructed a chimeric ribozyme with improved catalytic ability and S-domain/C-domain assembly and developed a pair of bimolecular RNase P ribozymes the assembly of which was considerably orthogonal to each other.",
           2,
           "biology"
          ],
          [
           "Acknowledgment to Reviewers of Biology in 2021",
           "10.3390/biology11020226",
           2022,
           "Rigorous peer-reviews are the basis of high-quality academic publishing [...]",
           0,
           "biology"
          ],
          [
           "Changes in Body Temperature Patterns Are Predictive of Mortality in Septic Shock: An Observational Study",
           "10.3390/biology12050638",
           2023,
           "Biological rhythms are important regulators of immune functions. In intensive care unit (ICU), sepsis is known to be associated with rhythm disruption. Our objectives were to determine factors associated with rhythm disruption of the body temperature and to assess the relationship between temperature and mortality in septic shock patients; In a cohort of septic shock, we recorded body temperature over a 24-h period on day 2 after ICU admission. For each patient, the temperature rhythmicity was assessed by defining period and amplitude, and the adjusted average (mesor) of the temperature by sinusoidal regression and cosinor analysis. Analyses were performed to assess factors associated with the three temperature parameters (period, amplitude, and mesor) and mortality. 162 septic shocks were enrolled. The multivariate analysis demonstrates that the period of temperature was associated with gender (women, coefficient −2.2 h, p = 0.031) and acetaminophen use (coefficient −4.3 h, p = 0.002). The mesor was associated with SOFA score (coefficient −0.05 °C per SOFA point, p = 0.046), procalcitonin (coefficient 0.001 °C per ng/mL, p = 0.005), and hydrocortisone use (coefficient −0.5 °C, p = 0.002). The amplitude was associated with the dialysis (coefficient −0.5 °C, p = 0.002). Mortality at day 28 was associated with lower mesor (adjusted hazard ratio 0.50, 95% CI 0.28 to 0.90; p = 0.02), and higher amplitude (adjusted hazard ratio 5.48, 95% CI 1.66 to 18.12; p = 0.005) of temperature. Many factors, such as therapeutics, influence the body temperature during septic shock. Lower mesor and higher amplitude were associated with mortality and could be considered prognostic markers in ICU. In the age of artificial intelligence, the incorporation of such data in an automated scoring alert could compete with physicians to identify high-risk patients during septic shock.",
           0,
           "biology"
          ],
          [
           "Characteristics of Neurokinin-3 Receptor and Its Binding Sites by Mutational Analysis",
           "10.3390/biology10100968",
           2021,
           "NKB (Neurokinin B) is already known to play a crucial role in fish reproduction, but little is known about the structure and function of NKB receptors. Based on an in silico model of the tilapia NKB receptor Tachykinin 3 receptor a (tiTac3Ra) found in the current study, we determined the key residues involved in binding to tilapia NKB and its functional homologue NKF (Neurokinin F). Despite studies in humans suggesting the crucial role of F2516.44 and M2897.43 in NKB binding, no direct peptide interaction was observed in tilapia homologs. In-silico, Ala mutations on residues F2516.44 and M2897.43 did not influence binding affinity, but significantly affected the stability of tiTac3Ra. Moreover, in vitro studies indicated them to be critical to tiNKB/tiNKF-induced receptor activity. The binding of NKB antagonists to tiTac3Ra both in-vitro and in vivo inhibits FSH (follicle stimulating hormone) and LH (luteinizing hormone) release and sperm production in mature tilapia males. Non-peptide NKB antagonist SB-222200 had a strong inhibitory effect on the Tac3Ra activation. SB-222200 also decreased LH plasma levels; two hours post intraperitoneal injection, changed sperm volume and the ratios of the different stages along the spermatogenesis in tilapia testes.",
           1,
           "biology"
          ],
          [
           "Age-Related Palatal Wound Healing: An Experimental In Vivo Study",
           "10.3390/biology10030240",
           2021,
           "We assessed age-related excisional palatal mucoperiosteal wound closure in rats. A 4.2 mm diameter punch was used to create a secondary healing defect in the palate of Wistar rats. Study group—21, 18-month-old vs. control 21, 2-month-old males. The 2-dimensional area, maximum length and width of the soft tissue defect served as clinical outcome parameters. The dynamics of the initial three healing weeks were assessed. Semi-quantitative histomorphometric analysis of inflammation and myofibroblasts served for the evaluation of the inflammatory and proliferative wound healing phases. Complete wound closure was faster in the old rats. A dimensional related wound closure was observed in the young rats versus a symmetrical wound closure in the old rats. Inflammatory response was significantly delayed and of lower intensity in the old rats. Myofibroblastic response, representing the proliferative stage, was delayed and of lower intensity in the old rats, albeit not statistically significant. Reduced initial tissue damage due to decreased and delayed inflammatory response in the old rats ultimately led to faster clinical wound healing compared to the young rats, despite a statistically non-significant lower proliferative response in the old rats.",
           2,
           "biology"
          ],
          [
           "Transvenous Lead Extraction in Patients with Cardiac Implantable Device: The Impact of Systemic and Local Infection on Clinical Outcomes—An ESC-EHRA ELECTRa (European Lead Extraction Controlled) Registry Substudy",
           "10.3390/biology11040615",
           2022,
           "Background: Infections of cardiac implantable devices (CIEDI) have poor outcomes despite improvement in lead extraction (TLE) procedures. Methods: To explore the influence of CIEDI on the outcomes of TLE and the differences between patients with systemic (Sy) vs. local (Lo) CIEDI, we performed a sub-analysis of the EORP ELECTRa (European Lead Extraction ConTRolled) Registry. Results: Among 3555 patients enrolled by 73 centers in 19 Countries, the indication for TLE was CIEDI in 1850: 1170 with Lo-CIEDI and 680 with Sy-CIEDI. Patients with CIEDI had a worse in-hospital prognosis in terms of major complications (3.57% vs. 1.71%; p = 0.0007) and mortality (2.27% vs. 0.49%; p < 0.0001). Sy-CIEDI was an independent predictor of in-hospital death (H.R. 2.14; 95%CI 1.06–4.33. p = 0.0345). Patients with Sy-CIEDI more frequently had an initial CIED implant and a higher prevalence of comorbidities, while subjects with Lo-CIEDI had a higher prevalence of previous CIED procedures. Time from signs of CIEDI and TLE was longer for Lo-CIEDI despite a shorter pre-TLE antibiotic treatment. Conclusions: Patients with CIEDI have a worse in-hospital prognosis after TLE, especially for patients with Sy-CIEDI. These results raise the suspicion that in a relevant group of patients CIEDI can be systemic from the beginning without progression from Lo-CIEDI. Future research is needed to characterize this subgroup of patients.",
           5,
           "biology"
          ],
          [
           "FLT3-ITD Allelic Burden and Acute Promyelocytic Leukemia Risk Stratification",
           "10.3390/biology10030243",
           2021,
           "The significance of FLT3-ITD in acute promyelocytic leukemia (APL) is not well-established. We performed a bi-center retrospective study of 138 APL patients, 59 (42.8%) of whom had FLT3-ITD. APL patients with FLT3-ITD had higher baseline white blood cell counts (WBCs) (p < 0.001), higher hemoglobin, (p = 0.03), higher aspartate aminotransferase (p = 0.001), lower platelets (p = 0.004), lower fibrinogen (p = 0.003), and higher incidences of disseminated intravascular coagulation (p = 0.005), M3v variant morphology (p < 0.001), and the bcr3 isoform (p < 0.001). FLT3-ITD was associated with inferior post-consolidation complete remission (CR) (p = 0.02) and 5-year overall survival (OS) of 79.7%, compared to 94.4% for FLT3-WT (wild-type) (p = 0.02). FLT3-ITD was strongly associated with baseline WBCs ≥ 25 × 109/L (odds ratio (OR): 54.4; 95% CI: 10.4–286.1; p < 0.001). High FLT3-ITD allelic burdens correlated with high-risk (HR) Sanz scores and high WBCs, with every 1% increase in allelic burden corresponding to a 0.6 × 109/L increase in WBC. HR APL was associated with a 38.5% increase in allelic burden compared with low-risk (LR) APL (95% CI: 19.8–57.2; p < 0.001). Our results provide additional evidence that FLT3-ITD APL is a distinct subtype of APL that warrants further study to delineate potential differences in therapeutic approach.",
           1,
           "biology"
          ],
          [
           "Ability of Adult Dermacentor reticulatus Ticks to Overwinter in the Temperate Climate Zone",
           "10.3390/biology9070145",
           2020,
           "Dermacentor reticulatus ticks, one of the most important vectors and reservoirs of tick-borne diseases in Europe, are widespread in the temperate climate zone and in some localities in the subtropical climate zone of the western Palaearctic region. These ticks occur in a large area characterised by a varied climate type, vegetation, and availability of potential hosts. Hence, they exhibit high ecological plasticity and adaptability to periodically adverse conditions. The aim of the present study was to investigate the ability of D. reticulatus adults to overwinter in the natural habitat. Specimens marked with a permanent oil marker on the festoons were placed in their natural habitats for the winter. Concurrently, tick survival in laboratory conditions at a temperature of 5 °C and 18 °C was assessed as a control. The groups were compared with each other by determination of the weight of fat bodies. In the field conditions, 67.9% females and 60.0% males survived the winter. There was no significant difference in the survival of ticks in the laboratory. A significantly lower fat body weight was found in the group of ticks overwintering in the field conditions and exhibiting questing activity between spring and late autumn during the following year. On the population scale, adult D. reticulatus ticks are able to survive the winter in temperate climate conditions at a level ensuring a further increase in their population size. In adverse weather conditions, ticks enter diapause, thus maximally reducing the utilisation of the content of their fat bodies. This facilitates long-term survival in the environment.",
           3,
           "biology"
          ],
          [
           "Characterization of Perionyx excavatus Development and Its Head Regeneration",
           "10.3390/biology9090273",
           2020,
           "Regeneration is a biological process restoring lost or amputated body parts. The capability of regeneration varies among organisms and the regeneration of the central nervous system (CNS) is limited to specific animals, including the earthworm Perionyx excavatus. Thus, it is crucial to establish P. excavatus as a model system to investigate mechanisms of CNS regeneration. Here, we set up a culture system to sustain the life cycle of P. excavatus and characterize the development of P. excavatus, from embryo to juvenile, based on its morphology, myogenesis and neurogenesis. During development, embryos have EdU-positive proliferating cells throughout the whole body, whereas juveniles maintain proliferating cells exclusively in the head and tail regions, not in the trunk region. Interestingly, juveniles amputated at the trunk, which lacks proliferating cells, are able to regenerate the entire head. In this process, a group of cells, which are fully differentiated, reactivates cell proliferation. Our data suggest that P. excavatus is a model system to study CNS regeneration, which is dependent on the dedifferentiation of cells.",
           3,
           "biology"
          ],
          [
           "The Effects of Obesity on the Inflammatory, Cardiovascular, and Neurobiological Responses to Exercise in Older Adults",
           "10.3390/biology12060865",
           2023,
           "Obesity with advancing age leads to increased health complications that are involved in various complex physiological processes. For example, inflammation is a critical cardiovascular disease risk factor that plays a role in the stages of atherosclerosis in both aging and obesity. Obesity can also induce profound changes to the neural circuitry that regulates food intake and energy homeostasis with advancing age. Here we discuss how obesity in older adults impacts inflammatory, cardiovascular, and neurobiological functions with an emphasis on how exercise mediates each topic. Although obesity is a reversible disorder through lifestyle changes, it is important to note that early interventions are crucial to prevent pathological changes seen in the aging obese population. Lifestyle modifications such as physical activity (including aerobic and resistance training) should be considered as a main intervention to minimize the synergistic effect of obesity on age-related conditions, such as cerebrovascular disease.",
           0,
           "biology"
          ],
          [
           "Hotspot siRNA Confers Plant Resistance against Viral Infection",
           "10.3390/biology11050714",
           2022,
           "A hallmark of antiviral RNA interference (RNAi) is the production of viral small interfering RNA (vsiRNA). Profiling of vsiRNAs indicates that certain regions of viral RNA genome or transcribed viral RNA, dubbed vsiRNA hotspots, are more prone to RNAi-mediated cleavage for vsiRNA biogenesis. However, the biological relevance of hotspot vsiRNAs to the host innate defence against pathogens remains to be elucidated. Here, we show that direct targeting a hotspot by a synthetic vsiRNA confers host resistance to virus infection. Using Northern blotting and RNAseq, we obtained a profile of vsiRNAs of the African cassava mosaic virus (ACMV), a single-stranded DNA virus. Sense and anti-sense strands of small RNAs corresponding to a hotspot and a coldspot vsiRNA were synthesised. Co-inoculation of Nicotiana benthamiana with the double-stranded hotspot siRNA protected plants from ACMV infection, where viral DNA replication and accumulation of viral mRNA were undetectable. The sense or anti-sense strand of this hotspot vsiRNA, and the coldspot vsiRNA in both double-stranded and single-stranded formats possessed no activity in viral protection. We further demonstrated that the hotspot vsiRNA-mediated virus resistance had a threshold effect and required an active RDR6. These data show that hotspot vsiRNAs bear a functional significance on antiviral RNAi, suggesting that they may have the potential as an exogenous protection agent for controlling destructive viral diseases in plants.",
           2,
           "biology"
          ],
          [
           "Secretion of Interleukin 6 in Human Skeletal Muscle Cultures Depends on Ca2+ Signalling",
           "10.3390/biology12070968",
           2023,
           "The systemic effects of physical activity are mediated by the release of IL-6 and other myokines from contracting muscle. Although the release of IL-6 from muscle has been extensively studied, the information on the cellular mechanisms is fragmentary and scarce, especially regarding the role of Ca2+ signals. The aim of this study was to characterize the role of the main components of Ca2+ signals in human skeletal muscle cells during IL-6 secretion stimulated by the Ca2+ mobilizing agonist ATP. Primary cultures were prepared from surgical samples, fluorescence microscopy was used to evaluate the Ca2+ signals and the stimulated release of IL-6 into the medium was determined using ELISA. Intracellular calcium chelator Bapta, low extracellular calcium and the Ca2+ channels blocker La3+ reduced the ATP-stimulated, but not the basal secretion. Secretion was inhibited by blockers of L-type (nifedipine, verapamil), T-type (NNC55-0396) and Orai1 (Synta66) Ca2+ channels and by silencing Orai1 expression. The same effect was achieved with inhibitors of ryanodine receptors (ryanodine, dantrolene) and IP3 receptors (xestospongin C, 2-APB, caffeine). Inhibitors of calmodulin (calmidazolium) and calcineurin (FK506) also decreased secretion. IL-6 transcription in response to ATP was not affected by Bapta or by the T channel blocker. Our results prove that ATP-stimulated IL-6 secretion is mediated at the post-transcriptional level by Ca2+ signals, including the mobilization of calcium stores, the activation of store-operated Ca2+ entry, and the subsequent activation of voltage-operated Ca2+ channels and calmodulin/calcineurin pathways.",
           0,
           "biology"
          ],
          [
           "Survival Analysis after Living Donor Liver Transplantation for Hepatocellular Carcinoma: A Single Center Cohort Study",
           "10.3390/biology10050446",
           2021,
           "Background: Living-donor liver transplantation (LDLT) for hepatocellular carcinoma (HCC) has been used as a curative treatment option for hepatocellular carcinoma (HCC) because of a shortage of deceased donors. This study aimed to investigate survival outcomes after LDLT for HCC. Method: This study included 359 patients undergoing LDLT for HCC. We analyzed overall survival (OS) and recurrence-free survival (RFS) and the prognostic factors related to them. Results: The 5-year OS and RFS rates of patients within the Milan criteria (WM) were better than those of patients beyond the Milan criteria (BM) (87.3% vs. 64.1% and 87.6% vs. 57.8%, respectively, both p < 0.05). Alpha-fetoprotein level (AFP) > 400 ng/mL (hazard ratio (HR), 2.07; 95% CI, 1.28–3.36; p < 0.05) and HCC of BM (HR, 2.61; 95% CI, 1.60–4.26; p < 0.05) at immediate pretransplant were independent risk factors of OS. AFP > 400 ng/mL (HR, 2.16; 95% CI, 1.34–3.49; p < 0.05) and HCC of BM (HR, 3.01; 95% CI, 1.81–5.01; p < 0.05) were also independent risk factors of RFS. In pathologic findings of explanted liver, tumor size, Edmondson–Steiner grade III–IV, and microvascular invasion were independent risk factors of both OS and RFS (p < 0.05). Conclusions: BM and AFP > 400 ng/mL at immediate pretransplant are unfavorable predictors of survival outcomes after LDLT for HCC.",
           1,
           "biology"
          ],
          [
           "Human Cytomegalovirus Infection Induces High Expression of Prolactin and Prolactin Receptors in Ovarian Cancer",
           "10.3390/biology9030044",
           2020,
           "One of the potential biomarkers for ovarian cancer patients is high serum level of prolactin (PRL), which is a growth factor that may promote tumor cell growth. The prolactin receptor (PRLR) and human cytomegalovirus (HCMV) proteins are frequently detected in ovarian tumor tissue specimens, but the potential impact of HCMV infection on the PRL system have so far not been investigated. In this study, HCMV’s effects on PRL and PRLR expression were assessed in infected ovarian cancer cells (SKOV3) by PCR and Western blot techniques. The levels of both PRL and PRLR transcripts as well as the corresponding proteins were highly increased in HCMV-infected SKOV3 cells. Tissue specimens obtained from 10 patients with ovarian cancer demonstrated high expression of PRLR, HCMV-IE, and pp65 proteins. Extensive expression of PRLR was detected in all examined ovarian tumor tissue specimens except for one from a patient who had focal expression of PRLR and this patient was HCMV-negative in her tumor. In conclusion, PRL and PRLR were induced to high levels in HCMV-infected ovarian cancer cells and PRLR expression was extensively detected in HCMV-infected ovarian tissue specimens. Highly induced PRL and PRLR by HCMV infection may be of relevance for the oncomodulatory role of this virus in ovarian cancer.",
           8,
           "biology"
          ],
          [
           "Ability of the ISAS3Fun Method to Detect Sperm Acrosome Integrity and Its Potential to Discriminate between High and Low Field Fertility Bulls",
           "10.3390/biology10111135",
           2021,
           "The objective of the present study was to investigate whether fertility differences in bulls are reflected in variations of sperm quality when analysing only one ejaculate per male. Two experiments were performed. In the first experiment, frozen semen samples from 20 adult bulls were tested; 10 bulls had high field fertility and 10 bulls had low field fertility. Analyses of sperm motility, membrane integrity, and membrane–acrosome integrity with the ISAS3Fun method were performed. Sperm morphometry of the fluorescence sperm subpopulations obtained with the ISAS3Fun method was also analysed. Significant differences between high- and low-fertility groups were only found with the ISAS3Fun technique, specifically in sperm acrosome integrity, the proportion of spermatozoa with an intact acrosome and damaged membrane, and in sperm head width of spermatozoa with intact structures. Discriminant analyses allowed us to correctly classify 90% of sperm samples in their fertility group using sperm quality parameters. Given that only the results obtained with the ISAS3Fun technique were related to bull fertility, we performed a second experiment aimed to validate the efficacy of this technique to detect the acrosomal integrity of bull spermatozoa, comparing them with the conventional FITC-PNA/propidium iodide (PNA/PI) combination under capacitating conditions. The results indicated that the ISAS3Fun combination provided an accurate assessment of both viability and acrosomal integrity for ejaculated spermatozoa, while the PNA/PI combination underestimated the extension of acrosomal damage due to false negatives. It was concluded that the simultaneous assessment of sperm plasma membranes and acrosome integrity with the ISAS3Fun method is precise and seems to have a greater potential to discriminate between high- and low-fertility bulls than more conventional in vitro sperm quality tests.",
           3,
           "biology"
          ],
          [
           "Behavioral Avoidance Response of Daphnia to Fungal Infection Caused by Metschnikowia Species in a Temperate Reservoir",
           "10.3390/biology11101409",
           2022,
           "Morphological or behavioral defense mechanisms are important evolutionary strategies for the survival of prey. Studies have focused on predation and competition, but infection has been overlooked, despite being a determining factor of distribution and species diversity of prey. We hypothesized that the winter migration of Daphnia pulicaria is a community defense strategy to avoid fungal infection. To test this hypothesis, environmental variables and the Cladocera community, including D. pulicaria, were monitored in three study sections of the Anri Reservoir in the Republic of Korea during September 2010–August 2015. During three winter seasons, the density of infected D. pulicaria increased in all study sections, and they migrated from the central to the littoral area. Most of the infected individuals had dormant eggs in sexually reproducing mothers. However, when the proportion of non-infected individuals was higher than that of infected individuals, winter migration was not observed. Additional microcosm experiments showed that dormant eggs of D. pulicaria obtained from ice crystals in the littoral area had lower hatching and infection rates than those obtained from mothers moving from other zones. Therefore, the migration of D. pulicaria during winter is an active response to avoid intergenerational fungal infection.",
           0,
           "biology"
          ],
          [
           "CiberAMP: An R Package to Identify Differential mRNA Expression Linked to Somatic Copy Number Variations in Cancer Datasets",
           "10.3390/biology11101411",
           2022,
           "Somatic copy number variations (SCNVs) are genetic alterations frequently found in cancer cells. These genetic alterations can lead to concomitant perturbations in the expression of the genes included in them and, as a result, promote a selective advantage to cancer cells. However, this is not always the case. Due to this, it is important to develop in silico tools to facilitate the accurate identification and functional cataloging of gene expression changes associated with SCNVs from pan-cancer data. Here, we present a new R-coded tool, designated as CiberAMP, which utilizes genomic and transcriptomic data contained in the Cancer Genome Atlas (TCGA) to identify such events. It also includes information on the genomic context in which such SCNVs take place. By doing so, CiberAMP provides clues about the potential functional relevance of each of the SCNV-associated gene expression changes found in the interrogated tumor samples. The main features and advantages of this new algorithm are illustrated using glioblastoma data from the TCGA database.",
           0,
           "biology"
          ],
          [
           "Sensitivity and Specificity of Patient-Reported Clinical Manifestations to Diagnose COVID-19 in Adults from a National Database in Chile: A Cross-Sectional Study",
           "10.3390/biology11081136",
           2022,
           "(1) Background: The diagnosis of COVID-19 is frequently made on the basis of a suggestive clinical history and the detection of SARS-CoV-2 RNA in respiratory secretions. However, the diagnostic accuracy of clinical features is unknown. (2) Objective: To assess the diagnostic accuracy of patient-reported clinical manifestations to identify cases of COVID-19. (3) Methodology: Cross-sectional study using data from a national registry in Chile. Infection by SARS-CoV-2 was confirmed using RT-PCR in all cases. Anonymised information regarding demographic characteristics and clinical features were assessed using sensitivity, specificity, and diagnostic odds ratios. A multivariable logistic regression model was constructed to combine epidemiological risk factors and clinical features. (4) Results: A total of 2,187,962 observations were available for analyses. Male participants had a mean age of 43.1 ± 17.5 years. The most common complaints within the study were headache (39%), myalgia (32.7%), cough (31.6%), and sore throat (25.7%). The most sensitive features of disease were headache, myalgia, and cough, and the most specific were anosmia and dysgeusia/ageusia. A multivariable model showed a fair diagnostic accuracy, with a ROC AUC of 0.744 (95% CI 0.743–0.746). (5) Discussion: No single clinical feature was able to fully confirm or exclude an infection by SARS-CoV-2. The combination of several demographic and clinical factors had a fair diagnostic accuracy in identifying patients with the disease. This model can help clinicians tailor the probability of COVID-19 and select diagnostic tests appropriate to their setting.",
           1,
           "biology"
          ],
          [
           "Pathobiology of Second-Generation Antihistamines Related to Sleep in Urticaria Patients",
           "10.3390/biology11030433",
           2022,
           "Background: Standard treatment options for urticaria are second-generation antihistamines; however, their effect on sleep is uncertain. This study measures the influence of different antihistamines on the biologic sleep pattern of urticaria patients and the relevance of sleep in urticaria patients. Methods: Ten patients with chronic spontaneous urticaria (CSU) and uncontrolled symptoms under a single dose of second-generation antihistamines were included. Two nights were monitored: the first night after 5 days on single dosage and the second night after 5 days on fourfold dosage. Patient-rated questionnaires were used and sleep was monitored using polygraphy. Results: The patients’ rated daytime sleepiness decreased (p = 0.0319), as did their insomnia severity (p = 0.0349). The urticaria control (UCT) improved (p = 0.0007), as did the quality of life (p < 0.0001). There was no significant change of nightly pruritus (p = 0.1173), but there was an improvement of daytime pruritus (p = 0.0120). A significant increase in rapid eye movement (REM) sleep was seen (p = 0.0002) (from a mean of 3.9% to 14.3%). The deep sleep state (N3) also improved (8.7% to 12.3%) (p = 0.1172). Conclusion: This study has demonstrated an improvement of the sleep pattern in CSU patients under up-dosed second-generation antihistamines, without increased daytime sleepiness, alongside an improvement of urticaria symptoms and quality of life.",
           0,
           "biology"
          ],
          [
           "Demonstrative Experiment on the Favorable Effects of Static Electric Field Treatment on Vitamin D3-Induced Hypercalcemia",
           "10.3390/biology10111116",
           2021,
           "The purpose of this study was to elucidate the effects of static electric field (SEF) treatment on vitamin D3 (Vit D3)-induced hypercalcemia and renal calcification in mice. The mice were assigned to three groups: Vit D3-treated mice, mice treated with Vit D3 and SEF (Vit D3 + SEF), and untreated mice. After the administration of Vit D3, the Vit D3 + SEF-treated mice were exposed to SEF treatment by a high-voltage alternating current over five days. Serum biochemical examinations revealed that both the creatinine and blood urea nitrogen concentrations were significantly higher in the Vit D3-treated group. Significantly, decreased Cl concentrations, and increased Ca and inorganic phosphorus concentrations, were found in the Vit D3-treated group. In the Vit D3 + SEF-treated group, these parameters returned to the levels of the untreated group. In the Vit D3-treated group, histopathological examinations showed marked multifocal calcification in the lumens of the renal tubules and the renal parenchyma. The myocardium was replaced by abundant granular mineralization (calcification), with degeneration and necrosis of the calcified fibers. The stomach showed calcification of the cardiac mucosa. SEF treatment remarkably attenuated the Vit D3-induced hypervitaminotic injuries. In conclusion, this study provides important evidence that SEF treatment can reduce hypercalcemia and remove calcium deposits from the renal, cardiac, and gastric tissues. SEF treatment is useful in the regulation of disorders caused by an imbalance of serum electrolytes.",
           0,
           "biology"
          ],
          [
           "Obesity and Metabolic Traits after High-Fat Diet in Iberian Pigs with Low Birth Weight of Placental Origin",
           "10.3390/biology11101533",
           2022,
           "Intrauterine growth restriction (IUGR) and later obesity and metabolic disorders have classically been associated with maternal malnutrition, but most cases of IUGR are related to placental insufficiency. The current study, using a swine model for IUGR and obesity, aimed to determine the interaction of birth weight (categorized as low birth weight [LBW] or normal birth-weight [NBW]) and postnatal diet (categorized as maintenance diet [MD] or fattening diet [FD]) on body weight, adiposity and metabolic traits. FD induced higher body weight and adiposity (both p < 0.0001), with higher fructosamine levels (p < 0.005) and a trend toward higher HOMA-β index (p = 0.05). NBW pigs remained heavier than LBW pigs during the early juvenile period (p < 0.005), but there were no differences at later stages. There were no differences in metabolic traits during juvenile development, but there were differences in adulthood, when LBW pigs showed higher glucose and lower insulin levels than NBW pigs (both p < 0.05). These results suggest that (a) FD allows LBW offspring to achieve similar obesity in adulthood as NBW offspring, and (b) glucose metabolism is more compromised in obese LBW than obese NBW pigs. The comparison of our data with previous studies highlights significant differences between offspring with LBW induced by maternal malnutrition or placental insufficiency, which should be considered when studying the condition.",
           0,
           "biology"
          ],
          [
           "Associations between Fat Mass and Fat Free Mass with Physical Fitness in Adolescent Girls: A 3-Year Longitudinal Study",
           "10.3390/biology11050783",
           2022,
           "The main purpose of the study was to examine the longitudinal associations between fat mass and fat free mass with health-related physical fitness. Two-hundred and forty 15-year old adolescent girls were measured at the baseline and after a period of 3 years (17 years). Health-related physical fitness included the following tests: (1) explosive power of the lower extremities (standing broad jump); (2) muscle endurance of the trunk (sit-ups in 60 s); (3) flexibility (sit-and-reach test); (4) muscle endurance of the lower extremities (squats in 60 s); (5) aerobic endurance (the 800 m run test); and (6) speed endurance (the 400 m running test). Fat mass and fat free mass were assessed using the bioelectrical impedance method. Longitudinal associations were analyzed with linear mixed model estimates. After adjusting for body mass index, fat mass was negatively associated with standing broad jump (β = −1.13, p < 0.001), sit-ups in 60 s (β = −0.27, p < 0.001), and squats in 60 s (β = −0.27, p < 0001), while positive associations with the 800 m running test (β = 0.02, p < 0.001) and the 400 m running test (β = 0.02, p < 0.001) were observed. On the other hand, fat free mass was positively associated with standing broad jump (β = 1.14, p < 0.001), sit-ups in 60 s (β = 0.28, p < 0.001), and squats in 60 s (β = 0.28, p < 0001), while the 800 m running test (β = −0.02, p < 0.001) and the 400 m running test (β = −0.02, p < 0.001) exhibited negative associations. This study shows that fat mass and fat free mass components are longitudinally, but oppositely associated with health-related physical fitness in adolescent girls.",
           4,
           "biology"
          ],
          [
           "Hide-and-Seek with Tiny Neotenic Beetles in One of the Hottest Biodiversity Hotspots: Towards an Understanding of the Real Diversity of Jurasaidae (Coleoptera: Elateroidea) in the Brazilian Atlantic Forest",
           "10.3390/biology10050420",
           2021,
           "Jurasaidae are a family of neotenic elateroid beetles which was described recently from the Brazilian Atlantic Forest biodiversity hotspot based on three species in two genera. All life stages live in the soil, including the larviform females, and only adult males are able to fly. Here, we report the discovery of two new species, Jurasai miraculum sp. nov. and J. vanini sp. nov., and a new, morphologically remarkable population of J. digitusdei Rosa et al., 2020. Our discovery sheds further light on the diversity and biogeography of the group. Most species of Jurasaidae are known from the rainforest remnants of the Atlantic Forest, but here for the first time we report a jurasaid species from the relatively drier Atlantic Forest/Caatinga transitional zone. Considering our recent findings, minute body size and cryptic lifestyle of all jurasaids, together with potentially high numbers of yet undescribed species of this family from the Atlantic Forest and possibly also other surrounding ecoregions, we call for both field research in potentially suitable localities as well as for a detailed investigation of a massive amount of already collected but still unprocessed materials deposited in a number of Brazilian institutes, laboratories and collections.",
           7,
           "biology"
          ],
          [
           "Idebenone Decreases Aβ Pathology by Modulating RAGE/Caspase-3 Signaling and the Aβ Degradation Enzyme NEP in a Mouse Model of AD",
           "10.3390/biology10090938",
           2021,
           "The coenzyme Q10 analogue idebenone is an FDA-approved antioxidant that can cross the blood–brain barrier (BBB). The effects of idebenone on the pathology of Alzheimer’s disease (AD) and the underlying molecular mechanisms have not been comprehensively investigated. Here, we examined the impact of idebenone treatment on AD pathology in 5xFAD mice, a model of AD. Idebenone significantly downregulated Aβ plaque number via multi-directional pathways in this model. Specifically, idebenone reduced the RAGE/caspase-3 signaling pathway and increased levels of the Aβ degradation enzyme NEP and α-secretase ADAM17 in 5xFAD mice. Importantly, idebenone significantly suppressed tau kinase p-GSK3βY216 levels, thereby inhibiting tau hyperphosphorylation at Thr231 and total tau levels in 5xFAD mice. Taken together, the present study indicates that idebenone modulates amyloidopathy and tauopathy in 5xFAD mice, suggesting therapeutic potential for AD.",
           7,
           "biology"
          ],
          [
           "Suspension of Amorphous Calcium Phosphate Nanoparticles Impact Commitment of Human Adipose-Derived Stem Cells In Vitro",
           "10.3390/biology10070675",
           2021,
           "Amorphous calcium phosphate (aCaP) nanoparticles may trigger the osteogenic commitment of adipose-derived stem cells (ASCs) in vitro. The ASCs of three human donors are investigated using basal culture medium DMEM to either 5 or 50 µg/mL aCaP nanoparticles suspension (control: no nanoparticles). After 7 or 14 days, stem cell marker genes, as well as endothelial, osteogenic, chondrogenic, and adipogenic genes, are analyzed by qPCR. Free calcium and phosphate ion concentrations are assessed in the cell culture supernatant. After one week and 5 µg/mL aCaP, downregulation of osteogenic markers ALP and Runx2 is found, and averaged across the three donors. Our results show that after two weeks, ALP is further downregulated, but Runx2 is upregulated. Endothelial cell marker genes, such as CD31 and CD34, are upregulated with 50 µg/mL aCaP and a 2-week exposure. Inter-donor variability is high: Two out of three donors show a significant upregulation of ALP and Runx2 at day 14 with 50 µg/mL aCaP compared to 5 µg/mL aCaP. Notably, all changes in stem cell commitment are obtained in the absence of an osteogenic medium. While the chemical composition of the culture medium and the saturation status towards calcium phosphate phases remain approximately the same for all conditions, gene expression of ASCs changes considerably. Hence, aCaP nanoparticles show the potential to trigger osteogenic and endothelial commitment in ASCs.",
           1,
           "biology"
          ],
          [
           "Repurposing of Antibiotic Sulfisoxazole Inhibits Lipolysis in Pre-Clinical Model of Cancer-Associated Cachexia",
           "10.3390/biology10080700",
           2021,
           "Clinical management of cancer-associated cachexia, a multi-organ wasting syndrome, has been challenging without effective treatment strategies. An effective treatment that directly targets cancer-induced wasting is desperately needed to improve the quality of life and the survival of cancer patients. Recently, an antibiotic SFX was shown to have anti-tumour and anti-metastatic effects in mouse models of breast cancer. Hence, in this study, we examined the efficacy of SFX in the treatment of cancer-induced cachexia. C26 cachexic mice models were administered with SFX, and the tumour volume and body weight were regularly measured. Blood glucose, skeletal muscles, and adipose tissue were examined at the endpoint. Contrary to a previous study, SFX did not reduce the tumour volume in mice bearing C26 cells. Administration of SFX neither revealed any survival benefit nor rescued C26 cachectic mice from muscle wasting. Interestingly, SFX administration partially rescued (~10%) tumour-induced weight loss by preserving both the subcutaneous and intestinal fat mass. Together, these results suggest that the administration of SFX could partially rescue cancer-induced weight loss by inhibiting lipolysis. As anti-cachexia therapies are scarce, the results could facilitate the design of combinatorial therapies involving SFX, standard-of-care chemotherapeutics, and drugs that inhibit muscle atrophy for the treatment of cancer cachexia.",
           1,
           "biology"
          ],
          [
           "Zipper Is Necessary for Branching Morphogenesis of the Terminal Cells in the Drosophila melanogaster’s Tracheal System",
           "10.3390/biology10080729",
           2021,
           "Branching morphogenesis and seamless tube formation in Drosophila melanogaster are essential for the development of vascular and tracheal systems, and instructive in studying complex branched structures such as human organs. Zipper is a myosin II’s actin-binding heavy chain; hence, it is important for contracting actin, cell proliferation, and cell sheet adhesion for branching of the tracheal system in post-larval development of the D. melanogaster. Nevertheless, the specific role of Zipper in the larva is still in question. This paper intended to investigate the specific role of Zipper in branching morphogenesis and lumenogenesis in early developmental stages. It did so by checking the localization of the protein in the cytoplasm of the terminal cells and also by analyzing the morphology of zipper RNAi loss-of-function mutants in regard to branching and lumen formation in the terminal cells. A rescue experiment of RNAi mutants was also performed to check the sufficiency of Zipper in branching morphogenesis. Confocal imaging showed the localization of Zipper in the cytoplasm of the terminal cells, and respective quantitative analyses demonstrated that zipper RNAi terminal cells develop significantly fewer branches. Such a result hinted that Zipper is required for the regulation of branching in the terminal cells of D. melanogaster. Nevertheless, Zipper is not significantly involved in the formation of seamless tubes. One hypothesis is that Zipper’s contractility at the lateral epidermis’ leading edge allows cell sheet movement and respective elongation; as a result of such an elongation, further branching may occur in the elongated region of the cell, hence defining branching morphogenesis in the terminal cells of the tracheal system.",
           1,
           "biology"
          ],
          [
           "Correction: Wang et al. TERT Promoter Revertant Mutation Inhibits Melanoma Growth through Intrinsic Apoptosis. Biology 2022, 11, 141",
           "10.3390/biology11101400",
           2022,
           "The authors would like to make the following correction to the published paper [...]",
           0,
           "biology"
          ],
          [
           "Temporary Survival Increasing the Diversity of Culturable Heterotrophic Bacteria in the Newly Exposed Moraine at a Glacier Snout",
           "10.3390/biology11111555",
           2022,
           "Laohugou Glacier No. 12 is located on the northern slope of the western Qilian Mountains with a temperate continental wet climate and an extremely cold winter. Bacteria in a newly exposed moraine have to cope with various pressures owing to deglaciation at the glacier snout. However, limited information is available regarding the high diversity and temporary survival of culturable heterotrophic bacteria under various environmental stresses. To examine the tolerance of extremophiles against varying environmental conditions in a newly exposed moraine, we simulated environmental stress in bacterial cultures. The results showed that the isolated strains belonged to actinobacteria, Proteobacteria, Bacteroidetes, Deinococcus-Thermus, and Firmicutes. Actinobacteria was the most abundant phylum, followed by Proteobacteria, at both high and low temperatures. Pseudarthrobacter was the most abundant genus, accounting for 14.2% of the total isolates. Although several microorganisms grew at 10 °C, the proportion of microorganisms that grew at 25 °C was substantially higher. In particular, 50% of all bacterial isolates grew only at a high temperature (HT), whereas 21.4% of the isolates grew at a low temperature (LT), and 38.6% of the isolates grew at both HT and LT. In addition, many radiation-resistant extremophiles were identified, which adapted to both cold and oxidative conditions. The nearest neighbors of approximately >90% of bacteria belonged to a nonglacial environment, such as oil-contaminated soil, rocks, and black sand, instead of glacial niches. This study provides insights into the ecological traits, stress responses, and temporary survival of culturable heterotrophic bacteria in a newly exposed moraine with variable environmental conditions and the relationship of these communities with the non-glacial environment. This study may help to understand the evolution, competition, and selective growth of bacteria in the transition regions between glaciers and retreats in the context of glacier melting and retreat owing to global warming.",
           0,
           "biology"
          ],
          [
           "Genetic Stability Assessment of Six Cryopreserved Strawberry (Fragaria × ananassa Duch.) Accessions by Phenotypic and Molecular Studies",
           "10.3390/biology11121746",
           2022,
           "For the long-term preservation of genetic resources, cryopreservation techniques have been developed for strawberry germplasm, mainly using in vitro-grown shoot tips. In this study, genetic stability was tested under greenhouse conditions for six strawberry accessions (IT232511, PHS0132, IT245810, IT245830, IT245852, and IT245860) derived from the following procedures: (1) conventional propagation (GH: greenhouse maintained); (2) in vitro propagation (TC: tissue culture); (3) pretreatment before cryopreservation (−LN: non-liquid nitrogen exposure); and (4) cryopreservation (+LN: liquid nitrogen exposure). To test the performance of phenotypic traits, we measured six vegetative and five fruit traits. There were no distinct differences in most of the characteristics, but a few traits, such as sugar content and pH of fruits in three accessions, showed higher values in +LN compared to GH. However, the differences disappeared in the first runner generation. To test genetic variations, a total of 102 bands were generated by twelve inter simple sequence repeat (ISSR) primers. A few polymorphic bands were found only in plants derived from TC of IT245860, which was not cryopreserved. The sequencing analysis of four polymorphic bands produced by ISSR_15 showed that none of these sequences matched the characterized genes in NCBI. Phenotypic abnormality was not observed across all plants. This study indicates that cryopreserved plants of the six strawberry accessions are phenotypically and genetically stable. Therefore, the results of this study can help to implement cryobanking of strawberry germplasm.",
           0,
           "biology"
          ],
          [
           "Immunohistochemical Characterization of the Nervous System of Culex pipiens (Diptera, Culicidae)",
           "10.3390/biology11010057",
           2022,
           "Arthropod-borne diseases represent one of the greatest infection-related threats as a result of climate change and globalization. Repeatedly, arbovirus-infected mosquitoes show behavioral changes whose underlying mechanisms are still largely unknown, but might help to develop control strategies. However, in contrast to well-characterized insects such as fruit flies, little is known about neuroanatomy and neurotransmission in mosquitoes. To overcome this limitation, the study focuses on the immunohistochemical characterization of the nervous system of Culex pipiens biotype molestus in comparison to Drosophila melanogaster using 13 antibodies labeling nervous tissue, neurotransmitters or neurotransmitter-related enzymes. Antibodies directed against γ-aminobutyric acid, serotonin, tyrosine-hydroxylase and glutamine synthetase were suitable for investigations in Culex pipiens and Drosophila melanogaster, albeit species-specific spatial differences were observed. Likewise, similar staining results were achieved for neuronal glycoproteins, axons, dendrites and synaptic zones in both species. Interestingly, anti-phosphosynapsin and anti-gephyrin appear to represent novel markers for synapses and glial cells, respectively. In contrast, antibodies directed against acetylcholine, choline acetyltransferase, elav and repo failed to produce a signal in Culex pipiens comparable to that in Drosophila melanogaster. In summary, present results enable a detailed investigation of the nervous system of mosquitoes, facilitating further studies of behavioral mechanisms associated with arboviruses in the course of vector research.",
           2,
           "biology"
          ],
          [
           "A Model of the Early Visual System Based on Parallel Spike-Sequence Detection, Showing Orientation Selectivity",
           "10.3390/biology10080801",
           2021,
           "Since the first half of the twentieth century, numerous studies have been conducted on how the visual cortex encodes basic image features. One of the hallmarks of basic feature extraction is the phenomenon of orientation selectivity, of which the underlying neuronal-level computational mechanisms remain partially unclear despite being intensively investigated. In this work we present a reduced visual system model (RVSM) of the first level of scene analysis, involving the retina, the lateral geniculate nucleus and the primary visual cortex (V1), showing orientation selectivity. The detection core of the RVSM is the neuromorphic spike-decoding structure MNSD, which is able to learn and recognize parallel spike sequences and considerably resembles the neuronal microcircuits of V1 in both topology and operation. This structure is equipped with plasticity of intrinsic excitability to embed recent findings about V1 operation. The RVSM, which embeds 81 groups of MNSD arranged in 4 oriented columns, is tested using sets of rotated Gabor patches as input. Finally, synthetic visual evoked activity generated by the RVSM is compared with real neurophysiological signal from V1 area: (1) postsynaptic activity of human subjects obtained by magnetoencephalography and (2) spiking activity of macaques obtained by multi-tetrode arrays. The system is implemented using the NEST simulator. The results attest to a good level of resemblance between the model response and real neurophysiological recordings. As the RVSM is available online, and the model parameters can be customized by the user, we propose it as a tool to elucidate the computational mechanisms underlying orientation selectivity.",
           2,
           "biology"
          ],
          [
           "Comparative Analysis and Phylogenetic Relationships of Ceriops Species (Rhizophoraceae) and Avicennia lanata (Acanthaceae): Insight into the Chloroplast Genome Evolution between Middle and Seaward Zones of Mangrove Forests",
           "10.3390/biology11030383",
           2022,
           "Ceriops and Avicennia are true mangroves in the middle and seaward zones of mangrove forests, respectively. The chloroplast genomes of Ceriops decandra, Ceriops zippeliana, and Ceriops tagal were assembled into lengths of 166,650, 166,083 and 164,432 bp, respectively, whereas Avicennia lanata was 148,264 bp in length. The gene content and gene order are highly conserved among these species. The chloroplast genome contains 125 genes in A. lanata and 129 genes in Ceriops species. Three duplicate genes (rpl2, rpl23, and trnM-CAU) were found in the IR regions of the three Ceriops species, resulting in expansion of the IR regions. The rpl32 gene was lost in C. zippeliana, whereas the infA gene was present in A. lanata. Short repeats (<40 bp) and a lower number of SSRs were found in A. lanata but not in Ceriops species. The phylogenetic analysis supports that all Ceriops species are clustered in Rhizophoraceae and A. lanata is in Acanthaceae. In a search for genes under selective pressures of coastal environments, the rps7 gene was under positive selection compared with non-mangrove species. Finally, two specific primer sets were developed for species identification of the three Ceriops species. Thus, this finding provides insightful genetic information for evolutionary relationships and molecular markers in Ceriops and Avicennia species.",
           10,
           "biology"
          ],
          [
           "Model and Data Concur and Explain the Coexistence of Two Very Distinct Animal Behavioral Types",
           "10.3390/biology9090241",
           2020,
           "Behaviors may enhance fitness in some situations while being detrimental in others. Linked behaviors (behavioral syndromes) may be central to understanding the maintenance of behavioral variability in natural populations. The spillover hypothesis of premating sexual cannibalism by females explains genetically determined female aggression towards both prey and males: growth to a larger size translates into higher fecundity, but at the risk of insufficient sperm acquisition. Here, we use an individual-based model to determine the ecological scenarios under which this spillover strategy is more likely to evolve over a strategy in which females attack approaching males only once the female has previously secured sperm. We found that a classic spillover strategy could never prevail. However, a more realistic early-spillover strategy, in which females become adults earlier in addition to reaching a larger size, could be maintained in some ecological scenarios and even invade a population of females following the other strategy. We also found under some ecological scenarios that both behavioral types coexist through frequency-dependent selection. Additionally, using data from the spider Lycosa hispanica, we provide strong support for the prediction that the two strategies may coexist in the wild. Our results clarify how animal personalities evolve and are maintained in nature.",
           1,
           "biology"
          ],
          [
           "Capturing Multiple Disease Resistance in Wheat through Intergeneric Hybridization",
           "10.3390/biology10070631",
           2021,
           "Derivatives from 4 species from the secondary gene pool of wheat—1 diploid (T. monococcum), 2 tetraploid (T. carthlicum; T. timopheevi), and 1 hexaploid (T. miguschovae)—were screened for resistance to Fusarium head blight, leaf rust, stem rust, and stripe rust. Where screening, genetic studies, and mapping were completed it was shown that all species carried resistance to multiple plant diseases. Some derived lines carried resistance to up to four different diseases. Where mapping was completed, it was shown that different diseases mapped to different chromosomes within any one accession.",
           1,
           "biology"
          ],
          [
           "White LED Lighting Increases the Root Productivity of Panax ginseng C. A. Meyer in a Hydroponic Cultivation System of a Plant Factory",
           "10.3390/biology12081052",
           2023,
           "To identify effective light spectra for increasing the productivity of Panax ginseng, we conducted experiments in a controlled environment using a hydroponic cultivation system in a plant factory. We investigated the effect of single LEDs (red, blue, and yellow) and mixed LEDs (red + blue and red + blue + white). The relationships between four light spectra (red, blue, yellow, and white) and physiological responses (net photosynthetic rate, stomata conductance, transpiration rate, and intercellular CO2 partial pressure), as well as growth responses (shoot and root biomass), were analyzed using multivariate statistical analysis. Among the four physiological response variables, shoot biomass was not increased by any pathway, and root biomass was increased only by the intercellular CO2 partial pressure. Red and yellow light increased shoot biomass, whereas white light promoted an increase in the net photosynthetic rate and enhanced root biomass. In contrast, blue light was less effective than the other light spectra in increasing both shoot and root biomass. Therefore, red and yellow light are the most effective light spectra for increasing shoot biomass and white light is effective for increasing root biomass in a plant factory that uses artificial LED lighting. Furthermore, the intercellular CO2 partial pressure is an important physiological variable for increasing the root biomass of P. ginseng.",
           2,
           "biology"
          ],
          [
           "Accumulation and Release of Mercury in the Lichen Evernia prunastri (L.) Ach",
           "10.3390/biology10111198",
           2021,
           "This study investigated the dynamics of the accumulation and release of Hg2+ in lichens, using Evernia prunastri (L.) Ach. as a model species. Thalli were incubated with solutions containing 1, 10, and 100 µM Hg2+ and then exposed for 1, 2, 3, 6, 12, 18, and 24 months at the Botanical Garden of the University of Siena (a location free from local Hg sources). Lichen samples accumulated Hg proportionally to the exposure concentration, and after the exposure, reductions over time were evident, already starting from 1–2 months. After 24 months, samples released 72–74 (healthy thalli) to 94% (unhealthy thalli) of the accumulated Hg, but control values of untreated samples were never reached. Depending on the Hg content after the exposure, stable decreased concentrations were reached after 6–24 months. The results of this study highlight the ability of the lichen E. prunastri to reflect rapidly increasing environmental Hg concentrations, as well as to indicate an ameliorated situation (e.g., the closure of an Hg source). However, we have found evidence that an acute pollution episode can influence the content of Hg in lichens for several years.",
           3,
           "biology"
          ],
          [
           "Exploring beyond Common Cell Death Pathways in Oral Cancer: A Systematic Review",
           "10.3390/biology13020103",
           2024,
           "Oral squamous cell carcinoma (OSCC) is the most common and lethal type of head and neck cancer in the world. Variable response and acquisition of resistance to traditional therapies show that it is essential to develop novel strategies that can provide better outcomes for the patient. Understanding of cellular and molecular mechanisms of cell death control has increased rapidly in recent years. Activation of cell death pathways, such as the emerging forms of non-apoptotic programmed cell death, including ferroptosis, pyroptosis, necroptosis, NETosis, parthanatos, mitoptosis and paraptosis, may represent clinically relevant novel therapeutic opportunities. This systematic review summarizes the recently described forms of cell death in OSCC, highlighting their potential for informing diagnosis, prognosis and treatment. Original studies that explored any of the selected cell deaths in OSCC were included. Electronic search, study selection, data collection and risk of bias assessment tools were realized. The literature search was carried out in four databases, and the extracted data from 79 articles were categorized and grouped by type of cell death. Ferroptosis, pyroptosis, and necroptosis represented the main forms of cell death in the selected studies, with links to cancer immunity and inflammatory responses, progression and prognosis of OSCC. Harnessing the potential of these pathways may be useful in patient-specific prognosis and individualized therapy. We provide perspectives on how these different cell death types can be integrated to develop decision tools for diagnosis, prognosis, and treatment of OSCC.",
           0,
           "biology"
          ],
          [
           "Cellulolytic Aerobic Bacteria Isolated from Agricultural and Forest Soils: An Overview",
           "10.3390/biology13020102",
           2024,
           "This review provides insights into cellulolytic bacteria present in global forest and agricultural soils over a period of 11 years. It delves into the study of soil-dwelling cellulolytic bacteria and the enzymes they produce, cellulases, which are crucial in both soil formation and the carbon cycle. Forests and agricultural activities are significant contributors to the production of lignocellulosic biomass. Forest ecosystems, which are key carbon sinks, contain 20–30% cellulose in their leaf litter. Concurrently, the agricultural sector generates approximately 998 million tons of lignocellulosic waste annually. Predominant genera include Bacillus, Pseudomonas, Stenotrophomonas, and Streptomyces in forests and Bacillus, Streptomyces, Pseudomonas, and Arthrobacter in agricultural soils. Selection of cellulolytic bacteria is based on their hydrolysis ability, using artificial cellulose media and dyes like Congo red or iodine for detection. Some studies also measure cellulolytic activity in vitro. Notably, bacterial cellulose hydrolysis capability may not align with their cellulolytic enzyme production. Enzymes such as GH1, GH3, GH5, GH6, GH8, GH9, GH10, GH12, GH26, GH44, GH45, GH48, GH51, GH74, GH124, and GH148 are crucial, particularly GH48 for crystalline cellulose degradation. Conversely, bacteria with GH5 and GH9 often fail to degrade crystalline cellulose. Accurate identification of cellulolytic bacteria necessitates comprehensive genomic analysis, supplemented by additional proteomic and transcriptomic techniques. Cellulases, known for degrading cellulose, are also significant in healthcare, food, textiles, bio-washing, bleaching, paper production, ink removal, and biotechnology, emphasizing the importance of discovering novel cellulolytic strains in soil.",
           0,
           "biology"
          ],
          [
           "The Function of Root Exudates in the Root Colonization by Beneficial Soil Rhizobacteria",
           "10.3390/biology13020095",
           2024,
           "Soil-beneficial microbes in the rhizosphere play important roles in improving plant growth and health. Root exudates play key roles in plant–microbe interactions and rhizobacterial colonization. This review describes the factors influencing the dynamic interactions between root exudates and the soil microbiome in the rhizosphere, including plant genotype, plant development, and environmental abiotic and biotic factors. We also discuss the roles of specific metabolic mechanisms, regulators, and signals of beneficial soil bacteria in terms of colonization ability. We highlight the latest research progress on the roles of root exudates in regulating beneficial rhizobacterial colonization. Organic acids, amino acids, sugars, sugar alcohols, flavonoids, phenolic compounds, volatiles, and other secondary metabolites are discussed in detail. Finally, we propose future research objectives that will help us better understand the role of root exudates in root colonization by rhizobacteria and promote the sustainable development of agriculture and forestry.",
           0,
           "biology"
          ],
          [
           "A New Species of Comptonia (Myricaceae) from the Early Miocene of Central Inner Mongolia, China, and Phytogeographic History of Sweet–Fern",
           "10.3390/biology11091326",
           2022,
           "Comptonia (Myricaceae) is well known as a monotypic genus living only in eastern North America; however, fossils show that the genus occurred extensively in the Northern Hemisphere during the Cenozoic. We observed dozens of Comptonia leaf fossils from the early Miocene in Zhuozi, China. The leaf architecture characteristics and epidermal features of the fossil specimens are described in detail here for the first time, and they were assigned to a new species: Comptonia hirsuta. The fruit fossils collected simultaneously from the same layer were assigned to Comptonia tymensis. The global fossil records indicate that the spatial distribution range of Comptonia reached its peak in both the Eocene and Miocene as two warm periods and then gradually decreased in the Oligocene, as well as after the late Miocene, because of the cooling global climate. Furthermore, the Comptonia taxon in East Asia may have migrated from North America via the Bering route in the late Paleocene or Eocene. Plant exchange between western Europe and eastern North America possibly occurred during the Eocene via the Thulean route. Phytogeographic variation in the Comptonia fossils from China also indicates that the reason for the disappearance of Comptonia from China may not only be due to the prolonged cooling and drying after the late Miocene, but also due to its progenitive pattern.",
           0,
           "biology"
          ],
          [
           "Immune Responses to SARS-CoV2 Mirror Societal Responses to COVID-19: Identifying Factors Underlying a Successful Viral Response",
           "10.3390/biology10060485",
           2021,
           "The adaptive immune system was sculpted to protect individuals, societies, and species since its inception, developing effective strategies to cope with emerging pathogens. Here, we show that similar successful or failed dynamics govern personal and societal responses to a pathogen as SARS-CoV2. Understanding the self-similarity between the health-protective measures taken to protect the individual or the society, help identify critical factors underlying the effectiveness of societal response to a pathogenic challenge. These include (1) the quick employment of adaptive-like, pathogen-specific strategies to cope with the threat including the development of “memory-like responses”; (2) enabling productive coaction and interaction within the society by employing effective decision-making processes; and (3) the quick inhibition of positive feedback loops generated by hazardous or false information. Learning from adaptive anti-pathogen immune responses, policymakers and scientists could reduce the direct damages associated with COVID-19 and avert an avoidable “social cytokine storm” with its ensuing socioeconomic damage.",
           0,
           "biology"
          ],
          [
           "Retraction: Kim et al. Advantage of Species Diversification to Facilitate Sustainable Development of Aquaculture Sector. Biology 2022, 11, 368",
           "10.3390/biology11040509",
           2022,
           "Biology retracts the article “Advantage of Species Diversification to Facilitate Sustainable Development of Aquaculture Sector” cited above [...]",
           0,
           "biology"
          ],
          [
           "Connexins and the Epithelial Tissue Barrier: A Focus on Connexin 26",
           "10.3390/biology10010059",
           2021,
           "Epithelial tissue responds rapidly to environmental triggers and is constantly renewed. This tissue is also highly accessible for therapeutic targeting. This review highlights the role of connexin mediated communication in avascular epithelial tissue. These proteins form communication conduits with the extracellular space (hemichannels) and between neighboring cells (gap junctions). Regulated exchange of small metabolites less than 1kDa aide the co-ordination of cellular activities and in spatial communication compartments segregating tissue networks. Dysregulation of connexin expression and function has profound impact on physiological processes in epithelial tissue including wound healing. Connexin 26, one of the smallest connexins, is expressed in diverse epithelial tissue and mutations in this protein are associated with hearing loss, skin and eye conditions of differing severity. The functional consequences of dysregulated connexin activity is discussed and the development of connexin targeted therapeutic strategies highlighted.",
           12,
           "biology"
          ],
          [
           "Hummingbird-Leaves-Reared Black Soldier Fly Prepupae: Assessment of Nutritional and Heavy Metal Compositions",
           "10.3390/biology9090274",
           2020,
           "Black soldier fly (BSF) larva is an attractive animal feed replacer due to its noticeable nutritional content. However, the conventional rearing method often resulted in BSF with undesirably high heavy metal residues that are harmful to animals. In this work, putrefied Sesbania grandiflora (S. Grandiflora) leaves were employed as feed to rear BSF larvae. The resultant BSF prepupae were found to contain 43.5% protein and 16.7% fat, reflecting a comparable protein content and a 2-fold reduction in crude fat than those reared using conventional kitchen waste. Moreover, high quantities of arginine (25.4 g/kg dry matter basis (DM)), carnitine (32.9 g/kg DM), and short-chain fatty acids, including lauric (40.00%), palmitic (19.20%), and oleic (12.10%) acids, have also been noticed in the BSF prepupae. Furthermore, the BSF larvae have been recorded with 0.185 mg/kg chromium, 0.380 mg/kg selenium, and mercury below the detection limit, which is far lower than those reared using conventional kitchen and agricultural wastes (≈1.7 mg/kg chromium, 1.2 mg/kg selenium, and 0.2 mg/kg mercury). Overall, the study shows that the nutritional quality of BSF prepupae is extensively improved when using S. Grandiflora as their feed. The resultant BSF prepupae may serve as an alternative feed for animal rearing.",
           3,
           "biology"
          ],
          [
           "Association between 30-s Chair Stand-Up Test and Anthropometric Values, Vibration Perception Threshold, FHSQ, and 15-D in Patients with Type 2 Diabetes Mellitus",
           "10.3390/biology10030246",
           2021,
           "Background: Type 2 diabetes mellitus (T2DM) is a chronic, worldwide disease affecting more than 400 million people. This pathology involves several associated problems, such as diabetic neuropathy complications, obesity, and foot problems, both in terms of health and sensitivity. Objective: The objective of this study was to explore the relationships of the 30-s chair stand-up test with the Foot Health Status Questionnaire (FHSQ), the vibration perception threshold (VPT), and the 15-dimensional (15-D) questionnaire in T2DM people. Methodology: Ninety participants with T2DM were assessed in terms of fat mass percentage, VPT, foot health, health-related quality of life (HRQoL), and the 30-s chair stand-up test. Results: The 30-s chair stand-up test was found to exhibit a moderate relationship with “physical activity” (rho = 0.441; p ≤ 0.001) and “vigor” (rho = 0.443; p ≤ 0.001) from FHSQ. The 30-s chair stand-up test was also found to be weakly associated with foot pain (rho = 0.358; p = 0.001), 15-D total score (rho = 0.376; p ≤ 0.001), “sleeping” (rho = 0.371; p < 0.001), and “depression” (rho = 0.352; p = 0.001). Conclusions: The 30-s chair stand-up test is associated with “physical activity”, “vigor”, and “foot pain” from the FHSQ and the 15-D questionnaire total score and its dimensions “sleeping” and “depression” in type 2 diabetes mellitus patients. Therefore, following the results obtained, qualified clinicians can use the 30-s chair stand-up test as a good tool for monitoring and managing type 2 diabetes.",
           2,
           "biology"
          ],
          [
           "Pinniped- and Cetacean-Derived ETosis Contributes to Combating Emerging Apicomplexan Parasites (Toxoplasma gondii, Neospora caninum) Circulating in Marine Environments",
           "10.3390/biology8010012",
           2019,
           "Leukocytes play a major role in combating infections either by phagocytosis, release of antimicrobial granules, or extracellular trap (ET) formation. ET formation is preceded by a certain leukocyte cell death form, known as ETosis, an evolutionarily conserved mechanism of the innate immune system also observed in marine mammals. Besides several biomolecules and microbial stimuli, marine mammal ETosis is also trigged by various terrestrial protozoa and metazoa, considered nowadays as neozoan parasites, which are circulating in oceans worldwide and causing critical emerging marine diseases. Recent studies demonstrated that pinniped- and cetacean-derived polymorphonuclear neutrophils (PMNs) and monocytes are able to form different phenotypes of ET structures composed of nuclear DNA, histones, and cytoplasmic peptides/proteases against terrestrial apicomplexan parasites, e.g., Toxoplasma gondii and Neospora caninum. Detailed molecular analyses and functional studies proved that marine mammal PMNs and monocytes cast ETs in a similar way as terrestrial mammals, entrapping and immobilizing T. gondii and N. caninum tachyzoites. Pinniped- and cetacean leukocytes induce vital and suicidal ETosis, with highly reliant actions of nicotinamide adenine dinucleotide phosphate oxidase (NOX), generation of reactive oxygen species (ROS), and combined mechanisms of myeloperoxidase (MPO), neutrophil elastase (NE), and DNA citrullination via peptidylarginine deiminase IV (PAD4).This scoping review intends to summarize the knowledge on emerging protozoans in the marine environment and secondly to review limited data about ETosis mechanisms in marine mammalian species.",
           19,
           "biology"
          ],
          [
           "Ranacyclin-NF, a Novel Bowman–Birk Type Protease Inhibitor from the Skin Secretion of the East Asian Frog, Pelophylax nigromaculatus",
           "10.3390/biology9070149",
           2020,
           "Serine protease inhibitors are found in plants, animals and microorganisms, where they play important roles in many physiological and pathological processes. Inhibitor scaffolds based on natural proteins and peptides have gradually become the focus of current research as they tend to bind to their targets with greater specificity than small molecules. In this report, a novel Bowman–Birk type inhibitor, named ranacyclin-NF (RNF), is described and was identified in the skin secretion of the East Asian frog, Pelophylax nigromaculatus. A synthetic replicate of the peptide was subjected to a series of functional assays. It displayed trypsin inhibitory activity with an inhibitory constant, Ki, of 447 nM and had negligible direct cytotoxicity. No observable direct antimicrobial activity was found but RNF improved the therapeutic potency of Gentamicin against Methicillin-resistant Staphylococcus aureus (MRSA). RNF shared significant sequence similarity to previously reported and related inhibitors from Odorrana grahami (ORB) and Rana esculenta (ranacyclin-T), both of which were found to be multi-functional. Two analogues of RNF, named ranacyclin-NF1 (RNF1) and ranacyclin-NF3L (RNF3L), were designed based on some features of ORB and ranacyclin-T to study structure–activity relationships. Structure–activity studies demonstrated that residues outside of the trypsin inhibitory loop (TIL) may be related to the efficacy of trypsin inhibitory activity.",
           7,
           "biology"
          ],
          [
           "Bioinformatic Analysis Reveals the Role of Translation Elongation Efficiency Optimisation in the Evolution of Ralstonia Genus",
           "10.3390/biology12101338",
           2023,
           "Translation efficiency modulates gene expression in prokaryotes. The comparative analysis of translation elongation efficiency characteristics of Ralstonia genus bacteria genomes revealed that these characteristics diverge in accordance with the phylogeny of Ralstonia. The first branch of this genus is a group of bacteria commonly found in moist environments such as soil and water that includes the species R. mannitolilytica, R. insidiosa, and R. pickettii, which are also described as nosocomial infection pathogens. In contrast, the second branch is plant pathogenic bacteria consisting of R. solanacearum, R. pseudosolanacearum, and R. syzygii. We found that the soil Ralstonia have a significantly lower number and energy of potential secondary structures in mRNA and an increased role of codon usage bias in the optimization of highly expressed genes’ translation elongation efficiency, not only compared to phytopathogenic Ralstonia but also to Cupriavidus necator, which is closely related to the Ralstonia genus. The observed alterations in translation elongation efficiency of orthologous genes are also reflected in the difference of potentially highly expressed gene’ sets’ content among Ralstonia branches with different lifestyles. Analysis of translation elongation efficiency characteristics can be considered a promising approach for studying complex mechanisms that determine the evolution and adaptation of bacteria in various environments.",
           0,
           "biology"
          ],
          [
           "Telomere Dynamics in Livestock",
           "10.3390/biology12111389",
           2023,
           "Telomeres are repeated sequences of nucleotides at the end of chromosomes. They deteriorate across mitotic divisions of a cell. In Homo sapiens this process of lifetime reduction has been shown to correspond with aspects of organismal aging and exposure to stress or other insults. The early impetus to characterize telomere dynamics in livestock related to the concern that aged donor DNA would result in earlier cell senescence and overall aging in cloned animals. Telomere length investigations in dairy cows included breed effects, estimates of additive genetic control (heritability 0.12 to 0.46), and effects of external stressors on telomere degradation across animal life. Evaluation of telomeres with respect to aging has also been conducted in pigs and horses, and there are fewer reports of telomere biology in beef cattle, sheep, and goats. There were minimal associations of telomere length with animal productivity measures. Most, but not all, work in livestock has documented an inverse relationship between peripheral blood cell telomere length and age; that is, a longer telomere length was associated with younger age. Because livestock longevity affects productivity and profitability, the role of tissue-specific telomere attrition in aging may present alternative improvement strategies for genetic improvement while also providing translational biomedical knowledge.",
           0,
           "biology"
          ],
          [
           "Endothelial Cell GATA2 Modulates the Cardiomyocyte Stress Response through the Regulation of Two Long Non-Coding RNAs",
           "10.3390/biology11121736",
           2022,
           "Capillary endothelial cells modulate myocardial growth and function during pathological stress, but it is unknown how and whether this contributes to the development of heart failure. We found that the endothelial cell transcription factor GATA2 is downregulated in human failing myocardium. Endothelial GATA2 knock-out (G2-EC-KO) mice develop heart failure and defective myocardial signal transduction during pressure overload, indicating that the GATA2 downregulation is maladaptive. Heart failure and perturbed signaling in G2-EC-KO mice could be induced by strong upregulation of two unknown, endothelial cell-derived long non-coding (lnc) RNAs (AK037972, AK038629, termed here GADLOR1 and 2). Mechanistically, the GADLOR1/2 lncRNAs transfer from endothelial cells to cardiomyocytes, where they block stress-induced signalling. Thereby, lncRNAs can contribute to disease as paracrine effectors of signal transduction and therefore might serve as therapeutic targets in the future.",
           3,
           "biology"
          ],
          [
           "Pathophysiology and Clinical Meaning of Ventilation-Perfusion Mismatch in the Acute Respiratory Distress Syndrome",
           "10.3390/biology12010067",
           2023,
           "Acute respiratory distress syndrome (ARDS) remains an important clinical challenge with a mortality rate of 35–45%. It is being increasingly demonstrated that the improvement of outcomes requires a tailored, individualized approach to therapy, guided by a detailed understanding of each patient’s pathophysiology. In patients with ARDS, disturbances in the physiological matching of alveolar ventilation (V) and pulmonary perfusion (Q) (V/Q mismatch) are a hallmark derangement. The perfusion of collapsed or consolidated lung units gives rise to intrapulmonary shunting and arterial hypoxemia, whereas the ventilation of non-perfused lung zones increases physiological dead-space, which potentially necessitates increased ventilation to avoid hypercapnia. Beyond its impact on gas exchange, V/Q mismatch is a predictor of adverse outcomes in patients with ARDS; more recently, its role in ventilation-induced lung injury and worsening lung edema has been described. Innovations in bedside imaging technologies such as electrical impedance tomography readily allow clinicians to determine the regional distributions of V and Q, as well as the adequacy of their matching, providing new insights into the phenotyping, prognostication, and clinical management of patients with ARDS. The purpose of this review is to discuss the pathophysiology, identification, consequences, and treatment of V/Q mismatch in the setting of ARDS, employing experimental data from clinical and preclinical studies as support.",
           1,
           "biology"
          ],
          [
           "Colorectal Cancer Study of Austria (CORSA): A Population-Based Multicenter Study",
           "10.3390/biology10080722",
           2021,
           "The Colorectal cancer Study of Austria (CORSA) is comprised more than 13,500 newly diagnosed colorectal cancer (CRC) patients, patients with high- and low-risk adenomas as well as population-based controls. The recruitment for the CORSA biobank is performed in close cooperation with the invited two-stage CRC screening project “Burgenland PREvention trial of colorectal Disease with ImmunologiCal Testing” (B-PREDICT). Annually, more than 150,000 inhabitants of the Austrian federal state Burgenland aged between 40 and 80 are invited to participate using FIT-tests as an initial screening. FIT-positive tested participants are offered a diagnostic colonoscopy and are asked to take part in CORSA, sign a written informed consent, complete questionnaires concerning dietary and lifestyle habits and provide an ethylenediaminetetraacetic acid (EDTA) blood sample as well as a stool sample. Additional CRC cases have been recruited at four hospitals in Vienna and a hospital in lower Austria. A major strength of CORSA is the population-based controls who are FIT-positive and colonoscopy-confirmed to be free of polyps and/or CRC.",
           4,
           "biology"
          ],
          [
           "Cardiac Peptides—Current Physiology, Pathophysiology, Biochemistry, Molecular Biology, and Clinical Application",
           "10.3390/biology11020330",
           2022,
           "The heart has long been considered a pumping organ, consisting of muscles [...]",
           3,
           "biology"
          ],
          [
           "Impact of FLT3-ITD Insertion Length on Outcomes in Acute Myeloid Leukemia: A Propensity Score-Adjusted Cohort Study",
           "10.3390/biology11060916",
           2022,
           "The prognostic significance of the length of internal tandem duplication (ITD) insertions in mutant FLT3 genes in acute myeloid leukemia (AML) is controversial. We conducted a retrospective study to evaluate the correlation between the ITD base-pair (bp) insertion length and clinical outcomes. The mutational status of the FLT3 gene was evaluated in 402 of 467 consecutive AML patients treated at the University of Maryland Greenebaum Comprehensive Cancer Center between 2013 and 2020; 77 had FLT3-ITD mutations. Patients were divided into three cohorts based on bp insertion length (<30 (0–33rd percentile), 30–53 (34th–66th percentile),and >53 (>66th percentile)). The median overall survival (OS) of patients was 16.5 months (confidence interval (CI) 7.3-NA), 18.5 months (CI 7.3-NA), and 21.9 months (CI 19.1-NA) (p = 0.03) for the <30, 30–53, and >53 bp insertion length cohorts, respectively. The adjusted median event-free survival (EFS) for the ITD insertion lengths >30, 30–53, and >53 bp was 11.1 months (CI 2.8–16.5), 5.2 months (CI 2.9–12.6), and 9.1 months (CI 5.4-NA) (p = 0.5), respectively. Complete remission (CR) rates were 64% (<30 inserted bp), 55% (30–53 inserted bp), and 79% (>53 inserted bp) (p = 0.23). For patients treated with gilteritinib and midostaurin, the unadjusted median OS was not statistically significantly different between cohorts.",
           3,
           "biology"
          ],
          [
           "Age-at-Death Estimation of Fetuses and Infants in Forensic Anthropology: A New “Coupling” Method to Detect Biases Due to Altered Growth Trajectories",
           "10.3390/biology11020200",
           2022,
           "The coupling between maturation and growth in the age estimation of young individuals with altered growth processes was analyzed in this study, whereby the age was determined using a geometric morphometrics method. A medical sample comprising 223 fetuses and infants was used to establish the method. The pars basilaris shapes, quantified by elliptic Fourier analysis, were grouped into consensus stages to characterize the maturation process along increasing age groups. Each pars basilaris maturation stage was “coupled” to biometry by defining an associated femur length range. The method was tested on a validation sample of 42 normal individuals and a pathological sample of 114 individuals whose pathologies were medically assessed. Couplings were present in 90.48% of the normal sample and 77.19% of the pathological sample. The method was able to detect “uncoupling” (i.e., possibly altered growth) in more than 22.8% of samples, even if there was no visible traces of pathology on bones in most cases. In conclusion, experts should be warned that living conditions may cause alterations in the development of young individuals in terms of uncoupling, and that the age-at-death estimation based on long bone biometry could be biased. In a forensic context, when age has been estimated in cases where uncoupling is present, experts should be careful to take potential inaccuracies into account when forming their conclusions.",
           2,
           "biology"
          ],
          [
           "Concurrent Mutations in SF3B1 and PHF6 in Myeloid Neoplasms",
           "10.3390/biology12010013",
           2022,
           "It has been reported that gene mutations in SF3B1 and PHF6 are mutually exclusive. However, this observation has never been rigorously assessed. We report the clinicopathologic and molecular genetic features of 21 cases of myeloid neoplasms with double mutations in SF3B1 and PHF6, including 9 (43%) with myelodysplastic syndrome, 5 (24%) with acute myeloid leukemia, 4 (19%) with myeloproliferative neoplasms, and 3 (14%) with myelodysplastic/myeloproliferative neoplasms. Multilineage dysplasia with ring sideroblasts, increased blasts, and myelofibrosis are common morphologic findings. All cases but one had diploid or non-complex karyotypes. SF3B1 mutations were detected in the first analysis of all the patients. PHF6 mutations occurred either concurrently with SF3B1 mutations or in subsequent follow-up samples and are associated with disease progression and impending death in most cases. Most cases had co-mutations, the most common being ASXL1, RUNX1, TET2, and NRAS. With a median follow-up of 39 months (range, 3-155), 17 (81%) patients died, 3 were in complete remission, and 1 had persistent myelodysplastic syndrome. The median overall survival was 51 months. In summary, concurrent mutations in SF3B1 and PHF6 are rare, but they do exist in a variety of myeloid neoplasms, with roles as early initiating events and in disease progression, respectively.",
           0,
           "biology"
          ],
          [
           "Effects of the Density of Invasive Lantana camara Plants on the Biodiversity of Large and Small Mammals in the Groenkloof Nature Reserve (GNR) in South Africa",
           "10.3390/biology12020296",
           2023,
           "Multi-scale approaches have been used to determine scales at which mammal species are responding to habitat destruction due to invasion, but the impacts of weeds on mammals have not been extensively studied, especially in Africa. Inside the Groenkloof Nature Reserve (GNR), we assessed how mammals are affected by an invasive weed Lantana camara. A series of models were applied to determine the differences in species abundance as well as richness, separated for large and small mammals. When diversity indices were used, an Analysis of Variance (ANOVA) revealed no statistically significant difference between treatments (F5 = 0.233, p = 0.945) for large mammals. The results of a Generalised Linear Mixed Model (GLMM) showed that vegetation type (Wald χ22 = 120.156; p < 0.01) and foraging guilds (Wald χ23 = 76.771; p < 0.01) were significant predictors of large mammal species richness. However, for small mammals, the results of a GLMM showed that only treatment type (Wald χ25 = 10.62; p = 0.050) was a significant predictor of the number of small mammals trapped. In addition, the ANOVA revealed statistically significant differences in species diversity between treatments (F5 = 0.934; p < 0.001) and by season (F1 = 9.122 p = 0.003) for small mammals. The presence of L. camara coupled with other predictors was associated with differences in large mammal abundances and diversity, and differences in how these large mammals were distributed across the landscape. Furthermore, the highest species diversity was found in the spring for small mammals. Therefore, for all the mammals studied, the presence of L. camara negatively affected species abundance, richness, and diversity, as well as how these species were distributed across the invaded and cleared areas.",
           1,
           "biology"
          ],
          [
           "Small Molecules Targeting INSM1 for the Treatment of High-Risk Neuroblastoma",
           "10.3390/biology12081134",
           2023,
           "Human neuroblastoma (NB) is the most common childhood extracranial tumor arising from the sympathetic nervous system. It is also a clinically heterogeneous disease that ranges from spontaneous regression to high-risk stage 4 disease. The cause of this disease remains elusive. However, the amplification of NMYC oncogene occurred in roughly 30% of NB patients, which strongly correlated with the advanced stage of disease subtype and the worse prognosis status. We discovered that N-Myc oncoprotein binds and activates INSM1, a zinc-finger transcription factor of neuroendocrine tumors. We also found that INSM1 modulates N-Myc stability mediated through PI3K/AKT/GSK3β signaling pathway. Therefore, INSM1 emerges as a critical co-player with N-Myc in facilitating NB tumor cell growth and sustaining the advanced stage of malignancy. Using an INSM1-promoter driven luciferase screening-platform, we have recently identified fifteen small molecules that negatively regulate INSM1 expression. Interestingly, the identified small molecules can be divided into four large groups of compounds such as cell signaling inhibitor, DNA/RNA inhibitor, HDAC inhibitor, and cardiac glycoside. These findings support the presence of a unique mechanism associated with INSM1 and N-Myc interplay, which is critical in regulating NB tumor cell growth. We discuss the feasibility of identifying novel or repurposing small molecules targeting INSM1 as a potential treatment option for high-risk NB.",
           0,
           "biology"
          ],
          [
           "The Mycobiota of High Altitude Pear Orchards Soil in Colombia",
           "10.3390/biology10101002",
           2021,
           "In Colombia, the cultivation of deciduous fruit trees such as pear is expanding for socio-economic reasons and is becoming more and more important for the local population. Since organized cultivation is slowly replacing sustenance cultivation, scientific information on the present agro-environment is needed to proceed in this change in an organic and environmentally friendly way. In particular, this study is an accurate description of the mycobiota present in the bulk soil of two different high altitude pear orchards in the Colombian Andes. The metabarcoding of soil samples allowed an in-depth analysis of the whole fungal community. The fungal assemblage was generally dominated by Ascomycota and secondly by Mortierellomycota. As observed in other studies in Colombia, the genus Mortierella was found to be especially abundant. The soil of the different pear orchards appeared to host quite different fungal communities according to the soil physico-chemical properties. The common mycobiota contained 35 fungal species, including several species of Mortierella, Humicola, Solicoccozyma and Exophiala. Moreover, most of the identified fungal species (79%) were recorded for the first time in Colombian soils, thus adding important information on soil biodiversity regarding both Colombia and pear orchards.",
           7,
           "biology"
          ],
          [
           "Comparative and Phylogenetic Analysis of Complete Plastomes among Aristidoideae Species (Poaceae)",
           "10.3390/biology11010063",
           2022,
           "Aristidoideae is a subfamily in the PACMAD clade of family Poaceae, including three genera, Aristida, Stipagrostis, and Sartidia. In this study, the plastomes of Aristida adscensionis and Stipagrostis pennata were newly sequenced, and a total of 16 Aristidoideae plastomes were compared. All plastomes were conservative in genome size, gene number, structure, and IR boundary. Repeat sequence analysis showed that forward and palindrome repeats were the most common repeat types. The number of SSRs ranged from 30 (Sartidia isaloensis) to 54 (Aristida purpurea). Codon usage analysis showed that plastome genes preferred to use codons ending with A/T. A total of 12 highly variable regions were screened, including four protein coding sequences (matK, ndhF, infA, and rpl32) and eight non-coding sequences (rpl16-1-rpl16-2, ccsA-ndhD, trnY-GUA-trnD-GUC, ndhF-rpl32, petN-trnC-GCA, trnT-GGU-trnE-UUC, trnG-GCC-trnfM-CAU, and rpl32-trnL-UAG). Furthermore, the phylogenetic position of this subfamily and their intergeneric relationships need to be illuminated. All Maximum Likelihood and Bayesian Inference trees strongly support the monophyly of Aristidoideae and each of three genera, and the clade of Aristidoideae and Panicoideae was a sister to other subfamilies in the PACMAD clade. Within Aristidoideae, Aristida is a sister to the clade composed of Stipagrostis and Sartidia. The divergence between C4 Stipagrostis and C3 Sartidia was estimated at 11.04 Ma, which may be associated with the drought event in the Miocene period. Finally, the differences in carbon fixation patterns, geographical distributions, and ploidy may be related to the difference of species numbers among these three genera. This study provides insights into the phylogeny and evolution of the subfamily Aristidoideae.",
           5,
           "biology"
          ],
          [
           "Mitochondrial Function Differences between Tumor Tissue of Human Metastatic and Premetastatic CRC",
           "10.3390/biology11020293",
           2022,
           "Most colorectal cancer (CRC) patients die as a consequence of metastasis. Mitochondrial dysfunction could enhance cancer development and metastatic progression. We aimed to evaluate the adaptations associated with mitochondrial function in tumor tissues from stages III and IV of human CRC and whether they could ultimately be used as a therapeutic target in metastatic colorectal cancer (mCRC). We analyzed the protein levels by Western blotting and the enzymatic activities of proteins involved in mitochondrial function, as well as the amount of mitochondrial DNA (mtDNA), by real-time PCR, analyzing samples of non-tumor adjacent tissue and tumor tissue from stages III and IV CRC patients without radio- or chemotherapy treatment prior to surgery. Our data indicate that the tumor tissue of pre-metastatic stage III CRC exhibited an oxidant metabolic profile very similar to the samples of non-tumor adjacent tissue of both stages. Notable differences in the protein expression levels of ATPase, IDH2, LDHA, and SIRT1, as well as mtDNA amount, were detected between the samples of non-tumor adjacent tissue and tumor tissue from metastatic CRC patients. These findings suggest a shift in the oxidative metabolic profile that takes place in the tumor tissue once the metastatic stage has been reached. Tumor tissue oxidative metabolism contributes to promote and maintain the metastatic phenotype, with evidence of mitochondrial function impairment in stage IV tumor tissue.",
           2,
           "biology"
          ],
          [
           "Translating Senotherapeutic Interventions into the Clinic with Emerging Proteomic Technologies",
           "10.3390/biology12101301",
           2023,
           "Cellular senescence is a state of irreversible growth arrest with profound phenotypic changes, including the senescence-associated secretory phenotype (SASP). Senescent cell accumulation contributes to aging and many pathologies including chronic inflammation, type 2 diabetes, cancer, and neurodegeneration. Targeted removal of senescent cells in preclinical models promotes health and longevity, suggesting that the selective elimination of senescent cells is a promising therapeutic approach for mitigating a myriad of age-related pathologies in humans. However, moving senescence-targeting drugs (senotherapeutics) into the clinic will require therapeutic targets and biomarkers, fueled by an improved understanding of the complex and dynamic biology of senescent cell populations and their molecular profiles, as well as the mechanisms underlying the emergence and maintenance of senescence cells and the SASP. Advances in mass spectrometry-based proteomic technologies and workflows have the potential to address these needs. Here, we review the state of translational senescence research and how proteomic approaches have added to our knowledge of senescence biology to date. Further, we lay out a roadmap from fundamental biological discovery to the clinical translation of senotherapeutic approaches through the development and application of emerging proteomic technologies, including targeted and untargeted proteomic approaches, bottom-up and top-down methods, stability proteomics, and surfaceomics. These technologies are integral for probing the cellular composition and dynamics of senescent cells and, ultimately, the development of senotype-specific biomarkers and senotherapeutics (senolytics and senomorphics). This review aims to highlight emerging areas and applications of proteomics that will aid in exploring new senescent cell biology and the future translation of senotherapeutics.",
           0,
           "biology"
          ],
          [
           "The Ultrastructural Analysis of Human Colorectal Cancer Stem Cell-Derived Spheroids and Their Mouse Xenograft Shows That the Same Cells Types Have Different Ratios",
           "10.3390/biology10090929",
           2021,
           "Spheroids from primary colorectal cancer cells and their mice xenografts have emerged as useful preclinical models for cancer research as they replicate tumor features more faithfully as compared to cell lines. While 3D models provide a reliable system for drug discovery and testing, their structural complexity represents a challenge and their structure-function relationships are only partly understood. Here, we present a comparative ultrastructural and flow citometric analysis of patient colorectal cancer-derived spheroids and their mice xenografts. Ultrastructural observations highlighted that multicellular spheroids and their xenografts contain the same cancer cell types but with different ratios, specifically multicellular spheroids were enriched in cells with a stem-like phenotype, while xenografts had an increased amount of lipid droplets-containing cells. The flow cytometric analysis for stem cell marker and activity showed enrichment of stem-like cells presence and activity in spheroids while xenografts had the inverse response. Our results evidence the effects on cancer cells of different in vitro and in vivo microenvironments. Those differences have to be paid into account in designing innovative experimental models for personalized drug testing.",
           6,
           "biology"
          ],
          [
           "Cytoskeletal Responses and Aif-1 Expression in Caco-2 Monolayers Exposed to Phorbol-12-Myristate-13-Acetate and Carnosine",
           "10.3390/biology12010036",
           2022,
           "The dis(re)organization of the cytoskeletal actin in enterocytes mediates epithelial barrier dys(re)function, playing a key role in modulating epithelial monolayer’s integrity and remodeling under transition from physiological to pathological states. Here, by fluorescence-based morphological and morphometric analyses, we detected differential responses of cytoskeletal actin in intestinal epithelial Caco-2 cell monolayers at two different stages of their spontaneous differentiation, i.e., undifferentiated cells at 7 days post-seeding (dps) and differentiated enterocyte-like cells at 21 dps, upon challenge in vitro with the inflammation-mimicking stimulus of phorbol-12-myristate-13-acetate (PMA). In addition, specific responses were found in the presence of the natural dipeptide carnosine detecting its potential counteraction against PMA-induced cytoskeletal alterations and remodeling in differentiated Caco-2 monolayers. In such an experimental context, by both immunocytochemistry and Western blot assays in Caco-2 monolayers, we identified the expression of the allograft inflammatory factor 1 (AIF-1) as protein functionally related to both inflammatory and cytoskeletal pathways. In 21 dps monolayers, particularly, we detected variations of its intracellular localization associated with the inflammatory stimulus and its mRNA/protein increase associated with the differentiated 21 dps enterocyte-like monolayer compared to the undifferentiated cells.",
           1,
           "biology"
          ],
          [
           "OsOSCA1.1 Mediates Hyperosmolality and Salt Stress Sensing in Oryza sativa",
           "10.3390/biology11050678",
           2022,
           "OSCA (reduced hyperosmolality-induced [Ca2+]i increase) is a family of mechanosensitive calcium-permeable channels that play a role in osmosensing and stomatal immunity in plants. Oryza sativa has 11 OsOSCA genes; some of these were shown to complement hyperosmolality-induced [Ca2+]cyt increases (OICIcyt), salt stress-induced [Ca2+]cyt increases (SICIcyt), and the associated growth phenotype in the Arabidopsis thaliana mutant osca1. However, their biological functions in rice remain unclear. In this paper, we found that OsOSCA1.1 mediates OICIcyt and SICIcyt in rice roots, which are critical for stomatal closure, plant survival, and gene expression in shoots, in response to hyperosmolality and the salt stress treatment of roots. Compared with wild-type (Zhonghua11, ZH11) plants, OICIcyt and SICIcyt were abolished in the roots of 10-day-old ososca1.1 seedlings, in response to treatment with 250 mM of sorbitol and 100 mM of NaCl, respectively. Moreover, hyperosmolality- and salt stress-induced stomatal closure were also disrupted in a 30-day-old ososca1.1 mutant, resulting in lower stomatal resistance and survival rates than that in ZH11. However, overexpression of OsOSCA1.1 in ososca1.1 complemented stomatal movement and survival, in response to hyperosmolality and salt stress. The transcriptomic analysis further revealed the following three types of OsOSCA1.1-regulated genes in the shoots: 2416 sorbitol-responsive, 2349 NaCl-responsive and 1844 common osmotic stress-responsive genes after treated with 250 mM of sorbitol and 125 mM NaCl of in 30-day-old rice roots for 24 h. The Gene Ontology enrichment analysis showed that these OsOSCA1.1-regulated genes were relatively enriched in transcription regulation, hormone response, and phosphorylation terms of the biological processes category, which is consistent with the Cis-regulatory elements ABRE, ARE, MYB and MYC binding motifs that were overrepresented in 2000-bp promoter regions of these OsOSCA1.1-regulated genes. These results indicate that OsOSCA-mediated calcium signaling specifically regulates gene expression, in response to drought and salt stress in rice.",
           6,
           "biology"
          ],
          [
           "Lipidomic Analysis of Liver Lipid Droplets after Chronic Alcohol Consumption with and without Betaine Supplementation",
           "10.3390/biology12030462",
           2023,
           "The earliest manifestation of alcohol-associated liver disease is hepatic steatosis, which is characterized by fat accumulation in specialized organelles called lipid droplets (LDs). Our previous studies reported that alcohol consumption elevates the numbers and sizes of LDs in hepatocytes, which is attenuated by simultaneous treatment with the methyl group donor, betaine. Here, we examined changes in the hepatic lipidome with respect to LD size and dynamics in male Wistar rats fed for 6 weeks with control or ethanol-containing liquid diets that were supplemented with or without 10 mg betaine/mL. At the time of sacrifice, three hepatic LD fractions, LD1 (large droplets), LD2 (medium-sized droplets), and LD3 (small droplets) were isolated from each rat. Untargeted lipidomic analyses revealed that each LD fraction of ethanol-fed rats had higher phospholipids, cholesteryl esters, diacylglycerols, ceramides, and hexosylceramides compared with the corresponding fractions of pair-fed controls. Interestingly, the ratio of phosphatidylcholine to phosphatidylethanolamine (the two most abundant phospholipids on the LD surface) was lower in LD1 fraction compared with LD3 fraction, irrespective of treatment; however, this ratio was significantly lower in ethanol LD fractions compared with their respective control fractions. Betaine supplementation significantly attenuated the ethanol-induced lipidomic changes. These were mainly associated with the regulation of LD surface phospholipids, ceramides, and glycerolipid metabolism in different-sized LD fractions. In conclusion, our results show that ethanol-induced changes in the hepatic LD lipidome likely stabilizes larger-sized LDs during steatosis development. Furthermore, betaine supplementation could effectively reduce the size and dynamics of LDs to attenuate alcohol-associated hepatic steatosis.",
           2,
           "biology"
          ],
          [
           "The Hypothalamus of the Beaked Whales: The Paraventricular, Supraoptic, and Suprachiasmatic Nuclei",
           "10.3390/biology12101319",
           2023,
           "The hypothalamus is the body’s control coordinating center. It is responsible for maintaining the body’s homeostasis by directly influencing the autonomic nervous system or managing hormones. Beaked whales are the longest divers among cetaceans and their brains are rarely available for study. Complete hypothalamic samples from a female Cuvier’s beaked whale and a male Blainville’s beaked whale were processed to investigate the paraventricular (PVN) and supraoptic (SON) nuclei, using immunohistochemical staining against vasopressin. The PVN occupied the preoptic region, where it reached its maximum size, and then regressed in the anterior or suprachiasmatic region. The SON was located from the preoptic to the tuberal hypothalamic region, encompassing the optical structures. It was composed of a retrochiasmatic region (SONr), which bordered and infiltrated the optic tracts, and a principal region (SONp), positioned more medially and dorsally. A third vasopressin-positive nucleus was also detected, i.e., the suprachiasmatic nucleus (SCN), which marked the end of the SON. This is the first description of the aforementioned nuclei in beaked whales—and in any marine mammals—as well as their rostro-caudal extent and immunoreactivity. Moreover, the SCN has been recognized for the first time in any marine mammal species.",
           0,
           "biology"
          ],
          [
           "The Capacity of Magnesium to Induce Osteoclast Differentiation Is Greatly Enhanced by the Presence of Zoledronate",
           "10.3390/biology12101297",
           2023,
           "Bisphosphonates (BPs) are successfully used to cure a number of diseases characterized by a metabolic reduction in bone density, such as Osteoporosis, or a neoplastic destruction of bone tissue, such as multiple myeloma and bone metastases. These drugs exert their therapeutic effect by causing a systemic osteoclast depletion that, in turn, is responsible for reduced bone resorption. Unfortunately, in addition to their beneficial activity, BPs can also determine a frightening side effect known as osteonecrosis of the jaw (ONJ). It is generally believed that the inability of osteoclasts to dispose of inflamed/necrotic bone represents the main physiopathological aspect of ONJ. In principle, a therapeutic strategy able to elicit a local re-activation of osteoclast production could counteract ONJ and promote the healing of its lesions. Using an experimental model of Vitamin D3-dependent osteoclastogenesis, we have previously demonstrated that Magnesium is a powerful inducer of osteoclast differentiation. Here we show that, surprisingly, this effect is greatly enhanced by the presence of Zoledronate, chosen for our study because it is the most effective and dangerous of the BPs. This finding allows us to hypothesize that Magnesium might play an important role in the topical therapy of ONJ.",
           0,
           "biology"
          ],
          [
           "AmazonForest: In Silico Metaprediction of Pathogenic Variants",
           "10.3390/biology11040538",
           2022,
           "ClinVar is a web platform that stores ∼789,000 genetic associations with complex diseases. A partial set of these cataloged genetic associations has challenged clinicians and geneticists, often leading to conflicting interpretations or uncertain clinical impact significance. In this study, we addressed the (re)classification of genetic variants by AmazonForest, which is a random-forest-based pathogenicity metaprediction model that works by combining functional impact data from eight prediction tools. We evaluated the performance of representation learning algorithms such as autoencoders to propose a better strategy. All metaprediction models were trained with ClinVar data, and genetic variants were annotated with eight functional impact predictors cataloged with SnpEff/SnpSift. AmazonForest implements the best random forest model with a one hot data-encoding strategy, which shows an Area Under ROC Curve of ≥0.93. AmazonForest was employed for pathogenicity prediction of a set of ∼101,000 genetic variants of uncertain significance or conflict of interpretation. Our findings revealed ∼24,000 variants with high pathogenic probability (RFprob≥0.9). In addition, we show results for Alzheimer’s Disease as a demonstration of its application in clinical interpretation of genetic variants in complex diseases. Lastly, AmazonForest is available as a web tool and R object that can be loaded to perform pathogenicity predictions.",
           0,
           "biology"
          ],
          [
           "Tegafur-Uracil versus 5-Fluorouracil in Combination with Cisplatin and Cetuximab in Elderly Patients with Recurrent or Metastatic Head and Neck Squamous Cell Carcinoma: A Propensity Score Matching Analysis",
           "10.3390/biology10101011",
           2021,
           "There are increasing incidences of elderly patients with recurrent or metastatic head and neck squamous cell carcinoma (R/M HNSCC). However, the treatment is not yet established. We conducted a propensity score matching analysis to evaluate the efficacy and safety of tegafur–uracil versus 5-fluorouracil in combination with cisplatin plus cetuximab in elderly patients with R/M HNSCC. Elderly patients with R/M HNSCC treated with cetuximab-containing chemotherapy were recruited into this study. In order to reduce the selection bias, propensity score matching was performed. Kaplan–Meier curves were plotted for progression-free survival (PFS) and overall survival (OS). Toxicities were graded according to the National Cancer Institute’s Common Terminology Criteria V3.0. After propensity sore matching, 54 patients with tegafur–uracil, cisplatin plus cetuximab (UPEx), and 54 patients with 5-fluorouracil, cisplatin plus cetuximab (EXTREME) were identified. The median PFS was 5.4 months in UPEx and 5.8 months in EXTREME (p = 0.451). The median OS was 10.8 months in UPEx and 10.2 months in EXTREME (p = 0.807). The overall response rate (ORR) and disease control rate (DCR) were insignificant in both arms, accounting for 61% versus 59% (p = 0.680) and 72% versus 70% (p = 0.732) in the UPEx arm and the EXTREME arm, respectively. A multivariate analysis showed that age and ECOG PS were, independently, predictors. Grade 3/4 adverse events were much fewer in UPEx than in EXTREME (p < 0.001). Both cetuximab-containing chemotherapies are effective in elderly patients with R/M HNSCC. Safety profiles are improved when tegafur–uracil is substituted for 5-fluorouracil. Further prospective studies are warranted to validate our conclusions.",
           0,
           "biology"
          ],
          [
           "Knowledge Gaps in the Definition of Threats for the Red List Assessment of European Freshwater-Dependent Fish Species",
           "10.3390/biology10070680",
           2021,
           "Freshwater ecosystems are disproportionally important for biodiversity conservation, as they support more than 9% of known animal species while representing less than 1% of the Earth’s surface. However, the vast majority of the threats (99%, or 826 out of 837) identified by the International Union for Conservation of Nature Red List of Threatened Species known to affect the 434 known freshwater-dependent fish and lampreys of Europe are not supported by validated published scientific knowledge. This general lack of information about freshwater-dependent fish and lamprey species may have deleterious effects on species conservation, and additional funding is required to fill baseline knowledge gaps.",
           0,
           "biology"
          ],
          [
           "A Pathfinder in High-Pressure Bioscience: In Memoriam of Gaston Hui Bon Hoa",
           "10.3390/biology10080778",
           2021,
           "On 26 July 2020, our colleague and friend Dr [...]",
           0,
           "biology"
          ],
          [
           "Genetic Analysis as a Tool to Improve the Monitoring of Stranded Cetaceans in Chile",
           "10.3390/biology12050748",
           2023,
           "Cetacean strandings are a valuable source of information for several studies from species richness to conservation and management. During the examination of strandings, taxonomic and sex identification might be hindered for several reasons. Molecular techniques are valuable tools to obtain that missing information. This study evaluates how gene fragment amplification protocols can support the records of strandings done in the field in Chile by identifying, corroborating, or correcting the identification of the species and sex of the recorded individuals. Through a collaboration between a scientific laboratory and government institution in Chile, 63 samples were analyzed. Thirty-nine samples were successfully identified to the species level. In total, 17 species of six families were detected, including six species of conservation interest. Of the 39 samples, 29 corresponded to corroborations of field identifications. Seven corresponded to unidentified samples and three to corrected misidentifications, adding up to 28% of the identified samples. Sex was successfully identified for 58 of the 63 individuals. Twenty were corroborations, 34 were previously unidentified, and four were corrections. Applying this method improves the stranding database of Chile and provides new data for future management and conservation tasks.",
           0,
           "biology"
          ],
          [
           "Insights on the Quest for the Structure–Function Relationship of the Mitochondrial Pyruvate Carrier",
           "10.3390/biology9110407",
           2020,
           "The molecular identity of the mitochondrial pyruvate carrier (MPC) was presented in 2012, forty years after the active transport of cytosolic pyruvate into the mitochondrial matrix was first demonstrated. An impressive amount of in vivo and in vitro studies has since revealed an unexpected interplay between one, two, or even three protein subunits defining different functional MPC assemblies in a metabolic-specific context. These have clear implications in cell homeostasis and disease, and on the development of future therapies. Despite intensive efforts by different research groups using state-of-the-art computational tools and experimental techniques, MPCs’ structure-based mechanism remains elusive. Here, we review the current state of knowledge concerning MPCs’ molecular structures by examining both earlier and recent studies and presenting novel data to identify the regulatory, structural, and core transport activities to each of the known MPC subunits. We also discuss the potential application of cryogenic electron microscopy (cryo-EM) studies of MPC reconstituted into nanodiscs of synthetic copolymers for solving human MPC2.",
           4,
           "biology"
          ],
          [
           "Nuclear Syndecan-1 Regulates Epithelial-Mesenchymal Plasticity in Tumor Cells",
           "10.3390/biology10060521",
           2021,
           "Tumor cells undergoing epithelial-mesenchymal transition (EMT) lose cell surface adhesion molecules and gain invasive and metastatic properties. EMT is a plastic process and tumor cells may shift between different epithelial-mesenchymal states during metastasis. However, how this is regulated is not fully understood. Syndecan-1 (SDC1) is the major cell surface proteoglycan in epithelial cells and has been shown to regulate carcinoma progression and EMT. Recently, it was discovered that SDC1 translocates into the cell nucleus in certain tumor cells. Nuclear SDC1 inhibits cell proliferation, but whether nuclear SDC1 contributes to the regulation of EMT is not clear. Here, we report that loss of nuclear SDC1 is associated with cellular elongation and an E-cadherin-to-N-cadherin switch during TGF-β1-induced EMT in human A549 lung adenocarcinoma cells. Further studies showed that nuclear translocation of SDC1 contributed to the repression of mesenchymal and invasive properties of human B6FS fibrosarcoma cells. The results demonstrate that nuclear translocation contributes to the capacity of SDC1 to regulate epithelial-mesenchymal plasticity in human tumor cells and opens up to mechanistic studies to elucidate the mechanisms involved.",
           8,
           "biology"
          ],
          [
           "Seeing Is Believing: Gap Junctions in Motion",
           "10.3390/biology10060494",
           2021,
           "Gap junctional intercellular communication (GJIC) channels between cells are composed of connexin proteins that form hexamers (connexons) in adjacent plasma membranes [...]",
           2,
           "biology"
          ],
          [
           "Correction: Peguda et al. The Activity of Polyhomoarginine against Acanthamoeba castellanii. Biology 2022, 11, 1726",
           "10.3390/biology12030470",
           2023,
           "In the original publication [...]",
           0,
           "biology"
          ],
          [
           "Biological Activity of Cyclic Peptide Extracted from Sphaeranthus amaranthoides Using De Novo Sequencing Strategy by Mass Spectrometry for Cancer",
           "10.3390/biology12030412",
           2023,
           "Though there are several advancements and developments in cancer therapy, the treatment remains challenging. In recent years, the antimicrobial peptides (AMPs) from traditional herbs are focused for identifying and developing potential anticancer molecules. In this study, AMPs are identified from Sphaeranthus amaranthoides, a natural medicinal herb widely used as a crucial immune stimulant in Indian medicine. A total of 86 peptide traces were identified using liquid-chromatography–electrospray-ionisation mass spectrometry (LC-ESI-MS). Among them, three peptides were sequenced using the manual de novo sequencing technique. The in-silico prediction revealed that SA923 is a cyclic peptide with C-N terminal interaction of the carbon atom of ASP7 with the nitrogen atom of GLU1 (1ELVFYRD7). Thus, SA923 is presented under the orbitides class of peptides, which lack the disulfide bonds for cyclization. In addition, SA923, steered with the physicochemical properties and support vector machine (SVM) algorithm mentioned for the segment, has the highest in silico anticancer potential. Further, the in vitro cytotoxicity assay revealed the peptide has anti-proliferative activity, and toxicity studies were demonstrated in Danio rerio (zebrafish) embryos.",
           0,
           "biology"
          ],
          [
           "Whole-Exome Sequencing in Family Trios Reveals De Novo Mutations Associated with Type 1 Diabetes Mellitus",
           "10.3390/biology12030413",
           2023,
           "Type 1 diabetes mellitus (T1DM) is a chronic autoimmune disease characterized by insulin deficiency and loss of pancreatic islet β-cells. The objective of this study is to identify de novo mutations in 13 trios from singleton families that contribute to the genetic basis of T1DM through the application of whole-exome sequencing (WES). Of the 13 families sampled for this project, 12 had de novo variants, with Family 7 having the highest number (nine) of variants linked to T1DM/autoimmune pathways, whilst Family 4 did not have any variants past the filtering steps. There were 10 variants of 7 genes reportedly associated with T1DM (MST1; TDG; TYRO3; IFIHI; GLIS3; VEGFA; TYK2). There were 20 variants of 13 genes that were linked to endocrine, metabolic, or autoimmune diseases. Our findings demonstrate that trio-based WES is a powerful approach for identifying new candidate genes for the pathogenesis of T1D. Genotyping and functional annotation of the discovered de novo variants in a large cohort is recommended to ascertain their association with disease pathogenesis.",
           0,
           "biology"
          ],
          [
           "Revised Annotation and Characterization of Novel Aedes albopictus miRNAs and Their Potential Functions in Dengue Virus Infection",
           "10.3390/biology11101536",
           2022,
           "The Asian tiger mosquito, Ae. albopictus, is a highly invasive species that transmits several arboviruses including dengue (DENV), Zika (ZIKV), and chikungunya (CHIKV). Although several studies have identified microRNAs (miRNAs) in Ae. albopictus, it is crucial to extend and improve current annotations with both the newly improved genome assembly and the increased number of small RNA-sequencing data. We combined our high-depth sequence data and 26 public datasets to re-annotate Ae. albopictus miRNAs and found a total of 72 novel mature miRNAs. We discovered that the expression of novel miRNAs was lower than known miRNAs. Furthermore, compared to known miRNAs, novel miRNAs are prone to expression in a stage-specific manner. Upon DENV infection, a total of 44 novel miRNAs were differentially expressed, and target prediction analysis revealed that miRNA-target genes were involved in lipid metabolism and protein processing in endoplasmic reticulum. Taken together, the miRNA annotation profile provided here is the most comprehensive to date. We believed that this would facilitate future research in understanding virus–host interactions, particularly in the role of miRNAs.",
           0,
           "biology"
          ],
          [
           "Editorial to the Special Issue “Human Bodywork: Applications in Health, Disease, and Rehabilitation”",
           "10.3390/biology12030451",
           2023,
           "In this research topic, the question concerning how the human body functions through the musculoskeletal system was addressed [...]",
           0,
           "biology"
          ],
          [
           "mTORC1/ERK1/2 Interplay Regulates Protein Synthesis and Survival in Acute Myeloid Leukemia Cell Lines",
           "10.3390/biology12050676",
           2023,
           "mTOR is constitutively activated in acute myeloid leukemia (AML) cells, as indicated by the phosphorylation of its substrates, 4EBP1 and P70S6K. Here, we found that quercetin (Q) and rapamycin (Rap) inhibited P70S6K phosphorylation, partially dephosphorylated 4EBP1, and activated ERK1/2 in U937 and THP1, two leukemia cell lines. ERK1/2 inhibition by U0126 induced a stronger dephosphorylation of mTORC1 substrates and activated AKT. The concomitant inhibition of ERK1/2 and AKT further dephosphorylated 4EBP1 and further increased Q- or Rap-mediated cytotoxicity, compared to the single ERK1/2 or AKT inhibition in cells undergoing Q- or Rap-treatments. Moreover, quercetin or rapamycin reduced autophagy, particularly when used in combination with the ERK1/2 inhibitor, U0126. This effect was not dependent on TFEB localization in nuclei or cytoplasm or on the transcription of different autophagy genes, but did correlate with the reduction in protein translation due to a strong eIF2α-Ser51 phosphorylation. Thus, ERK1/2, by limiting 4EBP1 de-phosphorylation and eIF2α phosphorylation, behaves as a paladin of protein synthesis. Based on these findings, the combined inhibition of mTORC1, ERK1/2, and AKT should be considered in treatment of AML.",
           0,
           "biology"
          ],
          [
           "Chronic Corticosterone Exposure Suppresses Copper Transport through GR-Mediated Intestinal CTR1 Pathway in Mice",
           "10.3390/biology12020197",
           2023,
           "Numerous studies have discovered that chronic stress induces metabolic disorders by affecting iron and zinc metabolism, but the relationship between chronic stress and copper metabolism remains unclear. Here, we explore the influence of chronic corticosterone (CORT) exposure on copper metabolism and its regulatory mechanism in mice. Mice were treated with 100 μg/mL CORT in drinking water for a 4-week trial. We found that CORT treatment resulted in a significant decrease in plasma copper level, plasma ceruloplasmin activity, plasma and liver Cu/Zn-SOD activity, hepatic copper content, and liver metallothionein content in mice. CORT treatment led to the reduction in duodenal expression of copper transporter 1 (CTR1), duodenal cytochrome b (DCYTB), and ATPase copper-transporting alpha (ATP7A) at the mRNA and protein level in mice. CORT treatment activated nuclear glucocorticoid receptor (GR) and down-regulated CRT1 expression in Caco-2 cells, whereas these phenotypes were reversible by an antagonist of GR, RU486. Chromatin immunoprecipitation analysis revealed that GR bound to the Ctr1 promoter in Caco-2 cells. Transient transfection assays in Caco-2 cells demonstrated that the Ctr1 promoter was responsive to the CORT-activated glucocorticoid receptor, whereas mutation/deletion of the glucocorticoid receptor element (GRE) markedly impaired activation of the Ctr1 promoter. In addition, CORT-induced downregulation of Ctr1 promoter activity was markedly attenuated in Caco-2 cells when RU486 was added. These findings present a novel molecular target for CORT that down-regulates intestinal CTR1 expression via GR-mediated trans-repression in mice.",
           1,
           "biology"
          ],
          [
           "CT/MRI LI-RADS v2018 vs. CEUS LI-RADS v2017—Can Things Be Put Together?",
           "10.3390/biology10050412",
           2021,
           "Different LI-RADS core documents were released for CEUS and for CT/MRI. Both documents rely on major and ancillary diagnostic criteria. The present paper offers an exhaustive comparison of the two documents focusing on the similarities, but especially on the differences, complementarity, and added value of imaging techniques in classifying liver nodules in cirrhotic livers. The major diagnostic criteria are defined, and the sensitivity and specificity of each major diagnostic criteria are presented according to the literature. The existing differences between techniques in assessing the major diagnostic features can be then exploited in order to ensure a better classification and a better clinical management of liver nodules in cirrhotic livers. Ancillary features depend on the imaging technique used, and their presence can upgrade or downgrade the LI-RADS score of an observation, but only as far as LI-RADS 4. MRI is the imaging technique that provides the greatest number of ancillary features, whereas CEUS has fewer ancillary features than other imaging techniques. In the final part of the manuscript, some recommendations are made by the authors in order to guidephysicians as to when adding another imaging technique can be helpful in managing liver nodules in cirrhotic livers.",
           10,
           "biology"
          ],
          [
           "Analyzing Predominant Bacterial Species and Potential Short-Chain Fatty Acid-Associated Metabolic Routes in Human Gut Microbiome Using Integrative Metagenomics",
           "10.3390/biology12010021",
           2022,
           "Gut microbiome plays an essential role in host health, and there is interest in utilizing diet to modulate the composition and function of microbial communities. Copra meal hydrolysate (CMH) is commonly used as a natural additive to enhance health. However, the gut microbiome is largely unknown at species level and is associated with metabolic routes involving short-chain fatty acids (SCFAs). In this study, we aimed to analyze, using integrative metagenomics, the predominant species and metabolic routes involved in SCFAs production in the human gut microbiome after treatment with CMH. The effect of CMH treatment on the Thai gut microbiome was demonstrated using 16S rRNA genes with whole-metagenome shotgun (WMGS) sequencing technology. Accordingly, these results revealed that CMH has potentially beneficial effects on the gut microbiome. Twelve predominant bacterial species, as well as their potential metabolic routes, were involved in cooperative microbiome networks under sugar utilization (e.g., glucose, mannose, or xylose) and energy supply (e.g., NADH and ATP) in relation to SCFAs biosynthesis. These findings suggest that CMH may be used as a potential prebiotic diet for modulating and maintaining the gut microbiome. To our knowledge, this is the first study to reveal the predominant bacterial species and metabolic routes in the Thai gut microbiome after treatment with potential prebiotics.",
           1,
           "biology"
          ],
          [
           "Reversion of MRAP2 Protein Sequence Generates a Functional Novel Pharmacological Modulator for MC4R Signaling",
           "10.3390/biology11060874",
           2022,
           "As a member of the melanocortin receptor family, melanocortin 4 receptor (MC4R) plays a critical role in regulating energy homeostasis and feeding behavior, and has been proven as a promising therapeutic target for treating severe obesity syndrome. Numerous studies have demonstrated that central MC4R signaling is significantly affected by melanocortin receptor accessory protein 2 (MRAP2) in humans, mice and zebrafish. MRAP2 proteins exist as parallel or antiparallel dimers on the plasma membrane, but the structural insight of dual orientations with the pharmacological profiles has not yet been fully studied. Investigation and optimization of the conformational topology of MRAP2 are critical for the development of transmembrane allosteric modulators to treat MC4R-associated disorders. In this study, we synthesized a brand new single transmembrane protein by reversing wild-type mouse and zebrafish MRAP2 sequences and examined their dimerization, interaction and pharmacological activities on mouse and zebrafish MC4R signaling. We showed that the reversed zebrafish MRAPa exhibited an opposite function on modulating zMC4R signaling and the reversed mouse MRAP2 lost the capability for regulating MC4R trafficking but exhibited a novel function for cAMP cascades, despite proper expression and folding. Taken together, our results provided new biochemical insights on the oligomeric states and membrane orientations of MRAP2 proteins, as well as its pharmacological assistance for modulating MC4R signaling.",
           2,
           "biology"
          ],
          [
           "The Tumor–Fat Interface Volume of Breast Cancer on Pretreatment MRI Is Associated with a Pathologic Response to Neoadjuvant Chemotherapy",
           "10.3390/biology9110391",
           2020,
           "Adipocytes are active sources of numerous adipokines that work in both a paracrine and endocrine manner. It is not known that the direct contact between tumor and neighboring fat measured by pretreatment breast magnetic resonance imaging (MRI) affects treatment outcomes to neoadjuvant chemotherapy (NAC) in breast cancer patients. A biomarker quantifying the tumor–fat interface volume from pretreatment MRI was proposed and used to predict pathologic complete response (pCR) in breast cancer patients treated with NAC. The tumor–fat interface volume was computed with data-driven clustering using multiphasic MRI. Our approach was developed and validated in two cohorts consisting of 1140 patients. A high tumor–fat interface volume was significantly associated with a non-pCR in both the development and validation cohorts (p = 0.030 and p = 0.037, respectively). Quantitative measurement of the tumor–fat interface volume based on pretreatment MRI may be useful for precision medicine and subsequently influence the treatment strategy of patients.",
           3,
           "biology"
          ],
          [
           "Expression Analysis of FGF/FGFR and FOX Family Proteins in Mucosal Tissue Obtained from Orofacial Cleft-Affected Children",
           "10.3390/biology10050423",
           2021,
           "Orofacial clefts affect hundreds of thousands of children worldwide annually and are usually corrected by a series of surgeries extending to childhood. The underlying mechanisms that lead to clefts are still unknown, mainly because of the multifactorial etiology and the myriad of interactions between genes and environmental factors. In the present study, we investigated the role and expression of candidate genes belonging to the FGF/FGFR signaling pathway and FOX family in tissue material obtained from 12 pediatric patients undergoing cleft correction surgery. The expression was investigated using immunohistochemistry (IHC) and chromogenic in-situ hybridization (CISH) in three cell/tissue types—epithelial cells, connective tissue, and endothelial cells. We found elevated expression of FGFR1 in epithelial cells while no expression was observed in endothelial cells. Further, our results elucidate the potential pathogenetic role of FGFR1 in cellular proliferation, local site inflammation, and fibrosis in cleft patients. Along with bFGF (also called FGF2), FGFR1 could play a pro-inflammatory role in clefts. Over-amplification of FGFR2 in some patients, along with bFGF, could potentially suggest roles for these genes in angiogenesis. Additionally, increased expression of FOXE1 (also called TTF2) contributes to local site inflammation. Finally, zero to low amplification of FOXO1 could suggest its potential role in inducing oxidative stress in the endothelium along with reduced epithelial apoptosis.",
           5,
           "biology"
          ],
          [
           "Mechanisms of Venoarteriolar Reflex in Type 2 Diabetes with or without Peripheral Neuropathy",
           "10.3390/biology10040333",
           2021,
           "The aim of this study is to investigate the underlying mechanisms of the venoarteriolar reflex (VAR) in type 2 diabetes mellitus (T2DM), with and without peripheral neuropathy. Laser Doppler flowmetry (LDF) recordings were performed on the medial malleus and dorsal foot skin, before and during leg dependency in healthy controls, in persons with obesity, in those with T2DM, in those with T2DM and subclinical neuropathy, and in those with T2DM and confirmed neuropathy. LDF recordings were analyzed with the wavelet transform to evaluate the mechanisms controlling the flowmotion (i.e., endothelial nitric oxide-independent and -dependent, neurogenic, myogenic, respiratory and cardiac mechanisms). Skin blood perfusion decreased throughout leg dependency at both sites. The decrease was blunted in persons with confirmed neuropathy compared to those with T2DM alone and the controls. During leg dependency, total spectral power increased in all groups compared to rest. The relative contribution of the endothelial bands increased and of the myogenic band decreased, without differences between groups. Neurogenic contribution decreased in controls, in persons with obesity and in those with T2DM, whereas it increased in subclinical- and confirmed neuropathy. In conclusion, this study provides evidence that confirmed diabetic neuropathy alters the VAR through the neurogenic response to leg dependency.",
           2,
           "biology"
          ],
          [
           "The Utility of Genomic and Transcriptomic Data in the Construction of Proxy Protein Sequence Databases for Unsequenced Tree Nuts",
           "10.3390/biology9050104",
           2020,
           "As the apparent incidence of tree nut allergies rises, the development of MS methods that accurately identify tree nuts in food is critical. However, analyses are limited by few available tree nut protein sequences. We assess the utility of translated genomic and transcriptomic data for library construction with Juglans regia, walnut, as a model. Extracted walnuts were subjected to nano-liquid chromatography–mass spectrometry (n-LC-MS/MS), and spectra were searched against databases made from a six-frame translation of the genome (6FT), a transcriptome, and three proteomes. Searches against proteomic databases yielded a variable number of peptides (1156–1275), and only ten additional unique peptides were identified in the 6FT database. Searches against a transcriptomic database yielded results similar to those of the National Center for Biotechnology Information (NCBI) proteome (1200 and 1275 peptides, respectively). Performance of the transcriptomic database was improved via the adjustment of RNA-Seq read processing methods, which increased the number of identified peptides which align to seed allergen proteins by ~20%. Together, these findings establish a path towards the construction of robust proxy protein databases for tree nut species and other non-model organisms.",
           2,
           "biology"
          ],
          [
           "Species-Specific Flash Patterns Track the Nocturnal Behavior of Sympatric Taiwanese Fireflies",
           "10.3390/biology11010058",
           2022,
           "It is highly challenging to evaluate the species’ content and behavior changes in wild fireflies, especially for a sympatric population. Here, the flash interval (FI) and flash duration (FD) of flying males from three sympatric species (Abscondita cerata, Luciola kagiana, and Luciola curtithorax) were investigated for their potentials in assessing species composition and nocturnal behaviors during the A. cerata mating season. Both FI and FD were quantified from the continuous flashes of adult fireflies (lasting 5–30 s) via spatiotemporal analyses of video recorded along the Genliao hiking trail in Taipei, Taiwan. Compared to FD patterns and flash colors, FI patterns exhibited the highest species specificity, making them a suitable reference for differentiating firefly species. Through the case study of a massive occurrence of A. cerata (21 April 2018), the species contents (~85% of the flying population) and active periods of a sympatric population comprising A. cerata and L. kagiana were successfully evaluated by FI pattern matching, as well as field specimen collections. Our study suggests that FI patterns may be a reliable species-specific luminous marker for monitoring the behavioral changes in a sympatric firefly population in the field, and has implication values for firefly conservation.",
           4,
           "biology"
          ],
          [
           "Potential Impact of Polymorphisms in Toll-like Receptors 2, 3, 4, 7, 9, miR-146a, miR-155, and miR-196a Genes on Osteoarthritis Susceptibility",
           "10.3390/biology12030458",
           2023,
           "Osteoarthritis (OA) is a progressive inflammatory disease of synovial joints and a leading cause of disability among adults. Inflammation-related genes, including genes for Toll-like receptors (TLRs), are tightly controlled by several microRNAs that, in addition to their pivotal role in the epigenetic regulation of target genes, are ligands for TLR activation and downstream signaling. Thus, we evaluated the association between OA risk and genetic variants in TLR2, TLR3, TLR4, TLR7, TLR9, and microRNAs that regulate TLRs signaling miR146a, miR155, and miR196a2. Our study group consisted of 95 surgically treated OA patients and a control group of 104 healthy individuals. Genetic polymorphisms were determined using TaqMan real-time PCR assays (Applied Biosystems). Adjusted logistic regression analysis demonstrated that polymorphisms in TLR4 rs4986790 (OR = 2.964, p = 0.006), TLR4 rs4986791 (OR = 8.766, p = 0.00001), and TLR7 rs385389 (OR = 1.579, p = 0.012) increased OA risk, while miR-196a2 rs11614913 (OR = 0.619, p = 0.034) was significantly associated with decreased OA risk. Our findings indicate that polymorphisms in the TLR4 and TLR7 genes might increase OA risk and suggest a novel association of miR-196a2 polymorphism with decreased OA susceptibility. The modulation of TLRs and miRNAs and their cross-talk might be an attractive target for a personalized approach to OA management.",
           3,
           "biology"
          ],
          [
           "Anthropometrics, Performance, and Psychological Outcomes in Mixed Martial Arts Athletes",
           "10.3390/biology11081147",
           2022,
           "The digit ratio (2D:4D) is related to prenatal testosterone (T) and sports performance. Few investigations have explored 2D:4D in determining the potential performance of individuals in power-based sports, specifically combat sports. This study compared 2D:4D between mixed martial arts (MMA) athletes and non-athletes and investigated the association between (1) handgrip strength (HGS) and lean body mass (LBM) with 2D:4D in MMA athletes and (2) psychometric variables and 2D:4D in MMA athletes and non-athletes. In total, 122 men participated in this study (53 non-athletes, 45 professionals, and 24 amateur fighters). The 2D:4D was measured using a caliper, HGS was assessed with a dynamometer, and psychometric variables were evaluated using questionnaires. Athletes displayed significantly (p < 0.05) lower median values of right (0.95 ± 0.04) and left (0.96 ± 0.03) 2D:4D in comparison with non-athletes, (0.97 ± 0.03) and (0.99 ± 0.03), respectively. We observed that left hand 2D:4D was negatively correlated with HGS (r = −0.43; p < 0.05) and lean body mass (r = −0.49; p < 0.05) in professional athletes. Professional athletes also displayed significant differences (* p < 0.05; ** p < 0.001) in psychometric variables compared to non-athletes for (1) agreeableness **, median values (interquartile range) = −0.11 (−0.19–0.07) and 0.2 (−0.09–0.33), respectively; (2) anger **, mean ± standard error = 2.40 ± 0.12 and 2.89 ± 0.89, respectively; and (3) openness *, mean ± standard error = 0.17 ± 0.04 and −0.006 ± 0.04, respectively. However, we did not observe an association between psychometric variables or wins with 2D:4D. In conjunction with other measures, 2D:4D is valuable in determining the potential athleticism of an MMA athlete.",
           8,
           "biology"
          ],
          [
           "A Review of Genetic Abnormalities in Unicentric and Multicentric Castleman Disease",
           "10.3390/biology10040251",
           2021,
           "Castleman disease (CD) is a rare lymphoproliferative disorder known to represent at least four distinct clinicopathologic subtypes. Large advancements in our clinical and histopathologic description of these diverse diseases have been made, resulting in subtyping based on number of enlarged lymph nodes (unicentric versus multicentric), according to viral infection by human herpes virus 8 (HHV-8) and human immunodeficiency virus (HIV), and with relation to clonal plasma cells (POEMS). In recent years, significant molecular and genetic abnormalities associated with CD have been described. However, we continue to lack a foundational understanding of the biological mechanisms driving this disease process. Here, we review all cases of CD with molecular abnormalities described in the literature to date, and correlate cytogenetic, molecular, and genetic abnormalities with disease subtypes and phenotypes. Our review notes complex karyotypes in subsets of cases, specific mutations in PDGFRB N666S in 10% of unicentric CD (UCD) and NCOA4 L261F in 23% of idiopathic multicentric CD (iMCD) cases. Genes affecting chromatin organization and abnormalities in methylation are seen more commonly in iMCD while abnormalities within the mitogen-activated protein kinase (MAPK) and interleukin signaling pathways are more frequent in UCD. Interestingly, there is a paucity of genetic studies evaluating HHV-8 positive multicentric CD (HHV-8+ MCD) and POEMS-associated CD. Our comprehensive review of genetic and molecular abnormalities in CD identifies subtype-specific and novel pathways which may allow for more targeted treatment options and unique biologic therapies.",
           12,
           "biology"
          ],
          [
           "Impact of the “Flavescence Dorée” Phytoplasma on Xylem Growth and Anatomical Characteristics in Trunks of ‘Chardonnay’ Grapevines (Vitis vinifera)",
           "10.3390/biology11070978",
           2022,
           "Flavescence dorée (FD) is a grapevine disease caused by ‘Candidatus Phytoplasma vitis’ (FDp), which is epidemically transmitted by the Nearctic leafhopper Scaphoideus titanus. In this study, we applied dendrochronological techniques to analyse the response to FDp infections in terms of wood ring widths and anatomical structures of the xylem and phloem tissues of the trunk of the susceptible grapevine cultivar ‘Chardonnay.’ As a rule, grapevines are susceptible to water shortage and reduce their growth in diameter in case of summer drought. In the season of the external expression of FD symptoms, however, the ring width reductions are extreme and supersede any drought-induced effects. In addition, the anatomy of the phloem tissue in the year of the FD symptom expression appears heavily disarranged. Moreover, in the most suffering individuals, the xylem formation remains incomplete and mostly limited to the early wood tissue. In conclusion, even though the FD phytoplasma does not inhabit and replicate inside the xylem tissue, our results confirm existing indirect inhibiting effects on the ring growth and the xylem tissue formation in FDp-infected grapevines.",
           3,
           "biology"
          ],
          [
           "Influence of Hyperproteinemia on Insect Innate Immune Function of the Circulatory System in Bombyx mori",
           "10.3390/biology10020112",
           2021,
           "Metabolic disorders of the circulatory system of animals (e.g., hyperglycemia and hyperlipidemia) can significantly affect immune function; however, since there is currently no reliable animal model for hyperproteinemia, its effects on immunity remain unclear. In this study, we established an animal model for hyperproteinemia in an invertebrate silkworm model, with a controllable plasma protein concentration (PPC) and no primary disease effects. We evaluated the influence of hyperproteinemia on innate immunity. The results showed that high PPC enhanced hemolymph phagocytosis via inducing a rapid increase in granulocytes. Moreover, while oenocytoids increased, the plasmacytes quickly dwindled. High PPC inhibited hemolymph melanization due to decreased phenoloxidase (PO) activity in the hemolymph via inhibiting the expression of the prophenoloxidase-encoding genes, PPO1 and PPO2. High PPC upregulated the gene expression of antimicrobial peptides via differential activation of the Toll and Imd signaling pathways associated with NF-κB signaling, followed by an induction of inconsistent antibacterial activity towards Gram-positive and Gram-negative bacteria in an animal model of high PPC. Therefore, high PPC has multiple significant effects on the innate immune function of the silkworm circulatory system.",
           5,
           "biology"
          ],
          [
           "Distributional Response of the Rare and Endangered Tree Species Abies chensiensis to Climate Change in East Asia",
           "10.3390/biology11111659",
           2022,
           "Globally, increasing temperatures due to climate change have severely affected natural ecosystems in several regions of the world; however, the impact on the alpine plant may be particularly profound, further raising the risk of extinction for rare and endangered alpine plants. To identify how alpine species have responded to past climate change and to predict the potential geographic distribution of species under future climate change, we investigated the distribution records of A. chensiensis, an endangered alpine plant in the Qinling Mountains listed in the Red List. In this study, the optimized MaxEnt model was used to analyse the key environmental variables related to the distribution of A. chensiensis based on 93 wild distribution records and six environmental variables. The potential distribution areas of A. chensiensis in the last interglacial (LIG), the last glacial maximum (LGM), the current period, and the 2050s and 2070s were simulated. Our results showed that temperature is critical to the distribution of A. chensiensis, with the mean temperature of the coldest quarter being the most important climatic factor affecting the distribution of this species. In addition, ecological niche modeling analysis showed that the A. chensiensis distribution area in the last interglacial experiencing population expansion and, during the last glacial maximum occurring, a population contraction. Under the emission scenarios in the 2050s and 2070s, the suitable distribution area would contract significantly, and the migration routes of the centroids tended to migrate toward the southern high-altitude mountains, suggesting a strong response from the A. chensiensis distribution to climate change. Collectively, the results of this study provide a comprehensive and multidimensional perspective on the geographic distribution pattern and history of population dynamics for the endemic, rare, and endangered species, A. chensiensis, and it underscores the significant impact of geological and climatic changes on the geographic pattern of alpine species populations.",
           5,
           "biology"
          ],
          [
           "Mesenchymal Stem Cell-Derived Extracellular Vesicles: Regenerative Potential and Challenges",
           "10.3390/biology10030172",
           2021,
           "Evidence suggests that stem cells exert regenerative potential via the release of extracellular vesicles. Mesenchymal stem cell extracellular vesicles (MSCEVs) offer therapeutic benefits for various pathophysiological ailments by restoring tissues. Facts suggest that MSCEV action can be potentiated by modifying the mesenchymal stem cells culturing methodology and bioengineering EVs. Limited clinical trials of MSCEVs have questioned their superiority, culturing quality, production scale-up and isolation, and administration format. Translation of preclinically successful MSCEVs into a clinical platform requires paying attention to several critical matters, such as the production technique, quantification/characterization, pharmacokinetics/targeting/transfer to the target site, and the safety profile. Keeping these issues as a priority, the present review was designed to highlight the challenges in translating preclinical MSCEV research into clinical platforms and provide evidence for the regenerative potential of MSCEVs in various conditions of the liver, kidney, heart, nervous system, bone, muscle, cartilage, and other organs/tissues.",
           31,
           "biology"
          ],
          [
           "Molecular Approaches for Detection of Trichoderma Green Mold Disease in Edible Mushroom Production",
           "10.3390/biology12020299",
           2023,
           "Due to the evident aggressive nature of green mold and the consequently huge economic damage it causes for producers of edible mushrooms, there is an urgent need for prevention and infection control measures, which should be based on the early detection of various Trichoderma spp. as green mold causative agents. The most promising current diagnostic tools are based on molecular methods, although additional optimization for real-time, in-field detection is still required. In the first part of this review, we briefly discuss cultivation-based methods and continue with the secondary metabolite-based methods. Furthermore, we present an overview of the commonly used molecular methods for Trichoderma species/strain detection. Additionally, we also comment on the potential of genomic approaches for green mold detection. In the last part, we discuss fast screening molecular methods for the early detection of Trichoderma infestation with the potential for in-field, point-of-need (PON) application, focusing on isothermal amplification methods. Finally, current challenges and future perspectives in Trichoderma diagnostics are summarized in the conclusions.",
           2,
           "biology"
          ],
          [
           "The Effect of Normobaric Hypoxia in Middle- and/or Long-Distance Runners: Systematic Review",
           "10.3390/biology11050689",
           2022,
           "Background: The use of normobaric hypoxia can bring benefits to sports performance because it improves haematological parameters and/or physical activity tests. Our objective was to conduct a systematic review so as to analyse the methods used in hypoxia and to detect its effects on middle- and/or long-distance runners. Methods: Research was conducted using five electronic databases (PubMed, SportDiscus, Cochrane Library, Scopus and PEDro) until December 2021. The methodological quality of the included studies was assessed using the PEDro scale. Results: Having analysed 158 studies, 12 were chosen for the qualitative and quantitative synthesis. A significant improvement on time until exhaustion was detected, and oxygen saturation decreased after the intervention. There were no significant changes in the 3000-metre time trial or in the haematocrit percentage. The changes in percentage of reticulocytes, heart rate, maximal heart rate, lactate concentration and erythropoietin were heterogeneous between the different research studies. Conclusion: short exposure (less than 3 h to normobaric hypoxia significantly increases the time to exhaustion). However, longer exposure times are necessary to increase haemoglobin. Altitude and exposure time are highly heterogeneous in the included studies.",
           3,
           "biology"
          ],
          [
           "Biotransformation of Androstenedione by Filamentous Fungi Isolated from Cultural Heritage Sites in the State Tretyakov Gallery",
           "10.3390/biology11060883",
           2022,
           "The transformation of steroids by microorganisms is widely used in medical biotechnology. A huge group of filamentous fungi is one of the most promising taxa for screening new biocatalytic reactions in order to obtain pharmaceutically significant steroids. In this work, we screened 10 filamentous fungi-destructors of egg tempera for the ability to biotransform androst-4-en-3,17-dione (AD) during cultivation in a liquid nutrient medium or in a buffer solution. These taxonomically unrelated strains, belonging to the classes Eurotiomycetes, Dothideomycetes and Sordariomycetes, are dominant representatives of the microbiome from halls where works of tempera painting are stored in the State Tretyakov Gallery (STG, Moscow, Russia). Since the binder of tempera paints, egg yolk, contains about 2% cholesterol, these degrading fungi appear to be a promising group for screening for steroid converting activity. It turned out that all the studied fungi-destructors are able to transform AD. Some strains showed transformation efficiency close to the industrial strain Curvularia lunata RNCIM F-981. In total, 33 steroids formed during the transformation of AD were characterized, for 19 of them the structure was established by gas chromatography/mass spectrometry analysis. In this work, we have shown for the first time that fungi-destructors of tempera paintings can efficiently transform steroids.",
           3,
           "biology"
          ],
          [
           "Quercetin: A Bioactive Compound Imparting Cardiovascular and Neuroprotective Benefits: Scope for Exploring Fresh Produce, Their Wastes, and By-Products",
           "10.3390/biology10070586",
           2021,
           "Quercetin, a bioactive secondary metabolite, holds incredible importance in terms of bioactivities, which has been proved by in vivo and in vitro studies. The treatment of cardiovascular and neurological diseases by quercetin has been extensively investigated over the past decade. Quercetin is present naturally in appreciable amounts in fresh produce (fruits and vegetables). However, today, corresponding to the growing population and global demand for fresh fruits and vegetables, a paradigm shift and focus is laid towards exploring industrial food wastes and/or byproducts as a new resource to obtain bioactive compounds such as quercetin. Based on the available research reports over the last decade, quercetin has been suggested as a reliable therapeutic candidate for either treating or alleviating health issues, mainly those of cardiovascular and neurological diseases. In the present review, we have summarized some of the critical findings and hypotheses of quercetin from the available databases foreseeing its future use as a potential therapeutic agent to treat cardiovascular and neurological diseases. It is anticipated that this review will be a potential reference material for future research activities to be undertaken on quercetin obtained from fresh produce as well as their respective processing wastes/byproducts that rely on the circular concept.",
           22,
           "biology"
          ],
          [
           "Dispersal and Repulsion of Entomopathogenic Nematodes to Prenol",
           "10.3390/biology8030058",
           2019,
           "Chemosensory cues are crucial for entomopathogenic nematodes (EPNs)—a guild of insect-killing parasitic nematodes that are used as biological control agents against a variety of agricultural pests. Dispersal is an essential element of the EPN life cycle in which newly developed infective juveniles (IJs) emerge and migrate away from a resource-depleted insect cadaver in order to search for new hosts. Emergence and dispersal are complex processes that involve biotic and abiotic factors, however, the elements that result in EPN dispersal behaviors have not been well-studied. Prenol is a simple isoprenoid and a natural alcohol found in association with EPN-infected, resource-depleted insect cadavers, and this odorant has been speculated to play a role in dispersal behavior in EPNs. This hypothesis was tested by evaluating the behavioral responses of five different species of EPNs to prenol both as a distal-chemotactic cue and as a dispersal cue. The results indicate that prenol acted as a repulsive agent for all five species tested, while only two species responded to prenol as a dispersal cue.",
           10,
           "biology"
          ],
          [
           "A Multifactorial Approach for Sarcopenia Assessment: A Literature Review",
           "10.3390/biology10121354",
           2021,
           "Sarcopenia refers to a progressive and generalized weakness of skeletal muscle as individuals age. Sarcopenia usually occurs after the age of 60 years and is associated with a persistent decline in muscle strength, function, and quality. A comparison of the risk factors associated with sarcopenia based on the European Working Group on Sarcopenia (1 and 2) in Older People, the Asian Working Group for Sarcopenia (1 and 2), the International Working Group on Sarcopenia, and the Foundation for the National Institutes of Health revealed no consistent patterns. Accordingly, the identification of a single risk factor for sarcopenia is unpredictable due to its “multifactorial” pathogenesis, with the involvement of a multitude of factors. Therefore, the first aim of this review was to outline and propose that the multiple factors associated with sarcopenia need to be considered in combination in the design of new experimentation in this area. A secondary aim was to highlight the biochemical risk factors that are already identified in subjects with sarcopenia to assist scientists in understanding the biology of the pathophysiological mechanisms affecting the old people with sarcopenia. We also briefly discuss primary outcomes (physical) and secondary outcomes (social and financial) of sarcopenia. For future investigative purposes, this comprehensive review may be useful in considering important risk factors in the utilization of a panel of biomarkers emanating from all pathways involved in the pathogenesis of this disease. This may help to establish a uniform consensus for screening and defining this disease. Considering the COVID-19 pandemic, its impact may be exacerbated in older populations, which requires immediate attention. Here, we briefly suggest strategies for advancing the development of smart technologies to deliver exercise in the COVID-19 era in an attempt regress the onset of sarcopenia. These strategies may also have an impact on sarcopenia’s primary and secondary outcomes.",
           10,
           "biology"
          ],
          [
           "The Key Element Role of Metallophores in the Pathogenicity and Virulence of Staphylococcus aureus: A Review",
           "10.3390/biology11101525",
           2022,
           "The ubiquitous bacterium Staphylococcus aureus causes many diseases that sometimes can be fatal due to its high pathogenicity. The latter is caused by the ability of this pathogen to secrete secondary metabolites, enabling it to colonize inside the host causing infection through various processes. Metallophores are secondary metabolites that enable bacteria to sequester metal ions from the surrounding environment since the availability of metal ions is crucial for bacterial metabolism and virulence. The uptake of iron and other metal ions such as nickel and zinc is one of these essential mechanisms that gives this germ its virulence properties and allow it to overcome the host immune system. Additionally, extensive interactions occur between this pathogen and other bacteria as they compete for resources. Staphylococcus aureus has high-affinity metal import pathways including metal ions acquisition, recruitment and metal–chelate complex import. These characteristics give this bacterium the ability to intake metallophores synthesized by other bacteria, thus enabling it to compete with other microorganisms for the limited nutrients. In scarce host conditions, free metal ions are extremely low because they are confined to storage and metabolic molecules, so metal ions are sequestered by metallophores produced by this bacterium. Both siderophores (iron chelating molecules) and staphylopine (wide- spectrum metallophore) are secreted by Staphylococcus aureus giving it infectious properties. The genetic regulation of the synthesis and export together with the import of metal loaded metallophores are well established and are all covered in this review.",
           15,
           "biology"
          ],
          [
           "Application of 2,4-Epibrassinolide Improves Drought Tolerance in Tobacco through Physiological and Biochemical Mechanisms",
           "10.3390/biology11081192",
           2022,
           "Drought stress is a major abiotic stress that hinders plant growth and development. Brassinosteroids (BR), including 2,4-epibrassinolide (EBR), play important roles in plant growth, development, and responses to abiotic stresses, including drought stress. This work investigates exogenous EBR application roles in improving drought tolerance in tobacco. Tobacco plants were divided into three groups: WW (well-watered), DS (drought stress), and DSB (drought stress + 0.05 mM EBR). The results revealed that DS decreased the leaf thickness (LT), whereas EBR application upregulated genes related to cell expansion, which were induced by the BR (DWF4, HERK2, and BZR1) and IAA (ARF9, ARF6, PIN1, SAUR19, and ABP1) signaling pathway. This promoted LT by 28%, increasing plant adaptation. Furthermore, EBR application improved SOD (22%), POD (11%), and CAT (5%) enzyme activities and their related genes expression (FeSOD, POD, and CAT) along with a higher accumulation of osmoregulatory substances such as proline (29%) and soluble sugars (14%) under DS and conferred drought tolerance. Finally, EBR application augmented the auxin (IAA) (21%) and brassinolide (131%) contents and upregulated genes related to drought tolerance induced by the BR (BRL3 and BZR2) and IAA (YUCCA6, SAUR32, and IAA26) signaling pathways. These results suggest that it could play an important role in improving mechanisms of drought tolerance in tobacco.",
           11,
           "biology"
          ],
          [
           "Impact of the Static Magnetic Field on Growth, Pigments, Osmolytes, Nitric Oxide, Hydrogen Sulfide, Phenylalanine Ammonia-Lyase Activity, Antioxidant Defense System, and Yield in Lettuce",
           "10.3390/biology9070172",
           2020,
           "Magnetic fields are an unavoidable physical factor affecting living organisms. Lettuce seeds (Lactuca sativa var. cabitat L.) were subjected to various intensities of the static magnetic field (SMF) viz., MF0 (control), SMF1 (0.44 Tesla (T), SMF2 (0.77 T), and SMF3 (1 T) for three exposure times (1, 2, and 3 h). SMF-treated seedlings showed induction in growth parameters and metabolism comparing to control. All photosynthetic pigments were induced markedly under SMF, especially chlorophyll a. SMF at different intensities boosted osmolytes, non-enzymatic antioxidants, and the phenylalanine ammonia-lyase activity over non-magnetized seedlings. Oxidative damage criteria viz., hydrogen peroxide, superoxide radical, and lipid peroxidation, as well as polyphenol oxidase activity, were kept at low values under SMF-treated seeds relative to control, especially SMF2. Electron donors to antioxidant enzymes including nitrate reductase, nitric oxide, and hydrogen sulfide induced via SMF exposure and consequently the activities of superoxide dismutase, glutathione-S-transferases, catalase, and peroxidases family enzymes were also stimulated under SMF, whatever the intensity or the exposure period applied. All these regulations reflected on the enhancement of lettuce yield production which reached 50% over the control at SMF3. Our findings offered that SMF-seed priming is an innovative and low-cost strategy that can improve the growth, bioactive constituents, and yield of lettuce.",
           31,
           "biology"
          ],
          [
           "Calcined Oyster Shell Powder as a Natural Preservative for Maintaining Quality of White Shrimp (Litopenaeus vannamei)",
           "10.3390/biology11020334",
           2022,
           "Oyster shell waste has led to many problems, including displeasing odors, pollution of the seaside, and harm to the environment. Using calcined oyster shells as a natural preservative might solve the problem of oyster shell waste. We studied the use of calcined oyster shell powder (COSP) as a natural preservative for improving shrimp shelf-life over 12 days under refrigerated conditions. As compared with the control, COSP treatment effectively retarded pH change, reduced the formation of total volatile basic nitrogen, and inhibited bacterial growth during refrigerated storage. In addition, shrimp muscle lipid oxidation measured by peroxide value (PV) and thiobarbituric acid (TBA) was decreased during storage. The quality was preserved up to 12 days with 2.0–4.0% COSP treatment as compared with only 6 days for un-treated shrimp. The development of preservatives for aquatic products is expected to delay growth of and spoilage by microorganisms in the refrigerated state, thus providing more barrier protection for aquatic food safety.",
           10,
           "biology"
          ],
          [
           "Climate Change Drives the Transmission and Spread of Vector-Borne Diseases: An Ecological Perspective",
           "10.3390/biology11111628",
           2022,
           "Climate change affects ecosystems and human health in multiple dimensions. With the acceleration of climate change, climate-sensitive vector-borne diseases (VBDs) pose an increasing threat to public health. This paper summaries 10 publications on the impacts of climate change on ecosystems and human health; then it synthesizes the other existing literature to more broadly explain how climate change drives the transmission and spread of VBDs through an ecological perspective. We highlight the multi-dimensional nature of climate change, its interaction with other factors, and the impact of the COVID-19 pandemic on transmission and spread of VBDs, specifically including: (1) the generally nonlinear relationship of local climate (temperature, precipitation and wind) and VBD transmission, with temperature especially exhibiting an n-shape relation; (2) the time-lagged effect of regional climate phenomena (the El Niño–Southern Oscillation and North Atlantic Oscillation) on VBD transmission; (3) the u-shaped effect of extreme climate (heat waves, cold waves, floods, and droughts) on VBD spread; (4) how interactions between non-climatic (land use and human mobility) and climatic factors increase VBD transmission and spread; and (5) that the impact of the COVID-19 pandemic on climate change is debatable, and its impact on VBDs remains uncertain. By exploring the influence of climate change and non-climatic factors on VBD transmission and spread, this paper provides scientific understanding and guidance for their effective prevention and control.",
           7,
           "biology"
          ],
          [
           "Phenotypic and Genotypic Detection of Biofilm-Forming Staphylococcus aureus from Different Food Sources in Bangladesh",
           "10.3390/biology11070949",
           2022,
           "Staphylococcus aureus is a major foodborne pathogen. The ability of S. aureus to produce biofilm is a significant virulence factor, triggering its persistence in hostile environments. In this study, we screened a total of 420 different food samples and human hand swabs to detect S. aureus and to determine their biofilm formation ability. Samples analyzed were meat, milk, eggs, fish, fast foods, and hand swabs. S. aureus were detected by culturing, staining, biochemical, and PCR. Biofilm formation ability was determined by Congo Red Agar (CRA) plate and Crystal Violet Microtiter Plate (CVMP) tests. The icaA, icaB, icaC, icaD, and bap genes involved in the synthesis of biofilm-forming intracellular adhesion compounds were detected by PCR. About 23.81% (100/420; 95% CI: 14.17–29.98%) of the samples harbored S. aureus, as revealed by detection of the nuc gene. The CRA plate test revealed 20% of S. aureus isolates as strong biofilm producers and 69% and 11% as intermediate and non-biofilm producers, respectively. By the CVMP staining method, 20%, 77%, and 3% of the isolates were found to be strong, intermediate, and non-biofilm producers. Furthermore, 21% of S. aureus isolates carried at least one biofilm-forming gene, where icaA, icaB, icaC, icaD, and bap genes were detected in 15%, 20%, 7%, 20%, and 10% of the S. aureus isolates, respectively. Bivariate analysis showed highly significant correlations (p < 0.001) between any of the two adhesion genes of S. aureus isolates. To the best of our knowledge, this is the first study in Bangladesh describing the detection of biofilm-forming S. aureus from foods and hand swabs using molecular-based evidence. Our findings suggest that food samples should be deemed a potential reservoir of biofilm-forming S. aureus, which indicates a potential public health significance.",
           12,
           "biology"
          ],
          [
           "Combination Effects of Integrin-linked Kinase and Abelson Kinase Inhibition on Aberrant Mitosis and Cell Death in Glioblastoma Cells",
           "10.3390/biology12070906",
           2023,
           "In cancer cells, inhibition of integrin-linked kinase (ILK) increases centrosome declustering causing mitotic arrest and cell death. Yet, not all cancer cells are susceptible to anti-ILK treatment alone. We investigate a combination drug strategy targeting ILK and another oncogenic kinase, Abelson kinase (ABL). Drug-concentration viability assays (i.e., MTT assays) indicate that ILK and ABL inhibitors in combination decreased the viability of glioblastoma cells over the ILK drug QLT-0267 alone. Combination strategies also increased aberrant mitoses and cell death over QLT-0267 alone. This was evident from an increase in mitotic arrest, apoptosis and a sub-G1 peak following FAC analysis. In vitro, ILK and ABL localized to the centrosome and the putative ILK kinase domain was important for this localization. Increased levels of cytosolic ABL are associated with its transformative abilities. ILK inhibitor effects on survival correlated with its ability to decrease cytosolic ABL levels and inhibit ABL’s localization to mitotic centrosomes in glioblastoma cells. ILK inhibitor effects on ABL’s centrosomal localization were reversed by the proteasomal inhibitor MG132 (a drug that inhibits ABL degradation). These results indicate that ILK regulates ABL at mitotic centrosomes and that combination treatments targeting ILK and ABL are more effective then QLT-0267 alone at decreasing the survival of dividing glioblastoma cells.",
           0,
           "biology"
          ],
          [
           "Seasonal Patterns of Picocyanobacterial Community Structure in the Kuroshio Current",
           "10.3390/biology12111424",
           2023,
           "The nutrient-scarce, warm, and high-salinity Kuroshio current has a profound impact on both the marine ecology of the northwestern Pacific Ocean and the global climate. This study aims to reveal the seasonal dynamics of picoplankton in the subtropical Kuroshio current. Our results showed that one of the picocyanobacteria, Synechococcus, mainly distributed in the surface water layer regardless of seasonal changes, and the cell abundance ranged from 104 to 105 cells mL−1. In contrast, the maximum concentration of the other picocyanobacteria, Prochlorococcus, was maintained at more than 105 cells mL−1 throughout the year. In the summer and the autumn, Prochlorococcus were mainly concentrated at the water layer near the bottom of the euphotic zone. They were evenly distributed in the euphotic zone in the spring and winter. The stirring effect caused by the monsoon determined their distribution in the water column. In addition, the results of 16S rRNA gene diversity analysis showed that the seasonal changes in the relative abundance of Synechococcus and Prochlorococcus in the surface water of each station accounted for 20 to 40% of the total reads. The clade II of Synechococcus and the High-light II of Prochlorococcus were the dominant strains in the waters all year round. Regarding other picoplankton, Proteobacteria and Actinobacteria occupied 45% and 10% of the total picoplankton in the four seasons. These data should be helpful for elucidating the impacts of global climate changes on marine ecology and biogeochemical cycles in the Western Boundary Currents in the future.",
           0,
           "biology"
          ],
          [
           "Preserving Pure Siamese Crocodile Populations: A Comprehensive Approach Using Multi-Genetic Tools",
           "10.3390/biology12111428",
           2023,
           "Hybrids between the critically endangered Siamese crocodile (Crocodylus siamensis) and least-concern saltwater crocodile (C. porosus) in captive populations represent a serious challenge for conservation and reintroduction programs due to the impact of anthropogenic activities. A previous study used microsatellite and mitochondrial DNA data to establish the criteria for identifying species and their hybrids; however, the results may have been influenced by biased allelic frequencies and genetic drift within the examined population. To overcome these limitations and identify the true signals of selection, alternative DNA markers and a diverse set of populations should be employed. Therefore, this study used DArT sequencing to identify genome-wide single nucleotide polymorphisms (SNPs) in both species and confirm the genetic scenario of the parental species and their hybrids. A population of saltwater crocodiles from Australia was used to compare the distribution of species-diagnostic SNPs. Different analytical approaches were compared to diagnose the level of hybridization when an admixture was present, wherein three individuals had potential backcrossing. Approximately 17.00–26.00% of loci were conserved between the Siamese and saltwater crocodile genomes. Species-diagnostic SNP loci for Siamese and saltwater crocodiles were identified as 8051 loci and 1288 loci, respectively. To validate the species-diagnostic SNP loci, a PCR-based approach was used by selecting 20 SNP loci for PCR primer design, among which 3 loci were successfully able to differentiate the actual species and different hybridization levels. Mitochondrial and nuclear genetic information, including microsatellite genotyping and species-diagnostic DNA markers, were combined as a novel method that can compensate for the limitations of each method. This method enables conservation prioritization before release into the wild, thereby ensuring sustainable genetic integrity for long-term species survival through reintroduction and management programs.",
           0,
           "biology"
          ],
          [
           "Gymnema sylvestre Extract Restores the Autophagic Pathway in Human Glioblastoma Cells U87Mg",
           "10.3390/biology10090870",
           2021,
           "Glioblastoma is a brain tumour, characterised by recurrent or innate resistance to conventional chemoradiotherapy. Novel natural molecules and phyto-extracts have been proposed as adjuvants to sensitise the response to Temozolomide (TMZ). In this study, we investigated the effect of GS extract on human glioblastoma cells U87Mg. According to the IC50-values, GS extract displayed a significant cytotoxicity. This was confirmed by cell growth inhibition and alteration in metabolic activity evaluated by cell count and MTT assay. GS induced reduction in Pro-caspase 9, 3, but not PARP cleavage nor DNA fragmentation. Thus, in GS-induced cytotoxicity, cell death is not associated with apoptosis. In this context, short-term treatment of U87Mg cells with GS extract (1 mg/mL) reduced the phosphorylation levels of mTOR and of its downstream target P70 S6 kinase, highlighting the role of GS extract into autophagy induction. The activation of autophagic flux by GS extract was confirmed by Western blot analysis, which revealed the reduction in p62 and the concomitant increase in LC3B II/I ratio. Immunofluorescence evidenced the accumulation of LC3B puncta in U87Mg cells pretreated with autophagy inhibitor Bafilomycin A1. Furthermore, as main key regulators of type II programmed cell death, p53, p21 and CDK4 were also investigated and were inhibited by GS treatment. In conclusion, GS extract could be considered as an autophagy inducer in glioblastoma cells U87Mg.",
           0,
           "biology"
          ],
          [
           "Opioid-Induced Immunomodulation: Consequences for the Experimental Coxsackievirus B3-Induced Myocarditis Model",
           "10.3390/biology9100335",
           2020,
           "Myocarditis is an inflammatory disorder of the heart predominantly caused by infectious agents. Since more than sixty years, the Coxsackievirus B3 (CVB3)-induced myocarditis mouse model is the experimental model used to investigate viral myocarditis. The pathogenesis of viral myocarditis is conceptually a multiphase process, initiated by the infection of cardiomyocytes, followed by activation of the immune system, and resulting in myocardial fibrosis and left ventricular dysfunction. In parallel to the direct infection of the heart, CVB3 replicates in lymphatic organs such as the pancreas. Due to infection of the pancreas, the model of experimental CVB3-induced myocarditis is estimated as a severe burden for the challenged animals. Application of analgesics in frame of the animal welfare act (European directive 2010/63/EU) is more and more becoming a matter of debate. For this purpose, we summarized published studies for 13 different opioids and discussed their potential impact on CVB3-induced myocarditis. In addition, with this summary we also want to provide guidance for researchers beyond the myocarditis field to estimate the impact of opioids on the immune system for their specific model. In the literature, both immunosuppressive as well as immune-activating effects of opioids have been described, but examinations in experimental CVB3-induced myocarditis have still not been reported so far. Based on the existing publications, administration of opioids in experimental CVB3-induced myocarditis might result in more severe disease progression, including higher mortality, or a less pronounced myocarditis model, failing to be used for the establishment of new treatment options. Taken together, the applicability of opioids in experimental CVB3-induced myocarditis and in inflammatory models in general needs to be carefully evaluated and further investigated.",
           1,
           "biology"
          ],
          [
           "Differential Expression of the Tetraspanin CD9 in Normal and Leukemic Stem Cells",
           "10.3390/biology10040312",
           2021,
           "CD9 plays a crucial role in cellular growth, mobility, and signal transduction, as well as in hematological malignancy. In myeloid neoplasms, CD9 is involved in the altered interactions between leukemic and stromal cells. However, apart from its role in CD34+ progenitors and myeloid and megakaryocytic differentiation, its function in normal and leukemic pluripotent cells has not yet been determined. Very small embryonic-like stem cells (VSELs) are promising pluripotent stem cells found in adult tissues that can be developed for safe and efficient regenerative medicine. VSELs express different surface receptors of the highest importance in cell functioning, including CD9, and can be effectively mobilized after organ injury or in leukemic patients. In the present study, we observed that CD9 is among the most expressed receptors in VSELs under steady-state conditions; however, once the VSELs are expanded, CD9+ VSELs decrease and are more apoptotic. CD9– VSELs had no proliferative improvement in vitro compared to those that were CD9+. Interestingly, the addition of SDF-1 induced CD9 expression on the surface of VSELs, as observed by flow cytometry, and improved their migration. In addition, we observed, in the phenotypically identical VSELs present in the peripheral blood of patients with myeloproliferative neoplasms, compared to healthy subjects, a significantly higher number of CD9+ cells. However, in their hematopoietic stem cell (HSC) counterparts, the expression remained comparable. These results indicate that, likewise, in progenitors and mature cells, CD9 may play an important function in normal and malignant VSELs. This could explain the refractoriness observed by some groups of expanded stem cells to repairing efficiently damaged tissue when used as a source in cell therapies. Understanding the function of the CD9 receptor in normal and malignant CD34+ and VSELs, along with its relationship with the CXCR4/SDF-1 pathway, will enable advances in the field of adult pluripotent cell usage in regenerative medicine and in their role in leukemia.",
           0,
           "biology"
          ],
          [
           "A Comparative Study of Rat Urine 1H-NMR Metabolome Changes Presumably Arising from Isoproterenol-Induced Heart Necrosis Versus Clarithromycin-Induced QT Interval Prolongation",
           "10.3390/biology9050098",
           2020,
           "Cardiotoxicity remains a challenging concern both in drug development and in the management of various clinical situations. There are a lot of examples of drugs withdrawn from the market or stopped during clinical trials due to unpredicted cardiac adverse events. Obviously, current conventional methods for cardiotoxicity assessment suffer from a lack of predictivity and sensitivity. Therefore, there is a need for developing new tools to better identify and characterize any cardiotoxicity that can occur during the pre-clinical and clinical phases of drug development as well as after marketing in exposed patients. In this study, isoproterenol and clarithromycin were used as prototypical cardiotoxic agents in rats in order to evaluate potential biomarkers of heart toxicity at very early stages using 1H-NMR-based metabonomics. While isoproterenol is known to cause heart necrosis, clarithromycin may induce QT interval prolongation. Heart necrosis and QT prolongation were validated by histological analysis, serum measurement of lactate dehydrogenase/creatine phosphate kinase and QTc measurement by electrocardiogram (ECG). Urine samples were collected before and repeatedly during daily exposure to the drugs for 1H-NMR based-metabonomics investigations. Specific metabolic signatures, characteristic of each tested drug, were obtained from which potential predictive biomarkers for drug-induced heart necrosis and drug-induced QT prolongation were retrieved. Isoproterenol-induced heart necrosis was characterized by higher levels of taurine, creatine, glucose and by lower levels of Krebs cycle intermediates, creatinine, betaine/trimethylamine N-oxide (TMAO), dimethylamine (DMA)/sarcosine. Clarithromycin-induced QT prolongation was characterized by higher levels of creatinine, taurine, betaine/TMAO and DMA/sarcosine and by lower levels of Krebs cycle intermediates, glucose and hippurate.",
           1,
           "biology"
          ],
          [
           "The Evolutionary History of New Zealand Deschampsia Is Marked by Long-Distance Dispersal, Endemism, and Hybridization",
           "10.3390/biology10101001",
           2021,
           "The contrasting evolutionary histories of endemic versus related cosmopolitan species provide avenues to understand the spatial drivers and limitations of biodiversity. Here, we investigated the evolutionary history of three New Zealand endemic Deschampsia species, and how they are related to cosmopolitan D. cespitosa. We used RADseq to test species delimitations, infer a dated species tree, and investigate gene flow patterns between the New Zealand endemics and the D. cespitosa populations of New Zealand, Australia and Korea. Whole plastid DNA analysis was performed on a larger worldwide sampling. Morphometrics of selected characters were applied to New Zealand sampling. Our RADseq review of over 55 Mbp showed the endemics as genetically well-defined from each other. Their last common ancestor with D. cespitosa lived during the last ten MY. The New Zealand D. cespitosa appears in a clade with Australian and Korean samples. Whole plastid DNA analysis revealed the endemics as members of a southern hemisphere clade, excluding the extant D. cespitosa of New Zealand. Both data provided strong evidence for hybridization between D. cespitosa and D. chapmanii. Our findings provide evidence for at least two migration events of the genus Deschampsia to New Zealand and hybridization between D. cespitosa and endemic taxa.",
           1,
           "biology"
          ],
          [
           "Interaction of Metals, Menopause and COVID-19—A Review of the Literature",
           "10.3390/biology12030350",
           2023,
           "A growing number of reports point to the possible role of environmental factors in determining the age of onset of menopause. Specific metals, such as mercury, cadmium, arsenic and lead can lead to fertility disorders, to endocrine dysregulation, and in addition, their high blood concentrations correlate with the onset of menopause. Changing concentrations of hormones in the blood during this period of a woman’s life can also have an impact on SARS-CoV-2 infection, and excessively high or low levels of metals may also be an important predictor for the course of COVID-19. Postmenopausal women are exposed to greater risk of serum biochemical changes, and with the possibility of nutritional disturbances, particularly involving trace minerals, the risk of age-related diseases is very high during this period. These adverse changes in serum trace minerals should be taken into consideration for the early diagnosis and prevention of menopause-related diseases. Dietary supplementation may be necessary, especially where levels are significantly reduced. We performed a manual search of scientific articles cited in major electronic databases (PubMed, EMBASE, Web of Science and Google Scholar) in November 2022 to identify studies relevant to the relationship between metals, COVID-19 and menopause. The effects of metals on the course of menopause is a broad topic and should certainly still be a subject of research, due to, among other things, continuing environmental pollution and the use of metals in many areas of life.",
           1,
           "biology"
          ],
          [
           "The Impact of Obesity on C1q/TNF-Related Protein-9 Expression and Endothelial Function following Acute High-Intensity Interval Exercise vs. Continuous Moderate-Intensity Exercise",
           "10.3390/biology11111667",
           2022,
           "C1q-TNF-related protein-9 (CTRP9) increases endothelial nitric oxide synthase and reduces vasoconstrictors. There is limited information regarding exercise-mediated CTRP9 in obesity. The purpose of this study was to compare high-intensity interval exercise (HIIE) and continuous moderate-intensity exercise (CME) on the CTRP9 response and an indicator of endothelial function (FMD) in obese participants. Sixteen young male participants (9 obese and 7 normal-weight) participated in a counterbalanced and caloric equated experiment: HIIE (30 min, 4 intervals of 4 min at 80–90% of VO2 max with 3 min rest between intervals) and CME (38 min at 50–60% VO2 max). Serum CTRP9 and FMD were measured prior to, immediately following exercise, and 1 h and 2 h into recovery. CTRP9 was significantly increased immediately following acute HIIE and CME in both groups (p = 0.003). There was a greater CME-induced FMD response at 2 h into recovery in obese participants (p = 0.009). A positive correlation between CTRP9 and FMD percent change was observed in response to acute CME when combined with both obese and normal-weight participants (r = 0.589, p = 0.016). The novel results from this study provide a foundation for additional examination of the mechanisms of exercise-mediated CTRP9 on endothelial function in individuals with obesity.",
           1,
           "biology"
          ],
          [
           "High-Throughput Analysis of Neutrophil Extracellular Trap Levels in Subtypes of People with Type 1 Diabetes",
           "10.3390/biology12060882",
           2023,
           "Neutrophils might play an important role in the pathogenesis of autoimmune diseases, including type 1 diabetes (T1D), by contributing to immune dysregulation via a highly inflammatory program called neutrophil extracellular trap (NET) formation or NETosis, involving the extrusion of chromatin entangled with anti-microbial proteins. However, numerous studies reported contradictory data on NET formation in T1D. This might in part be due to the inherent heterogeneity of the disease and the influence of the disease developmental stage on neutrophil behavior. Moreover, there is a lack of a standardized method to measure NETosis in an unbiased and robust manner. In this study, we employed the Incucyte® ZOOM live-cell imaging platform to study NETosis levels in various subtypes of adult and pediatric T1D donors compared to healthy controls (HC) at baseline and in response to phorbol–myristate acetate (PMA) and ionomycin. Firstly, we determined that the technique allows for an operator-independent and automated quantification of NET formation across multiple time points, which showed that PMA and ionomycin induced NETosis with distinct kinetic characteristics, confirmed by high-resolution microscopy. NETosis levels also showed a clear dose-response curve to increasing concentrations of both stimuli. Overall, using Incucyte® ZOOM, no aberrant NET formation was observed over time in the different subtypes of T1D populations, irrespective of age, compared to HC. These data were corroborated by the levels of peripheral NET markers in all study participants. The current study showed that live-cell imaging allows for a robust and unbiased analysis and quantification of NET formation in real-time. Peripheral neutrophil measures should be complemented with dynamic quantification of NETing neutrophils to make robust conclusions on NET formation in health and disease.",
           1,
           "biology"
          ],
          [
           "Macroanatomical, Histological and Microtomographic Study of the Teeth of the Komodo Dragon (Varanus komodoensis)—Adaptation to Hunting",
           "10.3390/biology12020247",
           2023,
           "The present study aimed to characterize the macrostructure and microstructure of the mandibular teeth of the Komodo dragon (Varanus komodoensis) and the methods it uses to obtain food. Examinations were performed using a stereoscopic microscope, autofluorescence method, histological method and computed microtomography. A detailed macro- and micro-structural description of V. komodoensis mandibular teeth were made. The mandibular teeth are laterally flattened along their entire length and the dental crown is hooked caudally. The part of the nasal margin of the tooth crown is irregular, while the caudal margin of the tooth is characteristically serrated, except for the tooth base area. There are longitudinal grooves on the lingual and vestibular surfaces up to the lower third of the tooth height. The mandibular tooth is surrounded by a cuff made of the oral mucosa, containing the opening of the venom gland. In the histological structure of the tooth, the enamel covering the tooth crown and the dentin under the enamel are distinguished. The inside of the tooth, except its basal part, is filled with the tooth chamber, while the inside of the lower part of the tooth is filled with plicidentine, which corresponds to external furrows on the enamel. The plicidentine arrangement resembles a honeycomb. A small amount of dentine folds reach up to the tooth apex. Characteristic features of the structure of the mandibular teeth in V. komodoensis may indicate their significant role, in addition to the venom glands, in obtaining food in the natural environment of this species.",
           3,
           "biology"
          ],
          [
           "Evaluation of the Impact of Population Management on the Genetic Parameters of Selected Spiral-Horned Antelopes",
           "10.3390/biology13020104",
           2024,
           "The rapid loss of biodiversity and the associated reduction and fragmentation of habitats means that ex situ populations have become an important part of species conservation. These populations, which are often established from a small number of founders, require careful management to avoid the negative effects of genetic drift and inbreeding. Although the inclusion of molecular data is recommended, their availability for captive breeding management remains limited. The aim of this study was to evaluate the relationship between the levels of genetic diversity in six spiral-horned antelope taxa bred under human care and their respective management strategies, conservation status, demography, and geographic origin, using 10 nuclear DNA microsatellite loci and mitochondrial control region DNA sequences. Our findings include associations between genetic diversity and management intensity but also with the diversity and contribution of wild populations to captive founders, with some populations apparently composed of animals from divergent wild lineages elevating captive genetic diversity. When population sizes are large, the potential advantages of maximizing genetic diversity in widely outcrossed populations may need careful consideration with respect to the potential disruption of adaptive diversity. Genetic data serve as a robust tool for managing captive populations, yet their interpretation necessitates a comprehensive understanding of species biology and history.",
           0,
           "biology"
          ],
          [
           "Zoonotic Visceral Leishmaniasis: New Insights on Innate Immune Response by Blood Macrophages and Liver Kupffer Cells to Leishmania infantum Parasites",
           "10.3390/biology11010100",
           2022,
           "L. infantum is the aetiological agent of zoonotic visceral leishmaniasis (ZVL), a disease that affects humans and dogs. Leishmania parasites are well adapted to aggressive conditions inside the phagolysosome and can control the immune activation of macrophages (MØs). Although MØs are highly active phagocytic cells with the capacity to destroy pathogens, they additionally comprise the host cells for Leishmania infection, replication, and stable establishment in the mammal host. The present study compares, for the first time, the innate immune response to L. infantum infection of two different macrophage lineages: the blood macrophages and the liver macrophages (Kupffer cells, KC). Our findings showed that L. infantum takes advantage of the natural predisposition of blood-MØs to phagocyte pathogens. However, parasites rapidly subvert the mechanisms of MØs immune activation. On the other hand, KCs, which are primed for immune tolerance, are not extensively activated and can overcome the dormancy induced by the parasite, exhibiting a selection of immune mechanisms, such as extracellular trap formation. Altogether, KCs reveal a different pattern of response in contrast with blood-MØs when confronting L. infantum parasites. In addition, KCs response appears to be more efficient in managing parasite infection, thus contributing to the ability of the liver to naturally restrain Leishmania dissemination.",
           3,
           "biology"
          ],
          [
           "Novel Severe Hemophilia A Mouse Model with Factor VIII Intron 22 Inversion",
           "10.3390/biology10080704",
           2021,
           "Hemophilia A (HA) is an X-linked recessive blood coagulation disorder, and approximately 50% of severe HA patients are caused by F8 intron 22 inversion (F8I22I). However, the F8I22I mouse model has not been developed despite being a necessary model to challenge pre-clinical study. A mouse model similar to human F8I22I was developed through consequent inversion by CRISPR/Cas9-based dual double-stranded breakage (DSB) formation, and clinical symptoms of severe hemophilia were confirmed. The F8I22I mouse showed inversion of a 391 kb segment and truncation of mRNA transcription at the F8 gene. Furthermore, the F8I22I mouse showed a deficiency of FVIII activity (10.9 vs. 0 ng/mL in WT and F8I22I, p < 0.0001) and severe coagulation disorder phenotype in the activated partial thromboplastin time (38 vs. 480 s, p < 0.0001), in vivo bleeding test (blood loss/body weight; 0.4 vs. 2.1%, p < 0.0001), and calibrated automated thrombogram assays (Thrombin generation peak, 183 vs. 21.5 nM, p = 0.0012). Moreover, histological changes related to spontaneous bleeding were observed in the liver, spleen, and lungs. We present a novel HA mouse model mimicking human F8I22I. With a structural similarity with human F8I22I, the F8I22I mouse model will be applicable to the evaluation of general hemophilia drugs and the development of gene-editing-based therapy research.",
           4,
           "biology"
          ],
          [
           "Transcriptome Analysis Reveals That Abeliophyllum distichum Nakai Extract Inhibits RANKL-Mediated Osteoclastogenensis Mainly through Suppressing Nfatc1 Expression",
           "10.3390/biology9080212",
           2020,
           "Abeliophyllum distichum Nakai is known as a monotypic genus endemic to South Korea. Currently, several pharmacological studies have revealed that A. distichum extract exhibits diverse biological functions, including anti-cancer, anti-diabetic, anti-hypertensive, and anti-inflammatory activities. In this study, we present the anti-osteoporotic activity of A. distichum extract by inhibiting osteoclast formation. First, we show that the methanolic extract of the leaves of A. distichum, but not extracts of the branches or fruits, significantly inhibits receptor activator of the NF-κB ligand (RANKL)-induced osteoclast differentiation. Second, our transcriptome analysis revealed that the leaf extract (LE) blocks sets of RANKL-mediated osteoclast-related genes. Third, the LE attenuates the phosphorylation of extracellular signal-related kinase. Finally, treatment with the LE effectively prevents postmenopausal bone loss in ovariectomized mice and glucocorticoid-induced osteoporosis in zebrafish. Our findings show that the extract of A. distichum efficiently suppressed osteoclastogenesis by regulating osteoclast-related genes, thus offering a novel therapeutic strategy for osteoporosis.",
           6,
           "biology"
          ],
          [
           "Imaging of the Intestinal Microcirculation during Acute and Chronic Inflammation",
           "10.3390/biology9120418",
           2020,
           "Because of its unique microvascular anatomy, the intestine is particularly vulnerable to microcirculatory disturbances. During inflammation, pathological changes in blood flow, vessel integrity and capillary density result in impaired tissue oxygenation. In severe cases, these changes can progress to multiorgan failure and possibly death. Microcirculation may be evaluated in superficial tissues in patients using video microscopy devices, but these techniques do not allow the assessment of intestinal microcirculation. The gold standard for the experimental evaluation of intestinal microcirculation is intravital microscopy, a technique that allows for the in vivo examination of many pathophysiological processes including leukocyte-endothelial interactions and capillary blood flow. This review provides an overview of changes in the intestinal microcirculation in various acute and chronic inflammatory conditions. Acute conditions discussed include local infections, severe acute pancreatitis, necrotizing enterocolitis and sepsis. Inflammatory bowel disease and irritable bowel syndrome are included as examples of chronic conditions of the intestine.",
           5,
           "biology"
          ],
          [
           "Rehydration Process in Rustyback Fern (Asplenium ceterach L.): Profiling of Volatile Organic Compounds",
           "10.3390/biology10070574",
           2021,
           "When exposed to stressful conditions, plants produce numerous volatile organic compounds (VOCs) that have different biological and environmental functions. VOCs emitted during the rehydration process by the fronds of desiccation tolerant fern Asplenium ceterach L. were investigated. Headspace GC–MS analysis revealed that the volatiles profile of rustyback fern is mainly composed of fatty acid derivatives: isomeric heptadienals (over 25%) and decadienals (over 20%), other linear aldehydes, alcohols, and related compounds. Aerial parts of the rustyback fern do not contain monoterpene-type, sesquiterpene-type, and diterpene-type hydrocarbons or corresponding terpenoids. Online detection of VOCs using proton-transfer reaction mass spectrometry (PTR–MS) showed a significant increase in emission intensity of dominant volatiles during the first hours of the rehydration process. Twelve hours after re-watering, emission of detected volatiles had returned to the basal levels that corresponded to hydrated plants. During the early phase of rehydration malondialdehyde (MDA) content in fronds, as an indicator of membrane damage, decreased rapidly which implies that lipoxygenase activity is not stimulated during the recovery process of rustyback fern.",
           4,
           "biology"
          ],
          [
           "Microtubular Assessment of C6 Rat Glioma Cell Spheroids Developed in Transparent Liquid Marbles or Hanging Drops",
           "10.3390/biology11040492",
           2022,
           "Glioblastoma is a brain tumour frequently used as an experimental model to exploit innovative therapeutic approaches due to its high lethality and refractoriness to therapies. Part of these innovative anticancer therapies address cytoskeletal microtubules (MTs) since specific tubulin post-translational modifications (PTMs) are considered markers of tumour plasticity. In vitro studies, which traditionally employ two-dimensional (2D) culture systems, are now being replaced by three-dimensional (3D) systems that more closely mimic in vivo physiological conditions and allow a better understanding of the signalling between cells. In this work, we compared 2 liquid base 3D methods for the generation of spheroids from C6 rat glioma cells (RGCs) using 30 µL of liquid marble (LM) or the hanging drops (HDs), which contained 2 different cell numbers (5000 or 15,000). After 24 or 48 h of in vitro culture (IVC), the morphology of the spheroids was observed and the behaviour of the two main tubulin PTMs, tyrosinated α-tubulin (Tyr-T) and acetylated α-tubulin (Ac-T), was evaluated by fluorescence and Western blot (WB). RGCs spontaneously formed spherical agglomerates more rapidly in the LM than in the HD system. Cell density influenced the size of the spheroids, which reached a larger size (> of 300 µm Ø), with 15,000 cells compared to 5000 cells (150 µm Ø). Moreover, an increase in Tyr-T and Ac-T was observed in both the HD and LM system from 24 to 48 h, with the highest values shown in the 48 h/LM spheroids of 5000 cells (p < 0.05). In conclusion, by comparing the morphology and microtubular architecture of spheroids from C6 rat glioma cells developed by LM or HD methodology, our findings demonstrate that the use of a fumed silica microbioreactor boosts the induction and maintenance of a high plasticity state in glioma cells. RGCs cultured in LM express levels of tubulin PTMs that can be used to evaluate the efficacy of new anticancer therapies.",
           2,
           "biology"
          ],
          [
           "A Stress Syndrome Prototype Reflects Type 3 Diabetes and Ischemic Stroke Risk: The SABPA Study",
           "10.3390/biology10020162",
           2021,
           "Type 3 diabetes (T3D) accurately reflects that dementia, e.g., Alzheimer’s disease, represents insulin resistance and neurodegeneration in the brain. Similar retinal microvascular changes were observed in Alzheimer’s and chronic stressed individuals. Hence, we aimed to show that chronic stress relates to T3D dementia signs and retinopathy, ultimately comprising a Stress syndrome prototype reflecting risk for T3D and stroke. A chronic stress and stroke risk phenotype (Stressed) score, independent of age, race or gender, was applied to stratify participants (N = 264; aged 44 ± 9 years) into high stress risk (Stressed, N = 159) and low stress risk (non-Stressed, N = 105) groups. We determined insulin resistance using the homeostatic model assessment (HOMA-IR), which is interchangeable with T3D, and dementia risk markers (cognitive executive functioning (cognitiveexe-func); telomere length; waist circumference (WC), neuronal glia injury; neuron-specific enolase/NSE, S100B). Retinopathy was determined in the mydriatic eye. The Stressed group had greater incidence of HOMA-IR in the upper quartile (≥5), larger WC, poorer cognitiveexe-func control, shorter telomeres, consistently raised neuronal glia injury, fewer retinal arteries, narrower arteries, wider veins and a larger optic cup/disc ratio (C/D) compared to the non-Stressed group. Furthermore, of the stroke risk markers, arterial narrowing was related to glaucoma risk with a greater C/D, whilst retinal vein widening was related to HOMA-IR, poor cognitiveexe-func control and neuronal glia injury (Adjusted R2 0.30; p ≤ 0.05). These associations were not evident in the non-Stressed group. Logistic regression associations between the Stressed phenotype and four dementia risk markers (cognitiveexe-func, telomere length, NSE and WC) comprised a Stress syndrome prototype (area under the curve 0.80; sensitivity/specificity 85%/58%; p ≤ 0.001). The Stress syndrome prototype reflected risk for HOMA-IR (odds ratio (OR) 7.72) and retinal glia ischemia (OR 1.27) and vein widening (OR 1.03). The Stressed phenotype was associated with neuronal glia injury and retinal ischemia, potentiating glaucoma risk. The detrimental effect of chronic stress exemplified a Stress syndrome prototype reflecting risk for type 3 diabetes, neurodegeneration and ischemic stroke.",
           6,
           "biology"
          ],
          [
           "Moderate Beer Intake Downregulates Inflammasome Pathway Gene Expression in Human Macrophages",
           "10.3390/biology10111159",
           2021,
           "Inflammasomes are key components of the innate immunity system that trigger the inflammatory response. Inappropriate activity of the inflammasome system has been linked to onset and perpetuation of inflammation in atherosclerotic plaques and cardiovascular disease. Low-to-moderate beer consumption is inversely associated with cardiovascular event presentation, while high levels of alcohol intake are associated with increased cardiovascular risk. Although fermented beverages have been suggested to exert their beneficial effects through their anti-oxidant and anti-inflammatory properties, little is known regarding the capacity of beer to modulate innate immunity cell responses. To this aim, primed or activated THP-1 macrophages were conditioned with human serum obtained from a prospective two-arms longitudinal crossover study to investigate the effect of a moderate and regular daily intake of beer, either alcohol-free or traditional, in the regulation of TLR-mediated inflammatory responses in healthy but overweight individuals. Conditioned macrophages with serum obtained after four-week intervention with alcohol-free beer significantly reduced the transcription of pro-inflammatory interleukins such as IL-1β and TNF. The serum of traditional beer consumers did not exhibit the same capacity as the serum of alcohol-free beer consumers to reduce gene expression of pro-inflammatory interleukins; however, serum from traditional beer consumers showed a regulatory effect at the protein level by significantly decreasing the intracellular protein levels of pro-IL-1β in primed macrophages and preventing cleaved-IL-1β protein release.",
           4,
           "biology"
          ],
          [
           "Bisphenol A (BPA) Directly Activates the G Protein-Coupled Estrogen Receptor 1 and Triggers the Metabolic Disruption in the Gonadal Tissue of Apostichopus japonicus",
           "10.3390/biology12060798",
           2023,
           "The sea cucumber, Apostichopus japonicus, is a marine benthic organism that feeds on small benthic particulate matter and is easily affected by pollutants. Bisphenol A (BPA, 4,4′-isopropylidenediphenol) has been identified as an endocrine disruptor. It is ubiquitously detectable in oceans and affects a variety of marine animals. It functions as an estrogen analog and typically causes reproductive toxicity by interfering with the endocrine system. To comparatively analyze the reproductive effects of estradiol (E2) and BPA on sea cucumbers, we identified a G protein-coupled estrogen receptor 1 (GPER1) in A. japonicus and investigated its effects on reproduction. The results showed that BPA and E2 exposure activated A. japonicus AjGPER1, thereby mediating the mitogen-activated protein kinase signaling pathways. High-level expression of AjGPER1 in the ovarian tissue was confirmed by qPCR. Furthermore, metabolic changes were induced by 100 nM (22.83 μg/L) BPA exposure in the ovarian tissue, leading to a notable increase in the activities of trehalase and phosphofructokinase. Overall, our findings suggest that AjGPER1 is directly activated by BPA and affects sea cucumber reproduction by disrupting ovarian tissue metabolism, suggesting that marine pollutants pose a threat to the conservation of sea cucumber resources.",
           0,
           "biology"
          ],
          [
           "The Water Content Drives the Susceptibility of the Lichen Evernia prunastri and the Moss Brachythecium sp. to High Ozone Concentrations",
           "10.3390/biology9050090",
           2020,
           "The aim of this study was to evaluate the tolerance of lichens (Evernia prunastri) and mosses (Brachythecium sp.) to short-term (1 h), acute (1 ppm) O3 fumigation under different hydration states (dry, <10% water content, metabolism almost inactive; wet, >200% water content, metabolism fully active). We hypothesized that stronger damage would occur following exposure under wet conditions. In addition, we checked for the effect of recovery (1 week) after the exposure. Ozone fumigation negatively affected the content of chlorophyll only in wet samples, but in the moss, such a difference was no longer evident after one week of recovery. Photosynthetic efficiency was always impaired by O3 exposure, irrespective of the dry or wet state, and also after one week of recovery, but the effect was much stronger in wet samples. The antioxidant power was increased in wet moss and in dry lichen, while a decrease was found for wet lichens after 1 week. Our results confirm that the tolerance to O3 of lichens and mosses may be determined by their low water content, which is the case during the peaks of O3 occurring during the Mediterranean summer. The role of antioxidant power as a mechanism of resistance to high O3 concentrations needs to be further investigated.",
           8,
           "biology"
          ],
          [
           "Cell Self-Destruction (Programmed Cell Death), Immunonutrition and Metabolism",
           "10.3390/biology12070949",
           2023,
           "The main purpose of this Special Issue is to provide readers with current understandings of the interactions and causal relations among injury stimuli (including microorganism infections), immune response and overnutrition/lipotoxicity in disease pathogenesis [...]",
           0,
           "biology"
          ],
          [
           "Genetic Diversity in Invasive Populations of Lupinus polyphyllus Lindl. and Heracleum sosnowskyi Manden.",
           "10.3390/biology10111094",
           2021,
           "In our study, two aggressive-invasive species, Lupinus polyphyllus Lindl. and Heracleum sosnowskyi Manden. from Russia and Ukraine, were investigated. The success in naturalization of both species is associated with human activities, since they have been used in agriculture and floriculture and both have qualities such as environmental tolerance, high fertility and phenotypic plasticity. The purpose of this study was to determine the level of genetic diversity of both species. For Heracleum sosnowskyi Manden., genetic diversity was compared in invasive and native populations. For Lupinus polyphyllus Lindl., the genetic diversity was compared in variety, feral and invasive populations. A genetic diversity was formulated using RAPD, ISSR and REMAP. For Heracleum sosnowskyi Manden., the average genetic diversity within the invasive population was similar (0.432), but slightly less (0.502) than within the native Caucasian population. This may suggest the successful naturalization of invaders and almost complete reconstruction of their genetic diversity. For Lupinus polyphyllus Lindl., the genetic diversity for the invasive population was the highest, with an average of 0.294, while for variety, it was the lowest, with an average of 0.194. The feral population had an intermediate place with an average of 0.248, which could suggest an increase of diversity in the process of naturalization.",
           6,
           "biology"
          ],
          [
           "Transcriptome Analysis and GC-MS Profiling of Key Fatty Acid Biosynthesis Genes in Akebia trifoliata (Thunb.) Koidz Seeds",
           "10.3390/biology11060855",
           2022,
           "Akebia trifoliata (Thunb.) Koidz is an important Chinese medicinal and economic crop. Its seeds, which are rich in fatty acids, are usually discarded. As of now, A. trifoliata lipid biosynthesis pathways and genes have not been clearly described. In this work, we found that seed and fruit development of A. trifoliata were not synchronized, and that when the fruit was ripe, seed oil content was not at its highest. As seeds developed, linoleic and oleic acid content was found to decrease and increase, respectively. RNA sequencing yielded 108.45 GB of clean reads from 15 cDNA libraries, containing 8756 differentially expressed genes. We identified 65 unigenes associated with lipid biosynthesis, including fatty acid and triacylglycerol biosynthesis. The 65 unigenes were mapped to the A. trifoliata lipid synthesis pathway. There were 20 AtrFAD family members in A. trifoliata, which could be divided into four sub-groups with the highest number of AtrSADs. Our study revealed the dynamic changes in A. trifoliata seed oil content and composition during its growth period and provides large-scale and comprehensive transcriptome data of A. trifoliata seeds. These findings provide a basis for the improvement of A. trifoliata seed oil yield and quality.",
           0,
           "biology"
          ],
          [
           "Doublecortin in the Fish Visual System, a Specific Protein of Maturing Neurons",
           "10.3390/biology11020248",
           2022,
           "Doublecortin (DCX) is a microtubule associated protein, essential for correct central nervous system development and lamination in the mammalian cortex. It has been demonstrated to be expressed in developing—but not in mature—neurons. The teleost visual system is an ideal model to study mechanisms of adult neurogenesis due to its continuous life-long growth. Here, we report immunohistochemical, in silico, and western blot analysis to detect the DCX protein in the visual system of teleost fish. We clearly determined the expression of DCX in newly generated cells in the retina of the cichlid fish Astatotilapia burtoni, but not in the cyprinid fish Danio rerio. Here, we show that DCX is not associated with migrating cells but could be related to axonal growth. This work brings to light the high conservation of DCX sequences between different evolutionary groups, which make it an ideal marker for maturing neurons in various species. The results from different techniques corroborate the absence of DCX expression in zebrafish. In A. burtoni, DCX is very useful for identifying new neurons in the transition zone of the retina. In addition, this marker can be applied to follow axons from maturing neurons through the neural fiber layer, optic nerve head, and optic nerve.",
           0,
           "biology"
          ],
          [
           "Traumatic Brain Injury Characteristics Predictive of Subsequent Sleep-Wake Disturbances in Pediatric Patients",
           "10.3390/biology11040600",
           2022,
           "The objective of this study was to determine the prevalence of sleep-wake disturbances (SWD) following pediatric traumatic brain injury (TBI), and to examine characteristics of TBI and patient demographics that might be predictive of subsequent SWD development. This single-institution retrospective study included patients diagnosed with a TBI during 2008–2019 who also had a subsequent diagnosis of an SWD. Data were collected using ICD-9/10 codes for 207 patients and included the following: age at initial TBI, gender, TBI severity, number of TBIs diagnosed prior to SWD diagnosis, type of SWD, and time from initial TBI to SWD diagnosis. Multinomial logit and negative-binomial models were fit to investigate whether the multiple types of SWD and the time to onset of SWD following TBI could be predicted by patient variables. Distributions of SWD diagnosed after TBI were similar between genders. The probability of insomnia increased with increasing patient age. The probability of ‘difficulty sleeping’ was highest in 7–9 year-old TBI patients. Older TBI patients had shorter time to SWD onset than younger patients. Patients with severe TBI had the shortest time to SWD onset, whereas patients with mild or moderate TBI had comparable times to SWD onset. Multiple TBI characteristics and patient demographics were predictive of a subsequent SWD diagnosis in the pediatric population. This is an important step toward increasing education among providers, parents, and patients about the risk of developing SWD following TBI.",
           0,
           "biology"
          ],
          [
           "Detecting Blood Methylation Signatures in Response to Childhood Cancer Radiotherapy via Machine Learning Methods",
           "10.3390/biology11040607",
           2022,
           "Radiotherapy is a helpful treatment for cancer, but it can also potentially cause changes in many molecules, resulting in adverse effects. Among these changes, the occurrence of abnormal DNA methylation patterns has alarmed scientists. To explore the influence of region-specific radiotherapy on blood DNA methylation, we designed a computational workflow by using machine learning methods that can identify crucial methylation alterations related to treatment exposure. Irrelevant methylation features from the DNA methylation profiles of 2052 childhood cancer survivors were excluded via the Boruta method, and the remaining features were ranked using the minimum redundancy maximum relevance method to generate feature lists. These feature lists were then fed into the incremental feature selection method, which uses a combination of deep forest, k-nearest neighbor, random forest, and decision tree to find the most important methylation signatures and build the best classifiers and classification rules. Several methylation signatures and rules have been discovered and confirmed, allowing for a better understanding of methylation patterns in response to different treatment exposures.",
           0,
           "biology"
          ],
          [
           "Development of an LDL Receptor-Targeted Peptide Susceptible to Facilitate the Brain Access of Diagnostic or Therapeutic Agents",
           "10.3390/biology9070161",
           2020,
           "Blood-brain barrier (BBB) crossing and brain penetration are really challenging for the delivery of therapeutic agents and imaging probes. The development of new crossing strategies is needed, and a wide range of approaches (invasive or not) have been proposed so far. The receptor-mediated transcytosis is an attractive mechanism, allowing the non-invasive penetration of the BBB. Among available targets, the low-density lipoprotein (LDL) receptor (LDLR) shows favorable characteristics mainly because of the lysosome-bypassed pathway of LDL delivery to the brain, allowing an intact discharge of the carried ligand to the brain targets. The phage display technology was employed to identify a dodecapeptide targeted to the extracellular domain of LDLR (ED-LDLR). This peptide was able to bind the ED-LDLR in the presence of natural ligands and dissociated at acidic pH and in the absence of calcium, in a similar manner as the LDL. In vitro, our peptide was endocytosed by endothelial cells through the caveolae-dependent pathway, proper to the LDLR route in BBB, suggesting the prevention of its lysosomal degradation. The in vivo studies performed by magnetic resonance imaging and fluorescent lifetime imaging suggested the brain penetration of this ED-LDLR-targeted peptide.",
           11,
           "biology"
          ],
          [
           "A Putative Prophylactic Solution for COVID-19: Development of Novel Multiepitope Vaccine Candidate against SARS-COV-2 by Comprehensive Immunoinformatic and Molecular Modelling Approach",
           "10.3390/biology9090296",
           2020,
           "The outbreak of 2019-novel coronavirus (SARS-CoV-2) that causes severe respiratory infection (COVID-19) has spread in China, and the World Health Organization has declared it a pandemic. However, no approved drug or vaccines are available, and treatment is mainly supportive and through a few repurposed drugs. The urgency of the situation requires the development of SARS-CoV-2-based vaccines. Immunoinformatic and molecular modelling are time-efficient methods that are generally used to accelerate the discovery and design of the candidate peptides for vaccine development. In recent years, the use of multiepitope vaccines has proved to be a promising immunization strategy against viruses and pathogens, thus inducing more comprehensive protective immunity. The current study demonstrated a comprehensive in silico strategy to design stable multiepitope vaccine construct (MVC) from B-cell and T-cell epitopes of essential SARS-CoV-2 proteins with the help of adjuvants and linkers. The integrated molecular dynamics simulations analysis revealed the stability of MVC and its interaction with human Toll-like receptors (TLRs), which trigger an innate and adaptive immune response. Later, the in silico cloning in a known pET28a vector system also estimated the possibility of MVC expression in Escherichia coli. Despite that this study lacks validation of this vaccine construct in terms of its efficacy, the current integrated strategy encompasses the initial multiple epitope vaccine design concepts. After validation, this MVC can be present as a better prophylactic solution against COVID-19.",
           12,
           "biology"
          ],
          [
           "Companion Animal Model in Translational Oncology; Feline Oral Squamous Cell Carcinoma and Canine Oral Melanoma",
           "10.3390/biology11010054",
           2022,
           "Companion animals with naturally occurring cancers can provide an advantageous model for cancer research and in particular anticancer drug development. Compared to commonly utilized mouse models, companion animals, specifically dogs and cats, share a closer phylogenetical distance, body size, and genome organization. Most importantly, pets develop spontaneous, rather than artificially induced, cancers. The incidence of cancer in people and companion animals is quite similar and cancer is the leading cause of death in dogs over 10 years of age. Many cancer types in dogs and cats have similar pathological, molecular, and clinical features to their human counterparts. Drug toxicity and response to anti-cancer treatment in dogs and cats are also similar to those in people. Companion animals share their lives with their owners, including the environmental and socioeconomic cancer-risk factors. In contrast to humans, pets have a shorter life span and cancer progression is often more rapid. Clinical trials in companion animals are cheaper and less time consuming compared to human trials. Dogs and cats with naturally occurring cancers are an ideal and unique model for human cancer research. Model selection for the specific type of cancer is of pivotal importance. Although companion animal models for translational research have been reviewed previously, this review will try to summarize the most important advantages and disadvantages of this model. Feline oral squamous cell carcinoma as a model for head and neck squamous cell carcinoma and canine oral melanoma as a model for mucosal melanoma and immunotherapy in people will be discussed as examples.",
           13,
           "biology"
          ],
          [
           "Actin Cytoskeleton Dynamics and Type I IFN-Mediated Immune Response: A Dangerous Liaison in Cancer?",
           "10.3390/biology10090913",
           2021,
           "Chronic viral infection and cancer are closely inter-related and are both characterized by profound alteration of tissue homeostasis. The actin cytoskeleton dynamics highly participate in tissue homeostasis and act as a sensor leading to an immune-mediated anti-cancer and anti-viral response. Herein we highlight the crucial role of actin cytoskeleton dynamics in participating in a viral mimicry activation with profound effect in anti-tumor immune response. This still poorly explored field understands the cytoskeleton dynamics as a platform of complex signaling pathways which may regulate Type I IFN response in cancer. This emerging network needs to be elucidated to identify more effective anti-cancer strategies and to further advance the immuno-oncology field which has revolutionized the cancer treatment. For a progress to occur in this exciting arena we have to shed light on actin cytoskeleton related pathways and immune response. Herein we summarize the major findings, considering the double sword of the immune response and in particular the role of Type I IFN pathways in resistance to anti-cancer treatment.",
           2,
           "biology"
          ],
          [
           "Quadruplex-Forming Motif Inserted into 3′UTR of Ty1his3-AI Retrotransposon Inhibits Retrotransposition in Yeast",
           "10.3390/biology10040347",
           2021,
           "Guanine quadruplexes (G4s) serve as regulators of replication, recombination and gene expression. G4 motifs have been recently identified in LTR retrotransposons, but their role in the retrotransposon life-cycle is yet to be understood. Therefore, we inserted G4s into the 3′UTR of Ty1his3-AI retrotransposon and measured the frequency of retrotransposition in yeast strains BY4741, Y00509 (without Pif1 helicase) and with G4-stabilization by N-methyl mesoporphyrin IX (NMM) treatment. We evaluated the impact of G4s on mRNA levels by RT-qPCR and products of reverse transcription by Southern blot analysis. We found that the presence of G4 inhibited Ty1his3-AI retrotransposition. The effect was stronger when G4s were on a transcription template strand which leads to reverse transcription interruption. Both NMM and Pif1p deficiency reduced the retrotransposition irrespective of the presence of a G4 motif in the Ty1his3-AI element. Quantity of mRNA and products of reverse transcription did not fully explain the impact of G4s on Ty1his3-AI retrotransposition indicating that G4s probably affect some other steps of the retrotransposon life-cycle (e.g., translation, VLP formation, integration). Our results suggest that G4 DNA conformation can tune the activity of mobile genetic elements that in turn contribute to shaping the eukaryotic genomes.",
           1,
           "biology"
          ],
          [
           "Individual Proportion Loss of Functional Connectivity Strength: A Novel Individual Functional Connectivity Biomarker for Subjective Cognitive Decline Populations",
           "10.3390/biology12040564",
           2023,
           "High individual variation in the subjective cognitive decline (SCD) population makes functional connectivity (FC) biomarkers unstable. This study proposed a novel individual FC index, named individual proportion loss of functional connectivity strength (IPLFCS), and explored potential biomarkers for SCD using this new index. We proposed an IPLFCS analysis framework and compared it with traditional FC in Chinese and Western cohorts. Post hoc tests were used to determine biomarkers. Pearson’s correlation analysis was used to investigate the correlation between neuropsychological scores or cortical amyloid deposits and IPLFCS biomarkers. Receiver operating characteristic curves were utilized to evaluate the ability of potential biomarkers to distinguish between groups. IPLFCS of the left middle temporal gyrus (LMTG) was identified as a potential biomarker. The IPLFC was correlated with the traditional FC (r = 0.956, p < 0.001; r = 0.946, p < 0.001) and cortical amyloid deposition (r = −0.245, p = 0.029; r = −0.185, p = 0.048) in both cohorts. Furthermore, the IPLFCS decreased across the Alzheimer’s disease (AD) continuum. Its diagnostic efficiency was superior to that of existing fMRI biomarkers. These findings suggest that IPLFCS of the LMTG could be a potential biomarker of SCD.",
           0,
           "biology"
          ],
          [
           "Using Pen-Side Measurable Blood Parameters to Predict or Identify Dystocic Lambing Events",
           "10.3390/biology11020206",
           2022,
           "Dystocia is the greatest contributor to neonatal lamb mortality in Australia and poses significant welfare and economic concerns worldwide. In this study, we set out to investigate whether pen-side analysis technology could be employed to detect blood parameters predictive of dystocic labour events in sheep. In a pilot trial, we collected and analysed blood samples in pen-side assays for glucose, lactate, pH, pCO2, pO2, base excess, HCO3, TCO2, sO2, lactate, sodium, potassium, chloride, calcium, urea nitrogen, creatinine, haematocrit, haemoglobin and anion gap. From the pilot data, we identified creatinine, TCO2, chloride and calcium as potentially useful markers. To develop a time course and to establish variability of the selected blood parameters, a time series of samples was collected from 12 ewes, from mid-gestation to 48 h after birth. For the main trial, blood samples were collected at mid- and late gestation for glucose determination and for the full set of blood parameters at three time points before, at and after birth. Possible predictors of lambing difficulty were chloride, haematocrit and haemoglobin, sampled one week before birth; creatinine, sampled at birth; and blood pH and base excess after birth. In conclusion, we found that pen-side analysis of blood markers showed promise in identifying dystocic lambing events.",
           0,
           "biology"
          ],
          [
           "Serial Increases in Human Leukocyte Antigen-DR Expression and Decreases in Interleukin-10 Expression in Alveolar Monocytes of Survivors of Pneumonia-Related Acute Respiratory Distress Syndrome",
           "10.3390/biology11121793",
           2022,
           "ARDS is a potentially lethal syndrome. HLA-DR expression in monocytes reflects their activation and antigen-presenting capacity. However, the correlation between clinical outcomes and HLA-DR expression in alveolar monocytes/macrophages in patients with pneumonia-related ARDS remains unclear. Thus, we determined the trends of HLA-DR and cytokine expressions in alveolar monocytes using repeated measurements to answer this question. Thirty-one pneumonia patients with respiratory failure and ARDS without coronavirus disease 2019 between November 2019 and November 2021 were enrolled in our intensive care unit and three without complete data were excluded. Interleukin (IL)-10, IL-12, and HLA-DR expression in bronchoalveolar lavage (BAL) monocytes were determined on days one and eight. Monocyte HLA-DR expression (mHLA-DR) and CD4 T lymphocytes percentages in BAL cells of survivors increased remarkably after seven days. Monocyte IL-10 expression and monocytes percentages in BAL cells of survivors decreased substantially after seven days. The mHLA-DR was negatively correlated with disease severity scores on day one and eight. In conclusion, serial increases in HLA-DR expression and decreases in IL-10 expression were observed in BAL monocytes of survivors of pneumonia-related ARDS. More studies are needed to confirm this point of view, and then development of a therapeutic agent restoring mHLA-DR and preventing IL-10 production can be considered.",
           0,
           "biology"
          ],
          [
           "Morphology and Chemical Messenger Regulation of Echinoderm Muscles",
           "10.3390/biology12101349",
           2023,
           "The muscular systems of echinoderms play important roles in various physiological and behavioral processes, including feeding, reproduction, movement, respiration, and excretion. Like vertebrates, echinoderm muscle systems can be subdivided into two major divisions, somatic and visceral musculature. The former usually has a myoepithelial organization, while the latter contains muscle bundles formed by the aggregation of myocytes. Neurons and their processes are also detected between these myoepithelial cells and myocytes, which are capable of releasing a variety of neurotransmitters and neuropeptides to regulate muscle activity. Although many studies have reported the pharmacological effects of these chemical messengers on various muscles of echinoderms, there has been limited research on their receptors and their signaling pathways. The muscle physiology of echinoderms is similar to that of chordates, both of which have the deuterostome mode of development. Studies of muscle regulation in echinoderms can provide new insights into the evolution of myoregulatory systems in deuterostomes.",
           0,
           "biology"
          ],
          [
           "Assessment of the Relationship between the Total Occlusal Area of the Human Permanent Upper First and Second Molars and the Robusticity of the Facial Skeleton in Sex-Different Cranial Samples of Homo Sapiens: A Preliminary Study",
           "10.3390/biology12040566",
           2023,
           "The aim of this study was to establish whether there is a significant relationship between the total occlusal area (TOCA) of two types of permanent upper molars (first—M1 and second—M2) and facial robusticity, as well as which of the examined facial regions indicate a relationship concerning the grade of their massiveness with the TOCA of analyzed molars in different sex adult Homo sapiens cranial samples. To obtain the values of the TOCA of the molars (n = 145), a morphometric method was performed based on the calibrated digital images of their occlusal surface using ImageJ software. The grades of the massiveness of six facial regions were assessed using qualitative scales of their expression, and an index of general facial robusticity was calculated. Two types of analyses were performed concerning standardized and non-standardized traits to the facial size, including Spearman’s/or Pearson’s correlations and partial rank correlations. The obtained results indicated the presence of a positive relationship between the relative TOCA of M2s and the relative general facial robusticity, as well as between the TOCA of both types of molars and the massiveness of trigone region of the facial skeleton in male crania. However, most of the obtained results were not consistent with the assumptions of the “localized masticatory stress hypothesis”.",
           1,
           "biology"
          ],
          [
           "Isolation and Identification of Endophytic Bacteria Bacillus sp. ME9 That Exhibits Biocontrol Activity against Xanthomonas phaseoli pv. manihotis",
           "10.3390/biology12091231",
           2023,
           "In recent years, the bacterial blight of cassava has caused substantial economic losses to the Chinese cassava industry. Chemical control methods have become the primary approach to control this disease; however, their widespread usage and harmful residues have raised concerns about environmental pollution. In order to avoid this, it is urgent to seek a green ecological method to prevent and control it. Biological control through the utilization of microorganisms not only effectively inhibits the disease, but also gives consideration to environmental friendliness. Therefore, investigating an endophytic biological control method for cassava bacterial blight is of great importance. In this study, cassava leaf tissues were used as test specimens in order to isolate endophytic bacteria by using dilution and separation methods. Bacillus ME9, derived from cassava endophytic bacteria, exhibits good antagonism against a diverse range of pathogens, including Xpm11. Its genome consists of a series of genes encoding antibacterial lipopeptides, which may be directly related to its antibacterial capabilities. Furthermore, inoculation resulted in a substantial change in the diversity of the endophytic bacterial community, characterized by improved diversity, and displayed an obvious inhibition of pathogenic bacterial growth, demonstrating successful colonization within plants. The results laid a foundation and provided theoretical support for the development and utilization of cassava endophytic bacterial diversity and endogenous disease control strategies.",
           1,
           "biology"
          ],
          [
           "Incidence and Survival of Testicular Cancers in a Province in Northern Italy and Their Association with Second Tumors",
           "10.3390/biology12111409",
           2023,
           "This study investigated the incidence, mortality, and 5-year survival rates of testicular cancers diagnosed in a northern Italian province, which were eventually associated with previous or subsequent extratesticular neoplasms. Cases from 1996 to 2020 were examined by age and histotype (seminoma vs. non-seminoma). The standardized incidence rate was calculated using the European population, and the annual percent change (APC) was reported. The five-year relative survival was estimated using the Pohar Perme method. The association with the second neoplasm was also evaluated. In our study, 385 patients with testicular cancer were included, most of whom were aged between 30 and 40 years. The non-seminoma and seminoma groups accounted for 44% and 18% of younger adults, respectively. The incidence rate increased during the study period (APC 1.6*); however, it increased in seminomas (APC 2.3*) but not in non-seminomas (APC −0.1). Conversely, the mortality rate remained constantly low either overall or in each of the two groups. The overall 5-year survival rate of testicular cancer patients was 95% (99% and 88% for seminomas and non-seminomas, respectively). Primary extratesticular tumors were documented in 37 cases, 18 after and 19 before the testicular cancer diagnosis. Our study confirms that the increased incidence and excellent survival rate are the prerogative of seminomas.",
           1,
           "biology"
          ],
          [
           "Intraoperative Flow Cytometry for the Characterization of Gynecological Malignancies",
           "10.3390/biology11091339",
           2022,
           "Cell-cycle analysis has shown the presence of aneuploidy to be associated with poor prognosis. We developed an innovative rapid cell-cycle analysis protocol (the Ioannina protocol) that permitted the intraoperative identification of neoplastic cells in a plethora of malignancies. Herein, we aimed to investigate the potential role of cell-cycle analysis in the intraoperative characterization of gynecological malignancies. Women who underwent surgery for gynecological malignancies in our institution over a three-year period were included in this study. Permanent section pathology evaluation was used as the gold standard for malignancy evaluation. Total accordance was observed between flow cytometry and pathology evaluation. In total, 21 aneuploid cancers were detected following DNA index calculation. Of these, 20 were hyperploid and 1 was hypoploid. In addition, tumor samples were characterized by a significantly lower percentage of cells in G0/G1, as well as an induced tumor index. The response time for flow cytometry to obtain results was 5–6 min per sample. It seems that flow cytometry analyses for intraoperative tumor evaluation can be safely expanded to gynecological malignancies. This is a novel practical approach that has been proven valuable in several tumor types to date, and also seems to be reliable for gynecological malignancies. Intraoperative flow cytometry is expected to be crucial in decisions of lymph node dissection in endometrial cancers, due to its rapid response regarding the tumor invasion of part or all of the myometrial thickness. In this way, the surgeon can quickly modify the plane of dissection. Our results warrant the further investigation of applying iFC in larger, multicenter studies.",
           9,
           "biology"
          ],
          [
           "IL-10 Producing Regulatory B Cells Mediated Protection against Murine Malaria Pathogenesis",
           "10.3390/biology11050669",
           2022,
           "Various immune cells are known to participate in combating infection. Regulatory B cells represent a subset of B cells that take part in immunomodulation and control inflammation. The immunoregulatory function of regulatory B cells has been shown in various murine models of several disorders. In this study, a comparable IL-10 competent B-10 cell subset (regulatory B cells) was characterized during lethal and non-lethal infection with malaria parasites using the mouse model. We observed that infection of Balb/c mice with P. yoelii I 7XL was lethal, and a rapid increase in dynamics of IL-10 producing B220+CD5+CD1d+ regulatory B cells over the course of infection was observed. However, animals infected with a less virulent strain of the parasite P. yoelii I7XNL attained complete resistance. It was observed that there is an increase in the population of regulatory B cells with an increase of parasitemia; however, a sudden drop in the frequency of these cells was observed with parasite clearance. Adoptive transfer of regulatory B cells to naïve mice followed by infection results in slow parasite growth and enhancement of survival in P. yoelii 17XL (lethal) infected animals. Adoptively transferred regulatory B cells also resulted in decreased production of pro-inflammatory cytokine (IFN-γ) and enhanced production of anti-inflammatory cytokine (IL-10). It infers that these regulatory B cells may contribute in immune protection by preventing the inflammation associated with disease and inhibiting the parasite growth.",
           7,
           "biology"
          ],
          [
           "Nutritional Enhancement of Health Beneficial Omega-3 Long-Chain Polyunsaturated Fatty Acids in the Muscle, Liver, Kidney, and Heart of Tattykeel Australian White MARGRA Lambs Fed Pellets Fortified with Omega-3 Oil in a Feedlot System",
           "10.3390/biology10090912",
           2021,
           "The aim of this research was to evaluate the nutritional enhancement of omega-3 long-chain polyunsaturated fatty acid (n-3 LC-PUFA) composition of edible lamb Longissimus thoracis et lumborum muscle, heart, kidney, and liver in response to dietary supplementation of lot-fed lambs with or without omega-3 oil fortified pellets. The hypothesis tested was that fortifying feedlot pellets with omega-3 oil will enhance the human health beneficial n-3 LC-PUFA composition of edible lamb muscle tissue and organs. Seventy-five Tattykeel Australian White lambs exclusive to the MARGRA brand, with an average body weight of 30 kg at six months of age, were randomly assigned to the following three dietary treatments of 25 lambs each, and lot-fed as a cohort for 47 days in a completely randomized experimental design: (1) Control grain pellets without oil plus hay; (2) Omega-3 oil fortified grain pellets plus hay; and (3) Commercial whole grain pellets plus hay. All lambs had ad libitum access to the basal hay diet and water. Post-slaughter fatty acid composition of the Longissimus thoracis et lumborum muscle, liver, kidney, and heart were determined using thee gas chromatography–mass spectrophotometry technique. Results indicated significant variations (p < 0.05) in fatty acid profiles between tissues and organs. Omega-3 oil fortified pellets significantly (p < 0.05) increased ≥C20 n-3 LC-PUFA (C20:5n-3 eicosapentaenoate, EPA + C22:5n3 docosapentaenoate, DPA + C22:6n3 docosahexanoate DHA); C18:3n-3 alpha-linolenate, ALA; C18:2 conjugated linoleic acid, CLA; total monounsaturated fatty acids, MUFA; polyunsaturated fatty acids, PUFA contents; and reduced the ratio of omega-6 to omega-3 fatty acids in all lamb organs and tissues without impacting shelf-life. The findings demonstrate that the inclusion of omega-3 oil in feedlot diets of lambs enhances the human health beneficial omega-3 long-chain polyunsaturated fatty acid profiles of edible muscle tissue and organs without compromising meat quality.",
           7,
           "biology"
          ],
          [
           "Risk Factors for Postoperative Morbidity and Mortality after Small Bowel Surgery in Patients with Cirrhotic Liver Disease—A Retrospective Analysis of 76 Cases in a Tertiary Center",
           "10.3390/biology9110349",
           2020,
           "(1) Purpose: As it is known, patients with liver cirrhosis (LC) undergoing colon surgery or hernia surgery have high perioperative morbidity and mortality. However, data about patients with LC undergoing small bowel surgery is lacking. This study aimed to analyze the morbidity and mortality of patients with LC after small bowel surgery in order to determine predictive risk factors for a poor outcome. (2) Methods: A retrospective analysis was performed of all patients undergoing small bowel surgery between January 2002 and July 2018 and identified 76 patients with LC. Postoperative complications were analyzed using the classification of Dindo/Clavien (D/C) and further subdivided (hemorrhage, pulmonary complication, wound healing disturbances, renal failure). A total of 38 possible predictive factors underwent univariate and multivariate analyses for different postoperative complications and in-hospital mortality. (3) Results: Postoperative complications [D/C grade ≥ II] occurred in 90.8% of patients and severe complications (D/C grade ≥ IIIB) in 53.9% of patients. Nine patients (11.8%) died during the postoperative course. Predictive factors for overall complications were “additional surgery” (OR 5.3) and “bowel anastomosis” (OR 5.6). For postoperative mortality, we identified the model of end-stage liver disease (MELD) score (OR 1.3) and portal hypertension (OR 5.8) as predictors. The most common complication was hemorrhage, followed by pulmonary complications, hydropic decompensation, renal failure, and wound healing disturbances. The most common risk factors for those complications were portal hypertension (PH), poor liver function, emergency or additional surgery, ascites, and high ASA score. (4) Conclusions: LC has a devastating influence on patients’ outcomes after small bowel resection. PH, poor liver function, high ASA score, and additional or emergency surgery as well as ascites were significant risk factors for worse outcomes. Therefore, PH should be treated before surgery whenever possible. Expansion of the operation should be avoided whenever possible and in case of at least moderate preoperative ascites, the creation of an anastomotic ostomy should be evaluated to prevent leakages.",
           5,
           "biology"
          ],
          [
           "Association of miRNA and mRNA Levels of the Clinical Onset of Multiple Sclerosis Patients",
           "10.3390/biology10060554",
           2021,
           "Multiple sclerosis (MS) is a demyelinating disease characterized by chronic inflammation of the central nervous system, in which many factors can act together to influence disease susceptibility and progression. To date, the exact cause of MS is still unclear, but it is believed to result from an abnormal response of the immune system to one or more myelin antigens that develops in genetically susceptible individuals after their exposure to a, as yet undefined, causal agent. In our study, we assessed the effect of microRNAs on the expression level of neuroprotective proteins, including neurotrophins (BDNF and NT4/5), heat shock proteins (HSP70 and HSP27), and sirtuin (SIRT1) in peripheral blood mononuclear cells in the development of multiple sclerosis. The analysis of dysregulation of miRNA levels and the resulting changes in target mRNA/protein expression levels could contribute to a better understanding of the etiology of multiple sclerosis, as well as new alternative methods of diagnosis and treatment of this disease. The aim of this study was to find a link between neurotrophins (BDNF and NT4), SIRT1, heat shock proteins (HSP27 and HSP27), and miRNAs that are involved in the development of multiple sclerosis. The analysis of the selected miRNAs showed a negative correlation of SIRT1 with miR-132 and miR-34a and of BDNF with 132-3p in PBMCs, which suggests that the miRNAs we selected may regulate the expression level of the studied genes.",
           9,
           "biology"
          ],
          [
           "Tumor Microenvironment and Glioblastoma Cell Interplay as Promoters of Therapeutic Resistance",
           "10.3390/biology12050736",
           2023,
           "The invasive nature of glioblastoma is problematic in a radical surgery approach and can be responsible for tumor recurrence. In order to create new therapeutic strategies, it is imperative to have a better understanding of the mechanisms behind tumor growth and invasion. The continuous cross-talk between glioma stem cells (GSCs) and the tumor microenvironment (TME) contributes to disease progression, which renders research in this field difficult and challenging. The main aim of the review was to assess the different possible mechanisms that could explain resistance to treatment promoted by TME and GSCs in glioblastoma, including the role of M2 macrophages, micro RNAs (miRNAs), and long non-coding RNAs (lncRNAs) from exosomes from the TME. A systematic review of the literature on the role of the TME in developing and promoting radioresistance and chemoresistance of GBM was performed according to PRISMA-P (Preferred Reporting Items for Systematic Review and Meta-Analysis Protocols) guidelines. A dedicated literature review search was also performed on the immunotherapeutic agents against the immune TME. We identified 367 papers using the reported keywords. The final qualitative analysis was conducted on 25 studies. A growing amount of evidence in the current literature supports the role of M2 macrophages and non-coding RNAs in promoting the mechanisms of chemo and radioresistance. A better insight into how GBM cells interact with TME is an essential step towards comprehending the mechanisms that give rise to resistance to standard treatment, which can help to pave the way for the development of novel therapeutic strategies for GBM patients.",
           5,
           "biology"
          ],
          [
           "Effects of Intermediate Frequency (150 kHz) Electromagnetic Radiation on the Vital Organs of Female Sprague Dawley Rats",
           "10.3390/biology12020310",
           2023,
           "Exposure to electromagnetic radiation (EMR) from intermediate frequency sources has increased exponentially in recent years. The consequences of this exposure on biological systems are prompting scientists to study the effects on human health. This current study aimed to determine the effects of intermediate frequency (150 kHz) EMR exposure on the vital organs of female Sprague Dawley rats. The EMR group (n = 10 animals) was exposed to a frequency of 150 kHz with an intensity of 65 ± 15 μW/cm2 for two months. The control group (n = 10 animals) was exposed to an intensity of 35 ± 15 nW/cm2. Haematological, histochemical, gross, and histopathological profiles of all major organs of all animals were then performed using standard procedures. All major organs generally showed no significant detectable effects in either the control or EMR groups. However, gross and histopathological examinations revealed the effects of EMR on the liver and lungs, which showed inflammatory changes without significant biochemical/haematological manifestations. In addition, a significant increase in serum sodium level and a decrease in serum urea level were also observed in the EMR group. It can be concluded that the current frequency and duration of exposure trigger the changes in the liver and lungs but are not sufficient to cause clinical and functional manifestations. Therefore, a long-term exposure study might be helpful to determine the effects of 150 kHz IF EMR on these organs.",
           4,
           "biology"
          ],
          [
           "Factors Associated with Increased Morbidity and Mortality of Obese and Overweight COVID-19 Patients",
           "10.3390/biology9090280",
           2020,
           "Overweight and obesity are defined as an unnecessary accumulation of fat, which poses a risk to health. It is a well-identified risk factor for increased mortality due to heightened rates of heart disease, certain cancers, musculoskeletal disorders, and bacterial, protozoan and viral infections. The increasing prevalence of obesity is of concern, as conventional pathogenesis may indeed be increased in obese hosts rather than healthy hosts, especially during this COVID-19 pandemic. COVID-19 is a new disease and we do not have the luxury of cumulative data. Obesity activates the development of gene induced hypoxia and adipogenesis in obese animals. Several factors can influence obesity, for example, stress can increase the body weight by allowing people to consume high amounts of food with a higher propensity to consume palatable food. Obesity is a risk factor for the development of immune-mediated and some inflammatory-mediated diseases, including atherosclerosis and psoriasis, leading to a dampened immune response to infectious agents, leading to weaker post-infection impacts. Moreover, the obese host creates a special microenvironment for disease pathogenesis, marked by persistent low-grade inflammation. Therefore, it is advisable to sustain healthy eating habits by increasing the consumption of various plant-based and low-fat foods to protect our bodies and decrease the risk of infectious diseases, especially COVID-19.",
           20,
           "biology"
          ],
          [
           "Carotid Atherosclerosis Progression in Postmenopausal Women Receiving a Mixed Phytoestrogen Regimen: Plausible Parallels with Kronos Early Estrogen Replacement Study",
           "10.3390/biology9030048",
           2020,
           "This randomized double-blinded, placebo-controlled clinical trial evaluated the progression of intima-media thickness of common carotid artery (cIMT) and the effect of phytoestrogen therapy on atherosclerosis development in early and late postmenopausal women. The 2-year cIMT progression was evaluated in 315 early postmenopausal women aged 40–55 years and in 231 late postmenopausal women aged 60–69 years free of cardiovascular disease. B-mode ultrasound was done at baseline and after 12 and 24 months of follow-up. The study revealed no significant changes in the rate of cIMT progression in 315 early postmenopausal women. By contrast, a statistically significant difference in the rate of atherosclerosis development was observed in late postmenopausal women treated with phytoestrogens compared to placebo (p = 0.008). The rate of cIMT progression in the placebo group was 0.019 mm/year led to a significant increase of cIMT during the observation period (p = 0.012), while the rate of cIMT progression in phytoestrogen late postmenopausal recipients was 0.011 mm/year, and total change did not reach statistical significance during the follow-up period (p = 0.101). These results suggest that late postmenopausal women can be a suitable cohort for trials assessing the anti-atherosclerosis effects of phytoestrogen preparations. In particular, the beneficial effect of phytoestrogens on cIMT progression was demonstrated in late postmenopausal women.",
           1,
           "biology"
          ],
          [
           "Promising Novel Method of Acetylation Modification for Regulating Fatty Acid Metabolism in Brassica napus L.",
           "10.3390/biology11040483",
           2022,
           "In this study, lysine acetylation analysis was conducted using two Brassica napus near-isogenic lines, HOCR and LOCR, containing high and low oleic acid contents, respectively, to explore this relationship. Proteins showing differences in quantitative information between the B. napus lines were identified in lysine acetylation analysis, and KEGG pathways were analyzed, yielding 45 enriched proteins, most of which are involved in carbon fixation in photosynthetic organisms, photosynthesis, ascorbate and aldarate metabolism, and glycolysis. Potential key genes related to fatty acid metabolisms were determined. To further explore the effect of acetylation modification on fatty acid metabolisms, the acyl-ACP3 related gene BnaACP363K was cloned, and a base mutation at No.63 was changed via overlapping primer PCR method. This study is the first to demonstrate that acetylation modification can regulate oleic acid metabolisms, which provides a promising approach for the study of the molecular mechanism of oleic acid in rapeseed.",
           0,
           "biology"
          ],
          [
           "The Balance between Orthodontic Force and Radiation in the Jawbone: Microstructural, Histological, and Molecular Study in a Rat Model",
           "10.3390/biology10111203",
           2021,
           "Irradiation of facial bones is associated with a lifelong risk of osteonecrosis. In a rat model, maxillae were exposed to a single 5 Gy dose of external beam radiation and orthodontic force was applied for 2 weeks on the first maxillary molar; control rats were treated identically without radiation. Tooth movement in irradiated jaws was 30% less than in controls, representing radiation-related damage. Micro-CT, histological, and molecular outcomes of orthodontic tooth movement were studied. Microstructurally, bone parameters (trabecular thickness, bone volume fraction, bone mineral density) were significantly affected by orthodontic force but not by radiation. Histological parameters were influenced only by orthodontic force, especially by an increase in osteoclasts. A molecular study revealed a differential distribution of cells expressing pre-osteoclast markers (RANK+—majority, CD11b+, CD14+—minority), with changes being influenced by orthodontic force (increased CD11b+ and CD14+ cells) and also by radiation (decreased RANK+ cells). The activation status of osteoclasts (TRAP staining) showed an orthodontic-force-related increase, which probably could not fully compensate for the radiation-associated impairment. The overall balance showed that orthodontic force had elicited a substantial microstructural, histological, and functional normalization process in irradiated maxillae but a radiation-induced impact was still conspicuous. Additional studies are needed to validate these findings.",
           0,
           "biology"
          ],
          [
           "The Level of Selected Blood Parameters in Young Soccer Players in Relation to the Concentration of 25(OH)D at the Beginning and End of Autumn",
           "10.3390/biology12010129",
           2023,
           "This study aimed to demonstrate the changes of selected blood parameters in relation to 25(OH)D concentration during the autumn period in young soccer players. A total of 35 participants’ results (age: 17.5 ± 0.6 years, body mass 71.3 ± 6.9 kg) were tested twice: in mid-September and in mid-December and divided into subgroups with regard to two criteria. First, according to the initial level of the 25(OH)D concentration (optimal group—ODG, suboptimal group—SDG), second, according to drops in 25(OH)D concentration (high drop group—HDG, low drop group—LDG). A significant decrease (p < 0.001) in the 25(OH)D concentration was reported in the total group (TGr) and in all subgroups. Blood parameters such as white blood cells, red blood cells, haemoglobin and haematocrit increased significantly (p < 0.05) in TGr during the analysed period of time. The analysis of changes in the lipid profile did not expose significant differences except triglycerides. The asparagine amino transferase and creatine kinase activity decreased significantly after autumn in all analysed groups. The declining level of 25(OH)D concentration should be compensated (e.g., with vitamin D supplementation) during autumn. Applied training loads could also influence the blood parameters variability in young soccer players. Regular measurements of 25(OH)D concentration are helpful in identifying potential drops and allows for the preparation of individual supplementation plans for the players.",
           0,
           "biology"
          ],
          [
           "Pressure-Dependent Elevation of Vasoactive Intestinal Peptide Level in Chicken Choroid",
           "10.3390/biology12040495",
           2023,
           "Purpose: Autonomic control is important in maintaining ocular integrity. As recent data suggested that intrinsic choroidal neurons (ICN), an intrinsic choroidal autonomic control, may regulate choroidal thickening via release of the vasodilative vasoactive intestinal peptide (VIP), it was the aim of the study to investigate the level of choroidal VIP (VIPchor) in the presence of an increased atmospheric pressure in a chicken model. Methods: Chicken choroidal whole mounts were exposed to ambient pressure (n = 20) and 40 mm Hg (n = 20) in a PC-controlled, open chamber system for 24 and 72 h, respectively. The VIP concentration was analyzed by ELISA, and the total protein concentration was measured by the BCA assay. Statistical analysis was done using an unpaired two-tailed t-test. Results: The pressurization systems enabled choroidal whole mount pressurization (40 mm Hg) with humidifying, pressure, temperature, and gas exchange. Overall, the VIPchor level concentration was significantly increased at 40 mmHg compared to the ambient pressure (30.09 ± 7.18 pg vs. 20.69 ± 3.24 pg; p < 0.0001). Subgroup analysis yielded a significantly increased VIPchor level at 40 mmHg compared to the ambient pressure after 24 h (28.42 ± 6.03 pg vs. 20.76 ± 4.06 pg; p = 0.005) and 72 h (31.77 ± 7.82 pg vs. 20.61 ± 2.12 pg; p = 0.002), respectively. The VIPchor elevation at 40 mm Hg ranged between 1.37- (24 h) and 1.54-fold (72 h) compared to the ambient pressure. No difference was observed between the VIPchor level at 24 h and 72 h (p > 0.05). Conclusions: The increase of the total choroidal VIP level, representing the intracellular VIP content, in the presence of an increased ambient pressure argues for a retention of VIP within the neurons, decreasing both vasodilatation and, consequently, choroid thickness. This finding might be a passive or even active function of ICN in the regulation of choroidal thickness, ocular integrity and IOP.",
           0,
           "biology"
          ],
          [
           "Principal Component and Structural Element Analysis Provide Insights into the Evolutionary Divergence of Conotoxins",
           "10.3390/biology12010020",
           2022,
           "Predatory cone snails (Conus) developed a sophisticated neuropharmacological mechanism to capture prey, escape against other predators, and deter competitors. Their venom’s remarkable specificity for various ion channels and receptors is an evolutionary feat attributable to the venom’s variety of peptide components (conotoxins). However, what caused conotoxin divergence remains unclear and may be related to the role of prey shift. Principal component analysis revealed clustering events within diet subgroups indicating peptide sequence similarity patterns based on the prey they subdue. Molecular analyses using multiple sequence alignment and structural element analysis were conducted to observe the events at the molecular level that caused the subgrouping. Three distinct subgroups were identified. Results showed homologous regions and conserved residues within diet subgroups but divergent between other groups. We specified that these structural elements caused subgrouping in alpha conotoxins that may play a role in function specificity. In each diet subgroup, amino acid character, length of intervening amino acids between cysteine residues, and polypeptide length influenced subgrouping. This study provides molecular insights into the role of prey shift, specifically diet preference, in conotoxin divergence.",
           0,
           "biology"
          ],
          [
           "The Clinical Role of Serum Epidermal Growth Factor Receptor 3 in Hepatitis C Virus-Infected Patients with Early Hepatocellular Carcinoma",
           "10.3390/biology10030215",
           2021,
           "Epidermal growth factor receptor 3 (ERBB3) is a surface tyrosine kinase receptor belonging to the EGFR/ERBB family, involved in tumor development and progression. We evaluated the diagnostic and prognostic value of serum ERBB3 measurement in hepatitis C virus (HCV)-infected patients with early hepatocellular carcinoma (HCC). A total of 164 HCV-infected patients (82 with cirrhosis and 82 with early HCC) were included in the study. HCC was classified according to the Barcelona Clinic Liver Cancer (BCLC) staging system. Among patients with HCC, 23 (28%) had a diagnosis of very early tumor (BCLC = 0), while 59 (62%) had a diagnosis of early HCC (BCLC = A). Median overall survival (OS) in patients with HCC was 79.2 (95% CI 51.6–124.8) months. While ERBB3 serum values were similar between patients with cirrhosis and those with HCC (p = 0.993), in the latter, serum ERBB3 ≥ 2860 RU resulted significantly and independently associated with OS (Hazard Ratio = 2.24, 95% CI 1.16–4.35, p = 0.017). Consistently, the 1-, 3-, and 5-year OS rates in patients with serum ERBB3 ≥ 2860 RU were 90% (36/40), 53% (19/36), and 28% (8/29) in comparison to patients with serum ERBB3 < 2860 RU, which were 98% (40/41), 80% (32/40), and 74% (26/35) (Log-rank test; p = 0.014). In conclusion, serum ERBB3 values resulted an independent prognostic factor of patients with early HCC and might be useful to tailor more personalized treatment strategies.",
           4,
           "biology"
          ],
          [
           "Identification of Prominent Genes between 3D Glioblastoma Models and Clinical Samples via GEO/TCGA/CGGA Data Analysis",
           "10.3390/biology12050648",
           2023,
           "A paradigm shift in preclinical evaluations of new anticancer GBM drugs should occur in favour of 3D cultures. This study leveraged the vast genomic data banks to investigate the suitability of 3D cultures as cell-based models for GBM. We hypothesised that correlating genes that are highly upregulated in 3D GBM models will have an impact in GBM patients, which will support 3D cultures as more reliable preclinical models for GBM. Using clinical samples of brain tissue from healthy individuals and GBM patients from The Cancer Genome Atlas (TCGA), Gene Expression Omnibus (GEO), Chinese Glioma Genome Atlas (CGGA), and Genotype-Tissue Expression (GTEx) databases, several genes related to pathways such as epithelial-to-mesenchymal transition (EMT)-related genes (CD44, TWIST1, SNAI1, CDH2, FN1, VIM), angiogenesis/migration-related genes (MMP1, MMP2, MMP9, VEGFA), hypoxia-related genes (HIF1A, PLAT), stemness-related genes (SOX2, PROM1, NES, FOS), and genes involved in the Wnt signalling pathway (DKK1, FZD7) were found to be upregulated in brain samples from GBM patients, and the expression of these genes were also enhanced in 3D GBM cells. Additionally, EMT-related genes were upregulated in GBM archetypes (wild-type IDH1R132 ) that historically have poorer treatment responses, with said genes being significant predictors of poorer survival in the TCGA cohort. These findings reinforced the hypothesis that 3D GBM cultures can be used as reliable models to study increased epithelial-to-mesenchymal transitions in clinical GBM samples.",
           0,
           "biology"
          ],
          [
           "Changes in Body Mass, Physical Activity, and Dietary Intake during the COVID-19 Pandemic Lockdowns in Canadian University Students",
           "10.3390/biology12020326",
           2023,
           "This study examined changes in body mass and body mass index (BMI), physical activity, and dietary intake in Canadian university students during the first year of the COVID-19 pandemic. Two self-reported recall surveys were conducted: after the first lockdown in September 2020 (T1) and following the second lockdown in March 2021 (T2). Eligible participants were full-time undergraduate students attending a Canadian university and residing in Canada during the first year of the pandemic. At T1, 510 students (99 male, 411 female) completed the survey, and of those, 135 (32 males, 103 females) completed the survey at T2 (73% attrition). At both T1 and T2, most participants were 18–24 years of age (93% and 90%, respectively), Caucasian (73% and 78%, respectively), and resided in the province of Ontario (79% and 80%, respectively). Body mass increased from T1 to T2 (+0.91 ± 3.89 kg t(132) = −2.7, p = 0.008). BMI also increased from T1 to T2 (+0.30 ± 1.33 kg/m2 [t(130) = −2.5, p = 0.012), with a greater number of participants within the overweight range (19.8% versus 24.4%, respectively). At T1, 38% of the participants reported a decrease in physical activity, while the number of students reporting a decrease in activity increased to 56% at T2. Dietary energy intake decreased from 1678 ± 958 kcal/day at T1 to 1565 ± 842 kcal/day at T2 [c2(1) = 7.2, p = 0.007]. Diet quality also decreased, with participants not meeting the recommended daily allowance for essential macro and micronutrients. A decrease was observed in daily servings of fruits (−27%, p < 0.001), vegetables (−72%, p < 0.001), and grains (−68%, p < 0.001). In conclusion, despite a small decrease in dietary energy intake, a modest weight gain occurred during the first year of the COVID-19 pandemic in this cohort of Canadian university students, which was potentially related to decreased physical activity and diet quality.",
           2,
           "biology"
          ],
          [
           "Effect of Mineral Carriers on Biofilm Formation and Nitrogen Removal Activity by an Indigenous Anammox Community from Cold Groundwater Ecosystem Alone and Bioaugmented with Biomass from a “Warm” Anammox Reactor",
           "10.3390/biology11101421",
           2022,
           "The complex pollution of aquifers by reduced and oxidized nitrogen compounds is currently considered one of the urgent environmental problems that require non-standard solutions. This work was a laboratory-scale trial to show the feasibility of using various mineral carriers to create a permeable in situ barrier in cold (10 °C) aquifers with extremely high nitrogen pollution and inhabited by the Candidatus Scalindua-dominated indigenous anammox community. It has been established that for the removal of ammonium and nitrite in situ due to the predominant contribution of the anammox process, quartz, kaolin clays of the Kantatsky and Kamalinsky deposits, bentonite clay of the Berezovsky deposit, and zeolite of the Kholinsky deposit can be used as components of the permeable barrier. Biofouling of natural loams from a contaminated aquifer can also occur under favorable conditions. It has been suggested that the anammox activity is determined by a number of factors, including the presence of the essential trace elements in the carrier and the surface morphology. However, one of the most important factors is competition with other microbial groups that can develop on the surface of the carrier at a faster rate. For this reason, carriers with a high specific surface area and containing the necessary microelements were overgrown with the most rapidly growing microorganisms. Bioaugmentation with a “warm” anammox community from a laboratory reactor dominated by Ca. Kuenenia improved nitrogen removal rates and biofilm formation on most of the mineral carriers, including bentonite clay of the Dinozavrovoye deposit, as well as loamy rock and zeolite-containing tripoli, in addition to carriers that perform best with the indigenous anammox community. The feasibility of coupled partial denitrification–anammox and the adaptation of a “warm” anammox community to low temperatures and hazardous components contained in polluted groundwater prior to bioaugmentation should be the scope of future research to enhance the anammox process in cold, nitrate-rich aquifers.",
           5,
           "biology"
          ],
          [
           "Stock Assessment of the Commercial Small Pelagic Fishes in the Beibu Gulf, the South China Sea, 2006–2020",
           "10.3390/biology13040226",
           2024,
           "Long-term variations in population structure, growth, mortality, exploitation rate, and recruitment pattern of two major commercial small pelagic fishes (CSPFs) (Decapterus maruadsi and Trachurus japonicus) are reported based on bottom trawl survey data collected during 2006–2020 in the Beibu Gulf, South China Sea. All individuals collected during each sampling quarter over a period of 15 years were subjected to laboratory-based analysis. In this study, the stock of D. maruadsi and T. japonicus inhabiting the Beibu Gulf was assessed using length-based methods (bootstrapped electronic length frequency analysis (ELEFAN)) to complete stock assessment in different fishery management periods (the division of fisheries management periods was based on China’s input and output in the South China Sea offshore fisheries over 15 years, specifically divided into period I (2006–2010), period II (2011–2015), and period III (2016–2020)). The results showed that the mean body length, dominant body size, and estimated asymptotic length of two CSPFs decreased, whereas their growth coefficient decreased, indicating miniaturization and slower growth, respectively. Estimated exploitation rates and catching body length for two CSPFs indicated that both stocks in the Beibu Gulf were overexploited in period I and moderately exploited after 2011. These stocks were taking a good turn in status in period III, with the exploitation rate much lower than the initial period and reversing the downward trend in catching body length. Furthermore, the variations in the spawning season of the two CSPF stocks and their barely satisfactory expected yield indicated the complexity of the current fishery management in the Beibu Gulf. These results suggest that management measures to reduce fishing pressure may have a positive influence on the biological characteristics of those CSPFs in the Beibu Gulf; however, the stock structure already affected by overfishing will be a huge challenge for the conservation and restoration of fisheries resources in the future. Given that the current stocks of D. maruadsi and T. japonicus in the Beibu Gulf still have low first-capture body length (Lc) and high fishing mortality (F) (compared to F0.1), we identify a need to refine population structure by controlling fishing efforts and increasing catchable size, and more consideration should be given to the local fishery resource status in fisheries management.",
           0,
           "biology"
          ],
          [
           "Use of Collagen Membrane in the Treatment of Periodontal Defects Distal to Mandibular Second Molars Following Surgical Removal of Impacted Mandibular Third Molars: A Comparative Clinical Study",
           "10.3390/biology10121348",
           2021,
           "The study aims to assess the efficacy of using collagen membrane in the treatment of distal periodontal defects of mandibular second molars following the removal of mesioangularly or horizontally impacted mandibular third molars surgically. Forty sites in twenty patients with bilaterally impacted mandibular third molars (mesioangular or horizontal) were considered for the study. In 20 test sites (Group A), after surgical removal of the mandibular third molar, a resorbable collagen membrane barrier was placed on the distal aspect of the mandibular second molar to cover the post-surgical bone defect. In the other control 20 sites (Group B), the same surgical procedure was repeated without placing any membrane barrier. The clinical parameters recorded were Oral Hygiene Index Simplified (OHI-S), Probing pocket depth (PPD), Clinical attachment level (CAL), and radiographic assessment of alveolar bone level (ABL). OHI-S score of most of the patients was observed to be satisfactory. Group A was observed to achieve a statistically significant reduction in PPD, CAL, and ABL gain compared to Group B. The improvements indicated that the use of collagen membrane facilitates early wound stabilization and promotes primary closure of the defect. This recovery is achieved through its unique property to assist fibrinogenesis over osteoconduction. Further longitudinal studies are needed to confirm the present findings.",
           3,
           "biology"
          ],
          [
           "Ability of the Right Ventricle to Serve as a Systemic Ventricle in Response to the Volume Overload at the Neonatal Stage",
           "10.3390/biology11121831",
           2022,
           "Background: In children with hypoplastic left heart syndrome (HLHS), volume overload (VO) is inevitable, and the right ventricle (RV) pumps blood into the systemic circulation. Understanding the molecular differences and their different responses to VO between the RV and left ventricle (LV) at the neonatal and highly plastic stages may improve the long-term management of children with HLHS. Methods and Results: A neonatal rat ventricular VO model was established by the creation of a fistula between the inferior vena cava and the abdominal aorta on postnatal day 1 (P1) and confirmed by echocardiographic and histopathological analyses. Transcriptomic analysis demonstrated that some of the major differences between a normal neonatal RV and LV were associated with the thyroid hormone and insulin signaling pathways. Under the influence of VO, the levels of insulin receptors and thyroid hormone receptors were significantly increased in the LV but decreased in the RV. The transcriptomic analysis also demonstrated that under the influence of VO, the top two common enriched pathways between the RV and LV were the insulin and thyroid hormone signaling pathways, whereas the RV-specific enriched pathways were primarily associated with lipid metabolism and arrhythmogenic right ventricular cardiomyopathy (ARVC); further, the LV-specific enriched pathways were primarily associated with nucleic acid metabolism and microRNAs in cancer. Conclusions: Insulin and thyroid hormones may play critical roles in the differences between a neonatal RV and LV as well as their common responses to VO. Regarding the isolated responses to VO, the RV favors an ARVC change and the LV favors a reduction in microRNAs in cancer. The current study suggests that insulin, thyroid hormone, and cancer-associated microRNAs are potential therapeutic targets that should be explored by basic science studies to improve the function of the RV to match that of the LV.",
           2,
           "biology"
          ],
          [
           "Connexin 43 and Sonic Hedgehog Pathway Interplay in Glioblastoma Cell Proliferation and Migration",
           "10.3390/biology10080767",
           2021,
           "Glioblastoma (GBM) represents the most common primary brain tumor within the adult population. Current therapeutic options are still limited by high rate of recurrences and signalling axes that promote GBM aggressiveness. The contribution of gap junctions (GJs) to tumor growth and progression has been proven by experimental evidence. Concomitantly, tumor microenvironment has received increasing interest as a critical process in dysregulation and homeostatic escape, finding a close link between molecular mechanisms involved in connexin 43 (CX43)-based intercellular communication and tumorigenesis. Moreover, evidence has come to suggest a crucial role of sonic hedgehog (SHH) signalling pathway in GBM proliferation, cell fate and differentiation. Herein, we used two human GBM cell lines, modulating SHH signalling and CX43-based intercellular communication in in vitro models using proliferation and migration assays. Our evidence suggests that modulation of the SHH effector smoothened (SMO), by using a known agonist (i.e., purmorphamine) and a known antagonist (i.e., cyclopamine), affects the CX43 expression levels and therefore the related functions. Moreover, SMO activation also increased cell proliferation and migration. Importantly, inhibition of CX43 channels was able to prevent SMO-induced effects. SHH pathway and CX43 interplay acts inducing tumorigenic program and supporting cell migration, likely representing druggable targets to develop new therapeutic strategies for GBM.",
           19,
           "biology"
          ],
          [
           "Innate Immune Recognition, Integrated Stress Response, Infection, and Tumorigenesis",
           "10.3390/biology12040499",
           2023,
           "Engagement of PRRs in recognition of PAMPs or DAMPs is one of the processes that initiates cellular stress. These sensors are involved in signaling pathways leading to induction of innate immune processes. Signaling initiated by PRRs is associated with the activation of MyD88-dependent signaling pathways and myddosome formation. MyD88 downstream signaling depends upon the context of signaling initiation, the cell (sub)type and the microenvironment of signal initiation. Recognition of PAMPs or DAMPs through PRRs activates the cellular autonomous defence mechanism, which orchestrates the cell responses to resolve specific insults at the single cell level. In general, stressed endoplasmic reticulum is directly linked with the induction of autophagy and initiation of mitochondrial stress. These processes are regulated by the release of Ca2+ from ER stores accepted by mitochondria, which respond through membrane depolarization and the production of reactive oxygen species generating signals leading to inflammasome activation. In parallel, signaling from PRRs initiates the accumulation of misfolded or inappropriately post-translationally modified proteins in the ER and triggers a group of conserved emergency rescue pathways known as unfolded protein response. The cell-autonomous effector mechanisms have evolutionarily ancient roots and were gradually specialized for the defence of specific cell (sub)types. All of these processes are common to the innate immune recognition of microbial pathogens and tumorigenesis as well. PRRs are active in both cases. Downstream are activated signaling pathways initiated by myddosomes, translated by the cellular autonomous defence mechanism, and finalized by inflammasomes.",
           3,
           "biology"
          ],
          [
           "3-Formylchromone Counteracts STAT3 Signaling Pathway by Elevating SHP-2 Expression in Hepatocellular Carcinoma",
           "10.3390/biology11010029",
           2021,
           "Hepatocellular carcinoma (HCC) is one of the leading cancers that contribute to a large number of deaths throughout the globe. The signal transducer and activator of transcription 3 (STAT3) is a tumorigenic protein that is overactivated in several human malignancies including HCC. In the present report, the effect of 3-formylchromone (3FC) on the STAT3 signaling pathway in the HCC model was investigated. 3FC downregulated the constitutive phosphorylation of STAT3 and non-receptor tyrosine kinases such as JAK1 and JAK2. It also suppressed the transportation of STAT3 to the nucleus and reduced its DNA-binding ability. Pervanadate treatment overrode the 3FC-triggered STAT3 inhibition, and the profiling of cellular phosphatase expression revealed an increase in SHP-2 levels upon 3FC treatment. The siRNA-driven deletion of SHP-2 led to reinstate STAT3 activation. 3FC downmodulated the levels of various oncogenic proteins and decreased CXCL12-driven cell migration and invasion. Interestingly, 3FC did not exhibit any substantial toxicity, whereas it significantly regressed tumor growth in an orthotopic HCC mouse model and abrogated lung metastasis. Overall, 3FC can function as a potent agent that can display antitumor activity by targeting STAT3 signaling in HCC models.",
           15,
           "biology"
          ],
          [
           "Effect of Long-Term Continuous Light Exposure and Western Diet on Adropin Expression, Lipid Metabolism, and Energy Homeostasis in Rats",
           "10.3390/biology10050413",
           2021,
           "Long-term continuous light exposure (CL) and western diet (WD) effects on Adropin expression, RORα, and Rev-erb-α nuclear receptors and energy homeostasis were studied in rats. Thirty-two male Wistar rats (250–290 g) were enrolled for 3 months in the following groups (n = 8/group): (a) Normal control group (NC), (b) CL group, (c) WD group, and (d) CL + WD group. Then, indirect calorimetry and food intake (FI) were measured. Finally, Adropin, hormone-sensitive lipase (HSL), adipocyte triglyceride lipase (ATGL), and free fatty acids (FFA) were measured. Additionally, the histopathology and gene expression of Enho, RORα, and Rev-erb-α genes were done. The CL alone elevated the Adropin plasma level and gene expression, increased RORα expression, and decreased the Rev-erb-α nuclear receptor expression mainly in the liver and kidney. Besides, CL increased the total energy expenditure (TEE) and decreased the respiratory quotient. WD alone or in combination with the CL reversed gene expression of Enho, RORα, and Rev-erb-α. Combined CL and WD increased the TEE, reduced the food intake, increased the ATGL, and reduced the Adropin level in addition to widespread degenerative changes in the liver, spleen, and renal tissues. The deleterious effects of CL and WD on energy homeostasis may include Adropin with the involvement of the RORα and Rev-erb-α nuclear receptors.",
           3,
           "biology"
          ],
          [
           "Reproductive Ability Disparity in the Pacific Whiteleg Shrimp (Penaeus vannamei): Insights from Ovarian Cellular and Molecular Levels",
           "10.3390/biology13040218",
           2024,
           "The Pacific whiteleg shrimp (Penaeus vannamei) is a highly significant species in shrimp aquaculture. In the production of shrimp larvae, noticeable variations in the reproductive capacity among female individuals have been observed. Some females experience slow gonadal development, resulting in the inability to spawn, while others undergo multiple maturations and contribute to the majority of larval supply. Despite numerous studies that have been conducted on the regulatory mechanisms of ovarian development in shrimp, the factors contributing to the differences in reproductive capacity among females remain unclear. To elucidate the underlying mechanisms, this study examined the differences in the ovarian characteristics between high and low reproductive bulks at different maturity stages, focusing on the cellular and molecular levels. Transmission electron microscopy analysis revealed that the abundance of the endoplasmic reticulum, ribosomes, mitochondria, and mitochondrial cristae in oocytes of high reproductive bulk was significantly higher than that of the low reproductive bulk in the early stages of ovarian maturation (stages I and II). As the ovaries progressed to late-stage maturation (stages III and IV), differences in the internal structures of oocytes between females with different reproductive capacities gradually diminished. Transcriptome analysis identified differentially expressed genes (DEGs) related to the mitochondria between two groups, suggesting that energy production processes might play a crucial role in the observed variations in ovary development. The expression levels of the ETS homology factor (EHF) and PRDI-BF1 and RIZ homology domain containing 9 (PRDM9), which were significantly different between the two groups, were compared using qRT-PCR in individuals at different stages of ovarian maturation. The results showed a significantly higher expression of the EHF gene in the ovaries of high reproductive bulk at the II and IV maturity stages compared to the low reproductive bulk, while almost no expression was detected in the eyestalk tissue of the high reproductive bulk. The PRDM9 gene was exclusively expressed in ovarian tissue, with significantly higher expression in the ovaries of the high reproductive bulk at the four maturity stages compared to the low reproductive bulk. Fluorescence in situ hybridization further compared the expression patterns of EHF and PRDM9 in the ovaries of individuals with different fertility levels, with both genes showing stronger positive signals in the high reproductive bulk at the four ovarian stages. These findings not only contribute to our understanding of the regulatory mechanisms involved in shrimp ovarian development, but also provide valuable insights for the cultivation of new varieties aimed at improving shrimp fecundity.",
           0,
           "biology"
          ],
          [
           "Quantitative Proteomics and Network Analysis of Differentially Expressed Proteins in Proteomes of Icefish Muscle Mitochondria Compared with Closely Related Red-Blooded Species",
           "10.3390/biology11081118",
           2022,
           "Antarctic icefish are extraordinary in their ability to thrive without haemoglobin. We wanted to understand how the mitochondrial proteome has adapted to the loss of this protein. Metabolic pathways that utilise oxygen are most likely to be rearranged in these species. Here, we have defined the mitochondrial proteomes of both the red and white muscle of two different icefish species (Champsocephalus gunnari and Chionodraco rastrospinosus) and compared these with two related red-blooded Notothenioids (Notothenia rossii, Trematomus bernacchii). Liquid Chromatography-Mass spectrometry (LC-MS/MS) was used to generate and examine the proteomic profiles of the two groups. We recorded a total of 91 differentially expressed proteins in the icefish red muscle mitochondria and 89 in the white muscle mitochondria when compared with the red-blooded related species. The icefish have a relatively higher abundance of proteins involved with Complex V of oxidative phosphorylation, RNA metabolism, and homeostasis, and fewer proteins for striated muscle contraction, haem, iron, creatine, and carbohydrate metabolism. Enrichment analyses showed that many important pathways were different in both red muscle and white muscle, including the citric acid cycle, ribosome machinery and fatty acid degradation. Life in the Antarctic waters poses extra challenges to the organisms that reside within them. Icefish have successfully inhabited this environment and we surmise that species without haemoglobin uniquely maintain their physiology. Our study highlights the mitochondrial protein pathway differences between similar fish species according to their specific tissue oxygenation idiosyncrasies.",
           0,
           "biology"
          ],
          [
           "Pathogenic D76N Variant of β2-Microglobulin: Synergy of Diverse Effects in Both the Native and Amyloid States",
           "10.3390/biology10111197",
           2021,
           "β2-microglobulin (β2m), the light chain of the MHC-I complex, is associated with dialysis-related amyloidosis (DRA). Recently, a hereditary systemic amyloidosis was discovered, caused by a naturally occurring D76N β2m variant, which showed a structure remarkably similar to the wild-type (WT) protein, albeit with decreased thermodynamic stability and increased amyloidogenicity. Here, we investigated the role of the D76N mutation in the amyloid formation of β2m by point mutations affecting the Asp76-Lys41 ion-pair of WT β2m and the charge cluster on Asp38. Using a variety of biophysical techniques, we investigated the conformational stability and partial unfolding of the native state of the variants, as well as their amyloidogenic propensity and the stability of amyloid fibrils under various conditions. Furthermore, we studied the intermolecular interactions of WT and mutant proteins with various binding partners that might have in vivo relevance. We found that, relative to WT β2m, the exceptional amyloidogenicity of the pathogenic D76N β2m variant is realized by the deleterious synergy of diverse effects of destabilized native structure, higher sensitivity to negatively charged amphiphilic molecules (e.g., lipids) and polyphosphate, more effective fibril nucleation, higher conformational stability of fibrils, and elevated affinity for extracellular components, including extracellular matrix proteins.",
           2,
           "biology"
          ],
          [
           "Heterometrus spinifer: An Untapped Source of Anti-Tumor Molecules",
           "10.3390/biology9070150",
           2020,
           "Despite intensive research, cancer incidence and mortality continue to rise. Consequently, the necessity to develop effective anti-cancer therapy is apparent. We have recently shown that the gut bacteria of animals living in polluted environments, such as crocodiles, are a potential source of novel anti-tumor molecules. To extend this work to other resilient species, we investigated the anti-tumor effects of gut bacteria of Heterometrus spinifer (a scorpion). Bacteria from the feces and gut were isolated, identified and evaluated for their anti-tumor effects. Bacterial-conditioned media was prepared in Roswell Park Memorial Institute (RPMI) 1640 media, and cytotoxicity and growth inhibitory properties were examined against cervical (HeLa) cancer cells. Liquid chromatography–mass spectrometry (LC-MS) was conducted to establish the identity of the molecules. Eighteen bacteria species from the gut (HSG01-18) and ten bacteria species from feces (HSF01-10) were tested for anti-tumor effects. Bacterial-conditioned media from scorpion gut and feces exhibited significant growth inhibitory effects against HeLa cells of 66.9% and 83.8%, respectively. Microscopic analysis of cancer cells treated with conditioned media HSG12 and HSG16 revealed apoptosis-like effects. HSG12 was identified as Pseudomonas aeruginosa and HSG16 was identified as Bacillus subtilis. Both conditioned media exhibited 100% growth inhibitory effects versus a selection of cancer cells, comprising cervical, breast and prostate cancer cells. LC–MS indicated the presence of 72 and 38 compounds, detected from HSG12 and HSG16, respectively. Out of these compounds, 47 were successfully identified while the remainder were unidentified and are possibly novel. This study suggests that the fecal and gut microbiota of scorpions might possess molecules with anti-cancer properties, however, further intensive research is needed to assess these expectations.",
           1,
           "biology"
          ],
          [
           "Okra Growth, Yield and Rhizosphere Microbiome Responses to the Encapsulated Bioinoculant Application under Reduced Fertilization Regime",
           "10.3390/biology11081107",
           2022,
           "There is limited evidence that Enterobacter hormaechei can improve plant physiology and yield through soil phosphate (P) and potassium (K) amelioration. This study unraveled the effect of different soil inoculation methods i.e., free-cell and encapsulated (alginate bead containing sugar-protein hydrolysate and molasses) E. hormaechei 40a with different rates of PK-fertilization on okra P and K uptake, and soil rhizosphere bacterial community. The results revealed that 3HB (half-dose PK-fertilizer + encapsulated strain 40a) had the highest soil available P (SAP) and K (SAK), as well as P and K uptake for all plant organs, followed by 3F (full-dose PK-fertilizer), 3HI (half-dose PK-fertilizer + free-cell strain 40a), and 3H (half-dose PK-fertilizer), and improved yield by up to 75.6%. Both inoculated and full-dose fertilizer treatments produced larger pods (>15 cm) compared to 3H. We discovered increased bacterial richness and diversity in both 3HB and 3HI samples compared to uninoculated treatments. Both 3HB and 3F treatments were positively correlated with the increasing abundance of Acidobacteriales, Burkholderia caballeronia paraburkholderia, Gemmataceae, and Sphingomonas along with the SAP and SAK. The plant-beneficial effect of one-time 3HB treatment on okra growth and yield was comparable to biweekly inoculation in 3HI, suggesting a new cost-effective farming approach in precision agriculture.",
           0,
           "biology"
          ],
          [
           "Protonation of γ‐Butyrolactone and γ‐Butyrolactam",
           "10.1002/open.202000220",
           2020,
           "γ‐Butyrolactone and γ‐butyrolactam were reacted in the superacidic systems XF/MF5 (X=H, D; M=As, Sb). Salts of the monoprotonated species of γ‐butyrolactone were obtained in terms of [(CH2)3OCOH]+[AsF6]−, [(CH2)3OCOH]+[SbF6]− and [(CH2)3OCOD]+[AsF6]− and the analogous lactam salts in terms of [(CH2)3NHCOH]+[AsF6]−, [(CH2)3NHCOH]+[SbF6]− and [(CH2)3NDCOD]+[AsF6]−. The salts were characterized by low temperature Raman and infrared spectroscopy and for both protonated hexafluoridoarsenates, [(CH2)3OCOH]+[AsF6]− and [(CH2)3NHCOH]+[AsF6]−, single‐crystal X‐ray structure analyses were conducted. In addition to the experimental results, quantum chemical calculations were performed on the B3LYP/aug‐cc‐pVTZ level of theory. As in both crystal structures C⋅⋅⋅F contacts were observed, the nature of these contacts is discussed with Mapped Electrostatic Potential as a rate of strength.",
           3,
           "chemistryopen"
          ],
          [
           "Assessment of the Full Compatibility of Copper(I)‐Catalyzed Alkyne‐Azide Cycloaddition and Oxime Click Reactions for bis‐Labelling of Oligonucleotides",
           "10.1002/open.201402099",
           2014,
           "The conjugation of oligonucleotides with reporters is of great interest for improving their intrinsic properties or endowing new ones. In this context, we report herein a new procedure for the bis‐labelling of oligonucleotides through oxime ligation (Click‐O) and copper(I)‐catalyzed alkyne–azide cycloaddition (Click‐H). 5′‐Azido and 3′‐aldehyde precursors were incorporated into oligonucleotides, and subsequent coupling reactions through Click‐O and Click‐H (or vice versa) were successfully achieved. In particular, we exhaustively investigated the full compatibility of each required step for both tethering strategies. The results demonstrate that click Huisgen and click oxime reactions are fully compatible. However, whilst both approaches can deliver the targeted doubly conjugated oligonucleotide, the route involving click oxime ligation prior to click Huisgen is significantly more successful. Thus the reactions investigated here can be considered to be key elements of the chemical toolbox for the synthesis of highly sophisticated bioconjugates.",
           2,
           "chemistryopen"
          ],
          [
           "Cover Picture: Gold Nanowire Forests for SERS Detection (ChemistryOpen 4/2014)",
           "10.1002/open.201480401",
           2014,
           "No Abstract",
           0,
           "chemistryopen"
          ],
          [
           "Gold Nanowire Forests for SERS Detection",
           "10.1002/open.201402024",
           2014,
           "Invited for this months cover is the group of Prof. Luis M. Liz‐Marzán, the Bionanoplasmonics Laboratory at CIC biomaGUNE, Spain. The cover picture shows a schematic view of a “forest” of gold nanowires vertically grown on a solid support. Standard Raman‐active molecules and their corresponding surface‐enhanced Raman scattering (SERS) spectra are depicted in between the nanowires. The manuscript by La Porta et al. describes the controlled growth of such gold nanowires and their corresponding plasmonic properties. For more details, see the Full Paper on p. 146 ff.",
           0,
           "chemistryopen"
          ],
          [
           "Cover Picture: Anion Binding Properties of Alkynylplatinum(II) Complexes with Amide‐Functionalized Terpyridine: Host–Guest Interactions and Fluoride Ion‐Induced Deprotonation (ChemistryOpen 5/2014)",
           "10.1002/open.201480501",
           2014,
           "No Abstract",
           0,
           "chemistryopen"
          ],
          [
           "Sol‐Gel Microspheres Doped with Glycerol: A Structural Insight in Light of Forthcoming Applications in the Polyurethane Foam Industry",
           "10.1002/open.201500023",
           2015,
           "Invited for this months cover are the groups of Professor Mario Pagliaro at the Istituto per lo Studio dei Materiali Nanostrutturati in Palermo and Professor Laura Ilharco at the Instituto Superior Técnico in Lisboa. The cover picture shows a­ GreenCaps­ microcapsule breaking and releasing encapsulated glycerol after the organosilica microspheres are sprayed from a pressurized polyurethane foam can. This shows how glycerol acts as a solid curing agent, promoting crosslinking of partially polymerized diphenylmethane diisocyanate. For more details, see the Full Paper on  p. 120 ff.",
           1,
           "chemistryopen"
          ],
          [
           "Influence of Nanoparticle Processing on the Thermoelectric Properties of (Bi<sub>x</sub>Sb<sub>1−X</sub>)<sub>2</sub>Te<sub>3</sub> Ternary Alloys",
           "10.1002/open.202000257",
           2021,
           "The synthesis of phase‐pure ternary solutions of tetradymite‐type materials (BixSb1−x)2Te3 (x=0.25; 0.50; 0.75) in an ionic liquid approach has been carried out. The nanoparticles are characterized by means of energy‐dispersive X‐ray spectroscopy (EDX), powder X‐ray diffraction (PXRD), scanning electron microscopy (SEM), and transmission electron microscopy. In addition, the role of different processing approaches on the thermoelectric properties ‐ Seebeck coefficient as well as electrical and thermal conductivity ‐ is demonstrated.",
           2,
           "chemistryopen"
          ],
          [
           "Decontamination and Remediation of the Sulfur Mustard Simulant CEES with “Off‐the‐Shelf” Reagents in Solution and Gel States: A Proof‐of‐Concept Study",
           "10.1002/open.201700063",
           2017,
           "The decontamination and remediation of sulfur mustard chemical warfare agents remains an ongoing challenge. Herein, we report the use of “off‐the‐shelf” metal salts alongside commercially available peroxides to catalyze the degradation of the simulant 2‐chloroethyl ethyl sulfide (CEES) in solution and encapsulated within a supramolecular gel.",
           10,
           "chemistryopen"
          ],
          [
           "Gas/Liquid‐Phase Micro‐Flow Trifluoromethylation using Fluoroform: Trifluoromethylation of Aldehydes, Ketones, Chalcones, and <i>N</i>‐Sulfinylimines",
           "10.1002/open.201900070",
           2019,
           "Invited for this month's cover picture is the group of Norio Shibata at the Nagoya Institute of Technology (Japan). The cover picture shows an image related to the perpetual motion machine of the second kind in the eighteenth century, and “alchemy”. Our biggest challenge on the path to the results presented in this paper was the creation of alchemy using fluorine chemistry. Read the full text of their Communication at 10.1002/open.201800286.",
           1,
           "chemistryopen"
          ],
          [
           "Continuous Flow Synthesis of Cd<sub>1‐x</sub>Zn<sub>x</sub>S and CdS/ZnS Core/Shell Semiconductor Nanoparticles by MicroJet Reactor Technology",
           "10.1002/open.202200232",
           2022,
           "From aqueous precursor solutions of metal salts and sodium sulfide using MicroJet Reactor (MJR) technology Cd1‐xZnxS and CdS/ZnS core/shell semiconductor nanoparticles were synthesized. The MJR approach represents an automated, continuous, flexible and scalable route for nanoparticle synthesis, providing a tight control over process parameters and thus simple size, shape and composition control. Since particle sizes below the excitonic Bohr radius were obtained by MJR, the nanoparticulate materials exhibit quantum confinement effects. By varying the precursor ratio the band gap of Cd1‐xZnxS Quantum Dots (QDs) could be targeted from 3.1 to 3.6 eV. CdS/ZnS core/shell QDs were prepared by enclosing CdS particles from MJR with ZnS produced by thermal decomposition of a Zn‐MPA complex. Adjustment of the shell thickness increased the photoluminescence intensity by 43 %. Synthesis of ternary sulfides in the form of core/shell particles broadens the spectrum of materials accessible by MJR and demonstrates the extraordinary flexibility of the technology.",
           0,
           "chemistryopen"
          ],
          [
           "Contradicting Influence of Zn Alloying on Electronic and Thermal Properties of a YbCd<sub>2</sub>Sb<sub>2</sub>‐Based Zintl Phase at 700 K",
           "10.1002/open.202200263",
           2023,
           "Zintl compounds are promising thermoelectric materials for power generation as their electronic and thermal transport properties can be simultaneously engineered with anion/cation alloying. Recently, a peak thermoelectric figure‐of‐merit, zT, of 1.4 was achieved in a (Yb0.9Mg0.1)Cd1.2Mg0.4Zn0.4Sb2 Zintl phase at 700 K. Although the effects of alloying Zn in lattice thermal conductivity had been studied thoroughly, how the Zn alloying affects its electronic transport properties has not yet been fully investigated. This study evaluates how the Zn alloying at Cd sites alters the band parameters of (Yb0.9Mg0.1)Cd1.6−xMg0.4ZnxSb2 (x=0‐0.6) using the Single Parabolic Band model at 700 K. The Zn alloying increased the density‐of‐states effective mass (md*) from 0.87 to 0.97 m0. Among Zn‐alloyed samples, the md* of the x=0.4 sample was the lowest (0.93 m0). The Zn alloying decreased the non‐degenerate mobility (μ0) from 71 to 57 cm2 s−1 V−1. Regardless of Zn alloying content, the μ0 of the Zn‐alloyed samples were similar (∼57 cm2 s−1 V−1). Consequently, the x=0.4 with the highest zT exhibited the lowest weighted mobility (μW). The lowest μW represents the lowest theoretical electronic transport properties among other x. The highest zT at x=0.4 despite the lowest μW was explained with a significant lattice thermal conductivity reduction achieved with Zn alloying with x=0.4, which outweighed the deteriorated electronic transport properties also due to the alloying.",
           0,
           "chemistryopen"
          ],
          [
           "Direct Syntheses of Diphenylmethanol Derivatives from Substituted Benzenes and CHCl<sub>3</sub> through Friedel‐Crafts Alkylation and Post‐Synthetic Hydrolysis or Alcoholysis Catalyzed by Alumina",
           "10.1002/open.202200042",
           2022,
           "The present study reports an innovative finding that alumina containing water or primary alcohol catalyzes the hydrolysis or alcoholysis, respectively, of the product formed through AlCl3‐mediated Friedel‐Crafts alkylation of methyl‐substituted benzenes and CHCl3. The former and later reactions mainly provided hydroxy‐ and alkoxy‐substituted diarylmethanes, respectively, while the reference reactions without alumina provided bisarylchloromethane. This method enables the selective syntheses of diphenylmethanol derivatives with very simple procedures, without expensive reagents and apparatuses. Furthermore, the alumina used in the reaction could be recycled by washing with water and subsequent drying. From the viewpoint of material recycling, this function is very important for the development of sustainable chemical reactions.",
           1,
           "chemistryopen"
          ],
          [
           "FeO(OH)@C‐Catalyzed Selective Hydrazine Substitution of <i>p</i>‐Nitro‐Aryl Fluorides and their Application for the Synthesis of Phthalazinones",
           "10.1002/open.202200023",
           2022,
           "An efficient hydrazine substitution of p‐nitro‐aryl fluorides with hydrazine hydrates catalyzed by FeO(OH)@C nanoparticles is described. This hydrazine substitutions of p‐nitro‐aryl fluorides bearing electron‐withdrawing groups proceeded efficiently with high yield and selectivity. Similarly, hydrogenations of p‐nitro‐aryl fluorides containing electron‐donating groups also smoothly proceeded under mild conditions. Furthermore, with these prepared aryl hydrazines, some phthalazinones, interesting as potential structures for pharmaceuticals, have successfully been synthesized in high yields.",
           1,
           "chemistryopen"
          ],
          [
           "Ionic Liquid‐Driven Formation of and Cation Exchange in Layered Sulfido Stannates – a CH<sub>2</sub> Group Makes the Difference",
           "10.1002/open.202000287",
           2020,
           "Two types of layered sulfido stannates or a molecular cluster compound are obtained upon ionothermal treatment of the simple sulfido stannate salt K4[SnS4] \n 4H2O that is based on binary tetrahedral [SnS4]4− anions. The formation of the respective products, novel compounds (C4C1C1Im)2[Sn3S7] (1 a), (C4C1C2Im)2[Sn3S7] (1 b), and (C4C1C2Im)2[Sn4S9] (2) with layered anionic substructures, or the recently reported compound (C4C1C1Im)4+x[Sn10O4S16(SMe)4][An]x (A) comprising a molecular cluster anion, is controlled by both the choice of the ionic liquid cation and the reaction temperature. We report the scale‐up of the syntheses by a factor of 100 with regard to other reported ionothermal syntheses of related compounds, and a procedure of how to isolate them in phase‐pure form – both being rare observations in chalcogenido stannate chemistry in ionic liquids. Moreover, the synthesis of compound 1 a can be achieved by rapid cation exchange starting out from 1 b, which has not been reported for organic cations in any chalcogenido stannate salt to date.",
           1,
           "chemistryopen"
          ],
          [
           "Tips and Tricks for the Surface Engineering of Well‐Ordered Morphologically Driven Silver‐Based Nanomaterials",
           "10.1002/open.201900007",
           2019,
           "Particularly‐shaped silver nanostructures are successfully applied in many scientific fields, such as nanotechnology, catalysis, (nano)engineering, optoelectronics, and sensing. In recent years, the production of shape‐controlled silver‐based nanostructures and the knowledge around this topic has grown significantly. Hence, on the basis of the most recent results reported in the literature, a critical analysis around the driving forces behind the synthesis of such nanostructures are proposed herein, pointing out the important role of surface‐regulating agents in driving crystalline growth by favoring (or opposing) development along specific directions. Additionally, growth mechanisms of the different morphologies considered here are discussed in depth, and critical points highlighted.",
           5,
           "chemistryopen"
          ],
          [
           "An Organic Zeolite With 10 Å Diameter Pores Assembles From a Soluble and Flexible Building Block by Non‐Covalent Interactions",
           "10.1002/open.201900006",
           2019,
           "Two similar molecular building blocks, which both contain a hydrogen‐bonded nitro group, have been prepared and crystallised. One structure has more flexibility with a butyl side chain which allows an open framework organic zeolite to form with large 10 Å diameter pores, whereas the other structure has less flexibility with an aryl side chain and is close packed. The pore size is comparable with those of the aluminophosphate VPI‐5 (12 Å). It is concluded that some flexibility in the design of the building block for porous organic molecular materials was beneficial.",
           2,
           "chemistryopen"
          ],
          [
           "Preparation of Injectable Composite Hydrogels by Blending Poloxamers with Calcium Carbonate‐Crosslinked Sodium Alginate",
           "10.1002/open.202000040",
           2020,
           "The effects of calcium carbonate‐crosslinked sodium alginate on poloxamer hydrogels have been investigated. The mechanical strength, degradability, and thermal stability of hydrogels were characterized. The chemical and physical crosslinking in the composite hydrogels has resulted in an improvement of the compressive strength and elasticity of the hydrogels. These mixed hydrogels showed improved mechanical properties, elasticity, and stability as well as environmental responsiveness and injectability.",
           12,
           "chemistryopen"
          ],
          [
           "Computational Approaches to Discover Novel Natural Compounds for SARS‐CoV‐2 Therapeutics",
           "10.1002/open.202000332",
           2021,
           "Scientists all over the world are facing a challenging task of finding effective therapeutics for the coronavirus disease (COVID‐19). One of the fastest ways of finding putative drug candidates is the use of computational drug discovery approaches. The purpose of the current study is to retrieve natural compounds that have obeyed to drug‐like properties as potential inhibitors. Computational molecular modelling techniques were employed to discover compounds with potential SARS‐CoV‐2 inhibition properties. Accordingly, the InterBioScreen (IBS) database was obtained and was prepared by minimizing the compounds. To the resultant compounds, the absorption, distribution, metabolism, excretion and toxicity (ADMET) and Lipinski's Rule of Five was applied to yield drug‐like compounds. The obtained compounds were subjected to molecular dynamics simulation studies to evaluate their stabilities. In the current article, we have employed the docking based virtual screening method using InterBioScreen (IBS) natural compound database yielding two compounds has potential hits. These compounds have demonstrated higher binding affinity scores than the reference compound together with good pharmacokinetic properties. Additionally, the identified hits have displayed stable interaction results inferred by molecular dynamics simulation results. Taken together, we advocate the use of two natural compounds, STOCK1N‐71493 and STOCK1N‐45683 as SARS‐CoV‐2 treatment regime.",
           8,
           "chemistryopen"
          ],
          [
           "Alcohol Dehydrogenases with <i>anti</i>‐Prelog Stereopreference in Synthesis of Enantiopure Alcohols",
           "10.1002/open.202100251",
           2022,
           "Biocatalytic production of both enantiomers of optically active alcohols with high enantiopurities is of great interest in industry. Alcohol dehydrogenases (ADHs) represent an important class of enzymes that could be used as catalysts to produce optically active alcohols from their corresponding prochiral ketones. This review covers examples of the synthesis of optically active alcohols using ADHs that exhibit anti‐Prelog stereopreference. Both wild‐type and engineered ADHs that exhibit anti‐Prelog stereopreference are highlighted.",
           10,
           "chemistryopen"
          ],
          [
           "An Iridium Complex as Bidentate Halogen Bond‐Based Anion Receptor Featuring an IncreasedOptical Response",
           "10.1002/open.202300183",
           2024,
           "We present a luminescent Ir(III) complex featuring a bidentate halogen bond donor site capable of strong anion binding. The tailor‐made Ir(III)(L)2 moiety offers a significantly higher emission quantum yield (8.4 %) compared to previous Ir(III)‐based chemo‐sensors (2.5 %). The successful binding of chloride, bromide and acetate is demonstrated using emission titrations. These experiments reveal association constants of up to 1.6×105 M−1. Furthermore, a new approach to evaluate the association constant by utilizing the shift of the emission was used for the first time. The experimentally observed characteristics are supported by quantum chemical simulations.",
           0,
           "chemistryopen"
          ],
          [
           "Synthesis and Characterization of Ligand‐Linked Pt Nanoparticles: Tunable, Three‐Dimensional, Porous Networks for Catalytic Hydrogen Sensing",
           "10.1002/open.202000344",
           2021,
           "Porous networks of Pt nanoparticles interlinked by bifunctional organic ligands have shown high potential as catalysts in micro‐machined hydrogen gas sensors. By varying the ligand among p‐phenylenediamine, benzidine, 4,4‘‘‐diamino‐p‐terphenyl, 1,5‐diaminonaphthalene, and trans‐1,4‐diaminocyclohexane, new variants of such networks were synthesized. Inter‐particle distances within the networks, determined via transmission electron microscopy tomography, varied from 0.8 to 1.4 nm in accordance with the nominal length of the respective ligand. While stable structures with intact and coordinatively bonded diamines were formed with all ligands, aromatic diamines showed superior thermal stability. The networks exhibited mesoporous structures depending on ligand and synthesis strategy and performed well as catalysts in hydrogen gas microsensors. They demonstrate the possibility of deliberately tuning micro‐ and mesoporosity and thereby transport properties and steric demands by choice of the right ligand also for other applications in heterogeneous catalysis.",
           5,
           "chemistryopen"
          ],
          [
           "Conductivity and Redox Potentials of Ionic Liquid Trihalogen Monoanions [X<sub>3</sub>]<sup>−</sup>, [XY<sub>2</sub>]<sup>−</sup>, and [BrF<sub>4</sub>]<sup>−</sup> (X=Cl, Br, I and Y=Cl, Br)",
           "10.1002/open.202000263",
           2021,
           "The ionic liquid (IL) trihalogen monoanions [N2221][X3]− and [N2221][XY2]− ([N2221]+=triethylmethylammonium, X=Cl, Br, I, Y=Cl, Br) were investigated electrochemically via temperature dependent conductance and cyclic voltammetry (CV) measurements. The polyhalogen monoanions were measured both as neat salts and as double salts in 1‐butyl‐1‐methyl‐pyrrolidinium trifluoromethane‐sulfonate ([BMP][OTf], [X3]−/[XY2]− 0.5 M). Lighter IL trihalogen monoanions displayed higher conductivities than their heavier homologues, with [Cl3]− being 1.1 and 3.7 times greater than [Br3]− and [I3]−, respectively. The addition of [BMP][OTf] reduced the conductivity significantly. Within the group of polyhalogen monoanions, the oxidation potential develops in the series [Cl3]−>[BrCl2]−>[Br3]−>[IBr2]−>[ICl2]−>[I3]−. The redox potential of the interhalogen monoanions was found to be primarily determined by the central halogen, I in [ICl2]− and [IBr2]−, and Br in [BrCl2]−. Additionally, tetrafluorobromate(III) ([N2221]+[BrF4]−) was analyzed via CV in MeCN at 0 °C, yielding a single reversible redox process ([BrF2]−/[BrF4]−).",
           8,
           "chemistryopen"
          ],
          [
           "Phosphine‐incorporated Metal‐Organic Framework for Palladium Catalyzed Heck Coupling Reaction",
           "10.1002/open.202300249",
           2024,
           "As an emerging material with the potential to combine the high efficiency of homogeneous catalysts and high stability and recyclability of heterogeneous catalysts, metal‐organic frameworks (MOFs) have been viewed as one of the candidates to produce catalysts of the next generation. Herein, we heterogenized the highly active mono(phosphine)‐Pd complex on surface of UiO‐66 MOF, as a catalyst for Suzuki and Heck cross coupling reactions. The successful immobilization of these Pd‐monophosphine complexes on MOF surface to form UiO‐66‐PPh2–Pd was characterized and confirmed via comprehensive set of analytical methods. UiO‐66‐PPh2–Pd showed high activity and selectivity for both Suzuki and Heck Cross Coupling Reactions. This strategy enabled facile access to mono(phosphine) complexes which are challenging to design and require multistep synthesis in homogeneous systems, paving the way for future MOF catalysts applications by similar systems.",
           0,
           "chemistryopen"
          ],
          [
           "Experimental and Theoretical Study of the Ultrafast Dynamics of a Ni<sub>2</sub>Dy<sub>2</sub>‐Compound in DMF After UV/Vis Photoexcitation",
           "10.1002/open.202200086",
           2022,
           "Invited for this month's cover picture are the groups of Wolfgang Hübner (TU Kaiserslautern, Germany), Annie Powell (Karlsruhe Institut of Technology, Germany), and Andreas‐Neil Unterreiner (Karlsruhe Institut of Technology, Germany). The cover picture shows the Dy2Ni2‐molecular magnet being excited with a UV/Vis laser pulse, together with its time‐resolved spectrum after the pulse. The comparison of the theoretical and the experimental spectra together with both the observed and the calculated relaxation times reveal, among others, three key points: the intermediate states participating in the laser‐induced dynamics, the partial metal‐to‐oxygen charge‐transfer excitations, and the order of magnitude of the coupling of the molecular magnet to the thermal bath of the environment. Read the full text of their Full Paper at 10.1002/open.202100153.",
           1,
           "chemistryopen"
          ],
          [
           "Directed Electron Transfer in Flavin Peptides with Oligoproline‐Type Helical Conformation as Models for Flavin‐Functional Proteins",
           "10.1002/open.202000199",
           2020,
           "To mimic the charge separation in functional proteins we studied flavin‐modified peptides as models. They were synthesized as oligoprolines that typically form a polyproline type‐II helix, because this secondary structure supports the electron transfer properties. We placed the flavin as photoexcitable chromophore and electron acceptor at the N‐terminus. Tryptophans were placed as electron donors to direct the electron transfer over 0–3 intervening prolines. Spectroscopic studies revealed competitive photophysical pathways. The reference peptide without tryptophan shows dominant non‐specific ET dynamics, leading to an ion pair formation, whereas peptides with tryptophans have weak non‐specific ET and intensified directed electron transfer. By different excitation wavelengths, we can conclude that the corresponding ion pair state of flavin within the peptide environment has to be energetically located between the S1 and S4 states, whereas the directed electron transfer to tryptophan occurs directly from the S1 state. These photochemical results have fundamental significance for proteins with flavin as redoxactive cofactor.",
           2,
           "chemistryopen"
          ],
          [
           "Intermolecular Charge‐Transfer Luminescence by Self‐Assembly of Pyridinium Luminophores in Solutions",
           "10.1002/open.202100191",
           2021,
           "Designing a luminophore for application both in solution and in the solid state is a highly challenging task given the distinct nature of intermolecular interactions in these phases. In this context, we demonstrate that self‐assembly of non‐emissive charged pyridinium luminophores enables luminescence in solutions through a mechanism that is characteristic for the crystal state. Specifically, protonation of pyridine luminophore subunits in a solution promotes oligomer formation through intermolecular π+‐π interactions, leading to an intermolecular charge‐transfer type luminescence. The luminescence turn‐on by protonation is utilized for a highly efficient solution‐state luminescent sensing of hydrogen chloride and sulfonic acids (TfOH, TsOH and MsOH) with detection limits spanning the range from 0.06 to 0.33 ppm. The protonation followed by self‐assembly results in a bathochromic shift of the emission from 420 nm to 550 nm.",
           1,
           "chemistryopen"
          ],
          [
           "Design and Synthesis of Hsp90 Inhibitors with B‐Raf and PDHK1 Multi‐Target Activity",
           "10.1002/open.202100131",
           2021,
           "The design of multi‐target ligands has become an innovative approach for the identification of effective therapeutic treatments against complex diseases, such as cancer. Recent studies have demonstrated that the combined inhibition of Hsp90 and B‐Raf provides synergistic effects against several types of cancers. Moreover, it has been reported that PDHK1, which presents an ATP‐binding pocket similar to that of Hsp90, plays an important role in tumor initiation, maintenance and progression, participating also to the senescence process induced by B‐Raf oncogenic proteins. Based on these premises, the simultaneous inhibition of these targets may provide several benefits for the treatment of cancer. In this work, we set up a design strategy including the assembly and integration of molecular fragments known to be important for binding to the Hsp90, PDHK1 and B‐Raf targets, aided by molecular docking for the selection of a set of compounds potentially able to exert Hsp90‐B‐Raf‐PDHK1 multi‐target activities. The designed compounds were synthesized and experimentally validated in vitro. According to the in vitro assays, compounds 4 a, 4 d and 4 e potently inhibited Hsp90 and moderately inhibited the PDHK1 kinase. Finally, molecular dynamics simulations were performed to provide further insights into the structural basis of their multi‐target activity.",
           5,
           "chemistryopen"
          ],
          [
           "Diels‐Alder Reactivity of a Chiral Anthracene Template with Symmetrical and Unsymmetrical Dienophiles: A DFT Study",
           "10.1002/open.202000137",
           2020,
           "In this work, we used Density Functional Theory calculations to assess the factors that control the reactivity of a chiral anthracene template with three sets of dienophiles including maleic anhydrides, maleimides and acetoxy lactones in the context of Diels‐Alder cycloadditions. The results obtained here (at the M06‐2X/6‐311++G(d,p) level of theory) suggest that the activation energies for maleic anhydrides and acetoxy lactones are dependent on the nature of the substituent in the dienophile. Among all studied substituents, only −CN reduces the energy barrier of the cycloaddition. For maleimides, the activation energies are independent of the heteroatom of the dienophile and the R group attached to it. The analysis of frontier molecular orbitals, charge transfer and the activation strain model (at the M06‐2X/TZVP level based on M06‐2X/6‐311++G(d,p) geometries) suggest that the activation energies in maleic anhydrides are mainly controlled by the amount of charge transfer from the diene to the dienophile during cycloaddition. For maleimides, there is a dual control of interaction and strain energies on the activation energies, whereas for the acetoxy lactones the activation energies seem to be controlled by the degree of template distortion at the transition state. Finally, calculations show that considering a catalyst on the studied cycloadditions changes the reaction mechanism from concerted to stepwise and proceed with much lower activation energies.",
           4,
           "chemistryopen"
          ],
          [
           "One‐Pot Synthesis of 2,5‐Furandicarboxylic Acid from 2‐Furoic Acid by a Pd‐catalyzed Bromination–Hydroxycarbonylation Tandem Reaction in Acetate Buffer",
           "10.1002/open.202100301",
           2022,
           "The one‐pot synthesis of 2,5‐furandicarboxylic acid from 2‐furoic acid with a yield of 57 % was achieved for the first time using a Pd‐catalyzed bromination‐hydroxycarbonylation tandem reaction in HOAc‐NaOAc buffer. This synthetic protocol shows major improvements compared to previously reported methods, such as using biomass‐based 2‐furoic acid as low‐cost raw material, one‐pot synthesis without isolation of intermediate products, and no need for an acidification procedure. Experiments indicate that the involved Xantphos‐modified Pd‐catalyst and the buffer solution play significant promoting roles for each individual reaction whereas Br2 (as the brominating reagent) had a negative effect on the second hydroxycarbonylation step, while CO was deleterious for the first bromination step. Hence, in this practical one‐pot synthesis, Br2 should be consumed in the first bromination step as fully as possible, and CO is introduced after the first bromination step has been completed.",
           0,
           "chemistryopen"
          ],
          [
           "Exploring Helical Folding in Oligomers of Cyclopentane‐Based ϵ‐Amino Acids: A Computational Study",
           "10.1002/open.202200035",
           2022,
           "Invited for this month's cover picture is the group of Young Kee Kang at Chungbuk National University (Republic of Korea). The cover picture shows the preferred conformation of the hexamer of ϵ‐amino acid Amc5a with a cyclopentane substituent in the backbone investigated using DFT methods in chloroform and water. The Amc5a hexamer adopted a stable left‐handed conformation with a rise of 4.8 Å per turn both in chloroform and water. However, the hexamer of Ampa (an analogue of Amc5a with replacing cyclopentane by pyrrolidine) adopted different conformations in chloroform and in water. Read the full text of their Research Article at 10.1002/open.202100253.",
           0,
           "chemistryopen"
          ],
          [
           "Synthesis of a New Series of Sialylated Homo‐ and Heterovalent Glycoclusters by using Orthogonal Ligations",
           "10.1002/open.201600062",
           2016,
           "The synthesis of heteroglycoclusters (hGCs) is being subjected to rising interest, owing to their potential applications in glycobiology. In this paper, we report an efficient and straightforward convergent protocol based on orthogonal chemoselective ligations to prepare structurally well‐defined cyclopeptide‐based homo‐ and heterovalent glycoconjugates displaying 5‐N‐acetyl‐neuraminic acid (Neu5Ac), galactose (Gal), and/or N‐acetyl glucosamine (GlcNAc). We first used copper‐catalyzed azide–alkyne cycloaddition and/or thiol‐ene coupling to conjugate propargylated α‐sialic acid 3, β‐GlcNAc thiol 5, and β‐Gal thiol 6 onto cyclopeptide scaffolds 7–9 to prepare tetravalent homoglycoclusters (10–12) and hGCs (13–14) with 2:2 combinations of sugars. In addition, we have demonstrated that 1,2‐diethoxycyclobutene‐3,4‐dione can be used as a bivalent linker to prepare various octavalent hGCs (16, 19, and 20) in a controlled manner from these tetravalent structures.",
           12,
           "chemistryopen"
          ],
          [
           "Synthesis of compounds based on the active domain of cabotegravir and their application in inhibiting tumor cells activity",
           "10.1002/open.202300284",
           2024,
           "Structural modification based on existing drugs, which ensures the safety of marketed drugs, is an essential approach in developing new drugs. In this study, we modified the structure of cabotegravir by introducing the front alkyne on the core structure through chemical reaction, resulting in the synthesis of 9 compounds resembling 1,2,3‐triazoles. The potential of these new cabotegravir derivatives as tumor suppressors in gastrointestinal tumors was investigated. Based on the MTT experiment, most compounds showed a reduction in the viability of KYSE30 and HCT116 cells. Notably, derivatives 5b and 5h exhibited the most significant inhibitory effects. To further explore the effects of derivatives 5b and 5h on gastrointestinal tumors, KYSE30 cells were chosen as a representative cell line. Both derivatives can effectively curtail the migration and invasion capabilities of KYSE30 cells and induce apoptosis in a dose‐dependent manner. We further demonstrated these derivatives induce cell apoptosis in KYSE30 cells by inhibiting the expression of Stat3 protein and Smad2/3 protein. Based on the above results, we suggest they show promise in developing drugs for esophageal squamous cell carcinoma.",
           0,
           "chemistryopen"
          ],
          [
           "Synthesis of Novel Aza‐aromatic Curcuminoids with Improved Biological Activities towards Various Cancer Cell Lines",
           "10.1002/open.201800029",
           2018,
           "Curcumin, a natural compound extracted from the rhizomes of Curcuma longa, displays pronounced anticancer properties but lacks good bioavailability and stability. In a previous study, we initiated structure modification of the curcumin scaffold by imination of the labile β‐diketone moiety to produce novel β‐enaminone derivatives. These compounds showed promising properties for elaborate follow‐up studies. In this work, we focused on another class of nitrogen‐containing curcuminoids with a similar objective: to address the bioavailability and stability issues and to improve the biological activity of curcumin. This paper thus reports on the synthesis of new pyridine‐, indole‐, and pyrrole‐based curcumin analogues (aza‐aromatic curcuminoids) and discusses their water solubility, antioxidant activity, and antiproliferative properties. In addition, multivariate statistics, including hierarchical clustering analysis and principal component analysis, were performed on a broad set of nitrogen‐containing curcuminoids. Compared to their respective mother structures, that is, curcumin and bisdemethoxycurcumin, all compounds, and especially the pyridin‐3‐yl β‐enaminone analogues, showed better water solubility profiles. Interestingly, the pyridine‐, indole‐, and pyrrole‐based curcumin derivatives demonstrated improved biological effects in terms of mitochondrial activity impairment and protein content, in addition to comparable or decreased antioxidant properties. Overall, the biologically active N‐alkyl β‐enaminone aza‐aromatic curcuminoids were shown to offer a desirable balance between good solubility and significant bioactivity.",
           20,
           "chemistryopen"
          ],
          [
           "L−Lysine Amino Acid Adsorption on Zeolite L: a Combined Synchrotron, X‐Ray and Neutron Diffraction Study",
           "10.1002/open.202000183",
           2020,
           "Combined neutron and X‐ray powder diffraction techniques highlighted the sorption capacity of the acidic L zeolite towards the L‐lysine amino acid. The role of zeolite channels in the stabilization of the lysine absorbed and the effect of water on protein structure are elucidated at atomistic level. The stabilization of the L α‐helical conformation is related to strong H‐bonds between the tail aminogroups of lysine molecules and the Brønsted acid site as well as to complex intermolecular H‐bond system between water molecules, zeolite and amino acid. This finding is relevant in the catalytic synthesis of polypeptide, as well as in industrial biotechnology by qualitatively predicting binding behaviour",
           4,
           "chemistryopen"
          ],
          [
           "Sol‐Gel‐Syntheses and Structural as well as Electrical Characterizations of Anatase‐ and Rutile‐Type Solid Solutions in the System IrO<sub>2</sub>−TiO<sub>2</sub>",
           "10.1002/open.202300032",
           2023,
           "This paper describes solid solutions in the quasibinary oxide system iridium‐titanium IrO2−TiO2 with rutile and anatase crystal structures. Based on X‐ray diffraction evaluations using Rietveld refinements, changes of lattice parameters were determined within the composition series of 0–100 mol % iridium. These changes prove the existence of a complete solid solution series in the rutile structure type. The solubility limit for iridium in the anatase lattice was found to be 6.0(8) mol % iridium for the underlying sol‐gel process. In addition, iridium is a promoter for the conversion from anatase to rutile type. Furthermore, the X‐ray diffraction results of a calcination temperature series for the composition with 5 mol % iridium are shown, which confirm the findings of the composition series and allow conclusions on the phase segregation behavior. The results are complemented by 2‐point conductivity measurements at different pressures in a piston press to investigate the question of the conductivity mechanism.",
           0,
           "chemistryopen"
          ],
          [
           "Tin Bromido Aluminate Networks with Bright Luminescence",
           "10.1002/open.202200226",
           2023,
           "The novel tin bromido aluminates [Sn3(AlBr4)6](Al2Br6) (1), Sn(AlBr4)2 (2), [EMIm][Sn(AlBr4)3] (3) and [BMPyr][Sn(AlBr4)3] (4) ([EMIm]: 1‐ethyl‐3‐methylimidazolium, [BMPyr]: 1‐butyl‐1‐methyl‐pyrrolidinium), are obtained from a ionic‐liquid‐based reaction of AlBr3 and SnCl2 or SnBr2, resulting in colorless and transparent crystals. 1 contains a neutral, inorganic ∞3[Sn3(AlBr4)6] network filled with intercalated Al2Br6 molecules. 2 represents a 3D structure isotypic to Pb(AlCl4)2 or α‐Sr[GaCl4]2. 3 and 4 exhibit infinite ∞1[Sn(AlBr4)3]n− chains that are separated by the voluminous [EMIm]+/[BMPyr]+ cations. All title compounds contain Sn2+ coordinated by AlBr4 tetrahedra, resulting in chains or 3D networks. Moreover, all title compounds show photoluminescence due to Br−→Al3+ ligand‐to‐metal charge‐transfer excitation, followed by 5s2p0←5s1p1 emission on Sn2+. Most surprisingly, the luminescence is highly efficient (quantum yield >50 %). Specifically, 3 and 4 exhibit outstanding quantum yields of 98 and 99 %, which are the highest values observed for Sn2+‐based luminescence so far. The title compounds have been characterized by single‐crystal structure analysis, elemental analysis, energy‐dispersive X‐ray analysis, thermogravimetry, infrared and Raman spectroscopy, UV‐Vis and photoluminescence spectroscopy.",
           0,
           "chemistryopen"
          ],
          [
           "Methyl Scanning for Mechanochemical Chalcogen‐Bonding Cascade Switches",
           "10.1002/open.201900288",
           2019,
           "Chalcogen‐bonding cascade switching was introduced recently to produce the chemistry tools needed to image physical forces in biological systems. In the original flipper probe, one methyl group appeared to possibly interfere with the cascade switch. In this report, this questionable methyl group is replaced by a hydrogen. The deletion of this methyl group in planarizable push‐pull probes was not trivial because it required the synthesis of dithienothiophenes with four different substituents on the four available carbons. The mechanosensitivity of the resulting demethylated flipper probe was nearly identical to that of the original. Thus methyl groups in the switching region are irrelevant for function, whereas those in the twisting region are essential. This result supports the chalcogen‐bonding cascade switching concept and, most importantly, removes significant synthetic demands from future probe development.",
           4,
           "chemistryopen"
          ],
          [
           "Design and Synthesis of Imidazole and Triazole Pyrazoles as <i>Mycobacterium Tuberculosis</i> CYP121A1 Inhibitors",
           "10.1002/open.201900227",
           2019,
           "The emergence of untreatable drug‐resistant strains of Mycobacterium tuberculosis is a major public health problem worldwide, and the identification of new efficient treatments is urgently needed. Mycobacterium tuberculosis cytochrome P450 CYP121A1 is a promising drug target for the treatment of tuberculosis owing to its essential role in mycobacterial growth. Using a rational approach, which includes molecular modelling studies, three series of azole pyrazole derivatives were designed through two synthetic pathways. The synthesized compounds were biologically evaluated for their inhibitory activity towards M. tuberculosis and their protein binding affinity (KD). Series 3 biarylpyrazole imidazole derivatives were the most effective with the isobutyl (10 f) and tert‐butyl (10 g) compounds displaying optimal activity (MIC 1.562 μg/mL, KD 0.22 μM (10 f) and 4.81 μM (10 g)). The spectroscopic data showed that all the synthesised compounds produced a type II red shift of the heme Soret band indicating either direct binding to heme iron or (where less extensive Soret shifts are observed) putative indirect binding via an interstitial water molecule. Evaluation of biological and physicochemical properties identified the following as requirements for activity: LogP >4, H‐bond acceptors/H‐bond donors 4/0, number of rotatable bonds 5–6, molecular volume >340 Å3, topological polar surface area <40 Å2.",
           19,
           "chemistryopen"
          ],
          [
           "Structural Preferences in Phosphanylthiolato Platinum(II) Complexes",
           "10.1002/open.201500136",
           2015,
           "The transition‐metal complexes of heterotopic phosphanylthiolato ligands are useful in various reactions which depend on the stereochemistry of the complexes. Bis‐chelate complex [Pt(SCH2CH2PPh2‐κ2P,S)2] (1) was obtained in good yields by direct base‐free substitution reaction of the corresponding phosphanylthiol (HSCH2CH2PPh2) with K2PtCl4 or by oxidative addition of the same phosphanylthiol to Pt(PPh3)4. In agreement with the antisymbiosis rule, complex 1 shows a cis‐P,P arrangement in solid state crystallizing in the monoclinic system (C2/c). Density functional theory (DFT) calculations on 1 reveal the right characteristics for the preferred cis‐P,P arrangement, rationalizing its formation. Direct base‐free reaction of [PtCl2(1,5‐cyclooctadiene)] with one equivalent of the same phosphanylthiol produce the trinuclear complex [PtCl(μ‐SCH2CH2PPh2‐κ2P,S)]3 (2) instead of the binuclear structure common in palladium and nickel derivatives. Crystals of 2 are triclinic (P\n) showing a sulfur‐bridging edge‐sharing cyclic trinuclear complex with square‐planar coordination geometry around the platinum atoms and a Pt3S3 cycle in skew‐boat conformation. This preference for the trinuclear structure was rationalized mechanistically and through conceptual DFT.",
           5,
           "chemistryopen"
          ],
          [
           "Direct Assembly of Prenylated Heteroarenes through a Cascade Minisci Reaction/Dehydration Sequence",
           "10.1002/open.201600096",
           2016,
           "The prenyl group is an important component in bioactive compounds. Herein, we report the assembly of prenylated heteroarenes through a cascade Minisci reaction and acid‐promoted dehydration sequence. The use of potassium (3‐hydroxy‐3‐methylbut‐1‐yl)trifluoroborate as a new coupling reagent allows the direct introduction of prenyl and 3‐hydroxy‐3‐methylbutyl groups to a wide variety of electron‐deficient heteroarenes. Synthetic application is also demonstrated.",
           8,
           "chemistryopen"
          ],
          [
           "Effect of the <i>Ortho</i> Alkylation of Perylene Bisimides on the Alignment and Self‐Assembly Properties",
           "10.1002/open.201402011",
           2014,
           "The effect of the ortho alkylation of perylene bisimides on the alignment and self‐assembly properties has been studied. It was found that the dichroic properties of perylene bisimides in a liquid crystal host can be reversed with a single synthetic step by ortho alkylation. Furthermore, a solvent‐induced growth of ultralong organic n‐type semiconducting fibrils from non‐ortho‐alkylated perylene bisimide was observed. Ortho substitution of the perylene bisimide core alters the mode of fibrillar growth, leading to isotropic crystallization.",
           13,
           "chemistryopen"
          ],
          [
           "Bis‐[3]Ferrocenophanes with Central &gt;E−E’&lt; Bonds (E, E’=P, SiH): Preparation, Properties, and Thermal Activation",
           "10.1002/open.201900279",
           2019,
           "Invited for this month's cover picture are the groups of Professors Rudolf Pietschnig at the University of Kassel, Professor Dietrich Gudat at the University of Stuttgart and Professor László Nyulászi at the Budapest University of Technology and Economics. The cover picture shows the thermally induced homolytic cleavage of the central P‐P bond in a phosphorus–rich bis‐ferrocenophane furnishing P‐centered radicals (as evidenced by the computed spin‐density highlighted in blue). The central P6 unit in the title compound is a structural analog of the connecting unit in Hittorf's violet phosphorus, which links the orthogonally arranged tubular entities. A portrait of the German physicist Johann Wilhelm Hittorf is included. Read the full text of their Full Paper at 10.1002/open.201900182.",
           0,
           "chemistryopen"
          ],
          [
           "Potassium‐Ion‐Selective Fluorescent Sensors To Detect Cereulide, the Emetic Toxin of <i>B. cereus</i>, in Food Samples and HeLa Cells",
           "10.1002/open.201700057",
           2017,
           "We report the development of new chemical probes for cereulide, a toxic metabolite produced by specific strains of Bacillus cereus, through displacement of potassium cations from a preformed specific complex and a subsequent change in the fluorescence emission. For this purpose, we designed fluorescent probes for potassium cations that were suitable for displacement assays with cereulide from organic extracts. The fluorescence detection of natural cereulide in rice samples was achieved by using synthetic cereulide as a reference and a potassium fluorescent reporter, and this was found to be useful as a portable and fast method for the in situ detection of cereulide in food extracts. To study the fate of cereulide in live cells, we designed a procedure that was suitable for live‐cell microscopy imaging of HeLa cells by comparing the cellular location of the potassium fluorogenic probe, which stained intracellular endolysosomes, in the absence and presence of cereulide; we concluded that in the presence of cereulide, the fluorescence of the probe was decreased because of complexation of the potassium ions by cereulide.",
           11,
           "chemistryopen"
          ],
          [
           "Identification of the Structure of Triethanolamine Oxygenation Products in Carbon Nitride Photocatalysis",
           "10.1002/open.202200095",
           2022,
           "Triethanolamine (TEOA) is one of the most commonly used sacrificial agents in photocatalysis. Due to its more complex structure compared to, for example, ethanol, and its sacrificial role in photocatalysis, it gives a mixture of products. The structures of these molecules are not usually analyzed. Herein, we obtain and isolate the products of TEOA and N‐tert‐butyl diethanolamine oxygenation under photocatalytic conditions with ≈15 % yield, and followingly characterized them by NMR and mass spectroscopy. The reaction is mediated by potassium poly(heptazine imide) (K‐PHI) in the presence of O2 and affords formyl esters of β‐hydroxyethylene formamides from the corresponding ethanolamines.",
           5,
           "chemistryopen"
          ],
          [
           "Rapid and Efficient Microwave‐Assisted Friedländer Quinoline Synthesis",
           "10.1002/open.202000247",
           2020,
           "A microwave‐based methodology facilitates reaction of 2‐aminophenylketones with cyclic ketones to form a quinoline scaffold. Syntheses of amido‐ and amino‐linked 17β‐hydroxysteroid dehydrogenase type 3 inhibitors with a benzophenone‐linked motif were pursued using 2‐aminobenzophenone as building block. Two amido‐linked targets were achieved in modest yield, but when using microwave‐assisted reductive amination for the amino‐linked counterparts an unexpected product was observed. X‐ray crystallography revealed it as a quinoline derivative, leading to optimisation of a simple and efficient modification of Friedländer methodology. Using reagents and acetic acid catalyst in organic solvent the unassisted reaction proceeds only over several days and in very poor yield. However, by employing neat acetic acid as both solvent and acid catalyst with microwave irradiation at 160 °C quinoline synthesis is achieved in 5 minutes in excellent yield. This has advantages over the previously reported high temperatures or strong acids required, not least given the green credentials of acetic acid, and examples using diverse ketones illustrate applicability. Additionally, the unassisted reaction proceeds effectively at room temperature, albeit much more slowly.",
           7,
           "chemistryopen"
          ],
          [
           "Computational Study of Mechanism and Enantioselectivity of Imine Reductase from <i>Amycolatopsis orientalis</i>",
           "10.1002/open.202100250",
           2021,
           "Imine reductases (IREDs) are NADPH‐dependent enzymes (NADPH=nicotinamide adenine dinucleotide phosphate) that catalyze the reduction of imines to amines. They exhibit high enantioselectivity for a broad range of substrates, making them of interest for biocatalytic applications. In this work, we have employed density functional theory (DFT) calculations to elucidate the reaction mechanism and the origins of enantioselectivity of IRED from Amycolatopsis orientalis. Two substrates are considered, namely 1‐methyl‐3,4‐dihydroisoquinoline and 2‐propyl‐piperideine. A model of the active site is built on the basis of the available crystal structure. For both substrates, different binding modes are first evaluated, followed by calculation of the hydride transfer transition states from each complex. We have also investigated the effect of mutations of certain important active site residues (Tyr179Ala and Asn241Ala) on the enantioselectivity. The calculated energies are consistent with the experimental observations and the analysis of transition states geometries provides insights into the origins of enantioselectivity of this enzyme.",
           5,
           "chemistryopen"
          ],
          [
           "Insights into Allosteric Control of Human Blood Group A and B Glycosyltransferases from Dynamic NMR",
           "10.1002/open.201900116",
           2019,
           "Human blood group A and B glycosyltransferases (GTA, GTB) are retaining glycosyltransferases, requiring a catalytic mechanism that conserves the anomeric configuration of the hexopyranose moiety of the donor substrate (UDP‐GalNAc, UDP‐Gal). Previous studies have shown that GTA and GTB cycle through structurally distinct states during catalysis. Here, we link binding and release of substrates, substrate‐analogs, and products to transitions between open, semi‐closed, and closed states of the enzymes. Methyl TROSY based titration experiments in combination with zz‐exchange experiments uncover dramatic changes of binding kinetics associated with allosteric interactions between donor‐type and acceptor‐type ligands. Taken together, this highlights how allosteric control of on‐ and off‐rates correlates with conformational changes, driving catalysis to completion.",
           2,
           "chemistryopen"
          ],
          [
           "Reactivity of Coinage Metal Hydrides for the Production of H<sub>2</sub> Molecules",
           "10.1002/open.202100108",
           2021,
           "The formation of molecular hydrogen as well as the possibility of using coinage metal hydrides as a prospective complex to produce hydrogen was presented in this work. Therefore, the reactions involving the interaction between two coinage metal hydrides, MH (M=Cu, Ag and Au, homo and heterodimers), were studied. The free energy profiles corresponding to aforementioned complexation were analysed by means of ab initio methods of quantum chemistry. The characteristics of these intermediates, final complexes and the electron density properties of the established interactions were discussed.",
           1,
           "chemistryopen"
          ],
          [
           "Flavonoids in Lemon and Grapefruit IntegroPectin**",
           "10.1002/open.202100223",
           2021,
           "Following the analysis of terpenes present in new lemon and grapefruit “IntegroPectin” pectins obtained via the hydrodynamic cavitation of industrial lemon and grapefruit processing waste, the HPLC‐MS analysis of flavonoid and other phenolic compounds reveals the presence of eriocitrin, naringin, hesperidin and kaempferol typical of the respective citrus fruits. The pectic fibers rich in rhamnogalacturonan‐I regions act as chemical sponges adsorbing and concentrating at their outer surface highly bioactive citrus flavonoids and terpenes. These findings, together with the unique molecular structure of these new whole citrus pectins, provide preliminary insight into the broad‐scope biological activity of these new biomaterials. Numerous new biomedical applications are anticipated, including likely use in the prevention and treatment of microbial infections and neurodegenerative disease.",
           14,
           "chemistryopen"
          ],
          [
           "Wearable Chemosensors: A Review of Recent Progress",
           "10.1002/open.201700159",
           2017,
           "In recent years, there has been growing demand for wearable chemosensors for their important potential applications in mobile and electronic healthcare, patient self‐assessment, human motion monitoring, and so on. Innovations in wearable chemosensors are revolutionizing the modern lifestyle, especially the involvement of both doctors and patients in the modern healthcare system. The facile interaction of wearable chemosensors with the human body makes them favorable and convenient tools for the detection and long‐term monitoring of the chemical, biological, and physical status of the human body at a low cost with high performance. In this Minireview, we give a brief overview of the recent advances and developments in the field of wearable chemosensors, summarize the basic types of wearable chemosensors, and discuss their main functions and fabrication methods. At the end of this paper, the future development direction of wearable chemosensors is prospected. With continued interest and attention to this field, new exciting progress is expected in the development of innovative wearable chemosensors.",
           39,
           "chemistryopen"
          ],
          [
           "Reactions of 1,2,4‐Oxadiazole[4,5‐<i>a</i>]piridinium Salts with Alcohols: the Synthesis of Alkoxybutadienyl 1,2,4‐Oxadiazoles",
           "10.1002/open.201900376",
           2020,
           "1,2,4‐Oxadiazole[4,5‐a]piridinium salts add alcohols and alkoxides to undergo electrocyclic ring opening affording alkoxybutadienyl 1,2,4‐oxadiazole derivatives. The pyridinium salts represent a special class of Zincke salts that are prone to rearrange to give alkoxybutadienyl 1,2,4‐oxadiazoles when treated with suitable nucleophiles or, alternatively, to give pyridones in the presence of bicarbonate. The pivotal tuning of the experimental conditions leads to a straightforward synthesis of valuable 1,2,4‐oxadiazole derivatives. The mechanism is also discussed in the light of previous observations.",
           0,
           "chemistryopen"
          ],
          [
           "Rhodol Derivatives as Selective Fluorescent Probes for the Detection of Hg<sup>II</sup> Ions and the Bioimaging of Hypochlorous Acid",
           "10.1002/open.201700154",
           2017,
           "Two sensors, 1 with a spirolactone group and 2 with a spirolactam group containing a phenyl isothiocyanate moiety, based on rhodol, were designed and synthesized in order to obtain materials with excellent optical properties for the detection of environmentally and biologically important Hg2+ and hypochlorous acid (HClO) ions. The crystal structure of 1 revealed two moieties, a rhodamine‐like portion with a spirolactone and a fluorescein‐like portion without a spirolactone. In the absence of analyte, 1 produced an optical output with a maximum absorption and emission at 475 and 570 nm, respectively, which was attributed to the fluorescein‐like moiety without a spirolactone. In contrast, the rhodamine‐like moiety containing a spirolactone was activated by the addition of H+ or Hg2+ ions, and 1 yielded new absorption and emission peaks at 530 and 612 nm, respectively. Further functionalization with a phenyl isothiocyanate group afforded 2, a fluorescent probe for HClO. High selectivity and sensitivity towards the hypochlorite ion were anticipated, owing to the stoichiometric and irreversible formation of a thiosemicarbazide group, which led to dramatic fluorescence responses. With good functionality at physiological pH, probe 2 was successfully used to image HClO in HeLa cells.",
           13,
           "chemistryopen"
          ],
          [
           "Electrochemical Determination of Chloroquine Phosphate in Real Samples Using a Diresorcinate‐1,10‐phenanthrolinecobalt(II)‐Modified Glassy Carbon Electrode",
           "10.1002/open.202300004",
           2023,
           "Chloroquine phosphate (CQP) is used for malaria treatment. As it is facing increasing resistance, it needs continuous monitoring using sensitive and specific detection methods. In this work, a voltammetric sensor was prepared by electropolymerization of a diresorcinate‐1,10‐phenanthrolinecobalt(II) complex on a glassy carbon electrode (poly(DHRPCo)/GCE) which was followingly characterized. Compared with a bare GCE, CQP showed single well shaped irreversible oxidative peak at the poly(DHRPCo)/GCE. The peak current showed excellent linearity with CQP concentration in the range of 0.005–300.0 μm with a detection limit of 0.39 nm. The response of CQP at poly(DHRPCo)/GCE was not influenced by the presence of amoxicillin, ciprofloxacillin and paracetamol in addition to its high stability and reproducibility. It was applied for detection of CQP in various real samples, including three brands of tablets, human blood serum, and urine samples. The detected amount in tablets were in the range 98.4–103.2 % of their labeled value. Spike recovery results in human blood serum, urine, and tablet samples were 99.35–100.28 %, 99.03–100.32 %, and 98.40–100.41 %, respectively. Interference recovery results with less than 4.60 % error, the lower limit of detection and the wider dynamic range than most of the previously reported methods validate the potential applicability of the proposed method for CQP determination in various real samples with complex matrices.",
           2,
           "chemistryopen"
          ],
          [
           "An Electrochemical Way to Generate Amphiphiles from Hydrazones for the Synthesis of 1,2,4‐Triazole Scaffold Cyclic Compounds",
           "10.1002/open.202100268",
           2022,
           "An electro‐oxidative cyclization pathway in which hydrazones are selected as starting materials to generate amphiphiles by reacting with benzylamines and benzamides was reported. This strategy successfully prepared a series of 1,2,4‐triazoles in satisfactory yields. Moreover, the use of cheap stainless steel as the anode, the feasibility to conduct the transformation as a one‐pot reaction and the proof that scaling‐up these reactions is possible make this transformation attractive for potential application in industry.",
           3,
           "chemistryopen"
          ],
          [
           "Trend‐Analysis of Solid‐State Structures: Low‐Energy Conformational ‘Reactions’ Involving Directed and Coupled Movements in Half‐Sandwich Compounds [CpFe(CO){C(=O)R}PPh<sub>3</sub>]",
           "10.1002/open.201800042",
           2018,
           "Invited for this month's cover picture are Prof. Dr. Henri Brunner from the University of Regensburg (Germany) and Prof. Dr. Takashi Tsuno from Nihon University (Japan). The cover picture shows the conformational reaction of JIDLUD→FIHTUL. The order of sample points of solid‐state structures reveals information concerning low‐energy, directed, and coupled movements in molecules. Read the full text of their Communication at 10.1002/open.201800007.",
           0,
           "chemistryopen"
          ],
          [
           "Coupled Optical and Electrochemical Probing of Silver Nanoparticle Destruction in a Reaction Layer",
           "10.1002/open.201800048",
           2018,
           "The oxidation of silver nanoparticles is induced to occur near to, but not at, an electrode surface. This reaction at a distance from the electrode is studied through the use of dark‐field microscopy, allowing individual nanoparticles and their reaction with the electrode product to be visualized. The oxidation product diffuses away from the electrode and oxidizes the nanoparticles in a reaction layer, resulting in their destruction. The kinetics of the silver nanoparticle solution‐phase reaction is shown to control the length scale over which the nanoparticles react. In general, the new methodology offers a route by which nanoparticle reactivity can be studied close to an electrode surface.",
           12,
           "chemistryopen"
          ],
          [
           "Cascade Reaction by Chemo‐ and Biocatalytic Approaches to Obtain Chiral Hydroxy Ketones and <i>anti</i> 1,3‐Diols",
           "10.1002/open.201800056",
           2018,
           "A chemo‐ and biocatalytic cascade approach was applied for the stereoselective synthesis of hydroxy ketones and the corresponding 1,3‐diols. A new class of tridentate N,N,O ligands was used with copper(II) complexes for the asymmetric β‐borylation of α,β‐unsaturated compounds. The complex containing ligand L5 emerged as the best performer, and it gave the organoborane derivatives with good ee values. The corresponding keto–alcohol compounds were then bioreduced by yeasts. The biotransformation set up with Rhodotorula rubra allowed (R)‐keto–alcohols and (S,S)‐diols to be obtained with up to 99 % ee and up to 99 % de in favor of the anti enantiomers.",
           9,
           "chemistryopen"
          ],
          [
           "Modified Calix[4]crowns as Molecular Receptors for Barium",
           "10.1002/open.201800065",
           2018,
           "Invited for this month's cover picture is the group around Dr. Constantin Mamat at the Institute of Radiopharmaceutical Cancer Research at the Helmholtz‐Zentrum Dresden‐Rossendorf (Germany) together with Prof. Martin Köckerling from the University of Rostock (Germany). The cover picture shows the ability of special functionalized calix[4]crown‐6 derivatives to stably bind group 2 metals like barium. This binding mode is highly important for radiopharmaceutical applications not to lose the respective radiometal in vivo to avoid high background signals and/or false positive results and damages in other tissues. For this purpose, different calix[4]crowns were tested, based upon their potential to stably bind barium as surrogate for radium. Radium nuclides are known to be good candidates for usage in α‐targeted therapies. Currently, radium‐223 is used for α‐therapy of bone metastases because of its calcium mimetics. Our aim is to apply the radium to treat other cancer tissues. That's why we need novel chelators to stably fix groups 2 metals like barium and radium. Read the full text of their Full Paper at 10.1002/open.201800019.",
           0,
           "chemistryopen"
          ],
          [
           "Organometallic Nucleosides: Synthesis and Biological Evaluation of Substituted Dicobalt Hexacarbonyl 2′‐Deoxy‐5‐oxopropynyluridines",
           "10.1002/open.201700168",
           2018,
           "Reactions of dicobalt octacarbonyl [Co2(CO)8] with 2′‐deoxy‐5‐oxopropynyluridines and related compounds gave dicobalt hexacarbonyl nucleoside complexes (83–31 %). The synthetic outcomes were confirmed by X‐ray structure determination of dicobalt hexacarbonyl 2′‐deoxy‐5‐(4‐hydroxybut‐1‐yn‐1‐yl)uridine, which exhibits intermolecular hydrogen bonding between a modified base and ribose. The electronic structure of this compound was characterized by the DFT calculations. The growth inhibition of HeLa and K562 cancer cell lines by organometallic nucleosides was examined and compared to that by alkynyl nucleoside precursors. Coordination of the dicobalt carbonyl moiety to the 2′‐deoxy‐5‐alkynyluridines led to a significant increase in the cytotoxic potency. The cobalt compounds displayed antiproliferative activities with median inhibitory values (IC50) in the range of 20 to 80 μm for the HeLa cell line and 18 to 30 μm for the K562 cell line. Coordination of an acetyl‐substituted cobalt nucleoside was expanded by using the 1,1‐bis(diphenylphosphino)methane (dppm) ligand, which exhibited cytotoxicity at comparable levels. The formation of reactive oxygen species in the presence of cobalt compounds was determined in K562 cells. The results indicate that the mechanism of action for most antiproliferative cobalt compounds may be related to the induction of oxidative stress.",
           8,
           "chemistryopen"
          ],
          [
           "Manufacturing Nanoparticles with Orthogonally Adjustable Dispersibility in Hydrocarbons, Fluorocarbons, and Water",
           "10.1002/open.201800031",
           2018,
           "Invited for this month's cover picture is the group of Prof. Dr. Andreas Hirsch from Friedrich Alexander University (Germany). The cover picture shows shell‐by‐shell coated nanoparticle ‘chameleons’—wet‐chemically surface‐modified nanoparticles that can reversibly adjust their dispersibility to entirely orthogonal solvent environments. Read the full text of their Full Paper at 10.1002/open.201800011.",
           0,
           "chemistryopen"
          ],
          [
           "Stable Oligomer Formation from Lignin by Pyrolysis of Softwood in an Aprotic Solvent with a Hydrogen Donor",
           "10.1002/open.202200104",
           2022,
           "Pyrolysis of Japanese cedar wood in diphenoxybenzene (an aprotic solvent) with a hydrogen donor was investigated between 270–380 °C. Under these conditions, re‐condensation via radical and quinone methide intermediates was efficiently suppressed and a thermally stable oligomer was obtained. The oligomer was stable even after the treatment time was extended. Yields of lignin‐derived products at 270 °C were limited to approximately 20 wt %, but increased to >80 wt % (lignin basis) at the higher temperatures. The oligomer yield increased directly with the extent of the cellulose degradation at 350 °C. Based on the NMR analysis results, the ether bonds in lignin were largely cleaved, but condensed linkages such as β‐aryl and β‐β and 5‐5’ types remained. The γ‐hydroxypropyl group was identified as a typical side chain, formed by hydrogenation of the double bond of a coniferyl alcohol‐type structure.",
           2,
           "chemistryopen"
          ],
          [
           "Covalent Immobilization of Dehydrogenases on Carbon Felt for Reusable Anodes with Effective Electrochemical Cofactor Regeneration",
           "10.1002/open.202200102",
           2022,
           "This study presents the immobilization with aldehyde groups (glyoxyl carbon felt) of alcohol dehydrogenase (ADH) and formate dehydrogenase (FDH) on carbon‐felt‐based electrodes. The compatibility of the immobilization method with the electrochemical application was studied with the ADH bioelectrode. The electrochemical regeneration process of nicotinamide adenine dinucleotide in its oxidized form (NAD+), on a carbon felt surface, has been deeply studied with tests performed at different electrical potentials. By applying a potential of 0.4 V versus Ag/AgCl electrode, a good compromise between NAD+ regeneration and energy consumption was observed. The effectiveness of the regeneration of NAD+ was confirmed by electrochemical oxidation of ethanol catalyzed by ADH in the presence of NADH, which is the no active form of the cofactor for this reaction. Good reusability was observed by using ADH immobilized on glyoxyl functionalized carbon felt with a residual activity higher than 60 % after 3 batches.",
           3,
           "chemistryopen"
          ],
          [
           "Construction of Recycling Photocatalytic Gels for the Disinfection of Pathogens and Degradation of Organic Pollutants",
           "10.1002/open.201900285",
           2019,
           "Bismuth oxybromide (BiOBr) nanosheets are exciting photocatalysts for microbial disinfection and organic dye degradation. However, it remains a great challenge to easily recycle these nanomaterials and improve their photocatalytic ability. Herein, we constructed a novel photocatalytic BiOBr@PAG gel containing BiOBr nanosheets and polyacrylamide gel (PAG), based on peroxydisulfate‐induced polymerization reaction. The photocatalytic gel had equally distribution of BiOBr nanosheets on the surface, and could be easily recycled from water. More strikingly, the gel could also rapidly kill all tested pathogenic bacteria (i. e., Escherichia coli, Pseudomonas aeruginosa, and Staphylococcus aureus) under irradiation. Its disinfection activity is attributed to remarkable intracellular ROS production and oxidative cell damage. Furthermore, the gel had higher photocatalytic activity than BiOBr nanosheets alone during degradation of organic dyes. This study developed a novel strategy for preparation of easy‐recycling and high‐efficiency photocatalytic systems for practical application in environmental treatment and medicinal disinfection.",
           3,
           "chemistryopen"
          ],
          [
           "Urinary Measurement of Epigenetic DNA Modifications: A Non‐Invasive Assessment of the Whole‐Body Epigenetic Status in Healthy Subjects and Colorectal Cancer Patients",
           "10.1002/open.201600103",
           2016,
           "Active mechanism of DNA demethylation can be responsible for the activation of previously silenced genes. Products of 5‐methylcytosine oxidation are released into the bloodstream and eventually excreted with urine. Therefore, whole‐body epigenetic status can be assessed non‐invasively on the basis of the urinary excretion of a broad spectrum of epigenetic modifications: 5‐hydroxymethylcytosine (5‐hmCyt), 5‐formylcytosine (5‐fCyt), 5‐carboxycytosine (5‐caCyt), and 5‐hydroxymethyluracil (5‐hmUra). We have developed a specific and sensitive, isotope‐dilution, automated, online, two‐dimensional ultra‐performance liquid chromatography system with tandem mass spectrometry (2D UPLC–MS/MS) to measure 5‐hmCyt, 5‐fCyt, 5‐caCyt, and their deoxynucleosides in the same urine sample. Human urine contains all of the modifications except from 5‐formyl‐2′‐deoxycytidine (5‐fdC) and 5‐carboxy‐2′‐deoxycytidine (5‐cadC). A highly significant difference in the urinary excretion of 5‐(hydroxymethyl)‐2’‐deoxycytidine (5‐hmdC) was found between healthy subjects and colorectal cancer patients (3.5 vs. 7.8 nmol mmol−1 creatinine, respectively), as well as strong correlations between the majority of analyzed compounds.",
           11,
           "chemistryopen"
          ],
          [
           "A Chromogenic Probe for the Selective Recognition of Sarin and Soman Mimic DFP",
           "10.1002/open.201402014",
           2014,
           "The synthesis, characterization and sensing features of a novel probe 1 for the selective chromogenic recognition of diisopropylfluorophosphate (DFP), a sarin and soman mimic, in 99:1 (v/v) water/acetonitrile and in the gas phase is reported. Colour modulation is based on the combined reaction of phosphorylation of 1 and fluoride‐induced hydrolysis of a silyl ether moiety. As fluoride is a specific reaction product of the reaction between DFP and the −OH group, the probe shows a selective colour modulation in the presence of this chemical. Other nerve agent simulants, certain anions, oxidant species and other organophosphorous compounds were unable to induce colour changes in 1. This is one of the very few examples of a selective detection, in solution and in the gas phase, of a sarin and soman simulant versus other reactive derivatives such as the tabun mimic diethylcyanophosphate (DCNP).",
           27,
           "chemistryopen"
          ],
          [
           "Asymmetric Synthesis of 4,4‐(Difluoro)glutamic Acid via Chiral Ni(II)‐Complexes of Dehydroalanine Schiff Bases. Effect of the Chiral Ligands Structure on the Stereochemical Outcome",
           "10.1002/open.201900343",
           2020,
           "Four differently substituted chiral Ni(II)‐complexes of dehydroalanine Schiff base were prepared and reacted with BrCF2COOEt/Cu under the standard reaction conditions. The observed diastereoselectivity was found to depend on the degree and pattern of chlorine substitution for hydrogen in the structure of the dehydroalanine complexes. The unsubstituted complex gave the ratio of diastereomers (S)(2S)/(S)(2R) of 66/34. On the other hand, introduction of chlorine atoms in the strategic positions on the chiral ligands allowed to achieve a practically attractive diastereoselectivity of (∼98.5/1.5). Diastereomerically pure major product was disassembled to prepare 9‐fluorenylmethyloxycarbonyl (Fmoc) derivative of (S)‐4,4‐difluoroglutamic acid.",
           15,
           "chemistryopen"
          ],
          [
           "Enzymatic Strategy for the Resolution of New 1‐Hydroxymethyl Tetrahydro‐<i>β</i>‐carboline Derivatives in Batch and Continuous‐Flow Systems",
           "10.1002/open.201500203",
           2016,
           "Many alkaloids containing a tetrahydro‐β‐carboline skeleton have well‐known therapeutic effects, leading to increased interest in the synthesis of these natural products. Enantiomers of N‐Boc‐protected 1‐hydroxymethyl‐1,2,3,4‐tetrahydro‐β‐carboline [(±)‐7], 1‐hydroxymethyl‐6‐methoxy‐1,2,3,4‐tetrahydro‐β‐carboline [(±)‐8], and 1‐hydroxymethyl‐6‐fluoro‐1,2,3,4‐tetrahydro‐β‐carboline [(±)‐9] were prepared through enzymecatalyzed asymmetric acylation of their primary hydroxyl group. The preliminary experiments were performed in a continuous‐flow system, while the preparative‐scale resolutions were done as batch reactions. Excellent enantioselectivities (E>200) were obtained with Candida antarctica lipase B (CAL‐B) and acetic anhydride in toluene at 60 °C. The recovered alcohols and the produced esters were obtained with high enantiomeric excess values (ee≥96 %). The O‐acylated enantiomers [(S)‐10–(S)‐12)] were transformed into the corresponding amino alcohols [(S)‐7–(S)‐9)] with methanolysis. Microwave‐assisted Boc removals were also performed and resulted in the corresponding compounds (R)‐4–(R)‐6 and (S)‐4–(S)‐6 without a drop in the enantiomeric excess values (ee≥96 %).",
           4,
           "chemistryopen"
          ],
          [
           "Mechanistic Investigation into Olefin Epoxidation with H<sub>2</sub>O<sub>2</sub> Catalyzed by Aqua‐Coordinated Sandwich‐Type Polyoxometalates: Role of the Noble Metal and Active Oxygen Position",
           "10.1002/open.201600064",
           2016,
           "Aqua‐coordinated sandwich‐type polyoxometalates (POMs), {[WZnTM2(H2O)2](ZnW9O34)2}n− (TM=RhIII, PdII, and PtII), catalyze olefin epoxidation with hydrogen peroxide and have been well established, and they present an advance toward the utilization of olefins. To elucidate the epoxidation mechanism, we systematically performed density functional calculations. The reaction proceeds through a two‐step mechanism: activation of H2O2 and oxygen transfer. The aqua‐coordinated complexes show two distinct H2O2 activation pathways: “two‐step” and “concerted”. The concerted processes are more facile and proceed with similar and rate‐determining energy barriers at the Rh‐, Pd‐, and Pt‐containing transition states, which agrees well with the experimental results. Next, the resulting TM−OH−(μ‐OOH) intermediate transfers an O atom to olefin to form an epoxide. The higher reactivity of the Rh‐containing POM is attributed to more interactions between the Rh and hydroperoxo unit. We also calculated all active oxygen positions to locate the most favorable pathway. The higher reactivity of the two‐metal‐bonded oxygen position is predominantly ascribed to its lower stereoscopic hindrance. Furthermore, the presence of one and two explicit water solvent molecules significantly reduces the energy barriers, making these sandwich POMs very efficient for the olefin epoxidation with H2O2.",
           5,
           "chemistryopen"
          ],
          [
           "<sup>13</sup>C/<sup>15</sup>N‐Enriched <scp>l</scp>‐Dopa as a Triple‐Resonance NMR Probe to Monitor Neurotransmitter Dopamine in the Brain and Liver Extracts of Mice",
           "10.1002/open.201500196",
           2015,
           "In an attempt to monitor μm‐level trace constituents, we applied here 1H‐{13C‐15N} triple‐resonance nuclear magnetic resonance (NMR) to 13C/15N‐enriched l‐Dopa as the inevitable precursor of the neurotransmitter dopamine in the brain. The perfect selectivity (to render endogenous components silent) and μm‐level sensitivity (700 MHz spectrometer equipped with a cryogenic probe) of triple‐resonance allowed the unambiguous and quantitative metabolic and pharmacokinetic analyses of administered l‐Dopa/dopamine in the brain and liver of mice. The level of dopamine generated in the brain (within the range 7–76 μm, which covers the typical stimulated level of ∼30 μm) could be clearly monitored ex vivo, but was slightly short of the detection limit of a 7 T MR machine for small animals. This work suggests that μm‐level trace constituents are potential targets of ex vivo monitoring as long as they contain N atom(s) and their appropriate 13C/15N‐enrichment is synthetically accessible.",
           6,
           "chemistryopen"
          ],
          [
           "Aromatic Fluorination of Multiblock Amphiphile Enhances Its Incorporation into Lipid Bilayer Membranes",
           "10.1002/open.201900374",
           2020,
           "We designed multiblock amphiphiles AmF and AmH, which consist of perfluorinated and non‐fluorinated hydrophobic units, respectively. Absorption spectroscopy revealed that both amphiphiles are molecularly dispersed in organic solvent, while they form aggregates under aqueous conditions. Furthermore, we investigated whether AmF and AmH can be incorporated into DOPC lipid bilayer membranes, and found that the maximum concentration of AmF that can be incorporated into DOPC lipid bilayer membranes is 43 times higher than that of AmH.",
           7,
           "chemistryopen"
          ],
          [
           "Heavy Chalcogenide‐Based Ionic Liquids in Syntheses of Metal Chalcogenide Materials near Room Temperature",
           "10.1002/open.202000346",
           2021,
           "This minireview describes two strategically different and unexplored approaches to use ionic liquids (IL) containing weakly solvated and highly reactive chalcogenide anions [E‐SiMe3]− and [E−H]− of the heavy chalcogens (E=S, Se, Te) in materials synthesis near room temperature. The first strategy involves the synthesis of unprecedented trimethylsilyl chalcogenido metalates Cat+[M(E‐SiMe3)n]− (Cat=organic IL cation) of main group and transition metals (M=Ga, In, Sn, Zn, Cu, Ag, Au). These fully characterized homoleptic metalates serve as thermally metastable precursors in low‐temperature syntheses of binary, ternary and even quaternary chalcogenide materials such as CIGS and CZTS relevant for semiconductor and photovoltaics (PV) applications. Furthermore, thermally and protolytically metastable coinage metalates Cat+[M(ESiMe3)2]− (M=Cu, Ag, Au; E=S, Se) are accessible. Finally, the use of precursors BMPyr[E‐SiMe3] (E=Se,Te; BMPyr=1‐butyl‐1‐methylpyrrolidinium) as sources of activated selenium and tellurium in the synthesis of high‐grade thermoelectric nanoparticles Bi2Se3 and Bi2Te3 is shortly highlighted. The second synthesis strategy involves the metalation of ionic liquids Cat[S−H] and Cat[Se−H] by protolytically highly active metal alkyls or amides RnM. This rather general approach towards unknown chalcogenido metalates Catm[Rn‐1M(E)]m (E=S, Se) will be demonstrated in a research paper following this short review head‐to‐tail.",
           5,
           "chemistryopen"
          ],
          [
           "Electrochemical Proton Intercalation in Vanadium Pentoxide Thin Films and its Electrochromic Behavior in the near‐IR Region",
           "10.1002/open.202000267",
           2021,
           "This work examines the proton intercalation in vanadium pentoxide (V2O5) thin films and its optical properties in the near‐infrared (near‐IR) region. Samples were prepared via direct current magnetron sputter deposition and cyclic voltammetry was used to characterize the insertion and extraction behavior of protons in V2O5 in a trifluoroacetic acid containing electrolyte. With the same setup chronopotentiometry was done to intercalate a well‐defined number of protons in the HxV2O5 system in the range of x=0 and x=1. These films were characterized with optical reflectometry in the near‐IR region (between 700 and 1700 nm wavelength) and the refractive index n and extinction coefficient k were determined using Cauchy’s dispersion model. The results show a clear correlation between proton concentration and n and k.",
           1,
           "chemistryopen"
          ],
          [
           "First Isolation and Structure Elucidation of GDNT‐β‐Glu – Tetraether Lipid Fragment from Archaeal <i>Sulfolobus</i> Strains",
           "10.1002/open.202100154",
           2021,
           "Due to their special chemical structure, tetraether lipids (TEL) represent essential elements of archaeal membranes, providing these organisms with extraordinary properties. Here we describe the characterization of a newly isolated structural element of the main lipids. The TEL fragment GDNT‐β‐Glu was isolated from Sulfolobus metallicus and characterized in terms of its chemical structure by NMR‐ and MS‐investigations. The obtained data are dissimilar to analogically derived established structures – in essence, the binding relationships in the polar head group are re‐determined and verified. With this work, we provide an important contribution to the structure elucidation of intact TEL also contained in other Sulfolobus strains such as Solfulobus acidocaldarius and Sulfolobus solfataricus.",
           1,
           "chemistryopen"
          ],
          [
           "Precursors for Atmospheric Plasma‐Enhanced Sintering: Low‐Temperature Inkjet Printing of Conductive Copper",
           "10.1002/open.201800131",
           2018,
           "Bidentate diamine and amino‐alcohol ligands have been used to form solid, water‐soluble, and air‐stable monomeric copper complexes of the type [Cu(NH2CH2CH(R)Y)2(NO3)2] (1, R=H, Y=NH2; 2, R=H, Y=OH; 3, R=Me, Y=OH). The complexes were characterized by elemental analysis, mass spectrometry, infrared spectroscopy, thermal gravimetric analysis, and single‐crystal X‐ray diffraction. Irrespective of their decomposition temperature, precursors 1–3 yield highly conductive copper features [1.5×10−6 Ω m (±5×10−7 Ω m)] upon atmospheric‐pressure plasma‐enhanced sintering.",
           16,
           "chemistryopen"
          ],
          [
           "Colloidal Synthesis of Gold Semishells",
           "10.1002/open.201200002",
           2012,
           "This work describes a novel and scalable colloid chemistry strategy to fabricate gold semishells based on the selective growth of gold on Janus silica particles (500 nm in diameter) partly functionalized with amino groups. The modulation of the geometry of the Janus silica particles allows us to tune the final morphology of the gold semishells. This method also provides a route to fabricating hollow gold semishells through etching of the silica cores with hydrofluoric acid. The optical properties were characterized by visible near‐infrared (vis‐NIR) spectroscopy and compared with simulations performed using the boundary element method (BEM). These revealed that the main optical features are located beyond the NIR region because of the large core size.",
           14,
           "chemistryopen"
          ],
          [
           "Introducing <i>N</i>‐Heteroaromatic Bases into Copper(II) Thiosemicarbazon Complexes: A Way to Change their Biological Activity",
           "10.1002/open.202200208",
           2022,
           "Three new copper(II) complexes, [Cu(1,10‐Phen)(L)] (1), [Cu(2,2′‐Bpy)(L)] (2) and [Cu(3,4‐Lut)(L)] (3), where H2L=2‐[(2,4‐dihydroxyphenyl)methylidene]‐N‐(prop‐2‐en‐1‐yl)hydrazine‐1‐carbothioamide, 1,10‐Phen=1,10‐phenanthroline, 2,2′‐Bpy=2,2′‐bipyridine, 3,4‐Lut=3,4‐lutidine, have been synthesized and characterized by elemental analysis, FTIR spectroscopy and single crystal X‐ray crystallography (1, 2). All compounds are mononuclear. The introduction of a monodentate N‐heteroaromatic base (3,4‐dimethylpyridine) has led to a significant increase of antimicrobial activity against Gram‐negative Escherichia coli and antifungal activity against Candida albicans compared to the pro‐ligand and the precursor complex [Cu(L)H2O]. The introduction of bidentate N‐heteroaromatic bases did not lead to such increase of antimicrobial and antifungal activities. Moreover, complex 3 surpasses the inhibitory activity of tetracycline toward Enterobacter cloacae and the inhibitory activity of fluconazole toward Candida parapsilosis and Cryptococcus neoformans. The study of antioxidant activity against cation radicals ABTS⋅+ showed that complexes 1–3 are more active than Trolox, but only introduction of the monodentate N‐heteroaromatic base (3,4‐dimethylpyridine) led to the increase of antioxidant properties compared to the precursor complex.",
           2,
           "chemistryopen"
          ],
          [
           "B‐DNA Structure and Stability as Function of Nucleic Acid Composition: Dispersion‐Corrected DFT Study of Dinucleoside Monophosphate Single and Double Strands",
           "10.1002/open.201300019",
           2013,
           "We have computationally investigated the structure and stability of all 16 combinations of two out of the four natural DNA bases A, T, G and C in a di‐2′‐deoxyribonucleoside‐monophosphate model DNA strand as well as in 10 double‐strand model complexes thereof, using dispersion‐corrected density functional theory (DFT‐D). Optimized geometries with B‐DNA conformation were obtained through the inclusion of implicit water solvent and, in the DNA models, of sodium counterions, to neutralize the negative charge of the phosphate groups. The results obtained allowed us to compare the relative stability of isomeric single and double strands. Moreover, the energy of the Watson–Crick pairing of complementary single strands to form double‐helical structures was calculated. The latter furnished the following increasing stability trend of the double‐helix formation energy: d(TpA)2 <d(CpA)2 <d(ApT)2 <d(ApA)2 <d(GpT)2 <d(GpA)2 <d(ApG)2 <d(CpG)2 <d(GpG)2 <d(GpC)2, where the energy differences between the last four dimers, d(ApG)2, d(CpG)2, d(GpG)2 and d(GpC)2, is within 4.0 kcal mol−1, and the energy between the most and the least stable isomers is 13.4 kcal mol−1. This trend shows that the formation energy essentially increases with the number of hydrogen bonds per base pair, that is two between A and T and three between G and C. Superimposed on this main trend are more subtle effects that depend on the order in which bases occur within a strand from the 5’‐ to the 3’‐end.",
           29,
           "chemistryopen"
          ],
          [
           "Selective Aerobic Oxidation of Alcohols in Low Melting Mixtures and Water and Use for Telescoped One‐Pot Hybrid Reactions",
           "10.1002/open.202200160",
           2022,
           "An efficient, selective and sustainable protocol was developed for the CuCl2/TEMPO/TMEDA‐catalyzed aerobic oxidation of activated alcohols to the corresponding carbonyl compounds using water or the environmentally friendly low melting mixture (LMM) d‐fructose‐urea as the reaction medium. Such oxidation reactions proceed under mild (room temperature or 40 °C) and aerobic conditions, with the carbonyl derivatives isolated in up to 98 % yield and within 4 h reaction time when using the above‐mentioned LMM. The potential application of this methodology is demonstrated by setting up useful telescoped, one‐pot two‐step hybrid transformations for the direct conversion of primary alcohols either into secondary alcohols or into valuable nitroalkenes, by combining oxidation processes with nucleophilic additions promoted by highly polarized organometallic compounds (Grignard and organolithium reagents) or with nitroaldol (Henry) reactions, respectively.",
           8,
           "chemistryopen"
          ],
          [
           "Synthesis and Properties of Twisted and Helical Azulene Oligomers and Azulene‐Based Polycyclic Hydrocarbons",
           "10.1002/open.202100298",
           2023,
           "The construction of 1,2‐position‐connected azulene oligomers was achieved. In the crystal packing structure of the terazulene, two molecules of (Ra)‐ and (Sa)‐configurations formed a pair. Variable temperature NMR measurements and theoretical calculations of the quaterazulene suggest that the helical and syn‐type structure with terminal azulene overlap is more stable. Two kinds of fused terazulenes (1,2′′‐closed and 1,8′′‐closed) were also synthesized by intramolecular Pd‐catalyzed C−H/C−Br arylation of the terazulene moieties. X‐ray structure analysis of 1,2′′‐closed terazulene revealed a planar structure, while an analysis of 1,8′′‐closed terazulene performed on a C60 co‐crystal revealed a curved structure forming a 1 : 1 complex covering the co‐crystal. Nucleus‐independent chemical shift (NICS) calculations carried out for the central seven‐membered ring of 1,8′′‐closed terazulene showed a positive value, suggesting anti‐aromatic properties.",
           3,
           "chemistryopen"
          ],
          [
           "Synthesis and Evaluation of Graphene Aerogel‐Supported Mn<sub>x</sub>Fe<sub>3−x</sub>O<sub>4</sub> for Oxygen Reduction in Urea/O<sub>2</sub> Fuel Cells",
           "10.1002/open.201900105",
           2019,
           "Graphene aerogel‐supported manganese ferrite (MnxFe3−xO4/GAs) and reduced‐graphene oxide/manganese ferrite composite (MnFe2O4/rGO) were synthesized and studied as cathode catalysts for oxygen reduction reactions in urea/O2 fuel cells. MnFe2O4/GAs exhibited a 3D framework with a continuous macroporous structure. Among the investigated Fe/Mn ratios, the more positive oxygen reduction onset potential was observed with Fe/Mn=2/1. The half‐wave potential of MnFe2O4/GAs was considerably more positive than that of MnFe2O4/rGO and comparable with that of Pt/C, while the stability of MnFe2O4/GAs significantly higher than that of Pt/C. The best urea/O2 fuel cell performance was also observed with the MnFe2O4/GAs. The MnFe2O4/GAs exhibited an OCV of 0.713 V and a maximum power density of 1.7 mW cm−2 at 60 °C. Thus, this work shows that 3D structured graphene aerogel‐supported MnFe2O4 catalysts can be used as an efficient cathode material for alkaline fuel cells.",
           6,
           "chemistryopen"
          ],
          [
           "A Photolabile Carboxyl Protecting Group for Solid Phase Peptide Synthesis",
           "10.1002/open.202000324",
           2021,
           "A new kind of photolabile protecting group (PLPG) for carboxyl moieties was designed and synthesized as the linker between resin and peptide. This group can be used for the protection of amino acid carboxyl groups. The peptide was synthesized on Nph (2‐hydroxy‐3‐(2‐nitrophenyl)‐heptanoic acid)‐derivatized resins and could be cleaved under UV exposure, thus avoiding the necessity for harsh acid‐mediated resin cleavage. The PLPG has been successfully used for solid‐phase synthesis of peptides.",
           3,
           "chemistryopen"
          ],
          [
           "Efficient Sustainable Tool for Monitoring Chemical Reactions and Structure Determination in Ionic Liquids by ESI‐MS",
           "10.1002/open.201300022",
           2013,
           "An easy and convenient procedure is described for monitoring chemical reactions and characterization of compounds dissolved in ionic liquids using the well‐known tandem mass spectrometry (MS/MS) technique. Generation of wastes was avoided by utilizing an easy procedure for analysis of ionic liquid systems without preliminary isolation and purification. The described procedure also decreased the risk of plausible contamination and damage of the ESI‐MS hardware and increased sensitivity and accuracy of the measurements. ESI‐MS detection in MS/MS mode was shown to be efficient in ionic liquids systems for structural and mechanistic studies, which are rather difficult otherwise. The developed ESI‐MS/MS approach was applied to study samples corresponding to peptide systems in ionic liquids and to platform chemical directed biomass conversion in ionic liquids.",
           6,
           "chemistryopen"
          ],
          [
           "Process Optimisation Studies and Aminonitrile Substrate Evaluation of <i>Rhodococcus erythropolis</i> SET1, A Nitrile Hydrolyzing Bacterium",
           "10.1002/open.202000088",
           2020,
           "A comprehensive series of optimization studies including pH, solvent and temperature were completed on the nitrile hydrolyzing Rhodococcus erythropolis bacterium SET1 with the substrate 3‐hydroxybutyronitrile. These identified temperature of 25 °C and pH of 7 as the best conditions to retain enantioselectivity and activity. The effect of the addition of organic solvents to the biotransformation mixture was also determined. The results of the study suggested that SET1 is suitable for use in selected organo‐aqueous media at specific ratios only. The functional group tolerance of the isolate with unprotected and protected β‐aminonitriles, structural analogues of β‐hydroxynitriles was also investigated with disappointingly poor isolated yields and selectivity obtained. The isolate was further evaluated with the α‐ aminonitrile phenylglycinonitrile generating acid in excellent yield and ee (>99 % (S) – isomer and 50 % yield). A series of pH studies with this substrate indicated pH 7 to be the optimum pH to avoid product and substrate degradation.",
           3,
           "chemistryopen"
          ],
          [
           "Resolution Enhancement in SEA XLOC for Heteronuclear NMR Long‐Range Correlation",
           "10.1002/open.201900136",
           2019,
           "It is shown how the resolution in SEA XLOC NMR spectra for distinguishing between heteronuclear two‐ and three‐bond correlations for all 13C multiplicities can be improved by a modified experiment delivering absorptive profiles in the indirect dimension. The method is demonstrated with applications to ibuprofen and strychnine.",
           6,
           "chemistryopen"
          ],
          [
           "Cover Picture: Diastereoselective Additive Trifluoromethylation/Halogenation of Isoxazole Triflones: Synthesis of All‐Carbon‐Functionalized Trifluoromethyl Isoxazoline Triflones (ChemistryOpen 1/2014)",
           "10.1002/open.201480101",
           2014,
           "No Abstract",
           0,
           "chemistryopen"
          ],
          [
           "Lewis‐Acid‐assisted Hydrogen Atom Transfer to Manganese(V)‐Oxo Corrole through Valence Tautomerization",
           "10.1002/open.201600117",
           2016,
           "The kinetics of formation of the valence tautomers (tpfc⋅)MnIV(O−LA)]n+ [where LA=ZnII, CaII, ScIII, YbIII, B(C6F5)3, and trifluoroacetic acid (TFA); tpfc=5,10,15‐tris(pentafluorophenyl) corrole] from (tpfc)MnV(O) were followed by UV/Vis spectroscopy, giving second‐order rate constants ranging over five orders of magnitude from 10−2 for Ca to 103 m−1 s−1 for Sc. Hydrogen atom transfer (HAT) rates from 2,4‐di‐tert‐butyl phenol (2,4‐DTBP) to the various Lewis acid valence tautomers of manganese oxo corrole complexes were evaluated and compared. For LA=TFA, ScIII, or YbIII, the rate constants of HAT were comparable to unactivated (tpfc)MnV(O). However, with LA=B(C6F5)3, ZnII, and CaII, 6‐, 21‐, and 31‐fold rate enhancements were observed, respectively. Remarkably, [(tpfc⋅)MnIV(OCa)]2+ gave the most enhancement despite its rate of formation being the slowest. Comparisons of HAT rate constants among the various Lewis acid tautomers revealed that both size and charge are important. This study underscores how valence may affect the reactivity of high‐valent manganese‐oxo compounds and sheds light on nature's choice of Ca in the activation of Mn‐oxo in the oxygen‐evolving complex.",
           8,
           "chemistryopen"
          ],
          [
           "Triple Helicene Cage: Three‐Dimensional π‐Conjugated Chiral Cage with Six [5]Helicene Units",
           "10.1002/open.201800006",
           2018,
           "A three‐dimensional π‐conjugated chiral cage with six [5]helicene units (a triple helicene cage) was synthesized for the first time. Taking advantage of the Yamamoto coupling reaction, the triflate‐substituted triple [5]helicene, a strained and preorganized precursor, was dimerized to afford the target compound. Single‐crystal X‐ray diffraction analysis revealed the unique structural features of the triple helicene cage: a cage‐shaped rigid structure with outer helical grooves and an inner chiral cavity. All‐P and all‐M enantiomers were separated successfully by HPLC over a chiral column and their chiroptical properties were characterized by circular dichroism spectra.",
           24,
           "chemistryopen"
          ],
          [
           "Activity coefficients of binary methanol alcohol mixtures from cluster weighting",
           "10.1002/open.202000171",
           2020,
           "The hydrogen bond network of different small alcohols is investigated via cluster analysis. Methanol/alcohol mixtures are studied with increasing chain length and branching of the molecule. Those changes can play an important role in different fields, including solvent and metal extraction. The extended tight binding method GFN2‐xTB allows the evaluation and geometry optimization of thousands of clusters built via a genetic algorithm. Interaction energies and geometries are evaluated and discussed for the neat systems. Thermodynamic properties, such as vaporization enthalpies and activity coefficients, are calculated with the binary quantum cluster equilibrium (bQCE) approach using our in‐house code Peacemaker 2.8. Combined distribution functions of the distances against the angles of the hydrogen bonds are evaluated for neat and mixed clusters and weighted by the equilibrium populations achieved from bQCE calculations.",
           9,
           "chemistryopen"
          ],
          [
           "On the Uselessness of Bond Paths Linking Distant Atoms and on the Violation of the Concept of Privileged Exchange Channels",
           "10.1002/open.201900109",
           2019,
           "We refer to frequently used determinants suggesting dominant interactions between distant atoms in various dimers. First of all, we show, against the still‐prevailling opinion, that, in general, bond paths have nothing in common with dominant intermolecular interactions and therefore they are useless in such cases. Quite the contrary, reliable information about dominant intermolecular interactions can be obtained by means of electrostatic potential maps, which very convincingly explain mutual orientation of molecules in a dimer. For the first time, numerous examples of interactions that violate both the concept of privileged exchange channels proposed by Pendás and his collaborators as well as inequalities obtained by Tognetti and Joubert for the β parameter related to secondary interactions are presented. The possible cause of this violation is suggested. We also show that the so‐called counterintuitive bond paths result from quite natural behavior of the electron density gradient vector, i. e. searching for those areas of space that are characterized by large values of electron density or the most expanded its distributions.",
           61,
           "chemistryopen"
          ],
          [
           "Pressure‐Induced Formation of Quaternary Compound and In−N Distribution in InGaAsN Zincblende from Ab Initio Calculation",
           "10.1002/open.201900018",
           2019,
           "We present the effects of In−N distribution and high pressure on the zincblende phase (0–5 GPa) of InxGa1−xAs0.963N0.037 (x=0.074, 0.111 and 0.148). Structural, electronic, and optical properties are analyzed, and it is found that non‐isotropic distribution of In−N (type C) possesses the minimum free energy for the InGaAsN conventional cell system. An increasing indium content reduces the formation enthalpy of InGaAsN. The formation enthalpy, conduction band minimum, strength of covalent bonds, and electron density differences in free space of InGaAsN are decreased under high‐pressure conditions. The dielectric performance and static permittivity of InGaAsN are lower than that of GaAs, for which the dielectric performance transforms to conductor performance at high frequency. The optimum photoabsorption coefficient is found at the composition of In0.111Ga0.889As0.963N0.037 (3In−N), which very well relates to the literature.",
           8,
           "chemistryopen"
          ],
          [
           "Chemical Recycling of End‐of‐Life Poly(lactide) via Zinc‐Catalyzed Depolymerization and Polymerization",
           "10.1002/open.202000243",
           2020,
           "The chemical recycling of poly(lactide) was investigated based on depolymerization and polymerization processes. Using methanol as depolymerization reagent and zinc salts as catalyst, poly(lactide) was depolymerized to methyl lactate applying microwave heating. An excellent performance was observed for zinc(II) acetate with turnover frequencies of up to 45000 h−1. In a second step the monomer methyl lactate was converted to (pre)poly(lactide) in the presence of catalytic amounts of zinc salts. Here zinc(II) triflate revealed excellent performance for the polymerization process (yield: 91 %, Mn∼8970 g/mol). Moreover, the (pre)poly(lactide) was depolymerized to lactide, the industrial relevant molecule for accessing high molecular weight poly(lactide), using zinc(II) acetate as catalyst.",
           23,
           "chemistryopen"
          ],
          [
           "Benchmark Study of the Performance of Density Functional Theory for Bond Activations with (Ni,Pd)‐Based Transition‐Metal Catalysts",
           "10.1002/open.201300012",
           2013,
           "The performance of 23 density functionals, including one LDA, four GGAs, three meta‐GGAs, three hybrid GGAs, eight hybrid meta‐GGAs, and ten double‐hybrid functionals, was investigated for the computation of activation energies of various covalent main‐group single bonds by four catalysts: Pd, PdCl−, PdCl2, and Ni (all in the singlet state). A reactant complex, the barrier, and reaction energy were considered, leading to 164 energy data points for statistical analysis. Extended Gaussian AO basis sets were used in all calculations. The best functional for the complete benchmark set relative to estimated CCSD(T)/CBS reference data is PBE0‐D3, with an MAD value of 1.1 kcal mol−1 followed by PW6B95‐D3, the double hybrid PWPB95‐D3, and B3LYP‐D3 (1.9 kcal mol−1 each). The other tested hybrid meta‐GGAs perform less well (M06‐HF: 7.0 kcal mol−1; M06‐2X: 6.3 kcal mol−1; M06: 4.9 kcal mol−1) for the investigated reactions. In the Ni case, some double hybrids show larger errors due to partial breakdown of the perturbative treatment for the correlation energy in cases with difficult electronic structures (partial multi‐reference character). Only double hybrids either with very low amounts of perturbative correlation (e.g., PBE0‐DH) or that use the opposite‐spin correlation component only (e.g., PWPB95) seem to be more robust. We also investigated the effect of the D3 dispersion correction. While the barriers are not affected by this correction, significant and mostly positive results were observed for reaction energies. Furthermore, six very recently proposed double‐hybrid functionals were analyzed regarding the influence of the amount of Fock exchange as well as the type of perturbative correlation treatment. According to these results, double hybrids with <50–60 % of exact exchange and ∼30 % perturbative correlation perform best.",
           148,
           "chemistryopen"
          ],
          [
           "B‐DNA Structure and Stability: The Role of Nucleotide Composition and Order",
           "10.1002/open.202100231",
           2022,
           "We have quantum chemically analyzed the influence of nucleotide composition and sequence (that is, order) on the stability of double‐stranded B‐DNA triplets in aqueous solution. To this end, we have investigated the structure and bonding of all 32 possible DNA duplexes with Watson–Crick base pairing, using dispersion‐corrected DFT at the BLYP‐D3(BJ)/TZ2P level and COSMO for simulating aqueous solvation. We find enhanced stabilities for duplexes possessing a higher GC base pair content. Our activation strain analyses unexpectedly identify the loss of stacking interactions within individual strands as a destabilizing factor in the duplex formation, in addition to the better‐known effects of partial desolvation. Furthermore, we show that the sequence‐dependent differences in the interaction energy for duplexes of the same overall base pair composition result from the so‐called “diagonal interactions” or “cross terms”. Whether cross terms are stabilizing or destabilizing depends on the nature of the electrostatic interaction between polar functional groups in the pertinent nucleobases.",
           9,
           "chemistryopen"
          ],
          [
           "Topological Control of Columnar Stacking Made of Liquid‐Crystalline Thiophene‐Fused Metallonaphthalocyanines",
           "10.1002/open.201500205",
           2015,
           "The spontaneous organization of two‐dimensional polyaromatic molecules into well‐defined nanostructures through noncovalent interactions is important in the development of organic‐based electronic and optoelectronic devices. Two regioisomers of thiophene‐fused zinc naphthalocyanines ZnTNcendo and ZnTNcexo have been designed and synthesized to obtain photo‐ and electroactive liquid crystalline materials. Both compounds exhibited liquid crystalline behavior over a wide temperature range through intermolecular π–π interactions and local phase segregation between the aromatic cores and peripheral side chains. The structural differences between ZnTNcendo and ZnTNcexo affected the stacking mode in self‐assembled columns, as well as symmetry of the two‐dimensional rectangular columnar lattice. The columnar structure in liquid crystalline phase exhibited an ambipolar charge‐transport behavior.",
           7,
           "chemistryopen"
          ],
          [
           "Acid‐Responsive <i>N</i>‐Heteroacene‐Based Material Showing Multi‐Emission Colors",
           "10.1002/open.201700007",
           2017,
           "An acid‐responsive N‐heteroacene‐based material has been prepared, which shows a blue emission color in a film. The protonation of this material in a thin film gives rise to remarkable changes in luminescent color compared to that in solution states. As the protonation of N‐heteroacene molecules in films gradually occurs, their emission color can be tuned by adjusting the exposure time of the thin films to HCl vapor.",
           13,
           "chemistryopen"
          ],
          [
           "Rhodol Derivatives as Selective Fluorescent Probes for the Detection of Hg<sup>II</sup> Ions and the Bioimaging of Hypochlorous Acid",
           "10.1002/open.201800008",
           2018,
           "Invited for this month's cover picture is the group of Professor Keith Man‐Chung Wong from the Southern University of Science and Technology (P.R. China). The cover picture illustrates a novel rhodol‐based fluorescence probe from the structural combination of rhodamine and fluorescein motifs. Read the full text of their Full Paper at 10.1002/open.201700154.",
           0,
           "chemistryopen"
          ],
          [
           "<i>N</i>‐Aryl Isoleucine Derivatives as Angiotensin II AT<sub>2</sub> Receptor Ligands",
           "10.1002/open.201300040",
           2014,
           "A novel series of ligands for the recombinant human AT2 receptor has been synthesized utilizing a fast and efficient palladium‐catalyzed procedure for aminocarbonylation as the key reaction. Molybdenum hexacarbonyl [Mo(CO)6] was employed as the carbon monoxide source, and controlled microwave heating was applied. The prepared N‐aryl isoleucine derivatives, encompassing a variety of amide groups attached to the aromatic system, exhibit binding affinities at best with Ki values in the low micromolar range versus the recombinant human AT2 receptor. Some of the new nonpeptidic isoleucine derivatives may serve as starting points for further structural optimization. The presented data emphasize the importance of using human receptors in drug discovery programs.",
           5,
           "chemistryopen"
          ],
          [
           "Manufacturing Graphene‐Encapsulated Copper Particles by Chemical Vapor Deposition in a Cold Wall Reactor",
           "10.1002/open.201800228",
           2019,
           "Functional fillers, such as Ag, are commonly employed for effectively improving the thermal or electrical conductivity in polymer composites. However, a disadvantage of such a strategy is that the cost and performance cannot be balanced simultaneously. Therefore, the drive to find a material with both a cost efficient fabrication process and excellent performance attracts intense research interest. In this work, inspired by the core–shell structure, we developed a facile manufacturing method to prepare graphene‐encapsulated Cu nanoparticles (GCPs) through utilizing an improved chemical vapor deposition (CVD) system with a cold wall reactor. The obtained GCPs could retain their spherical shape and exhibited an outstanding thermal stability up to 179 °C. Owing to the superior thermal conductivity of graphene and excellent oxidation resistance of GCPs, the produced GCPs are practically used in a thermally conductive adhesive (TCA), which commonly consists of Ag as the functional filler. Measurement shows a substantial 74.6 % improvement by partial replacement of Ag with GCPs.",
           7,
           "chemistryopen"
          ],
          [
           "A pH‐Switchable Triple Hydrogen‐Bonding Motif",
           "10.1002/open.201900338",
           2020,
           "A stimuli responsive linear hydrogen bonding motif, capable of in situ protonation and deprotonation, has been investigated. The interactions of the responsive hydrogen bonding motif with complementary partners were examined through a series of 1H NMR experiments, revealing that the recognition preference of the responsive hydrogen bonding motif in a mixture can be switched between two states.",
           6,
           "chemistryopen"
          ],
          [
           "Effect of Direct Alkyne Substitution on the Photophysical Properties of Two Novel Octasubstituted Zinc Phthalocyanines",
           "10.1002/open.202300295",
           2024,
           "The synthesis of two novel phthalonitrile derivatives (3–4) bearing ethynylcyclohex‐1‐ene and ethynylcyclohexane groups and two peripherally octa substituted zinc (II) phthalocyanines (5–6) were prepared. The synthesis of phthalonitrile derivatives was performed with Sonagashira coupling reaction by using palladium‐catalyzed. The newly synthesized compounds were characterized by using FT‐IR, NMR, mass, and UV‐Vis absorption spectroscopy techniques. Aggregation studies of 5 and 6 were performed in various organic solvents and different concentrations in tetrahydrofuran (THF). The photophysical studies of the Pcs were performed in THF to determine the effect of the alkyne groups on the fluorescence of the Pc ring. Substances showing fluorescence properties can be used in practical applications such as to create an image in microscopy. Fluorescence quantum yield (ΦF) and fluorescence lifetime (τF) of 5–6 were calculated. The fluorescence quenching studies of 5–6 were performed by adding the different concentrations of 1,4‐benzoquinone (BQ) to a constant concentration of the Pcs in THF and it was found that benzoquinone was an effective quencher. The values of the Stern‐Volmer constant (Ksv) and quenching constant (kq) of zinc phthalocyanines (5–6) were examined. All obtained results were compared with each other and with unsubstituted zinc Pc compound used as a reference.",
           0,
           "chemistryopen"
          ],
          [
           "Steric and Electronic Effects in Gold N‐Heterocyclic Carbene Complexes Revealed by Computational Analysis",
           "10.1002/open.201900076",
           2019,
           "A computational analysis of a series of cationic and neutral gold imidazolylidene and benzimidizolylidene complexes is reported. The Bond Dissociation Energies of the various ligands in the complexes calculated at the PBE0‐D3/def2‐TZVP level of theory increase with increasing ligand volume, except for those of complexes containing t‐butyl‐substituted ligands, which are anomalously low particularly for the benzimidazolylidene species. Atoms in Molecules studies show the presence of a variety of weak intramolecular interactions, characterised by the presence of bond critical points with a range of different properties. Energy Decomposition Analysis and calculation of Electrostatic Surface Potentials indicate that some interactions are weakly attractive dispersion‐type interactions, while others are repulsive. The octanol/water partition coefficients (log P values) were calculated as a measure of the lipophilicities of the complexes and were found to increase with increasing volume.",
           0,
           "chemistryopen"
          ],
          [
           "Facile Electrochemical Intramolecular Amination of Urea‐Tethered Terminal Alkenes for the Synthesis of Cyclic Ureas",
           "10.1002/open.201800064",
           2018,
           "Facile intramolecular amination of unactivated alkenes has been achieved by using electricity as a catalyst that helps to generate an intermediate and accelerates formation of cyclic ureas in high yields. Using this method, no metal catalysts were used. During electrolysis, a nitrogen radical was formed at the urea substrate that cyclised with the alkene and generated a terminal carbon radical which further formed a bond with the 2,2,6,6‐tetramethylpiperidine‐N‐oxyl radical (TEMPO). This method of electrolysis not only gives cyclic ureas but also functionalises terminal unactivated alkenes. This method can be considered to be environmentally friendly given that it avoids the issues of toxicity or complicated metal ligands and could therefore be potentially employed in green chemistry.",
           15,
           "chemistryopen"
          ],
          [
           "Toward Fast and Efficient Visible‐Light‐Driven Molecular Motors: A Minimal Design",
           "10.1002/open.201800089",
           2018,
           "A key goal in the development of light‐driven rotary molecular motors is to facilitate their usage in biology and medicine by shifting the required irradiation wavelengths from the UV regime to the nondestructive visible regime. Although some progress has been made toward this goal, most available visible‐light‐driven motors either have relatively low quantum yields or require that thermal steps follow the photoisomerizations that underlie the rotary motion. Here, a minimal design for visible‐light‐driven motors without these drawbacks is presented and evaluated on the basis of state‐of‐the‐art quantum chemical calculations and molecular dynamics simulations. The design, featuring dihydropyridinium and cyclohexenylidene motifs and comprising only five conjugated double bonds, is found to produce a full 360° rotation through fast photoisomerizations (excited‐state lifetimes of ≈170–250 fs) powered by photons with energies well below 3 eV.",
           14,
           "chemistryopen"
          ],
          [
           "Spaced TiO<sub>2</sub> Nanotubes Enable Optimized Pt Atomic Layer Deposition for Efficient Photocatalytic H<sub>2</sub> Generation",
           "10.1002/open.201800172",
           2018,
           "In the present work, we report the use of TiO2 nanotube (NT) layers with a regular intertube spacing that are decorated by Pt nanoparticles through the atomic layer deposition (ALD) of Pt. These Pt‐decorated spaced (SP) TiO2 NTs are subsequently explored for photocatalytic H2 evolution and are compared to classical close‐packed (CP) TiO2 NTs that are also decorated with various amounts of Pt by using ALD. On both tube types, by varying the number of ALD cycles, Pt nanoparticles of different sizes and areal densities are formed, uniformly decorating the inner and outer walls from tube top to tube bottom. The photocatalytic activity for H2 evolution strongly depends on the size and density of Pt nanoparticles, driven by the number of ALD cycles. We show that, for SP NTs, a much higher photocatalytic performance can be achieved with significantly smaller Pt nanoparticles (i.e. for fewer ALD cycles) compared to CP NTs.",
           12,
           "chemistryopen"
          ],
          [
           "Construction of the Pentacyclic Core and Formal Total Synthesis of (<i>rac</i>)‐Renieramycin T",
           "10.1002/open.201800178",
           2018,
           "Invited for this month's cover picture is the group of Professor Naoki Saito at the Graduate School of Pharmaceutical Sciences, Meiji Pharmaceutical University (Japan). They achieved the first total synthesis of renieramycin T in 2016, and they have been following an alternative route to supply a large amount of it in order to promote research of the next stage, such as structure–activity relationship studies. This paper reports a formal total synthesis in 21 steps from a known piperazine‐2,5‐dione derivative. The key step of this synthesis is the modified Pictet–Spengler cyclization of a primary amine with an oxomalonic acid ester derivative followed by decarboxylation, and stereo‐controlled protonation at C‐1 position of the enol intermediate from the less‐hindered face. Read the full text of their Full Paper at 10.1002/open.201800112.",
           1,
           "chemistryopen"
          ],
          [
           "Intrinsic Dynamic Nature of Neutral Hydrogen Bonds Elucidated with QTAIM Dual Functional Analysis: Role of the Compliance Force Constants and QTAIM‐DFA Parameters in Stability",
           "10.1002/open.201800133",
           2018,
           "Invited for this month's cover picture is Professor Satoko Hayashi's group from the Faculty of Systems Engineering at Wakayama University (Japan). The cover picture shows Japanese lanterns for the Bon festival dance dangling on two ropes, and several molecular graphs with contour maps for hydrogen bonds (HBs) emerging from the lanterns. The curves of the ropes may correspond to the ΔE (energy of formation) and Cij (compliance constant) values for HBs, for which the product will be constant. Read the full text of their Full Paper at 10.1002/open.201800051.",
           0,
           "chemistryopen"
          ],
          [
           "Synthesis, Characterization, Cytotoxicity, and Antibacterial Properties of <i>trans</i>‐γ‐Halo‐δ‐lactones",
           "10.1002/open.201800110",
           2018,
           "A new four‐step pathway for the synthesis of γ‐halo‐δ‐lactones is described from simple, commercially available substrates: aryl bromides and 3‐methyl crotonaldehyde. The halogenolactonization reaction of β,δ‐substituted, γ,δ‐unsaturated carboxylic acid 4 a–c is regio‐ and stereoselective and gives only the trans‐isomers of lactones 5 a–c, 6 a–c, and 7 a–c. The structures of all synthesized compounds were confirmed by using spectroscopic methods. For bromolactone, containing a naphthyl moiety in the structure, crystallographic analysis was also performed. The lactones were tested for their cytotoxic activity against L929 cell lines (mouse fibroblasts) and antibacterial activity against Escherichia coli strains ATCC 8739 and Staphylococcus aureus ATCC 65389. Compounds 5 a, 5 c, 7 a, and 7 b statistically significantly inhibited the metabolic activity of mouse fibroblasts L929. Compounds 5 b and 6 a were not cytotoxic towards L929 cells, but showed moderate bactericidal properties.",
           9,
           "chemistryopen"
          ],
          [
           "β‐Deuterium Isotope Effects on Firefly Luciferase Bioluminescence",
           "10.1002/open.201700136",
           2017,
           "A 5,5‐d2‐luciferin was prepared to measure isotope effects on reactions of two intermediates in firefly bioluminescence: emission by oxyluciferin and elimination of a putative luciferyl adenylate hydroperoxide to dehydroluciferin. A negligible isotope effect on bioluminescence provides further support for the belief that the emitting species is the keto‐phenolate of oxyluciferin and rules out its excited‐state tautomerization, one potential contribution to a bioluminescence quantum yield less than unity. A small isotope effect on dehydroluciferin formation supports a single‐electron‐transfer mechanism for reaction of the luciferyl adenylate enolate with oxygen to form the hydroperoxide or dehydroluciferin. Partitioning between the dioxetanone intermediate (en route to oxyluciferin) and dehydroluciferin is determined, not by the fate of the hydroperoxide, but by that of the radical formed from luciferyl adenylate, and the kinetic isotope effect (KIE) reflects H‐atom abstraction by superoxide.",
           7,
           "chemistryopen"
          ],
          [
           "Chemoenzymatic Synthesis in Flow Reactors: A Rapid and Convenient Preparation of Captopril",
           "10.1002/open.201700082",
           2017,
           "The chemoenzymatic flow synthesis of enantiomerically pure captopril, a widely used antihypertensive drug, is accomplished starting from simple, inexpensive, and readily available reagents. The first step is a heterogeneous biocatalyzed regio‐ and stereoselective oxidation of cheap prochiral 2‐methyl‐1,3‐propandiol, performed in flow using immobilized whole cells of Acetobacter aceti MIM 2000/28, thus avoiding the use of aggressive and environmentally harmful chemical oxidants. The isolation of the highly hydrophilic intermediate (R)‐3‐hydroxy‐2‐methylpropanoic acid is achieved in‐line by using a catch‐and‐release strategy. Then, three sequential high‐throughput chemical steps lead to the isolation of captopril in only 75 min. In‐line quenching and liquid–liquid separation enable breaks in the workflow and other manipulations to be avoided.",
           39,
           "chemistryopen"
          ],
          [
           "Optical Activity of Spin‐Forbidden Electronic Transitions in Metal Complexes from Time‐Dependent Density Functional Theory with Spin‐Orbit Coupling",
           "10.1002/open.202200020",
           2022,
           "The calculation of magnetic transition dipole moments and rotatory strengths was implemented at the zeroth‐order regular approximation (ZORA) two‐component relativistic time‐dependent density functional theory (TDDFT) level. The circular dichroism of the spin‐forbidden ligand‐field transitions of tris(ethylenediamine)cobalt(III) computed in this way agrees very well with available measurements. Phosphorescence dissymmetry factors \n and the corresponding lifetimes are evaluated for three N‐heterocyclic‐carbene‐based iridium complexes, two of which contain helicene moieties, and for two platinahelicenes. The agreement with experimental data is satisfactory. The calculations reproduce the signs and order of magnitude of \n, and the large variations of phosphorescence lifetimes among the systems. The electron spin contribution to the magnetic transition dipole moment is shown to be important in all of the computations.",
           10,
           "chemistryopen"
          ],
          [
           "Decomposition of Copper Formate Clusters: Insight into Elementary Steps of Calcination and Carbon Dioxide Activation",
           "10.1002/open.201900282",
           2019,
           "The decomposition of copper formate clusters is investigated in the gas phase by infrared multiple photon dissociation of Cu(II)n(HCO2)2n+1−, n≤8. In combination with quantum chemical calculations and reactivity measurements using oxygen, elementary steps of the decomposition of copper formate are characterized, which play a key role during calcination as well as for the function of copper hydride based catalysts. The decomposition of larger clusters (n>2) takes place exclusively by the sequential loss of neutral copper formate units Cu(II)(HCO2)2 or Cu(II)2(HCO2)4, leading to clusters with n=1 or n=2. Only for these small clusters, redox reactions are observed as discussed in detail previously, including the formation of formic acid or loss of hydrogen atoms, leading to a variety of Cu(I) complexes. The stoichiometric monovalent copper formate clusters Cu(I)m(HCO2)m+1−, (m=1,2) decompose exclusively by decarboxylation, leading towards copper hydrides in oxidation state +I. Copper oxide centers are obtained via reactions of molecular oxygen with copper hydride centers, species containing carbon dioxide radical anions as ligands or a Cu(0) center. However, stoichiometric copper(I) and copper(II) formate Cu(I)(HCO2)2− and Cu(II)(HCO2)3−, respectively, is unreactive towards oxygen.",
           11,
           "chemistryopen"
          ],
          [
           "Discovery of Novel Molecular Frameworks of Farnesoid X Receptor Modulators by Ensemble Machine Learning",
           "10.1002/open.201800270",
           2018,
           "Invited for this month's cover picture is the group of Prof. Dr. Gisbert Schneider from the Swiss Federal Institute of Technology (ETH) Zurich (Switzerland). The cover picture illustrates the application of machine‐learning methods to expand the chemical space of farnesoid X receptor (FXR)‐targeting small molecules, by employing an ensemble of three complementary machine‐learning approaches (counter‐propagation artificial neural network, k‐nearest neighbor learner, and three‐dimensional pharmacophore model). Read the full text of their Full Paper at 10.1002/open.201800156.",
           1,
           "chemistryopen"
          ],
          [
           "A Pitfall in Heavy Metal Separation with Amino‐modified Silica Adsorbents from Aqueous Solution: The Occurring pH Shift",
           "10.1002/open.202200034",
           2022,
           "Selective separation of heavy metal ions from acidic aqueous solutions is of strong interest for certain industrial processes, such as electroplating, as well as environmental protection, for example battery recycling. Amino‐functionalized adsorbents are often discussed as suitable material for this purpose. Herein, two silica‐based adsorbents functionalized with 3‐aminopropyl‐ and 3‐[2‐[2‐aminoethylamino]‐ethylamino]‐propyl‐ligands resulting in adsorbents MonoA and TriA, respectively, were investigated regarding their separation behavior with focus on nickel(II) and cobalt(II) in batch as well as continuous flow experiments in acidic aqueous solutions. For both adsorbents, pH shifts into the alkaline range were observed in the process solutions, causing precipitation of metal hydroxides mainly in the particle pores in case of adsorbent MonoA and a combination of precipitation and adsorption regarding adsorbent TriA.Contrary to prior studies, our findings evidence that amino‐functionalized adsorbents are not applicable for nickel(II) and cobalt(II) in selective adsorption processes and additionally demonstrate that, besides batch investigations, continuous flow experiments are essential for well‐founded adsorbent selections in process development.",
           4,
           "chemistryopen"
          ],
          [
           "Facet‐Control versus Co‐Catalyst‐Control in Photocatalytic H<sub>2</sub> Evolution from Anatase TiO<sub>2</sub> Nanocrystals",
           "10.1002/open.202200010",
           2022,
           "Titanium dioxide (TiO2) and, in particular, its anatase polymorph, is widely studied for photocatalytic H2 production. In the present work, we examine the importance of reactive facets of anatase crystallites on the photocatalytic H2 evolution from aqueous methanol solutions. For this, we synthesized anatase TiO2 nanocrystals with a large amount of either {001} facets, that is, nanosheets, or {101} facets, that is, octahedral nanocubes, and examined their photocatalytic H2 evolution and then repeated this procedure with samples where Pt co‐catalyst is present on all facets. Octahedral nanocubes with abundant {101} facets produce >4 times more H2 than nanosheets enriched in {001} facets if the reaction is carried out under co‐catalyst‐free conditions. For samples that carry Pt co‐catalyst on both {001} and {101} facets, faceting loses entirely its significance. This demonstrates that the beneficial role of faceting, namely the introduction of {101} facets that act as electron transfer mediator is relevant only for co‐catalyst‐free TiO2 surfaces.",
           5,
           "chemistryopen"
          ],
          [
           "A Xanthan‐Gum‐Stabilized PEG‐Conjugated Nanocurcumin Complex: Telescoping Synthesis for Enhanced Permeation Potential",
           "10.1002/open.202200200",
           2023,
           "We report a facile room temperature telescoping synthesis of a nanocurcumin complex with 17.5‐fold permeation enhancement as determined by comparative in vitro permeation study with raw curcumin. The permeation results were further validated with in silico drug absorption prediction using ADMET predictors.",
           1,
           "chemistryopen"
          ],
          [
           "Electron Transfer and Electron Excitation Processes in 2,5‐Diaminoterephthalate Derivatives with Broad Scope for Functionalization",
           "10.1002/open.201900138",
           2019,
           "Derivatives of 2,5‐diaminoterephthalate (DAT) are efficient fluorescence dyes that are also redox‐active, thus allowing for the electrochemical manipulation of spectral properties. The electrochemical behaviour of seven DAT derivatives was studied by cyclic voltammetry in dichloromethane. In the absence of a proton donor, DATs should be oxidized in two one‐electron steps. The first step is usually quasi‐reversible while the second step is either quasi‐reversible or irreversible. Some electrochemical properties such as the formal potentials and the ratio between the anodic and the cathodic current were determined from the cyclic voltammograms. Correlation between the formal potential of first oxidation and the absorption or the fluorescence emission wavelengths are established for this specific type of dyes. These correlations were confirmed with density functional theory calculations.",
           2,
           "chemistryopen"
          ],
          [
           "Aptamer‐Based Cancer Cell Analysis and Treatment",
           "10.1002/open.202200141",
           2022,
           "Aptamers are a class of single‐stranded DNA or RNA oligonucleotides that can exclusively bind to various targets with high affinity and selectivity. Regarded as “chemical antibodies”, aptamers possess several intrinsic advantages, including easy synthesis, convenient modification, high programmability, and good biocompatibility. In recent decades, many studies have demonstrated the superiority of aptamers as molecular tools for various biological applications, particularly in the area of cancer theranostics. In this review, we focus on recent progress in developing aptamer‐based strategies for the precise analysis and treatment of cancer cells.",
           3,
           "chemistryopen"
          ],
          [
           "Molecular Dynamics Insights for Screening the Ability of Polymers to Remove Pesticides from Water",
           "10.1002/open.201800293",
           2019,
           "The use of pesticides in agriculture is known to have environmental impacts, namely it leads to underground and spring water contamination. Thus, it turns out that nowadays general‐endeavor towards the sustainability of farmer production requires novel strategies to capture pesticides from water and soils. We propose a methodology based on molecular dynamics simulations to identify polymers that are potentially featured to be applied for pesticide remediation in water and soils. We have employed cymoxanil (CYM), glufosinate ammonium (GLF), imidacloprid (IMI) and mancozeb (MAN) as pesticides, and have tested polymers with different characteristics as removing agents. Specifically, we have investigated oligomers of polypropylene (PP), poly(acrylic acid) protonated (PAAH) and deprotonated (PAA), and chitosan protonated (CTH) and deprotonated (CT). It has been found that all oligomers show a certain degree of selectivity concerning the interaction with the tested pesticides.",
           7,
           "chemistryopen"
          ],
          [
           "Thermally Induced Synthesis of Anthracene‐, Pyrene‐ and Naphthalene‐Fused Porphyrins",
           "10.1002/open.202100201",
           2021,
           "The synthesis of π‐extended porphyrins containing anthracenyl moieties still represents an important challenge. Here, we report on the synthesis of a series of unsubstituted naphthyl‐, pyrenyl‐ and anthracenyl‐fused zinc porphyrin derivatives. To this aim, meso‐substitued porphyrins are synthesized and the fusion of the PAHs (Polycyclic Aromatic Hydrocarbon) on the β‐positions are performed through thermally induced dehydro‐aromatization. The fused zinc‐porphyrin derivatives are fully characterized and their optical absorption and photoluminescence properties are reported. We also demonstrate that zinc can be removed from the porphyrin core, giving rise to pure C, H, N materials. This work constitutes the first step towards the synthesis of the fully‐fused tetra‐anthracenylporphyrin.",
           3,
           "chemistryopen"
          ],
          [
           "Wastewater To Resource: Design of a Sustainable Phosphorus Recovery System",
           "10.1002/open.201900189",
           2019,
           "To enable a more sustainable wastewater treatment processes, a transition towards resource recovery methods that have minimal environmental impact while being financially viable is imperative. Phosphorus (P) is a finite resource that is being discharged into the aqueous environment in excessive quantities. As such, understanding the financial and environmental effectiveness of different approaches for removing and recovering P from wastewater streams is important to reduce the overall impact of wastewater treatment. In this study, a process‐systems modelling framework for comprehensively evaluating these approaches in terms of both economic and environmental impacts is developed. Applying this framework, treatment pathways are designed, simulated and analysed to determine the most suitable approaches for P removal and recovery. The purpose of this methodology is not only to assist with plant design, but also to identify the principal economic and environmental factors acting as barriers to implementing a given technology, incorporating the impact of waste recovery. The results suggest that the chemical and ion‐exchange approaches studied deliver sustainable advantages over biological pathways, both economically and environmentally, with each possessing different strengths. The assessment methodology developed enables a more rational and environmentally sound wastewater plant design approach to be taken.",
           9,
           "chemistryopen"
          ],
          [
           "(BEDT‐TTF)<sub>2</sub>Cu<sub>2</sub>(HCOO)<sub>5</sub>: An Organic–Inorganic Hybrid Conducting Magnet",
           "10.1002/open.201700041",
           2017,
           "A dual‐functional organic–inorganic hybrid (BEDT‐TTF)2Cu2(HCOO)5 (1) (BEDT‐TTF=bis(ethylenedithio)tetrathiafulvalene) was obtained through the electrochemical oxidation of neutral BEDT‐TTF in the presence of an ammonium salt of the one‐dimensional copper‐formate framework [(C2H5)3NH]2Cu2(HCOO)5 in a C6H5Cl–C2H5OH solution. Compound 1 was composed of organic donor BEDT‐TTF+0⋅5 in a θ‐phase arrangement and Jahn–Teller distorted (4,4) grid anion sheets [Cu2(HCOO)5‐]n with S=1/2. We identified the material as a semiconductor with values of σ300K=10−1 S cm−1. The anion sheet is a coordination isomer of [Cu2(HCOO)5‐]n and, compared with the starting material, shows antiferromagnetic behavior as the well‐known inorganic Cu−O, Co−O square layers for creating inorganic conducting magnets. Long‐range antiferromagnetic ordering was observed at 8.0 K.",
           3,
           "chemistryopen"
          ],
          [
           "Green and Red Fluorescent Dyes for Translational Applications in Imaging and Sensing Analytes: A Dual‐Color Flag",
           "10.1002/open.201700177",
           2017,
           "Invited for this month's cover picture is the BIOSCOPE group of Professors Carlos Lodeiro and José Luis Capelo at the REQUIMTE/UCIBIO‐LAQv‐FCT University NOVA of Lisbon (Portugal), and their collaborators. The cover picture is devoted to Translational Research, and shows the Portuguese Flag represented by the interaction between cells and Janus gold/silver nanoparticles functionalized with rhodamine (red) and Fluorescein (green) dyes as tools for biomedical translational research. Read the full text of their Review at 10.1002/open.201700135.",
           12,
           "chemistryopen"
          ],
          [
           "The Diels‐Alder Approach towards Cannabinoid Derivatives and Formal Synthesis of Tetrahydrocannabinol (THC)",
           "10.1002/open.202000343",
           2021,
           "Based on the Diels‐Alder reaction of vinylchromenes with electron‐poor dienophiles, we developed a strategy for the synthesis of tetrahydrocannabinol derivatives. Substituted vinyl chromenes could be converted with several dienophiles to successfully isolate several complex molecules. These molecules already contain the cannabinoid‐like base structure and further processing of one such derivative led to a precursor of Δ9‐tetrahydrocannabinol. The most challenging step towards this precursor was an epoxidation step that was ultimately achieved via dimethyl dioxirane.",
           1,
           "chemistryopen"
          ],
          [
           "Does Electron Capture Dissociation Cleave Protein Disulfide Bonds?",
           "10.1002/open.201200038",
           2012,
           "Peptide and protein characterization by mass spectrometry (MS) relies on their dissociation in the gas phase into specific fragments whose mass values can be aligned as ‘mass ladders’ to provide sequence information and to localize possible posttranslational modifications. The most common dissociation method involves slow heating of even‐electron (M+n H)n+ ions from electrospray ionization by energetic collisions with inert gas, and cleavage of amide backbone bonds. More recently, dissociation methods based on electron capture or transfer were found to provide far more extensive sequence coverage through unselective cleavage of backbone NCα bonds. As another important feature of electron capture dissociation (ECD) and electron transfer dissociation (ETD), their unique unimolecular radical ion chemistry generally preserves labile posttranslational modifications such as glycosylation and phosphorylation. Moreover, it was postulated that disulfide bond cleavage is preferred over backbone cleavage, and that capture of a single electron can break both a backbone and a disulfide bond, or even two disulfide bonds between two peptide chains. However, the proposal of preferential disulfide bond cleavage in ECD or ETD has recently been debated. The experimental data presented here reveal that the mechanism of protein disulfide bond cleavage is much more intricate than previously anticipated.",
           40,
           "chemistryopen"
          ],
          [
           "Halogen Bonding in Two‐Dimensional Crystal Engineering",
           "10.1002/open.201900337",
           2020,
           "Halogen bonds, which provide an intermolecular interaction with moderate strength and high directionality, have emerged as a promising tool in the repertoire of non‐covalent interactions. In this review, we provide a survey of the literature where halogen bonding was used for the fabrication of supramolecular networks on solid surfaces. The definitions of, and the distinction between halogen bonding and halogen‐halogen interactions are provided. Self‐assembled networks formed at the solution/solid interface and at the vacuum‐solid interface, stabilized in part by halogen bonding, are discussed. Besides the broad classification based on the interface at which the systems are studied, the systems are categorized further as those sustained by halogen‐halogen and halogen‐heteroatom contacts.",
           96,
           "chemistryopen"
          ],
          [
           "Reaction Mechanisms and Rate Constants of Auto‐Catalytic Urethane Formation and Cleavage Reactions",
           "10.1002/open.202000150",
           2021,
           "The chemistry of urethanes plays a key role in important industrial processes. Although catalysts are often used, the study of the reactions without added catalysts provides the basis for a deeper understanding. For the non‐catalytic urethane formation and cleavage reactions, the dominating reaction mechanism has long been debated. To our knowledge, the reaction kinetics have not been predicted quantitatively so far. Therefore, we report a new computational study of urethane formation and cleavage reactions. To analyze various potential reaction mechanisms and to predict the reaction rate constants quantum chemistry and transition state theory were employed. For validation, experimental data from literature and from own experiments were used. Quantitative agreement of experiments and predictions could be demonstrated. The calculations confirm earlier assumptions that urethane formation reactions proceed via mechanisms where alcohol molecules act as auto‐catalysts. Our results show that it is essential to consider several transition states corresponding to different reaction orders to enable agreement with experimental observations. Urethane cleavage seems to be catalyzed by an isourethane, leading to an observed 2nd‐order dependence of the reaction rate on the urethane concentration. The results of our study support a deeper understanding of the reactions as well as a better description of reaction kinetics and will therefore help in catalyst development and process optimization.",
           12,
           "chemistryopen"
          ],
          [
           "Iron Oxide Nanoparticles: Biosynthesis, Magnetic Behavior, Cytotoxic Effect",
           "10.1002/open.202000186",
           2021,
           "Iron oxide nanoparticles have attracted much attention because of their superparamagnetic properties and their potential applications in many fields such as magnetic storage devices, catalysis, sensors, superparamagnetic relaxometry (SPMR), and high‐sensitivity biomolecule magnetic resonance imaging (MRI) for medical diagnosis and therapeutics. In this study, iron oxide nanoparticles (Fe2O3NPs) have been synthesized using ataranjabin(camelthorn or persian manna) aqueous solution. The synthesized Fe2O3NPs were identified through powder X‐ray diffraction (PXRD), X‐ray photoelectron spectroscopy (XPS), Fourier transform infrared spectroscopy (FT‐IR), field energy scanning electron microscopy (FESEM), transmission electron microscopy (TEM), energy‐dispersive spectroscopy (EDX), vibrating‐sample magnetometer (VSM) and Raman technics. The results show that the nanoparticles have a hexagonal structure with 20 to 60 nm in size. The cytotoxic effect of the synthesized nanoparticles has been tested upon application against lung cancer cell (A549) lines. It was found that there is no cytotoxic activity at lower concentrations of 200 μg/mL. The ability of the synthesized nanoparticles for lead removal in wastewaters was tested. Results show that highest concentration of adsorbent (50 mg/L) has maximum removal efficiency (96.73 %). So, synthesized Fe2O3NPs can be a good candidate to use as heavy metals cleaner from contaminated waters.",
           40,
           "chemistryopen"
          ],
          [
           "Computational Pharmacokinetics Report, ADMET Study and Conceptual DFT‐Based Estimation of the Chemical Reactivity Properties of Marine Cyclopeptides",
           "10.1002/open.202100178",
           2021,
           "Homophymines A–E and A1–E1 are bioactive natural cyclodepsipeptides with a complex molecular architecture. These molecules could have a potential use as antimicrobial, antiviral, and anticancer substances. We have carried out a computational study of the properties of this family of marine peptides using a CDFT‐based Computational Peptidology (CDFT‐CP) methodology that results from the combination of the chemical reactivity descriptors that arise from conceptual Density Functional Theory (CDFT) together with cheminformatics tools. The latter can be used to estimate the associated physicochemical parameters and to improve the process of virtual screening through a similarity search. Using this approach, the ability of the peptides to behave as a potentially useful drugs can be investigated. An analysis of their bioactivity and pharmacokinetics indices related to the ADMET (Absorption, Distribution, Metabolism, Excretion and Toxicity) features has also been carried out.",
           13,
           "chemistryopen"
          ],
          [
           "Interaction of Aluminum Metaphosphates in the Setting of Potassium Silicate Solutions in Terms of the Crystalline Phase Composition.",
           "10.1002/open.202000060",
           2020,
           "Aluminum phosphates are known as inorganic hardening agents for the setting of alkali silicate solutions, but only few studies have been published on the setting mechanism of potassium water glass. The solution behavior of two aluminum metaphosphates in alkaline environments were investigated photometrically determining the dissolved aluminum content. The crystalline phase composition of the hardened potassium silicate systems was determined by X‐ray diffraction. New insights into the setting mechanism were obtained concerning the structure of the aluminum metaphosphate and the SiO2/K2O ratio of three different potassium silicate solutions. With increasing pH value aluminum tetrametaphosphate reacts rapidly and forms crystalline potassium tetrametaphosphate dihydrate by an ion‐exchange‐reaction. In parallel, a depolymerization of the cyclic metaphosphate structure occurs leading to potassium dihydrogen phosphate as final fragmentation product. With aluminum hexametaphosphate no ion‐exchange reaction product was observed. Only potassium dihydrogen phosphate could be found in higher quantities compared to the reaction with aluminum tetrametaphosphate.",
           2,
           "chemistryopen"
          ],
          [
           "Tetrahydropyranyl: A Non‐aromatic, Mild‐Acid‐Labile Group for Hydroxyl Protection in Solid‐Phase Peptide Synthesis",
           "10.1002/open.201600157",
           2017,
           "The use of the tetrahydropyranyl (Thp) group for the protection of serine and threonine side‐chain hydroxyl groups in solid‐phase peptide synthesis has not been widely investigated. Ser/Thr side‐chain hydroxyl protection with this acid‐labile and non‐aromatic moiety is presented here. Although Thp reacts with free carboxylic acids, it can be concluded that to introduce Thp ethers at the hydroxyl groups of N‐protected Ser and Thr, protection of the C‐terminal carboxyl group is unnecessary due to the lability of Thp esters. Thp‐protected Ser/Thr‐containing tripeptides are synthesized and the removal of Thp studied in low concentrations of trifluoroacetic acid in the presence of cation scavengers. Given its general stability to most non‐acidic reagents, improved solubility of its conjugates and ease with which it can be removed, Thp emerges as an effective protecting group for the hydroxyl groups of Ser and Thr in solid‐phase peptide synthesis.",
           4,
           "chemistryopen"
          ],
          [
           "De Novo Modular Development of a Foldameric Protein–Protein Interaction Inhibitor for Separate Hot Spots: A Dynamic Covalent Assembly Approach",
           "10.1002/open.201700012",
           2017,
           "Protein–protein interactions stabilized by multiple separate hot spots are highly challenging targets for synthetic scaffolds. Surface‐mimetic foldamers bearing multiple recognition segments are promising candidate inhibitors. In this work, a modular bottom‐up approach is implemented by identifying short foldameric recognition segments that interact with the independent hot spots, and connecting them through dynamic covalent library (DCL) optimization. The independent hot spots of a model target (calmodulin) are mapped with hexameric β‐peptide helices using a pull‐down assay. Recognition segment hits are subjected to a target‐templated DCL ligation through thiol–disulfide exchange. The most potent derivative displays low nanomolar affinity towards calmodulin and effectively inhibits the calmodulin–TRPV1 interaction. The DCL assembly of the folded segments offers an efficient approach towards the de novo development of a high‐affinity inhibitor of protein–protein interactions.",
           16,
           "chemistryopen"
          ],
          [
           "Manganese‐Zinc Ferrites: Safe and Efficient Nanolabels for Cell Imaging and Tracking In Vivo",
           "10.1002/open.201800261",
           2019,
           "Manganese‐zinc ferrite nanoparticles were synthesized by using a hydrothermal treatment, coated with silica, and then tested as efficient cellular labels for cell tracking, using magnetic resonance imaging (MRI) in vivo. A toxicity study was performed on rat mesenchymal stem cells and C6 glioblastoma cells. Adverse effects on viability and cell proliferation were observed at the highest concentration (0.55 mM) only; cell viability was not compromised at lower concentrations. Nanoparticle internalization was confirmed by transmission electron microscopy. The particles were found in membranous vesicles inside the cytoplasm. Although the metal content (0.42 pg Fe/cell) was lower compared to commercially available iron oxide nanoparticles, labeled cells reached a comparable relaxation rate R2, owing to higher nanoparticle relaxivity. Cells from transgenic luciferase‐positive rats were used for in vivo experiments. Labeled cells were transplanted into the muscles of non‐bioluminescent rats and visualized by MRI. The cells produced a distinct hypointense signal in T2‐ or T2*‐weighted MR images in vivo. Cell viability in vivo was verified by bioluminescence.",
           9,
           "chemistryopen"
          ],
          [
           "Comparison of Iridium(I) Catalysts in Temperature Mediated Hydrogen Isotope Exchange Reactions",
           "10.1002/open.201900204",
           2019,
           "The reactivity and selectivity of iridium(I) catalysed hydrogen isotope exchange (HIE) reactions can be varied by using wide range of reaction temperatures. Herein, we have done a detailed comparison study with common iridium(I) catalysts (1–6) which will help us to understand and optimize the approaches of either high selectivity or maximum deuterium incorporation. We have demonstrated that the temperature window for these studied iridium(I) catalysts is surprisingly very broad. This principle was further proven in some HIE reactions on complex drug molecules.",
           14,
           "chemistryopen"
          ],
          [
           "The Power of Biocatalysis: A One‐Pot Total Synthesis of Rhamnolipids from Butane as the Sole Carbon and Energy Source",
           "10.1002/open.201600127",
           2016,
           "Microbially derived surfactants, so‐called biosurfactants, have drawn much attention in recent years and are expected to replace current petrochemical surfactants, owing to their environmental and toxicological benefits. One strategy to support that goal is to reduce production costs by replacing relatively expensive sugars with cheaper raw materials, such as short‐chain alkanes. Herein, we report the successful one‐pot total synthesis of rhamnolipids, a class of biosurfactants with 12 stereocenters, from butane as sole carbon and energy source through the design of a tailored whole‐cell biocatalyst.",
           15,
           "chemistryopen"
          ],
          [
           "On the Use of Solomon Echoes in <sup>27</sup>Al NMR Studies of Complex Aluminium Hydrides**",
           "10.1002/open.202300011",
           2023,
           "The quadrupole coupling constant CQ and the asymmetry parameter η have been determined for two complex aluminium hydrides from 27Al NMR spectra recorded for stationary samples by using the Solomon echo sequence. The thus obtained data for KAlH4 (CQ=(1.30±0.02) MHz, η=(0.64±0.02)) and NaAlH4 (CQ=(3.11±0.02) MHz, η<0.01) agree very well with data previously determined from MAS NMR spectra. The accuracy with which these parameters can be determined from static spectra turned out to be at least as good as via the MAS approach. The experimentally determined parameters (δiso, CQ and η) are compared with those obtained from DFT‐GIPAW (density functional theory – gauge‐including projected augmented wave) calculations. Except for the quadrupole coupling constant for KAlH4, which is overestimated in the GIPAW calculations by about 30 %, the agreement is excellent. Advantages of the application of the Solomon echo sequence for the measurement of less stable materials or for in situ studies are discussed.",
           0,
           "chemistryopen"
          ],
          [
           "Computational Study of the Fries Rearrangement Catalyzed by Acyltransferase from <i>Pseudomonas protegens</i>",
           "10.1002/open.202300256",
           2024,
           "The acyltransferase from Pseudomonas protegens (PpATase) catalyzes in nature the reversible transformation of monoacetylphloroglucinol to diacetylphloroglucinol and phloroglucinol. Interestingly, this enzyme has been shown to catalyze the promiscuous transformation of 3‐hydroxyphenyl acetate to 2′,4′‐dihydroxyacetophenone, representing a biological version of the Fries rearrangement. In the present study, we report a mechanistic investigation of this activity of PpATase using quantum chemical calculations. A detailed mechanism is proposed, and the energy profile for the reaction is presented. The calculations show that the acylation of the enzyme is highly exothermic, while the acetyl transfer back to the substrate is only slightly exothermic. The deprotonation of the C6−H of the substrate is rate‐limiting, and a remote aspartate residue (Asp137) is proposed to be the general base group in this step. Analysis of the binding energies of various acetyl acceptors shows that PpATase can promote both intramolecular and intermolecular Fries rearrangement towards diverse compounds.",
           0,
           "chemistryopen"
          ],
          [
           "Synthesis and Characterization of Dithiooxamidate-Bridged Polynuclear Ni Complexes",
           "10.3390/chemistry5040150",
           2023,
           "Mixed-valence complexes contain two metals with different formal oxidation numbers and, therefore, show mixed properties that are influenced by the electronic coupling between the two metals, which is, in turn, regulated by a bridging ligand. This is an attractive point for many researchers. Oxalate is widely used as a bridging ligand for preparing polynuclear complexes. More than 1000 complexes have been reported until now. However, dithiooxamidate, which is an oxalate analog, is less popular as a bridging ligand. Here, a new dithiooxamidate-bridged Ni-diphosphine dinuclear complex with the formula [(μ2-toxa){Ni(dppe)}2](BF4)2 (toxa = dithiooxamidate; dppe = 1,2-bis(diphenylphosphino)ethane) was prepared and characterized via single-crystal X-ray diffraction. When using 1,3-bis(diphenylphosphino)propane (dppp) instead of dppe, dinuclear, trinuclear, and tetranuclear complexes were obtained, i.e., [(μ2-toxa){Ni(dppp)}2](BF4)2, [{μ2-Ni(toxa)2}{Ni(dppp)}2](BF4)2, and [{μ3-Ni(toxa)3}{Ni(dppp)}3](BF4)2, respectively. Bidentate toxa ligands in dinuclear complexes coordinate each Ni atom as κ(S,N). However, the trinuclear and the tetranuclear complexes have the toxa ligands with κ(N,N) and κ(S,S) coordination. The [(μ2-toxa){Ni(dppe)}2](BF4)2 complex undergoes four reversible redox processes, whose analysis via a controlled-potential absorption spectrum reveals the presence of a Ni(II)-Ni(I) mixed-valence state at ∆E1/2 = 0.22 V with a comproportionation constant of 6.1 × 103.",
           0,
           "chemistry"
          ],
          [
           "Structures of Three Alkaline-Earth Metal Germanides Refined from Single-Crystal X-ray Diffraction Data",
           "10.3390/chemistry4040094",
           2022,
           "The calcium- and strontium- alumo-germanides SrxCa1–xAl2Ge2 (x ≈ 0.4) and SrAl2Ge2 have been synthesized and structurally characterized. Additionally, a binary calcium germanide CaGe has also been identified as a byproduct. All three crystal structures have been established from single-crystal X-ray diffraction methods and refined with high accuracy and precision. The binary CaGe crystallizes with a CrB-type structure in the orthorhombic space group Cmcm (no. 63; Z = 4; Pearson symbol oC8), where the germanium atoms are interconnected into infinite zigzag chains, formally [Ge]2−. The calcium atoms are arranged in monocapped trigonal prisms, centered by Ge atoms. SrxCa1−xAl2Ge2 (x ≈ 0.4) and SrAl2Ge2 have been confirmed to crystallize with a CaAl2Si2-type structure in the trigonal space group P3¯m1 (no. 164; Z = 1; Pearson symbol hP5), where the germanium and aluminum atoms form puckered double-layers, formally [Al2Ge2]2−. The calcium atoms are located between the layers and reside inside distorted octahedra of Ge atoms. All presented structures have a valence electron count satisfying the octet rules (e.g., Ca2+Ge2− and Ca2+[Al2Ge2]2−) and can be regarded as Zintl phases.",
           2,
           "chemistry"
          ],
          [
           "Enantiopure Cyclometalated Rh(III) and Ir(III) Complexes Displaying Rigid Configuration at Metal Center: Design, Structures, Chiroptical Properties and Role of the Iodide Ligand",
           "10.3390/chemistry4010014",
           2022,
           "Enantiopure N-heterocyclic carbene half-sandwich metal complexes of the general formula [Cp*M(C^C:)I] (M = Rh, Ir; C^C: = NI-NHC; NI-H = Naphthalimide; NHC = N-heterocyclic carbene) are reported. The rhodium compound was obtained as a single isomer displaying six membered metallacycle and was resolved on chiral column chromatography to the corresponding enantiomers (S)-[Cp*Rh(C^C:)I] (S)-2 and (R)-[Cp*Rh(C^C:)I] (R)-2. The iridium congener, however, furnishes a pair of regioisomers, which were resolved into (S)-[Cp*Ir(C^C:)I] (S)-3 and (R)-[Cp*Ir(C^C:)I] (R)-3 and (S)-[Cp*Ir(C^C:)I] (S)-4 and (R)-[Cp*Ir(C^C:)I] (R)-4. These regioisomers differ from each other, only by the size of the metallacycle; five-membered for 3 and six-membered for 4. The molecular structures of (S)-2 and (S)-4 are reported. Moreover, the chiroptical properties of these compounds are presented and discussed. These compounds display exceptional stable configurations at the metal center in solution with enantiomerization barrier ΔG≠ up to 124 kJ/mol. This is because the nature of the naphthalimide-NHC clamp ligand and the iodide ligand contribute to their configuration’s robustness. In contrast to related complexes reported in the literature, which are often labile in solution.",
           0,
           "chemistry"
          ],
          [
           "A Brucite-Like Mixed-Valent Cluster Capped by [MnIIIp-tBu-calix[4]arene]− Moieties",
           "10.3390/chemistry2020016",
           2020,
           "p-tBu-calix[4]arene (H4TBC[4]) has proven to be an incredibly versatile ligand for the synthesis of 3d- and 3d/4f- clusters, in particular those containing mixed-valent Mn ions. These are of interest to the magnetochemist for the diversity of magnetic behaviours that can be shown, along with a huge variety of nuclearities and topologies accessible, which allow one to outline magneto-structural correlations and a quantitative understanding of their properties. This contribution reports the synthesis, analysis and magnetic properties of a Brucite-like Mn-oxo/hydroxo octanuclear fragment encapsulated within/capped by four [MnIII-TBC[4]]− moieties. A diol coligand in the reaction mixture plays a seemingly important role in determining the outcome, though it is not incorporated in the final structure.",
           2,
           "chemistry"
          ],
          [
           "Comparison of the Molecular Properties of Euglobals Differing by the Mutual Positions of the Two R–C=O Groups (R = H and CH2CH(CH3)2): A Computational Study",
           "10.3390/chemistry5040144",
           2023,
           "Euglobals are a subclass of acylphloroglucinols, mostly found in plants of the Eucalyptus genus. They possess anticancer activity, being potent inhibitors of the Epstein–Barr virus activation. Their molecules can be viewed as acylphloroglucinol monoterpene or sesquiterpene adducts, with the former having greater activity than the latter. The acylphloroglucinol moiety contains two mutually meta acyl (R–C=O) groups, respectively, in ortho and meta positions with respect to the two C atoms shared by the two moieties. The current work focuses on euglobal molecules in which R = H is in one acyl group and R = isobutyl is in the other. It aims to identify the property differences between molecules having the same terpene moiety and the two acyl groups in reversed positions. Ten such pairs were studied computationally using different levels of theory (HF, DFT, and MP2). The results highlight considerable differences between the two molecules of each pair, regarding molecular features such as relative energies, characteristics of the intramolecular hydrogen bonds (IHBs), dipole moment, bond vibrational frequencies, and frequency changes caused by the IHBs. A comparison of the results from the different levels of theory utilised shows similar patterns for the influence of position reversal on the same characteristic.",
           0,
           "chemistry"
          ],
          [
           "Structural Elucidation of Enantiopure and Racemic 2-Bromo-3-Methylbutyric Acid",
           "10.3390/chemistry2030044",
           2020,
           "Halogenated carboxylic acids have been important compounds in chemical synthesis and indispensable research tools in biochemical studies for decades. Nevertheless, the number of structurally characterized simple α-brominated monocarboxylic acids is still limited. We herein report the crystallization and structural elucidation of (R)- and rac-2-bromo-3-methylbutyric acid (2-bromo-3-methylbutanoic acid, 1) to shed light on intermolecular interactions, in particular hydrogen bonding motifs, packing modes and preferred conformations in the solid-state. The crystal structures of (R)- and rac-1 are revealed by X-ray crystallography. Both compounds crystallize in the triclinic crystal system with Z = 2; (R)-1 exhibits two crystallographically distinct molecules. In the crystal, (R)-1 forms homochiral O–H···O hydrogen-bonded carboxylic acid dimers with approximate non-crystallographic C2 symmetry. In contrast, rac-1 features centrosymmetric heterochiral dimers with the same carboxy syn···syn homosynthon. The crystal packing of centrosymmetric rac-1 is denser than that of its enantiopure counterpart (R)-1. The molecules in both crystal structures adopt a virtually identical staggered conformation, despite different crystal environments, which indicates a preferred molecular structure of 1. Intermolecular interactions apart from classical O–H···O hydrogen bonds do not appear to have a crucial bearing on the solid-state structures of (R)- and rac-1.",
           1,
           "chemistry"
          ],
          [
           "Controlled Stepwise Synthesis and Characterization of a Ternary Multicomponent Crystal with 2-Methylresorcinol",
           "10.3390/chemistry2010009",
           2020,
           "A typical approach of a multicomponent crystal design starts with a retrosynthetic analysis of the target molecule followed by a one-pot reaction of all components. To develop protocols for multicomponent crystal syntheses, controlled stepwise syntheses of a selected crystalline ternary multicomponent system 1 involving 2-methylresorcinol (MRS), tetramethyl-pyrazine (TMP), and 1,2-bis(4-pyridyl)ethane (BPE) are presented. The obtained binary cocrystals 2 (involving MRS and TMP) and 3 (involving MRS and BPE) as well as the final resulting ternary multicomponent system 1 were characterized by X-ray analysis.",
           3,
           "chemistry"
          ],
          [
           "Production of Alkyl Levulinates from Carbohydrate-Derived Chemical Intermediates Using Phosphotungstic Acid Supported on Humin-Derived Activated Carbon (PTA/HAC) as a Recyclable Heterogeneous Acid Catalyst",
           "10.3390/chemistry5020057",
           2023,
           "This work reports a straightforward and high-yielding synthesis of alkyl levulinates (ALs), a class of promising biofuel, renewable solvent, and chemical feedstock of renewable origin. ALs were prepared by the acid-catalyzed esterification of levulinic acid (LA) and by the alcoholysis of carbohydrate-derived chemical platforms, such as furfuryl alcohol (FAL) and α-angelica lactone (α-AGL). Phosphotungstic acid (PTA) was chosen as the solid acid catalyst for the transformation, which was heterogenized on humin-derived activated carbon (HAC) for superior recyclability. Using HAC as catalyst support expands the scope of valorizing humin, a complex furanic resin produced inevitably as a side product (often considered waste) during the acid-catalyzed hydrolysis/dehydration of sugars and polymeric carbohydrates. Under optimized conditions (150 °C, 7 h, 25 wt.% of 20%PTA/HAC-600 catalyst), ethyl levulinate (EL) was obtained in an 85% isolated yield starting from FAL. Using the general synthetic protocol, EL was isolated in 88% and 84% yields from LA and α-AGL, respectively. The 20%PTA/HAC-600 catalyst was successfully recovered from the reaction mixture and recycled for five cycles. A marginal loss in the yield of ALs was observed in consecutive catalytic cycles due to partial leaching of PTA from the HAC support.",
           0,
           "chemistry"
          ],
          [
           "Lattice Dynamics of KAgF3 Perovskite, Unique 1D Antiferromagnet",
           "10.3390/chemistry3010007",
           2021,
           "Theoretical DFT calculations using GGA+U and HSE06 frameworks enabled vibrational mode assignment and partial (atomic) phonon DOS determination in KAgF3 perovskite, a low-dimensional magnetic fluoroargentate(II). Twelve bands in the spectra of KAgF3 were assigned to either IR active or Raman active modes, reaching excellent correlation with experimental values (R2 > 0.997). Low-temperature Raman measurements indicate that the intriguing spin-Peierls-like phase transition at 230 K is an order–disorder transition and it does not strongly impact the vibrational structure of the material.",
           6,
           "chemistry"
          ],
          [
           "Oxidative Repair of Pyrimidine Cyclobutane Dimers by Nitrate Radicals (NO3•): A Kinetic and Computational Study",
           "10.3390/chemistry2020027",
           2020,
           "Pyrimidine cyclobutane dimers are hazardous DNA lesions formed upon exposure of DNA to UV light, which can be repaired through oxidative electron transfer (ET). Laser flash photolysis and computational studies were performed to explore the role of configuration and constitution at the cyclobutane ring on the oxidative repair process, using the nitrate radical (NO3•) as oxidant. The rate coefficients of 8–280 × 107 M−1 s−1 in acetonitrile revealed a very high reactivity of the cyclobutane dimers of N,N’-dimethylated uracil (DMU), thymine (DMT), and 6-methyluracil (DMU6-Me) towards NO3•, which likely proceeds via ET at N(1) as a major pathway. The overall rate of NO3• consumption was determined by (i) the redox potential, which was lower for the syn- than for the anti-configured dimers, and (ii) the accessibility of the reaction site for NO3•. In the trans dimers, both N(1) atoms could be approached from above and below the molecular plane, whereas in the cis dimers, only the convex side was readily accessible for NO3•. The higher reactivity of the DMT dimers compared with isomeric DMU dimers was due to the electron-donating methyl groups on the cyclobutane ring, which increased their susceptibility to oxidation. On the other hand, the approach of NO3• to the dimers of DMU6-Me was hindered by the methyl substituents adjacent to N(1), making these dimers the least reactive in this series.",
           0,
           "chemistry"
          ],
          [
           "Current Density and Spectroscopy—A Themed Issue in Honor of Professor Riccardo Zanasi on the Occasion of His 70th Birthday",
           "10.3390/chemistry4010010",
           2022,
           "It is our great pleasure to introduce the Festschrift of Chemistry to honor Professor Riccardo Zanasi (Figure 1) on the occasion of his 70th birthday and to recognize his important contributions to quantum chemistry, particularly in the field of magnetic response and chiroptical spectroscopies [...]",
           0,
           "chemistry"
          ],
          [
           "DNA-Based Mechanical Sensors for Cell Applications",
           "10.3390/chemistry5030106",
           2023,
           "Cells constantly experience mechanical forces during growth and development. Increasing evidence suggests that mechanical forces can regulate cellular processes such as proliferation, migration, and differentiation. Therefore, developing new tools to measure and manipulate cellular mechanical forces is essential. DNA nanostructures, due to their simple design and high programmability, have been utilized to create various mechanical sensors and have become a key tool for studying mechanical information in both cellular and non-cellular systems. In this article, we review the development of DNA-based mechanical sensors and their applications in measuring mechanical forces in the extracellular matrix and cell–cell interactions and summarize the latest advances in monitoring and manipulating cellular morphology and function. We hope that this review can provide insights for the development of new mechanical nanodevices.",
           2,
           "chemistry"
          ],
          [
           "Molecular Modeling Based on Time-Dependent Density Functional Theory (TD-DFT) Applied to the UV-Vis Spectra of Natural Compounds",
           "10.3390/chemistry5010004",
           2022,
           "As diseases caused by solar radiation have gained great prominence, several methods to prevent them have been developed. Among the most common, the use of sunscreens is customary and accessible. The application of theoretical methods has helped to design new compounds with therapeutic and protective functions. Natural compounds with described photoprotective potential properties (3-O-methylquercetin, gallic acid, aloin, catechin, quercetin, and resveratrol) were selected to perform theoretical studies. Computational methods were applied to predict their absorption spectra, using DFT and TD-DFT methods with functional B3LYP/6−311+g(d,p) basis sets and methanol (IEFPCM) as a solvent. The main electronic transitions of the compounds were evaluated by observing whether the differences in HOMO and LUMO energies that absorb in the UV range are UVA (320–400 nm), UVB (290–320 nm), or UVC (100–290 nm). Experimental validation was carried out for EMC, quercetin, and resveratrol, demonstrating the consistency of the computational method. Results obtained suggest that resveratrol is a candidate for use in sunscreens. The study provided relevant information about the in silico predictive power of natural molecules with the potential for use as photoprotective adjuvants, which may result in fewer time and resource expenditures in the search for photoprotective compounds.",
           2,
           "chemistry"
          ],
          [
           "Constructing a Triangle Ensemble of Pt Clusters for Enhanced Direct-Pathway Electrocatalysis of Formic Acid Oxidation",
           "10.3390/chemistry5030111",
           2023,
           "The pursuit of operational advancements in direct formic acid fuel cells (DFAFCs) necessitates the development of high-performance platinum (Pt)-based catalysts for formic acid electrooxidation (FAOR). However, FAOR on Pt-based catalysts follows a dual pathway mechanism, in which the direct pathway is a preferred route due to its efficient dehydrogenation process. Conversely, the indirect pathway results in the generation of adsorbed CO species, a process that deleteriously poisons the active sites of the catalyst, with CO species only being oxidizable at higher potentials, causing a significant compromise in catalyst performance. Herein, we have successfully synthesized Pt-C3N4@CNT, where three Pt clusters are precisely dispersed in a triplet form within the C3N4 by virtue of the unique structure of C3N4. The mass activity for the direct pathway (0.44 V) delivered a current density of 1.91 A mgPt−1, while the indirect pathway (0.86 V) had no obvious oxidation peak. The selectivity of Pt-C3N4@CNT catalysts for the direct pathway of FAOR was improved due to the special structure of C3N4, which facilitates the dispersion of Pt tri-atoms in the structure and the electronic interaction with Pt. In this study, we provide a new strategy for the development of highly active and selective catalysts for DFAFCs.",
           1,
           "chemistry"
          ],
          [
           "Expanding the Scope of Asinger Chemistry towards Enantiomerically Pure Secondary Amines and β-Aminothiols through Chemoenzymatic Derivatization of 3-Thiazolines",
           "10.3390/chemistry1010012",
           2019,
           "A proof of concept for a novel approach towards enantiomerically highly enriched acyclic secondary amines and β-aminothiols as non-cyclic target molecules when starting from 3-thiazolines as heterocycles is presented. Starting from 2,2,4,5,5-pentamethyl-3-thiazoline, we demonstrated this chemoenzymatic pathway to both of these types of amine molecules, which were isolated as urea derivatives with a non-optimized yield of up to 20%. As a substrate, 2,2,4,5,5-pentamethyl-3-thiazolidine, which was obtained with an enantiomeric excess (ee) of 99% in a biotransformation from the corresponding 3-thiazoline according to a recently developed protocol, was used. For the reductive desulfurization of this substrate leading to a sulfur-free secondary amine, in situ formed Ni2B turned out to be a suitable reducing reagent. However, when using lithium aluminum hydride as a reducing agent, β-aminothiol was obtained.",
           0,
           "chemistry"
          ],
          [
           "New Bi-Nuclear Nickel(II) Complex-Based Salen Schiff Base: Synthesis, Crystal Structure, Spectroscopic, Thermal, and Electrical Investigations",
           "10.3390/chemistry4040080",
           2022,
           "In this study, a new bi-nuclear nickel complex [Ni2HL2(EtOH)2](Cl)(EtOH) of a Schiff base ligand, 2-[3-[2-hydroxybenzylideneamino]propyliminomethyl]phenol, was synthesized and characterized using UV/Vis, IR, HRMS, and TGA/DTA analysis. The molecular structure of the obtained complex was corroborated by the single crystal X-ray diffraction technique. It was found in the complex that two molecules of the ligand coordinate with two nickel atoms through azomethine-N and phenoxy-O, resulting in 6-coordinate distorted octahedral geometry, in which two ethanol molecules occupy the axial positions. The dielectric and electrical properties of the obtained samples were studied by impedance spectroscopy at different frequencies (from 1 Hz to 1 MHz) in the temperature range 298–343 K. It is found that the electrical conductivity of the Ni(II) complex is lower than that of the free ligand H2L, suggesting that the complexation traps the charge carriers contained in the ligand.",
           0,
           "chemistry"
          ],
          [
           "On the Aromaticity and 13C-NMR Pattern of Pentagonal-Pyramidal Hexamethylbenzene Dication [C6(CH3)6]2+: A {C5(CH3)5}−–{CCH3}3+ Aggregate",
           "10.3390/chemistry3040097",
           2021,
           "The experimentally characterized hexamethylbenzene dication C6(CH3)62+ shows a pentagonal-pyramidal structure involving a carbon-capped five-membered ring. The structural characterization of this hypercoordination (or hypervalency) gives rise if the aromatic behavior remains in the resulting pentagon ring. Here, we investigated the induced magnetic field of C6(CH3)62+ to gain a deeper understanding of the resulting non-classical structural situation in a representative pentagonal-pyramidal structure. Our results support the view of a C5(CH3)5−/CCH33+ structure, depicting a π-aromatic pentamethylcyclopentadienyl anion with a 6π-electron kernel, with a capped carbon which does not decrease the characteristic shielding cone property of the aromatic ring. Hence, carbon-capped rings are suggested to retain the aromatic behavior from the former aromatic ring. We expect that the analysis of both the overall magnetic response and NMR chemical shifts may be informative to unravel the characteristic patterns in the formation of hypervalent carbon atoms involving non-classical chemical environments.",
           1,
           "chemistry"
          ],
          [
           "Hydroquinone-Based Anion Receptors for Redox-Switchable Chloride Binding",
           "10.3390/chemistry1010007",
           2019,
           "A series of chloride receptors has been synthesized containing an amide hydrogen bonding site and a hydroquinone motif. It was anticipated that oxidation of the hydroquinone unit to quinone would greatly the diminish chloride binding affinity of these receptors. A conformational switch is promoted in the quinone form through the formation of an intramolecular hydrogen bond between the amide and the quinone carbonyl, which blocks the amide binding site. The reversibility of this oxidation process highlighted the potential of these systems for use as redox-switchable receptors. 1H-NMR binding studies confirmed stronger binding capabilities of the hydroquinone form compared to the quinone; however, X-ray crystal structures of the free hydroquinone receptors revealed the presence of an analogous inhibiting intramolecular hydrogen bond in this state of the receptor. Binding studies also revealed interesting and contrasting trends in chloride affinity when comparing the two switch states, which is dictated by a secondary interaction in the binding mode between the amide carbonyl and the hydroquinone/quinone couple. Additionally, the electrochemical properties of the systems have been explored using cyclic voltammetry and it was observed that the reduction potential of the system was directly related to the expected strength of the internal hydrogen bond.",
           7,
           "chemistry"
          ],
          [
           "Towards High Efficacy of Pd-Au/C Catalyst for Tetrachloromethane Hydrodechlorination",
           "10.3390/chemistry3010025",
           2021,
           "We present an efficient strategy for synthesising the PdAu catalysts with a homogeneous PdAu alloy phase for environmentally important hydrodechlorination of tetrachloromethane in the gas phase. The synthesis of carbon-supported catalysts involved two major steps: (i) incorporation of palladium and gold nanoparticles into carbon support and (ii) activation of the catalysts. The critical part of this work was to find the optimal conditions for both steps. Thus, the incorporation of the nanoparticles was carried out in two ways, by impregnation and direct redox reaction method using acetone solutions of metal precursor salts. The activation was performed either by a conventional thermal reduction in hydrogen or flash irradiation in a microwave oven. The homogeneity and structure of the PdAu alloy were found to depend on the catalyst activation method critically. In all cases, we observed better homogeneity for catalysts that were subject to microwave irradiation. Moreover, the flash microwave irradiation of prepared catalysts provided catalysts of better stability and selectivity towards the desired products (hydrocarbons) in the hydrodechlorination of tetrachloromethane as compared to the catalyst obtained by conventional thermal activation in hydrogen.",
           1,
           "chemistry"
          ],
          [
           "In Situ FBG Monitoring of a Henequen-Epoxy Biocomposite: From Manufacturing to Performance",
           "10.3390/chemistry4020028",
           2022,
           "This work reports the in situ instrumentation from manufacturing to loading of a henequen fiber woven-bioepoxy composite. Continuous monitoring was performed by means of fiber Bragg gratings (FBG) with the aim of tracking the curing behavior of the biolaminate by vacuum-assisted resin infusion (VARI). The instrumented composite was later tested mechanically under bending. Among the results obtained, micro-deformations were detected as a consequence of curing residual stresses, and when tested, the FBG data had similarity with the strain calculated according to the ASTM D7264/D7264M standard.",
           1,
           "chemistry"
          ],
          [
           "Revisiting the Impact of Tungsten on the Catalytic Properties of Ammonia-SCR V2O5-WO3/TiO2 Catalysts: Geometric vs. Electronic Effects",
           "10.3390/chemistry5010023",
           2023,
           "The SCR performance of V2O5-WO3/TiO2 SCR-catalysts characterized by different surface W density (2.1W/nm2 and 9.5W/nm2) and different surface V density varying in the range 1–8V/nm2 has been investigated in order to clarify existing controversies on the preferential involvement of electronic and geometric effects in the catalytic properties. It was found that tungsten has a weak effect on the VOx cluster size distribution through contraction of dilution effect. In contrast, the optimal interaction between W and V, when both reach their highest composition, appears to be a relevant parameter that can enhance their acidic properties and improve the catalytic efficiency in dry conditions. On the other hand, an absence of significant interaction leads to discontinuity due to deactivation. In the presence of steam, acidic properties are averaged, lowering the impact of the V to W ratio. Finally, the critical importance of acidic properties which outperform redox properties in the definition of active site is pointed out in the light of this study.",
           0,
           "chemistry"
          ],
          [
           "Conversion Study on the Formation of Mechanochemically Synthesized BaTiO3",
           "10.3390/chemistry4020042",
           2022,
           "Mechanochemistry is a method that can cover the energy demand of reaction pathways between solid materials. This requires enough energy to maintain the reactions between the starting materials. This is called “high-energy milling”. In our case, a planetary ball mill provided the required energy. Using the Burgio-equation, the required energy is determinable; the energy released during a single impact of a milling ball (Eb), as well as during the whole milling process (Ecum). The aim of this work was the one-step production of BaTiO3 from BaO and TiO2 starting materials. Whereas during mechanochemical reactions it is possible to produce nanoparticles of up to 10 nm, the essence of this study is to develop the preparation of BaTiO3 with a perovskite structure even without subsequent heat treatment, since sintering at high temperatures is associated with a rapid increase in the size of the particles. By describing the synthesis parameters and their energy values (Eb and Ecum), it is possible to transpose experimental conditions, so that in the case of other types of planetary ball mills or grinding vessel made of other materials, the results can be used. In this study, the mechanical treatment was carried out with a Fritsch Pulverisette-6 planetary ball mill and the transformation of the starting materials was investigated by X-ray diffractometric, Raman and Energy-dispersive X-ray spectroscopic, and transmission electron microscopic measurements.",
           1,
           "chemistry"
          ],
          [
           "The Dielectric Behavior of Protected HKUST-1",
           "10.3390/chemistry4020041",
           2022,
           "We investigated the adsorption properties and the dielectric behavior of a very well-known metal-organic framework (MOF), namely Cu3(BTC)2 (known as HKUST-1; BTC = 1,3,5-benzenetricarboxylate), before and after protection with some amines. This treatment has the purpose of reducing the inherent hygroscopic nature of HKUST-1, which is a serious drawback in its application of as low-dielectric-constant (low-κ) material. Moreover, we investigated the structure of HKUST-1 under a strong electric field, confirming the robustness of the framework. Even under dielectric perturbation, the water molecules adsorbed by the MOF remained almost invisible to X-ray diffraction, apart from those directly bound to the metal ions. However, the replacement of H2O with a more visible guest molecule such as CH2Br2 made the cavity that traps the guest more visible. Finally, in this work we demonstrate that impedance spectroscopy is a valuable tool for identifying water sorption in porous materials, providing information that is complementary to that of adsorption isotherms.",
           0,
           "chemistry"
          ],
          [
           "Solid State Fabrication of Copper Nanoclusters and Supraparticles",
           "10.3390/chemistry5030134",
           2023,
           "In this study, we present solid state processes for the fabrication of copper nanoclusters (NCs) and hierarchical supraparticles (SPs). To achieve this, copper salt and thiols are mixed and are then grinded for 10–15 min, and the nano-products are thereby obtained. Interestingly, it was found in this study that the formation of the NCs or SPs is completely dependent on the grinding methods that are used: with mechanical grinding, the products are several nanometer-sized NCs, whereas manual grinding in an agate mortar can obtain Cu SPs with diameters as low as 10 nm all the way up to 200 nm. The photoluminescence emission wavelength of the nano-products is located at ~680 nm. The Stokes shift of the obtained nanomaterials is more than 300 nm. The emission quantum yields of the Cu NCs and SPs are as high as 47.5% and 63%, respectively. Due to their facile fabrication processes and their favorable optical properties, the two as-prepared types of copper nano-materials exhibit great potential for bio-imaging and bio-sensing applications.",
           0,
           "chemistry"
          ],
          [
           "Heteroditopic Rotaxanes and Catenanes for Ion Pair Recognition",
           "10.3390/chemistry5010009",
           2023,
           "A review of heteroditopic interlocked molecules and their application as receptors for simple inorganic ion pair species. The review details the design and ion recognition properties of the rotaxane and catenane receptors, as well as highlighting some of the experimental challenges; hence, it provides insight into possible future avenues of research in this youthful field.",
           3,
           "chemistry"
          ],
          [
           "Synthesis and Self-Assembling Properties of Peracetylated β-1-Triazolyl Alkyl D-Glucosides and D-Galactosides",
           "10.3390/chemistry3030068",
           2021,
           "Carbohydrate-based low-molecular-weight gelators (LMWGs) are useful classes of compounds due to their numerous applications. Among sugar-based LMWGs, certain peracetylated sugar beta-triazole derivatives were found to be effective organogelators and showed interesting self-assembling properties. To further understand the structural influence towards molecular assemblies and obtain new functional materials with interesting properties, we designed and synthesized a library of tetraacetyl beta-1-triazolyl alkyl-D-glucosides and D-galactosides, in which a two or three carbon spacer is inserted between the anomeric position and the triazole moiety. A series of 16 glucose derivatives and 14 galactose derivatives were synthesized and analyzed. The self-assembling properties of these new triazole containing glycoconjugates in different solvents were analyzed. Several glucose derivatives were found to be effective LMWGs, with compound 7a forming gels in a variety of organic solvents as well as in the presence of metal ions in aqueous solutions. The organogels formed by several compounds were characterized using optical microscopy, atomic force microscopy (AFM) and UV-vis spectroscopy, etc. The co-gels formed by compound 7a with the Fmoc derivative 7i showed interesting fluorescence enhancement upon gelation. Several gelators were also characterized using powder X-ray diffraction and FT-IR spectroscopy. The potential applications of these sugar-based gelators for drug delivery and dye removal were also studied.",
           3,
           "chemistry"
          ],
          [
           "New Polymorph of β-Cyclodextrin with a Higher Bioavailability",
           "10.3390/chemistry6010003",
           2023,
           "A new polymorph of anhydrous β-cyclodextrin (polymorph III) was obtained and characterized for the first time using powder X-ray diffraction, infrared spectroscopy, and thermal analysis. The solution enthalpy and time of dissolution in water were determined using solution calorimetry for this polymorph and compared with those of the dried commercial form of β-cyclodextrin (polymorph I), its amorphous form, and 2-hydroxypropyl-β-cyclodextrin. The specific heat capacities of polymorphs I and III were determined using differential scanning calorimetry across a wide range of temperatures, providing enthalpy and Gibbs energy values for the polymorphic transition at 298 K. The affinities of polymorph III and 2-hydroxypropyl-β-cyclodextrin for water were characterized by determining their hydration isotherms, which provided values of hydration Gibbs energy. Being energy-rich, the new-found polymorph of β-cyclodextrin has a significantly higher dissolution rate and an increased affinity for water compared with the dried commercial form of β-cyclodextrin. These properties render the new polymorph promising in industrial applications for guest inclusion in aqueous solutions and pastes, and may be a desirable alternative for water-soluble β-cyclodextrin derivatives.",
           0,
           "chemistry"
          ],
          [
           "Magnetic Aromaticity of Cycloporphyrin Nanorings",
           "10.3390/chemistry3030071",
           2021,
           "The ascertainment of magnetic aromaticity is not necessarily straightforward, especially for large and bent systems, such as the cycloporphyrin nanorings recently synthesized by the group of Anderson. Six of these cycloporphyrin nanorings were studied here computationally. Indirect methods, based on nuclear shielding and magnetizabilities, and direct methods, based on standard quantum mechanics, were both used effectively to determine their magnetically induced current strength, which mostly confirmed Anderson’s classification. However, in the case of hexanions, and in particular for cyclohexaporphyrin hexacations, a significant cancellation of delocalized diatropic and paratropic flow occurred, showing that the resultant faint aromatic character was a result of competing aromatic and antiaromatic contributions, as also evidenced by the ipsocentric method. A warning is renewed on the use of isotropic shielding to determine the tropicity of the magnetically induced current.",
           6,
           "chemistry"
          ],
          [
           "Phosphine Functionalized CpC Ligands and Their Metal Complexes",
           "10.3390/chemistry5020062",
           2023,
           "Simple nucleophilic aliphatic substitution gives access to mono- and diphosphine ligands with a CpC group in the backbone. The monophosphine ligand coordinates to gold(I) via the phosphine site, to thallium(I) via the cyclopentadienyl site and to ruthenium(II) via a combination of both, resulting in an ansa-type structure. Coordination with the cyclopentadiene site is not possible for the diphosphine ligand. In this case, monodentate coordination to gold(I) and bidentate coordination to the [PdCl(μ2-Cl)]2, the [Rh(CO)(μ2-Cl)]2, and the Rh(CO)Cl fragment is observed, showing the variability in coordination modes possible for the long-chain diphosphine ligand. Ligands and complexes were characterized by means of NMR and IR spectroscopy, elemental analysis and X-ray structure analysis.",
           0,
           "chemistry"
          ],
          [
           "Using Imidazolium in the Construction of Hybrid 2D and 3D Lead Bromide Pseudoperovskites",
           "10.3390/chemistry5020090",
           2023,
           "The field of hybrid organic–inorganic perovskite materials continues to attract the interest of the scientific community due to their fascinating properties and the plethora of promising applications in photovoltaic and optoelectronic devices. To enhance the efficiency and stability of perovskite-based devices, it is essential to discover novel compounds but also to investigate their various physicochemical, structural, and thermal properties. In this work, we report the synthesis and structural characterization of two novel hybrid lead bromide perovskites, combining the imidazolium cation (IMI) with methylammonium (MA) or formamidinium (FA) cations. The isolated polycrystalline powders were studied with X-ray powder diffraction (XPRD) and were formulated as (IMI)(MA)Pb2Br6, a 3D structure consisting of dimers of face-sharing octahedra linked in corner-sharing mode, and (IMI)(FA)PbBr4, a 2D (110) oriented layer structure with zig-zag corner-sharing octahedra. The thermal stability of (IMI)(MA)Pb2Br6 and (IMI)(FA)PbBr4 was investigated with thermogravimetric (TG) and differential scanning calorimetry (DSC) experiments which showed that both compounds are chemically stable (at least) up to 250 °C. Variable-temperature X-ray diffractometric (VT-XRD) studies of (IMI)(FA)PbBr4 highlighted a structural modification occurring above 100 °C, that is a phase transformation from triclinic to orthorhombic, via an elusive monoclinic phase.",
           0,
           "chemistry"
          ],
          [
           "Aromaticity of Heterocirculenes",
           "10.3390/chemistry3040102",
           2021,
           "This review summarizes the results on the aromaticity of a series of synthesized and hypothetical neutral heterocirculene molecules and their double charged ions. The aromaticity of heterocirculenes is a direct reflection of their electronic structure responsible for the specific optoelectronic and photophysical properties. We show how the presence of a heteroatom in the outer macrocycle affects the aromaticity of hetero[8]circulenes. In addition, we also describe the change in aromaticity and strain energy for a series of the “lower” (n < 8) and “higher” (n > 8) hetero[n]circulenes. It was demonstrated that the loss of planarity with increased strain leads to an increased antiaromaticity of the lower hetero[n]circulenes, whereas higher hetero[n]circulenes demonstrate a more pronounced aromatic nature because of the small departure from planarity of each heteroarene ring in hetero[n]circulene molecule. Finally, we discuss the aromatic nature of the first examples of π-extended hetero[8]circulenes.",
           10,
           "chemistry"
          ],
          [
           "Construction of an ATP-Activated Y-Shape DNA Probe for Smart miRNA Imaging in Living Cells",
           "10.3390/chemistry5030112",
           2023,
           "A stringent DNA probe to profile microRNA (miRNA) expression within a specific cell remains a key challenge in biology. To address this issue, an intracellular ATP-activated Y-DNA probe for accurate imaging of miRNA in living cells was designed. Y-DNA was based on the fabrication of tripartite function modules, which consisted of a folate (FA)-modified targeting module, an ATP aptamer-sealed driver, and a miRNA sensing module. The Y-DNA probe could be specifically activated by ATP after it efficiently internalized into FA-receptor-overexpressed cells based on caveolar-mediated endocytosis, leading to the activation of the miRNA sensing module. The activated Y-DNA probe allowed for the imaging of miRNA in living cells with high sensitivity. The design of the ATP-activated Y-DNA sensor opens the door for bioorthogonal miRNA imaging and promotes the development of various responsive DNA molecular probes with enhanced anti-interference ability for clinical diagnosis.",
           0,
           "chemistry"
          ],
          [
           "Are Metallacyclopentadienes Always Non-Aromatic?",
           "10.3390/chemistry3040094",
           2021,
           "Even though metallacyclopentadienes (MCPs) are among the most common metallacycles, their electron delocalization (aromaticity) has received far less attention than other metallacycles, such as metallabenzenes. We systematically studied the aromaticity of MCPs with energetic (isomerization stabilization energy), density (delocalization index) and magnetic (current density) aromaticity indices. The indices agree that metallacyclopentadienes are, in general, weakly aromatic at most. The 18e− complexes showed the expected weak aromaticity, and only the d8 molecules are somewhat anti-aromatic. However, the theoretical account of the aromaticity of the 16e− MCPs is more convoluted. We find that the aromatic criteria for a 16e−d4 ruthenacyclopentadiene disagree. The lack of agreement shows that significant electron delocalization is not always related to great stability or to strong diatropic currents.",
           2,
           "chemistry"
          ],
          [
           "Catalysis of an Aldol Condensation Using a Coordination Cage",
           "10.3390/chemistry2010004",
           2020,
           "The aldol condensation of indane-1,3-dione (ID) to give ‘bindone’ in water is catalysed by an M8L12 cubic coordination cage (Hw). The absolute rate of reaction is slow under weakly acidic conditions (pH 3–4), but in the absence of a catalyst it is undetectable. In water, the binding constant of ID in the cavity of Hw is ca. 2.4 (±1.2) × 103 M−1, giving a ∆G for the binding of −19.3 (±1.2) kJ mol−1. The crystal structure of the complex revealed the presence of two molecules of the guest ID stacked inside the cavity, giving a packing coefficient of 74% as well as another molecule hydrogen-bonded to the cage’s exterior surface. We suggest that the catalysis occurs due to the stabilisation of the enolate anion of ID by the 16+ surface of the cage, which also attracts molecules of neutral ID to the surface because of its hydrophobicity. The cage, therefore, brings together neutral ID and its enolate anion via two different interactions to catalyse the reaction, which—as the control experiments show—occurs at the exterior surface of the cage and not inside the cage cavity.",
           14,
           "chemistry"
          ],
          [
           "Stimuli-Responsive Designer Supramolecular Polymer Gel",
           "10.3390/chemistry5010048",
           2023,
           "This paper reports a stimuli-responsive designer supramolecular polymer gel in dimethylsulphoxide (DMSO)/water (1:2) based on a dipeptide amphiphile and β-cyclodextrin (β-CD) The dipeptide amphiphile contains caproic acid at the N terminus and methyl ester at the C terminus. From X-ray single crystal diffraction, the amphiphile adopts a kink-like conformation. The amphiphile self-assembled to form a parallel sheet-like structure stabilized by multiple intermolecular hydrogen bonds. Moreover, the parallel sheet-like structure is also stabilized by edge-to-edge π–π stacking interactions. In higher-order packing, it forms a corrugated sheet-like structure stabilized by hydrophobic interactions. The dipeptide amphiphile interacts with β-cyclodextrin and forms gel through supramolecular polymer formation in (DMSO)/water (1:2) by a simple heating-cooling cycle. The sol-to-gel transformation is because of a host–guest complex between compound 1 and β-CD and the formation of supramolecular polymer accompanied by microstructure changes from nanofibers to microrods. The gel is temperature responsive with a Tgel of 70 °C. The supramolecular polymer gel is also responsive to stimuli such aspicric acid and HCl. The extensive spectroscopic studies show that the aromatic hydrophobic side chain of compound 1 forms a host–guest complex with β-CD. These results will be helpful for the design of advanced programable eco-friendly functional materials.",
           2,
           "chemistry"
          ],
          [
           "A Sensor (Optode) Based on Cellulose Triacetate Membrane for Fe(III) Detection in Water Samples",
           "10.3390/chemistry6010005",
           2023,
           "Iron is a heavy metal that often contaminates water. High iron concentrations are toxic to human health, so monitoring its presence in water is necessary. Iron in water can be detected using an optical sensor (optode). This research aims to fabricate an optode based on a cellulose triacetate membrane with a selective reagent against Fe(III). The optode was fabricated by mixing cellulose triacetate polymer, a plasticiser (a mixture of oleic acid and acetophenone), aliquot-336, and thiocyanate as a selective reagent. Membrane performance was tested based on working range, linearity, limit of detection and quantitation, precision, and accuracy. The performance of the membrane showed a linear response in the concentration range of 0.1–4 mg/L with a coefficient of determination (R2) of 0.9937, limit of detection of 0.0250 mg/L, limit of quantitation of 0.0757 mg/L, repeatability precision with a relative standard deviation of 3.31%, and an accuracy of 100.49%. Optode selectivity was good for interfering ions Cr(VI) and Pb(II). The colour complex of the optode was stable until the 10th day. The application of iron detection in water samples shows an average concentration of 0.2541 mg/L with good precision and accuracy.",
           0,
           "chemistry"
          ],
          [
           "Two-Dimensional Materials: From Discovery to Application in Membrane Distillation/Crystallization Processes",
           "10.3390/chemistry5040148",
           2023,
           "Sustainable water desalination and purification membrane processes require new practical pathways to improve their efficiency. To this end, the inclusion of two-dimensional materials in membrane structure has proven to have a significant impact in various applications. In particular, in processes such as membrane distillation and crystallization, these materials, thanks to their characteristics, help to increase the recovery of clean water and, at the same time, to improve the quality and the production of the recovered salts. Therefore, a fundamental aspect of obtaining 2D materials with certain characteristics is the technique used for the preparation. This review provides a broad discussion on the preparation and proprieties of 2D materials, including examples of organic structures (such as graphene and structures containing transition metals and organic metals). Finally, the critical challenges, future research directions, and the opportunities for developing advanced membranes based on 2D materials are outlined.",
           0,
           "chemistry"
          ],
          [
           "Synthesis of Glycoluril Dimers with the Ability to Form Polymeric Self-Associates in Water",
           "10.3390/chemistry4030053",
           2022,
           "Supramolecular self-assembly in water resulting in polymeric structures is emerging because of its potential in the preparation of adaptive materials with applications in biology and medicine. Here, we report the first example of host molecules based on glycoluril dimers, which self-associate into linear oligomers in water. The degree of polymerization for the resulting supramolecular aggregates was calculated using the isodesmic model and the Carothers equation. The model compound was prepared to enable a deeper understanding of the forces responsible for the self-association of the glycoluril dimer-based monomers in water.",
           2,
           "chemistry"
          ],
          [
           "Biogenic Silver and Copper Nanoparticles: Potential Antifungal Agents in Rice and Wheat Crops",
           "10.3390/chemistry5040143",
           2023,
           "Metal nanoparticles are widely studied due to their various applications, such as their potential use in the control of phytopathogens and the promotion of plant growth, with a significant impact on agriculture. Various microbial metabolites are used to reduce and stabilize metals and metal oxides to the nanoscale. In the present work, the biological synthesis of silver and copper oxide nanoparticles using Trichoderma harzianum TA2 is reported. The nanoparticles were purified and characterized with complementary methodologies to obtain information on the size, distribution, morphology, surface charge, and functional groups of the nanoparticles. The in vitro antifungal activity of the nanoparticles against pathogens of rice and wheat, as well as their effect on seed germination, were evaluated. In general, the nanoparticles showed a spherical shape, an average size of 17–26 nm, and low polydispersity. Furthermore, they showed antifungal activity at low concentrations against Sclerotium oryzae (0.140 ηM), Rhizoctonia oryzae-sativae (0.140 ηM), Fusarium graminearum (0.034 ηM), and Pyricularia oryzae (0.034 ηM). The germination of seeds treated with nanoparticles was not negatively affected. This is the first report of biogenic silver and copper oxide nanoparticles from a single strain of T.harzianum with antifungal activity against four phytopathogens of interest in Uruguay. Furthermore, the synthesis of the biogenic nanoparticles was faster and more efficient than previous reports using other fungi. In conclusion, this work reveals that biogenic metallic nanoparticles from T. harzianum TA2 can be considered as candidates for the control of phytopathogens affecting important crops.",
           1,
           "chemistry"
          ],
          [
           "Conversion of Sugar Di-Ketals to Bio-Hydrocarbons through Catalytic Cracking over Beta Catalysts in Fixed and Fluidized Catalytic Beds",
           "10.3390/chemistry5010035",
           2023,
           "Second-generation biomass (BM) can be produced in amounts that meet worldwide fuel demands. However, BM favors parallel and undesirable reactions in its transformation chain. We circumvent this problem by first modifying BM by ketalization, giving a user-friendly liquid we named BP (bio-petroleum). This study converted a representative compound of BP, DX (1,2:3,5-di-O-isopropylidene-α-D-xylofuranose), mixed with n-hexane by beta zeolites and catalysts containing beta zeolite. Beta zeolite showed low coke and high liquid product yields in converting this mixture (having 30 wt. % DX) into hydrocarbons in a fixed-bed reactor at 500 °C with a space velocity of 16 h−1 (0.3 catalyst/feed). Its performance was further improved by steam treatment (lowering the coke yield by lowering the acid site density) or incorporation into a catalyst (improving DX participation due to the active sites in the matrix). Further, by changing the conversion process from a fixed bed to a fluidized cracking unit, a much larger amount of the deactivated catalyst could be used (catalyst/feed = 3), remarkably reducing oxygenates and fully converting DX. Additionally, the green hydrocarbon efficiency (olefin, aromatics, furans, and cyclo-alkanes) of DX was approximately 77%. Hence, beta catalysts were shown to have a great potential to provide green fuels for future bio-refineries.",
           1,
           "chemistry"
          ],
          [
           "Self-Assembly and Gelation Study of Dipeptide Isomers with Norvaline and Phenylalanine",
           "10.3390/chemistry4040093",
           2022,
           "Dipeptides have emerged as attractive building blocks for supramolecular materials thanks to their low-cost, inherent biocompatibility, ease of preparation, and environmental friendliness as they do not persist in the environment. In particular, hydrophobic amino acids are ideal candidates for self-assembly in polar and green solvents, as a certain level of hydrophobicity is required to favor their aggregation and reduce the peptide solubility. In this work, we analyzed the ability to self-assemble and the gel of dipeptides based on the amino acids norvaline (Nva) and phenylalanine (Phe), studying all their combinations and not yielding to enantiomers, which display the same physicochemical properties, and hence the same self-assembly behavior in achiral environments as those studied herein. A single-crystal X-ray diffraction of all the compounds revealed fine details over their molecular packing and non-covalent interactions.",
           2,
           "chemistry"
          ],
          [
           "Isoselenazole Synthesis by Rh-Catalyzed Direct Annulation of Benzimidates with Sodium Selenite",
           "10.3390/chemistry5040140",
           2023,
           "Organoselenium compounds have attracted significant research interest because of their potent therapeutic activities and indispensable applications in the organic chemistry field. The selenation reactions conventionally rely on the use of sensitive Se reagents; thus, new synthetic methods with improved efficiency and operational simplicity have recently been of particular interest. In this manuscript, we report a Rh-catalyzed direct selenium annulation using tractable sodium selenite (Na2SeO3) as the limiting reagent. The selenite species was converted to highly electrophilic SeO(OBz)2 in situ upon treatment with Bz2O, thereby undergoing C–H/N–H double nucleophilic selenation. A series of benzimidates successfully underwent selenation under mild reaction conditions to afford isoselenazole derivatives.",
           0,
           "chemistry"
          ],
          [
           "Stereoselective Synthesis of a Novel Series of Dispiro-oxindolopyrrolizidines Embodying Thiazolo[3,2-a]benzimidazole Motif: A Molecular Electron Density Theory Study of the Mechanism of the [3 + 2] Cycloaddition Reaction",
           "10.3390/chemistry5040158",
           2023,
           "A one-pot multi-component reaction was employed for the stereoselective synthesis of a novel set of dispiro-oxindolopyrrolizidines analogs incorporating a thiazolo[3,2-a]benzimidazole scaffold based on the [3 + 2] cycloaddition (32CA) reaction approach. The desired novel dispiro-oxindolopyrrolizidines 9a–d were achieved using the 32CA reaction of new ethylene derivatives based on thiazolo[3,2-a]benzimidazole moiety seven with thiazolidine derivatives eight and different substituted isatin compounds 5a–d (R = H, Cl, NO2, and Br). The final dispiro-oxindolopyrrolizidines cycloadducts were separated, purified, and fully characterized by means of a set of spectroscopic tools including IR, HNMR, CNMR, and MS. The Molecular Electron Density Theory (MEDT) was applied to explain the mechanism and stereoselectivity in the of the key 32CA reaction step. The reactive pseudo(mono)radical electronic structure of the in situ generated azomethine ylides and the high polar character of the corresponding 32CA reactions account for the low computed activation Gibbs free energies and total endo stereoselectivity of this kinetically controlled exergonic reaction. The computed relative Gibbs free activation energies of competitive reaction paths and regioisomers ratio distribution of 80:20 justify the major formation of 9a via the most favorable ortho/endo reaction path.",
           0,
           "chemistry"
          ],
          [
           "Twinning in Zr-Based Metal-Organic Framework Crystals",
           "10.3390/chemistry2030050",
           2020,
           "Ab initio structure determination of new metal-organic framework (MOF) compounds is generally done by single crystal X-ray diffraction, but this technique can yield incorrect crystal structures if crystal twinning is overlooked. Herein, the crystal structures of three Zirconium-based MOFs, that are especially prone to twinning, have been determined from twinned crystals. These twin laws (and others) could potentially occur in many MOFs or related network structures, and the methods and tools described herein to detect and treat twinning could be useful to resolve the structures of affected crystals. Our results highlight the prevalence (and sometimes inevitability) of twinning in certain Zr-MOFs. Of special importance are the works of Howard Flack which, in addition to fundamental advances in crystallography, provide accessible tools for inexperienced crystallographers to take twinning into account in structure elucidation.",
           4,
           "chemistry"
          ],
          [
           "Five Bonds to Carbon through Tri-Coordination in &#x0D;\nAl3C3−/0",
           "10.3390/chemistry5020076",
           2023,
           "Here, five bonds to carbon through tri-coordination are theoretically established in the global minimum energy isomers of Al3C3− anion (1a) and Al3C3 neutral (1n) for the first time. Various isomers of Al3C3−/0 are theoretically identified using density functional theory at the PBE0-D3/def2-TZVP level. Chemical bonding features are thoroughly analyzed for these two isomers (1a and 1n) with different bonding and topological quantum chemical tools, such as adaptive natural density partitioning (AdNDP), Wiberg Bond Indices (WBIs), nucleus-independent chemical shifts (NICS), and atoms in molecules (AIM) analyses. The structure of isomer 1a is planar with C2v symmetry, whereas its neutral counterpart 1n is non-planar with C2 symmetry, in which its terminal aluminum atoms are out of the plane. The central allenic carbon atom of isomers 1a and 1n exhibits tri-coordination and thus makes it a case of five bonds to carbon, which is confirmed through their total bond order as observed in WBI. Both the isomers show σ- and π-aromaticity and are predicted with the NICS and AdNDP analyses. Further, the results of ab initio molecular dynamics simulations reveal their kinetic stability at room temperature; thus, they are experimentally viable systems.",
           3,
           "chemistry"
          ],
          [
           "Steering the Metal Precursor Location in Pd/Zeotype Catalysts and Its Implications for Catalysis",
           "10.3390/chemistry5010026",
           2023,
           "Bifunctional catalysts containing a dehydrogenation–hydrogenation function and an acidic function are widely applied for the hydroconversion of hydrocarbon feedstocks obtained from both fossil and renewable resources. It is well known that the distance between the two functionalities is important for the performance of the catalyst. In this study, we show that the heat treatment of the catalyst precursor can be used to steer the location of the Pd precursor with respect to the acid sites in SAPO-11 and ZSM-22 zeotype materials when ions are exchanged with Pd(NH3)4(NO3)2. Two sets of catalysts were prepared based on composite materials of alumina with either SAPO-11 or ZSM-22. Pd was placed on/in the zeotype, followed by a calcination-reduction (CR) or direct reduction (DR) treatment. Furthermore, catalysts with Pd on the alumina binder were prepared. CR results in having more Pd nanoparticles inside the zeotype crystals, whereas DR yields more particles on the outer surface of the zeotype crystals as is confirmed using HAADF-STEM and XPS measurements. The catalytic performance in both n-heptane and n-hexadecane hydroconversion of the catalysts shows that having the Pd nanoparticles on the alumina binder is most beneficial for maximizing the isomer yields. Pd-on-zeotype catalysts prepared using the DR approach show intermediate performances, outperforming their Pd-in-zeotype counterparts that were prepared with the CR approach.",
           2,
           "chemistry"
          ],
          [
           "Electrochemical and Surface Analytical Study on the Role of Poly(butylene-succinate)-l-proline during Corrosion of Mild Steel in 1 M HCl",
           "10.3390/chemistry2040057",
           2020,
           "The synthesis and corrosion inhibition performance of poly(butylene-succinate)-L-proline (PBSLP) prepared by solution polymerization are reported. PBSLP was characterized by FTIR, XRD, and SEM/energy dispersive X-ray (EDX). PBSLP was used to protect mild steel in 1 M hydrochloric acid. An SEM and an atomic force microscope (AFM) were used to characterize the surface morphology of the mild steel coupons. Potentiodynamic polarization and electrochemical impedance spectroscopy (EIS) were used to characterize the inhibition mechanism of PBSLP, and the inhibitor was a mixed-type corrosion inhibitor with a maximum corrosion inhibition efficiency of 93.0%. Adsorption studies revealed the adsorption of PBSLP to be a monolayer process and therefore, obeyed the Langmuir isotherm model.",
           2,
           "chemistry"
          ],
          [
           "Modified Mycotoxins, a Still Unresolved Issue",
           "10.3390/chemistry4040099",
           2022,
           "Mycotoxins are toxic secondary metabolites produced by filamentous microfungi on almost every agricultural commodity worldwide. After the infection of crop plants, mycotoxins are modified by plant enzymes or other fungi and often conjugated to more polar substances, like sugars. The formed—often less toxic—metabolites are stored in the vacuole in soluble form or bound to macromolecules. As these substances are usually not detected during routine analysis and no maximum limits are in force, they are called modified mycotoxins. While, in most cases, modified mycotoxins have lower intrinsic toxicity, they might be reactivated during mammalian metabolism. In particular, the polar group might be cleaved off (e.g., by intestinal bacteria), releasing the native mycotoxin. This review aims to provide an overview of the critical issues related to modified mycotoxins. The main conclusion is that analytical aspects, toxicological evaluation, and exposure assessment merit more investigation.",
           2,
           "chemistry"
          ],
          [
           "Photocatalytic Duplex-Based DNAzymes Switched by an Abasic Site",
           "10.3390/chemistry5030102",
           2023,
           "DNAzymes have attracted increasing interest in developments of gene tools, therapies, and biosensors. Among them, G-quadruplexes are widely used as the key structure elements of DNAzymes to activate the catalytic competency of specific cofactors, such as hemin, but there is a great demand to diversify DNAzymes using other more straightforward DNA structures such as fully matched duplex (FM-DNA). However, the perfect base pairs in duplex limit the DNAzyme activity. In this work, a photocatalytic DNAzyme was developed by introducing an abasic site (AP site) into duplex (AP-DNA) to switch its photocatalytic activity. Palmatine (PAL), a photosensitizer from natural isoquinoline alkaloids, served as a cofactor of the DNAzyme by binding at the AP site. The AP site provides a less polarized environment to favor the PAL fluorescence. As a result, dissolved oxygen was converted into singlet oxygen (1O2) via energy transfer from the excited PAL. The oxidation of substrates by the in situ photogenerated 1O2 served as a readout for the DNAzyme. In addition, the duplex-based DNAzyme was engineered from FM-DNA by the cascade uracil-DNA glycosylase to generate AP-DNA. Our work provides a new way to construct duplex-based DNAzymes.",
           1,
           "chemistry"
          ],
          [
           "Complementarity and Preorganisation in the Assembly of Heterometallic–Organic Cages via the Metalloligand Approach—Recent Advances",
           "10.3390/chemistry4040095",
           2022,
           "The design of new metallocage polyhedra towards pre-determined structures can offer both practical as well as intellectual challenges. In this mini-review we discuss a selection of recent examples in which the use of the metalloligand approach has been employed to overcome such challenges. An attractive feature of this approach is its stepwise nature that lends itself to the design and rational synthesis of heterometallic metal–organic cages, with the latter often associated with enhanced functionality.",
           0,
           "chemistry"
          ],
          [
           "Sol–Gel Routes toward Ceramic Nanofibers for High-Performance Thermal Management",
           "10.3390/chemistry4040098",
           2022,
           "Ceramic-based nanofiber materials for high-performance thermal management have drawn increasing attention owing to their high-temperature resistance, efficient thermal insulation, superior mechanical flexibility, as well as excellent physical–chemical stability. We present an overview of the ceramic-based nanofiber obtained by sol–gel routes for high-performance thermal management, including the materials, the fabrication methods of the sol–gel route, and their application for thermal management. We first provide a brief introduction to the ceramic-based nanofibers. The materials and fabrication methods of the sol–gel route are further discussed in the second part, including the kinds of nanofibers such as oxide, carbide, and nitride, and the methods such as centrifugal spinning, electrospinning, solution blow spinning, and self-assembly. Finally, their application for thermal management is further illustrated. This review will provide some necessary suggestions to researchers for the investigation of ceramic-based nanofibers produced with the sol–gel route for thermal management.",
           4,
           "chemistry"
          ],
          [
           "Natural Products as Mcl-1 Inhibitors: A Comparative Study of Experimental and Computational Modelling Data",
           "10.3390/chemistry4030067",
           2022,
           "The human myeloid leukemia cell differentiation protein (hMcl-1) is an anti-apoptotic multi-partner protein, belonging to the B-cell lymphoma-2 (Bcl-2) family of proteins. Studies have linked hMcl-1 alleviated expression with resistance to hemopoietic chemotherapeutics, which makes it a key drug target in blood cancers. However, most of the developed small- to medium-sized hMcl-1 inhibitors have typical off-target activity towards other members of the Bcl-2 family. To improve the hMcl-1 inhibitor design, especially exploring a suitable scaffold with pharmacophoric features, we focused on natural hMcl-1 inhibitors. To date, seven classes of natural compounds have been isolated, which display a low micromolar affinity for hMcl-1 and have limited biophysical studies. We screened hMcl-1 co-crystal structures, and identified nine co-crystal structures of hMcl-1 protein, which were later evaluated by multiple receptor conformations (which indicates that the differences between hMcl-1 in crystal structures are low (RMSD values between 0.52 and 1.13 Å, average RMSD of 0.638–0.888 Å, with a standard deviation of 0.102–0.185Å)), and multiple ligand conformations (which led to the selection of the PDB structure, 3WIX (RMSD value = 0.879 Å, standard deviation 0.116 Å), to accommodate various Mcl-1 ligands from a range of co-crystal PDB files) methods. Later, the three adopted docking methods were assessed for their ability to reproduce the conformation bound to the crystal as well as predict trends in Ki values based on calculated RMSD and docking energies. Iterative docking and clustering of the docked pose within ≤1.0 Å was used to evaluate the reproducibility of the adopted docking methods and compared with their experimentally determined hMcl-1 affinity data.",
           5,
           "chemistry"
          ],
          [
           "Total Synthesis of the Proposed Structure of Indolyl 1,2-Propanediol Alkaloid, 1-(1H-Indol-3-yloxy)propan-2-ol",
           "10.3390/chemistry5040177",
           2023,
           "The first total synthesis of the proposed structure of unprecedented indolyl derivative bearing 1,2-propanediol moiety is described. Isomerization of 3-alkoxyindolines through indolenium intermediates was the key step in the total synthesis. 1H, 13C-NMR, IR, and HRMS spectra of the synthetic compound drastically differed to those of the originally reported structure, which suggests the natural product requires revision.",
           0,
           "chemistry"
          ],
          [
           "Progress and Perspectives of Conducting Metal–Organic Frameworks for Electrochemical Energy Storage and Conversion",
           "10.3390/chemistry5040161",
           2023,
           "The metal–organic framework (MOF) is a kind of porous material with lattice materials. Due to its large surface area and structural diversity, it has made great progress in the fields of batteries, capacitors, electrocatalysis, etc. Conductive MOF (c-MOF) increases the conductivity based on the original advantages of the MOF, which is more suitable for the development of batteries, capacitors, electrocatalysis, and other fields. This review summarizes the preparation of c-MOF and the research progress of conductive MOFs in the field of electrochemical energy storage and conversion.",
           1,
           "chemistry"
          ],
          [
           "Synthesis of Selenium-Based Small Molecules Inspired by CNS-Targeting Psychotropic Drugs and Mediators",
           "10.3390/chemistry5030101",
           2023,
           "Due to its endogenously high oxygen consumption, the central nervous system (CNS) is vulnerable to oxidative stress conditions. Notably, the activity of several CNS-targeting compounds, such as antidepressant and hypnotic drugs, or endogenous mediators, such as melatonin, is indeed linked to their ability of mitigating oxidative stress. In this work, we report the synthesis of two organoselenium compounds of which the structure was inspired by CNS-targeting psychotropic drugs (zolpidem and fluoxetine) and an endogenous mediator (melatonin). The molecules were designed with the aim of combining the ROS-scavenging properties, which were already assessed for the parent compounds, with a secondary antioxidant action, a glutathione peroxidase (GPx) mimic role empowered by the presence of selenium. The compounds were obtained through a facile three-step synthesis and were predicted by computational tools to passively permeate through the blood–brain barrier and to efficiently bind to the GABA A receptor, the macromolecular target of zolpidem. Of note, the designed synthetic pathway enables the production of several other derivatives through minor modifications of the scheme, paving the way for structure–activity relationship studies.",
           0,
           "chemistry"
          ],
          [
           "Silver Ions Incorporation into Nanofibers for Enhanced hMSC Viability",
           "10.3390/chemistry4030064",
           2022,
           "Antimicrobial properties of silver have been known for a long time, but there is also cytotoxicity of high concentrations of silver. Therefore, it is important to select the concentration and shape of silver depending on the goals. The ideal wound dressing should ensure that the wound remains optimally moist, protected from infections, has no toxic compounds, and stimulates regeneration. In the present work, we obtained a series of polycaprolactone-based nanomaterials fabricated by electrospinning and incorporated with silver ions (up to 0.6 at.%). By adjusting the magnetron current (0.3 A) and implanter voltage (5 kV), the deposition of TiO2 and Ag+ implantation into PCL/PEO nanofibers was optimized to achieve implantation of Ag+ without damaging the nanofibrous structure of the biodegradable nanofibers. The obtained results allow us to predict significant protection properties of the developed material not only from mechanical influence but also thanks to the antimicrobial effect due to silver ions, which is important for chronic wounds and injuries with a large area of damage and can activate host cells proliferation.",
           5,
           "chemistry"
          ],
          [
           "Cesium Heteropolyacid Salts: Synthesis, Characterization and Activity of the Solid and Versatile Heterogeneous Catalysts",
           "10.3390/chemistry5010047",
           2023,
           "Keggin-type heteropolyacid cesium salts have been regarded as potential candidates for heterogeneous catalytic reactions. This review describes the success of Keggin-type heteropolyacids cesium salts (Cs-HPA salts) as efficient catalysts in various synthesis processes. The Cs-HPA catalysts can be synthesized as solid salts through the metathesis of a solution containing precursor HPA and another solution containing soluble Cs salt, which will give Cs-HPA salt as a solid precipitate. Alternatively, they can be also obtained from the commercial precursor HPA. In this review, all the routes to prepare the different cesium salts (i.e., saturated, lacunar, metal-doped) were described. These salts can be used in acid-catalyzed reactions (i.e., esterification, etherification, acetalization, dehydration) or oxidative transformations (oxidative esterification, oxidation, epoxidation). All of these reactions were addressed herein. Aspects related to the synthesis and characterization of these catalyst salts were discussed. This review aims to discuss the most pertinent heterogeneous catalytic systems based on Keggin HPA Cs salts. The focus was to correlate the physicochemical properties of these salts with their catalytic activity. Ultimately, the most recent advances achieved in the applications of these Cs-HPA salts as catalysts in the synthesis of industrial interest compounds were discussed. Cesium heteropoly salts are an alternative to the traditional soluble mineral acids as well as to solid-supported catalysts.",
           4,
           "chemistry"
          ],
          [
           "Aptamer-Based Immune Drug Systems (AptIDCs) Potentiating Cancer Immunotherapy",
           "10.3390/chemistry5030114",
           2023,
           "Aptamers are artificial oligonucleotides with excellent molecule-targeting ability. Compared with monoclonal antibodies, aptamers have the advantages of low cost, no batch effect, and negligible immunogenicity, making them promising candidates for cancer immunotherapy. To date, a series of aptamer agonists/antagonists have been discovered and directly used to activate immune response, such as immune checkpoint blockade, immune costimulation, and cytokine regulation. By incorporating both tumor- and immune cell-targeting aptamers, multivalent bispecific aptamers were designed to pursue high tumor affinity and enhanced immune efficacy. More importantly, benefiting from feasible chemical modification and programmability, aptamers can be engineered with diverse nanomaterials (e.g., liposomes, hydrogels) and even living immune cells (e.g., NK cells, T cells). These aptamer-based assemblies exhibit powerful capabilities in targeted cargo delivery, regulation of cell–cell interactions, tumor immunogenicity activation, tumor microenvironment remodeling, etc., holding huge potential in boosting immunotherapeutic efficacy. In this review, we focus on the recent advances in aptamer-based immune drug systems (AptIDCs) and highlight their advantages in cancer immunotherapy. The current challenges and future prospects of this field are also pointed out in this paper.",
           0,
           "chemistry"
          ],
          [
           "Chemistry: A Place to Publish Your Creative Multidisciplinary Research",
           "10.3390/chemistry5040172",
           2023,
           "It is my pleasure to welcome you to Chemistry (ISSN: 2624-8549), an open access peer-reviewed journal that publishes both primary reports and reviews highlighting important advances in fundamental areas of chemistry and/or illustrating the central role of chemistry in bridging the physical and life sciences [...]",
           0,
           "chemistry"
          ],
          [
           "Multiple Intramolecular Hydrogen Bonding in Large Biomolecules: DFT Calculations and Deuterium Isotope Effects on 13C Chemical Shifts as a Tool in Structural Studies",
           "10.3390/chemistry5020089",
           2023,
           "Large biomolecules often have multiple intramolecular hydrogen bonds. In the cases where these interact, it requires special tools to disentangle the patterns. Such a tool could be deuterium isotope effects on chemical shifts. The use of theoretical calculations is an indispensable tool in such studies. The present paper illustrates how DFT calculations of chemical shifts and deuterium isotope effects on chemical shifts in combination with measurements of these effects can establish the complex intramolecular hydrogen bond patterns of rifampicin as an example) The structures were calculated using DFT theoretical calculations, performed with the Gaussian 16 software. The geometries were optimized using the B3LYP functional and the Pople basis set 6-31G(d) and the solvent (DMSO) was taken into account in the PCM approach. Besides the 6-31G(d) basis set, the 6-31 G(d,p) and the 6-3111G(d,p) basis sets were also tested. The nuclear shieldings were calculated using the GIAO approach. Deuteriation was simulated by shortening the X-H bond lengths by 0.01 Å.",
           1,
           "chemistry"
          ],
          [
           "Probing Low-Temperature OCM Performance over a Dual-Domain Catalyst Bed",
           "10.3390/chemistry5020075",
           2023,
           "The Mn-Na2WO4/SiO2 catalyst is regarded as the most promising catalyst for the oxidative coupling of methane (OCM). Despite its remarkable performance, the Mn-Na2WO4/SiO2 catalyst requires a high reaction temperature (>750 °C) to show significant activity, a temperature regime that simultaneously causes quick deactivation. In the current work, we show that the benefits of this catalyst can be leveraged even at lower reaction temperatures by a using a stacked catalyst bed, which includes also a small amount of 5% La2O3/MgO on-top- of the Mn-Na2WO4/SiO2 catalyst. The simple stacking of the two catalysts provides >7-fold higher activity and ~1.4-fold higher C2 yield at 705 °C compared to Mn-Na2WO4/SiO2 and La2O3/MgO, respectively. We specifically show that the enhanced OCM performance is associated with synergistic interactions between the two catalyst domains and study their origin.",
           1,
           "chemistry"
          ],
          [
           "Ratiometric Detection of Zn2+ Using DNAzyme-Based Bioluminescence Resonance Energy Transfer Sensors",
           "10.3390/chemistry5030119",
           2023,
           "While fluorescent sensors have been developed for monitoring metal ions in health and diseases, they are limited by the requirement of an excitation light source that can lead to photobleaching and a high autofluorescence background. To address these issues, bioluminescence resonance energy transfer (BRET)-based protein or small molecule sensors have been developed; however, most of them are not highly selective nor generalizable to different metal ions. Taking advantage of the high selectivity and generalizability of DNAzymes, we report herein DNAzyme-based ratiometric sensors for Zn2+ based on BRET. The 8-17 DNAzyme was labeled with luciferase and Cy3. The proximity between luciferase and Cy3 permitted BRET when coelenterazine, the substrate for luciferase, was introduced. Adding samples containing Zn2+ resulted in a cleavage of the substrate strand, causing dehybridization of the DNAzyme construct, thus increasing the distance between Cy3 and luciferase and changing the BRET signals. Using these sensors, we detected Zn2+ in serum samples and achieved Zn2+ detection with a smartphone camera. Moreover, since the BRET pair is not the component that determines the selectivity of the sensors, this sensing platform has the potential to be adapted for the detection of other metal ions with other metal-dependent DNAzymes.",
           1,
           "chemistry"
          ],
          [
           "UiO-66 MOF-Derived Ru@ZrO2 Catalysts for Photo-Thermal CO2 Hydrogenation",
           "10.3390/chemistry5020051",
           2023,
           "The use of metal–organic frameworks (MOFs) as templates or precursors in the manufacture of heterogeneous catalysts is highly attractive due to the transfer of MOFs’ inherent porosity and homogeneous metallic distribution to the derived structure. Herein, we report on the preparation of MOF-derived Ru@ZrO2 catalysts by controlled thermal treatment of zirconium-based MOF UiO-66 with ruthenium moieties. Ru3+ (3 or 10 mol%) precursor was added to UiO-66 synthesis and, subsequently, the as-synthesized hybrid structure was calcined in flowing air at different temperatures (400–600 °C) to obtain ZrO2-derived oxides doped with highly dispersed Ru metallic clusters. The materials were tested for the catalytic photo-thermal conversion of CO2 to CH4. Methanation experiments were conducted in a continuous flow (feed flow rate of 5 sccm and 1:4 CO2 to H2 molar ratio) reactor at temperatures from 80 to 300 °C. Ru0.10@ZrO2 catalyst calcined at 600 °C was able to hydrogenate CO2 to CH4 with production rates up to 65 mmolCH4·gcat.–1·h–1, CH4 yield of 80% and nearly 100% selectivity at 300 °C. The effect of the illumination was investigated with this catalyst using a high-power visible LED. A CO2 conversion enhancement from 18% to 38% was measured when 24 sun of visible LED radiation was applied, mainly due to the increase in the temperature as a result of the efficient absorption of the radiation received. MOF-derived Ru@ZrO2 catalysts have resulted to be noticeably active materials for the photo-thermal hydrogenation of CO2 for the purpose of the production of carbon-neutral methane. A remarkable effect of the ZrO2 crystalline phase on the CH4 selectivity has been found, with monoclinic zirconia being much more selective to CH4 than its cubic allotrope.",
           1,
           "chemistry"
          ],
          [
           "Unexpected Ethyltellurenylation of Epoxides with Elemental Tellurium under Lithium Triethylborohydride Conditions",
           "10.3390/chemistry2030041",
           2020,
           "The one-pot multistep ethyltellurenylation reaction of epoxides with elemental tellurium and lithium triethylborohydride is described. The reaction mechanism was experimentally investigated. Dilithium ditelluride and triethyl borane, formed from elemental tellurium and lithium triethylborohydride, were shown to be the key species involved in the reaction mechanism. Epoxides undergo ring-opening reaction with dilithium ditelluride to afford β-hydroxy ditellurides, which are sequentially converted into the corresponding β-hydroxy-alkyl ethyl tellurides by transmetalation with triethyl borane, reasonably proceeding through the SH2 mechanism.",
           3,
           "chemistry"
          ],
          [
           "Responsive DNA Nanostructures for Bioanalysis and Therapy",
           "10.3390/chemistry5040147",
           2023,
           "DNA nanostructures have been widely explored as an encouraging tool for bioanalysis and cancer therapy due to its structural programmability and good biocompatibility. The incorporation of stimulus-responsive modules enables the accurate targeting and flexible control of structure and morphology, which is benefit to precise bioanalysis and therapy. This mini review briefly discusses the advancements in stimuli-responsive DNA nanostructures construction and their applications in biomolecules sensing and cancer treatment.",
           1,
           "chemistry"
          ],
          [
           "On-Surface Synthesis of Polypyridine: Strain Enforces Extended Linear Chains",
           "10.3390/chemistry4010009",
           2022,
           "Strain-induced on-surface transformations provide an appealing route to steer the selectivity towards desired products. Here, we demonstrate the selective on-surface synthesis of extended all-trans poly(2,6-pyridine) chains on Au(111). By combining high-resolution scanning tunneling and atomic force microscopy, we revealed the detailed chemical structure of the reaction products. Density functional theory calculations indicate that the synthesis of extended covalent structures is energetically favored over the formation of macrocycles, due to the minimization of internal strain. Our results consolidate the exploitation of internal strain relief as a driving force to promote selective on-surface reactions.",
           5,
           "chemistry"
          ],
          [
           "Occurrence of Marine Ingredients in Fragrance: Update on the State of Knowledge",
           "10.3390/chemistry3040103",
           2021,
           "The fragrance field of perfumes has attracted considerable scientific, industrial, cultural, and civilizational interest. The marine odor is characterized by the specific smell of sea breeze, seashore, algae, and oyster, among others. Marine odor is a more recent fragrance and is considered as one of the green and modern fragrances. The smells reproducing the marine environment are described due to their content of Calone 1951 (7-methyl-2H-1,5-benzodioxepin-3(4H)-one), which is a synthetic compound. In addition to the synthetic group of benzodioxepanes, such as Calone 51 and its derivatives, three other groups of chemical compounds seem to represent the marine smell. The first group includes the polyunsaturated cyclic ((+)-Dictyopterene A) and acyclic (giffordene) hydrocarbons, acting as pheromones. The second group corresponds to polyunsaturated aldehydes, such as the (Z,Z)-3,6-nonadienal, (E,Z)-2,6-nonadienal, which are most likely derived from the degradation of polyunsaturated fatty acids. The third group is represented by small molecules such as sulfur compounds and halogenated phenols which are regarded as the main flavor compounds of many types of seafood. This review exposes, most notably, the knowledge state on the occurrence of marine ingredients in fragrance. We also provide a detailed discussion on several aspects of essential oils, which are the most natural ingredients from various marine sources used in fragrance and cosmetics, including synthetic and natural marine ingredients.",
           8,
           "chemistry"
          ],
          [
           "Reactivity of Rare-Earth Oxides in Anhydrous Imidazolium Acetate Ionic Liquids",
           "10.3390/chemistry5020094",
           2023,
           "Rare-earth metal sesquioxides (RE2O3) are stable compounds that require high activation energies in solid-state reactions or strong acids for dissolution in aqueous media. Alternatively, dissolution and downstream chemistry of RE2O3 have been achieved with ionic liquids (ILs), but typically with additional water. In contrast, the anhydrous IL 1-butyl-3-methylimidazolium acetate [BMIm][OAc] dissolves RE2O3 for RE = La–Ho and forms homoleptic dinuclear metal complexes that crystallize as [BMIm]2[RE2(OAc)8] salts. Chloride ions promote the dissolution without being included in the compounds. Since the lattice energy of RE2O3 increases with decreasing size of the RE3+ cation, Ho2O3 dissolves very slowly, while the sesquioxides with even smaller cations appear to be inert under the applied conditions. The Sm and Eu complex salts show blue and red photoluminescence and Van Vleck paramagnetism. The proton source for the dissolution is the imidazolium cation. Abstraction of the acidic proton at the C2-atom yields an N-heterocyclic carbene (imidazole-2-ylidene). The IL can be regenerated by subsequent reaction with acetic acid. In the overall process, RE2O3 is dissolved by anhydrous acetic acid, a reaction that does not proceed directly.",
           3,
           "chemistry"
          ],
          [
           "Application of DFT/TD-DFT Frameworks in the Drug Delivery Mechanism: Investigation of Chelated Bisphosphonate with Transition Metal Cations in Bone Treatment",
           "10.3390/chemistry5010027",
           2023,
           "Carbon nanotubes (CNTs) are applied in a drug delivery system, which can be reacted with different structures such biomolecules. Bones have vital functions and are the locations of biochemical reactions in cells that might be exposed various diseases. As different metal ions are integral components of bone tissue with different functions in the physiological cellular medium as well as in bone treatment, they can be used differently as a basis or as a supplement for various materials in the field of bone repair. Therefore, this research aims to represent the recent progress in conjugated bisphosphonate (BP)-divalent transition metal ions of Mn2+, Fe2+, and Co2+ with an emphasis on the properties of interaction with a (6, 6) armchair carbon nanotube as a nanocarrier to exhibit the potential biomedical application of drug delivery. In this article, “CNT” linked to “BP“ of alendronic acid, ibandronic acid, neridronic acid, and pamidronic acid, which are chelated to transition metal cations of Mn2+, Fe2+, and Co2+, was investigated based on DFT insights for obtaining the electron charge density. Transition metals chelating with phosphonate groups, which are large with six O atoms with negative charges, are active in generating chelated complexes with the bisphosphonates [BPs- Mn2+/Fe2+/Co2+] through the status of drug design. In this work, B3LYP/6-311+G(d,p)/lanl2dz we have estimated the susceptibility of CNT for conjugating alendronic acid, ibandronic acid, neridronic acid, and pamidronic acid, which are chelated to transition metal cations of Mn2+, Fe2+, and Co2+ through NMR, NQR, IR, UV-VIS spectroscopy, and HOMO-LUMO analysis. Finally, the obtained results have confirmed that the possibility of applying CNT and BPs of alendronic acid, ibandronic acid, neridronic acid, and pamidronic acid becomes suitable in transition metal chelating for delivery application. The calculated HOMO–LUMO energy gaps for BPs of alendronic acid, ibandronic acid, neridronic acid, and pamidronic acid at the B3LYP/6-311+G (d,p) level have revealed that the energy gap reflects the chemical activity of the molecule.",
           3,
           "chemistry"
          ],
          [
           "pH-Responsive Color Indicator of Saffron (Crocus sativus L.) Anthocyanin-Activated Salep Mucilage Edible Film for Real-Time Monitoring of Fish Fillet Freshness",
           "10.3390/chemistry4040089",
           2022,
           "Researchers have been focusing increasingly on preparing innovative packaging films made from renewable and biodegradable materials in recent years. This research set out to fabricate and analyze pH-sensitive edible films based on salep mucilage combined with anthocyanin from saffron (Crocus sativus L.) (SAAs). A casting technique was developed with varying concentrations of SAAs (0, 2.5, 5, 7.5, and 10%v/v) pH-sensitive edible films. The surface morphology, physicochemical, barrier, and mechanical properties, as well as the pH sensitivity of films, were investigated. The results showed SAAs increased thickness, water solubility, moisture content, and oxygen permeability (O2P) up to 199.03 µm, 63.71%, 14.13%, and 47.73 (cm3 µm m−2 day−1 kPa−1), respectively, of the pH-sensitive salep mucilage edible indicator films. As expected, the SAAs concentration from 0% to 10%v/v decreased tensile strength, transparency, and contact angle to 11.94 MPa, 14.27%, and 54.02°, respectively. Although achieving the highest elongation at the break (108%) and the lowest water vapor permeability (WVP) (1.39 g s−1 m−1 Pa−1 × 10−11), the pH-sensitive edible indicator film containing 5 %v/v of SAAs showed the best results. An investigation of pH sensitivity revealed that the solution’s pH variation altered the SAAs color. When the pH was raised from 3 to 11, the SAAs’ color shifted from pink to brown. The SAAs-halochromic salep mucilage edible indicator film was employed as a label in an experiment to track the degradation of fish fillets stored at 4 °C, revealing that the halochromic indicator changed color from yellow to brown as the fish was stored. Our findings show that SAAs-loaded salep mucilage indicator films help monitor real-time food deterioration.",
           5,
           "chemistry"
          ],
          [
           "U(VI) Coordination Modes in Complex Uranium Silicates: Cs[(UO6)2(UO2)9(Si2O7)F] and Rb2[(PtO4)(UO2)5(Si2O7)]",
           "10.3390/chemistry4040100",
           2022,
           "Crystals of two new inorganic uranyl silicates, Cs[(UO6)2(UO2)9(Si2O7)F] (1) and Rb2[(PtO4)(UO2)5(Si2O7)] (2), were produced from melts in evacuated silica tubes. Their structures have been solved by direct methods: 1 is trigonal, P-31c, a = 10.2040(3), c = 17.1278(5) Å, V = 1544.45(10) Å3, R1 = 0.042; 2 is tetragonal, P4/mbm, a = 16.0400(24), c = 3.9231(6) Å, V = 1009.34(10) Å3, R1 = 0.045. 1 is the first example of cation–cation interactions between the uranyl polyhedra in uranyl silicates. Therein, UVI adopts three coordination modes, UO6 octahedra, UO6F, and UO7 pentagonal bipyramids, with the latter sharing common edges to form U2O12 dimers. Three dimers associate into six-membered rings via cation–cation interactions. The structure of 1 can be described as a complex uranyl fluoride silicate framework with channels filled by the U1 atoms and disordered Cs+ cations. 2 represents a new type of topology never observed before among the structures of uranyl compounds; it is also a first complex uranium platinum oxide. Therein, the UO6 tetragonal bipyramids share edges to form chains. Five such chains are stitched into a complex ribbon via the silicon polyhedra. The ribbons are connected into a framework by the PtO4 squares; rubidium atoms are located in the channels of the framework.",
           1,
           "chemistry"
          ],
          [
           "Effect of Fiber Content and Silane Treatment on the Mechanical Properties of Recycled Acrylonitrile-Butadiene-Styrene Fiber Composites",
           "10.3390/chemistry3040091",
           2021,
           "The aim of the present study was to investigate the effects of fiber content and then silane treatment on the mechanical performance of the natural fiber composites of recycled acrylonitrile–butadiene–styrene (ABS) provided by the automotive sector. Wood and palmyra fibers were used as fillers in 10% and 20% fiber content composites. The fibers were treated with N-(2-Aminoethyl)-3-aminopropyltrimethoxysilane to improve the interfacial adhesion between fibers and polymer matrices. The mechanical properties of the composites were determined by tensile and impact tests. Morphological analysis was later performed using a scanning electron microscope (SEM). According to the experiment results, the tensile and impact strength of both wood and palmyra fibers increase after silane treatment. However, for the low-wood-fiber-content composite, the tensile and impact strength decrease after silane treatment due to the presence of an excess amount of silane relative to fiber content. The addition of wood and palmyra fibers significantly improved the tensile modulus of composite material and further increases slightly after silane treatment. Finally, SEM analysis shows a homogenous mix of fibers and polymer matrices with fewer voids after silane treatment, thereby improving interfacial adhesion.",
           8,
           "chemistry"
          ],
          [
           "Advantages of Yolk Shell Catalysts for the DRM: A Comparison of Ni/ZnO@SiO2 vs. Ni/CeO2 and Ni/Al2O3",
           "10.3390/chemistry1010003",
           2018,
           "Encapsulation of metal nanoparticles is a leading technique used to inhibit the main deactivation mechanisms in dry reforming of methane reaction (DRM): Carbon formation and Sintering. Ni catalysts (15%) supported on alumina (Al2O3) and ceria (CeO2) have shown they are no exception to this analysis. The alumina supported catalysts experienced graphitic carbonaceous deposits, whilst the ceria showed considerable sintering over 15 h of DRM reaction. The effect of encapsulation compared to that of the performance of uncoated catalysts for DRM reaction has been examined at different temperatures, before conducting longer stability tests. The encapsulation of Ni/ZnO cores in silica (SiO2) leads to advantageous conversion of both CO2 and CH4 at high temperatures compared to its uncoated alternatives. This work showcases the significance of the encapsulation process and its overall effects on the catalytic performance in chemical CO2 recycling via DRM.",
           19,
           "chemistry"
          ],
          [
           "A Procedure for Computing Hydrocarbon Strain Energies Using Computational Group Equivalents, with Application to 66 Molecules †",
           "10.3390/chemistry2020022",
           2020,
           "A method is presented for the direct computation of hydrocarbon strain energies using computational group equivalents. Parameters are provided at several high levels of electronic structure theory: W1BD, G-4, CBS-APNO, CBS-QB3, and M062X/6-31+G(2df,p). As an illustration of the procedure, strain energies are computed for 66 hydrocarbons, most of them highly strained.",
           21,
           "chemistry"
          ],
          [
           "Current Scenario of MXene-Based Nanomaterials for Wastewater Remediation: A Review",
           "10.3390/chemistry4040104",
           2022,
           "Rapid urban and industrial sectors generate massive amounts of wastewater, creating severe ecological disruption and harming living organisms. The number of harmful pollutants such as dyes, heavy metals, antibiotics, phenolic compounds, and volatile and several organic chemicals discharged into aquatic systems varies depending on the effluent composition of various sectors. MXene-based composites with unique characteristics were spotlighted as newly developed nanomaterials specifically for environmental-related applications. Therefore, this review broadly discusses the properties, basic principles of MXene, and synthesis routes for developing different MXene-based nanomaterials. The most current strategies on the energy and environmental applications of MXene-based nanomaterials, particularly in photocatalysis, adsorption, and water splitting, were deeply explored for the remediation of different pollutants and hydrogen (H2) evolution from wastewater. The detailed mechanism for H2 evolution and the remediation of industrial pollutants via photocatalysis and adsorption processes was elaborated. The multi-roles of MXene-based nanomaterials with their regeneration possibilities were emphasized. Several essential aspects, including the economic, toxicity and ecological power of MXene-based nanomaterials, were also discussed regarding their opportunity for industrialization. Finally, the perspectives and challenges behind newly developed MXene and MXene-based nanomaterials for environmental pollution were reviewed.",
           8,
           "chemistry"
          ],
          [
           "The Photophysical Properties of Triisopropylsilyl-ethynylpentacene—A Molecule with an Unusually Large Singlet-Triplet Energy Gap—In Solution and Solid Phases",
           "10.3390/chemistry2020033",
           2020,
           "The process of singlet-exciton fission (SEF) has attracted much attention of late. One of the most popular SEF compounds is TIPS-pentacene (TIPS-P, where TIPS = triisopropylsilylethynyl) but, despite its extensive use as both a reference and building block, its photophysical properties are not so well established. In particular, the triplet state excitation energy remains uncertain. Here, we report quantitative data and spectral characterization for excited-singlet and -triplet states in dilute solution. The triplet energy is determined to be 7940 ± 1200 cm−1 on the basis of sensitization studies using time-resolved photoacoustic calorimetry. The triplet quantum yield at the limit of low concentration and low laser intensity is only ca. 1%. Self-quenching occurs at high solute concentration where the fluorescence yield and lifetime decrease markedly relative to dilute solution but we were unable to detect excimer emission by steady-state spectroscopy. Short-lived fluorescence, free from excimer emission or phosphorescence, occurs for crystals of TIPS-P, most likely from amorphous domains.",
           14,
           "chemistry"
          ],
          [
           "Pure Hydrolysis of Polyamides: A Comparative Study",
           "10.3390/chemistry6010002",
           2023,
           "Polyamides (PAs) undergo local environmental degradation, leading to a decline in their mechanical properties over time. PAs can experience various forms of degradation, such as thermal degradation, oxidation, hydrothermal oxidation, UV oxidation, and hydrolysis. In order to better comprehend the degradation process of PAs, it is crucial to understand each of these degradation mechanisms individually. While this review focuses on hydrolysis, the data from degrading similar PAs under pure thermal oxidation and/or hydrothermal oxidation are also collected to grasp more perspective. This review analyzes the available characterization data and evaluates the changes in molecular weight, crystallinity, chemical structure, and mechanical properties of PAs that have aged in oxygen-free water at high temperatures. The molecular weight and mechanical strength decrease as the crystallinity ratio rises over aging time. This development is occurring at a slower rate than degradation in pure thermal oxidation. By combining the data for the changes in mechanical properties with the ones for molecular weight and crystallinity, the point of embrittlement can be not only predicted, but also modeled. This prediction is also shown to be dependent on the fibers, additives, types of PA, pH, and more.",
           1,
           "chemistry"
          ],
          [
           "Metals, n-Alkanes, Hopanes, and Polycyclic Aromatic Hydrocarbon in Sediments from Three Amazonian Streams Crossing Manaus (Brazil)",
           "10.3390/chemistry2020018",
           2020,
           "Pollution is increasing in the Amazon region and its real impact is still unclear. Since this region is of great interest to the global community, this study aimed to assess geochemical biomarkers and metals in sediments from three streams crossing Manaus, a Brazilian city of 2.1 million inhabitants located in the heart of the Amazon rainforest. The Mindu and Quarenta streams criss-cross the urban area of Manaus and receive domestic effluents from many heavily populated districts. In addition, the Quarenta stream is subjected to effluents from the industrial district of Manaus. The Tarumã-Açu stream is mostly covered by vegetation, although the region presents some occurrence of family farming, floating petrol station, marinas, and floating restaurants and bars. n-Alkanes were determined by Gas Chromatography with Flame Ionization Detection (GC-FID), whereas hopanes and polycyclic aromatic hydrocarbons (PAHs) were determined by Gas Chromatography coupled to Mass Spectrometry (GC-MS). The metals Ag, Cd, Cr, Co, Cu, Mn, Ni, Pb, and Zn were determined by Inductively Coupled Plasma Optical Emission Spectroscopy (ICP-OES) after microwave-assisted acid digestion. Concentrations of total PAHs and metals were higher in sediments from the urban streams Mindu and Quarenta because of the occurrence of more intense and diverse sources of pollution. In addition, some sediment samples from both these streams presented concentrations of fluoranthene, phenanthrene, and metals higher than the limits of low probability of adverse effects on biota established by the international guideline and by the Brazilian legislation. A similar total n-alkane concentration for sediments from all streams associated with profiles of n-alkanes with no odd/even hydrocarbon predominance suggests that biomass burning is an important source of hydrocarbons. Petroleum-derived products also represented a source for n-alkanes, as confirmed by the presence of α,β-hopanes, including an α,β-homohopane series from C31 to C35 with the presence of both 22S and 22R epimers. This is the first report on n-alkanes, PAHs, and hopanes in sediments from the Mindu, Quarenta, and Tarumã-Açu streams. The concentrations reported herein may be considered as baseline data in future monitoring programs of these streams.",
           3,
           "chemistry"
          ],
          [
           "Fabrication of Polymersomes: A Macromolecular Architecture in Nanotherapeutics",
           "10.3390/chemistry4030070",
           2022,
           "In consideration of the issues of drug delivery systems, the artificial vesicle structures composed of block copolymers called polymersomes recently gained considerable attention. The possibility of tuning the mechanical parameter and increasing the scale-up production of polymersomes led to its wide application in healthcare. Bearing in mind the disease condition, the structure and properties of the polymersomes could be tuned to serve the purpose. Furthermore, specific ligands can be incorporated on the vesicular surface to induce smart polymersomes, thus improving targeted delivery. The synthesis method and surface functionalization are the two key aspects that determine the versatility of biological applications as they account for stability, specific targeting, degradability, biocompatibility, and bioavailability. A perfectly aligned polymer vesicle can mimic the cells/organelles and function by avoiding cytotoxicity. This supramolecular structure can carry and deliver payloads of a wide range, including drugs, proteins, and genes, contributing to the construction of next-generation therapeutics. These aspects promote the potential use of such components as a framework to approach damaged tissue while maintaining healthy environments during circulation. Herein, this article concentrates specifically on the drug delivery applications of polymersomes.",
           8,
           "chemistry"
          ],
          [
           "Synthesis of Metal Nanoparticles via Pulicaria undulata and an Evaluation of Their Antimicrobial, Antioxidant, and Cytotoxic Activities",
           "10.3390/chemistry5040141",
           2023,
           "Nanoparticle engineering via plants (green synthesis) is a promising eco-friendly technique. In this work, a green protocol was applied to the preparation of silver, zinc, and selenium nanoparticle solutions supported by the extracted aerial parts of Pulicaria undulata. The formation of nanoparticles in the solution was characterized using phytochemical analysis, and UV-visible, TEM, and zeta-potential spectroscopy. In addition, various biological activities were investigated for the extract of P. undulata and the produced nanoparticles (selenium, silver, and zinc), including antioxidant, antimicrobial, and cytotoxic activities. The volatile components of the extracted constitute verified the fact that twenty-five volatile components were characterized for the majority of abundant categories for the fatty acids, esters of fatty acids (59.47%), and hydrocarbons (38.19%) of the total area. The antioxidant activity of P. undulata extract and metal nanoparticles was assessed using DPPH assay. The results indicated reduced potency for the metal nanoparticles’ solutions relative to the results for the plant extract. The cytotoxicity of the investigated samples was assessed using an MTT assay against various tumor and normal cell lines with improved cytotoxic potency of the solutions of metal nanoparticles, compared to the plant extract. The antimicrobial activity was also estimated against various bacterial and fungal species. The results confirmed amended potency for inhibiting the growth of microbial species for the solutions of metal nanoparticles when compared to the extracted aerial parts of the plant. The present study showed that green synthetized nanoparticles using P. undulata have various potential bioactivities.",
           0,
           "chemistry"
          ],
          [
           "Atomic Details of Biomineralization Proteins Inspiring Protein Design and Reengineering for Functional Biominerals",
           "10.3390/chemistry4030059",
           2022,
           "Biominerals are extraordinary materials that provide organisms with a variety of functions to support life. The synthesis of biominerals and organization at the macroscopic level is a consequence of the interactions of these materials with proteins. The association of biominerals and proteins is very ancient and has sparked a wealth of research across biological, medical and material sciences. Calcium carbonate, hydroxyapatite, and silica represent widespread natural biominerals. The atomic details of the interface between macromolecules and these biominerals is very intriguing from a chemical perspective, considering the association of chemical entities that are structurally different. With this review I provide an overview of the available structural studies of biomineralization proteins, explored from the Protein Data Bank (wwPDB) archive and scientific literature, and of how these studies are inspiring the design and engineering of proteins able to synthesize novel biominerals. The progression of this review from classical template proteins to silica polymerization seeks to benefit researchers involved in various interdisciplinary aspects of a biomineralization project, who need background information and a quick update on advances in the field. Lessons learned from structural studies are exemplary and will guide new projects for the imaging of new hybrid biomineral/protein superstructures at the atomic level.",
           1,
           "chemistry"
          ],
          [
           "The Anion Impact on Dimensionality of Cadmium(II) Complexes with Nicotinamide",
           "10.3390/chemistry5020092",
           2023,
           "Three novel cadmium(II) coordination compounds, the dimeric [Cd(CH3COO)2(nia)2]2 (1), the polymeric {[Cd(nia)4](ClO4)2}n (2), and the monomeric [Cd(H2O)3(nia)3](ClO4)2·nia (3), were prepared in the reactions of the nicotinamide (pyridine-3-carboxamide, nia) with the corresponding cadmium(II) salts. All prepared compounds were characterized by elemental analyses, FT-IR spectroscopy, TGA/DTA, and single crystal X-ray analysis. The impact of anions (acetate, perchlorate) and solvent used on the dimensionality of cadmium(II) complexes and the cadmium(II) coordination environment was investigated. The bridging capabilities of acetate ions enabled the formation of dimers in the crystal structure of 1. It was shown that the dimensionality of perchlorate complexes depends on the solvent used. The coordination polymer 2 is isolated from an ethanol solution, while monomeric compound 3 was obtained by using a water/ethanol mixture as a solvent. The pentagonal-bipyramidal coordination of cadmium(II) was found in the presence of chelating and bridging acetate ions in 1. In the presence of non-coordinating perchlorate anions in 2 and 3, the coordination geometry of cadmium(II) is found to be octahedral. The supramolecular amide-amide homosynthon R22(8) was preserved in the hydrogen-bonded frameworks of all three compounds.",
           0,
           "chemistry"
          ],
          [
           "Synthesis of Naphthoxazinones in a One-Pot Two-Step Manner by the Application of Propylphosphonic Anhydride (T3P®)",
           "10.3390/chemistry2020037",
           2020,
           "A sequential one-pot two-step protocol has been elaborated for the synthesis of naphthoxazinones from 2-naphthol, methyl carbamate, and aromatic aldehydes. First, a three-component reaction was optimized with the dehydrating additive propylphosphonic anhydride (T3P®), resulting in 1-carbamatoalkyl 2-naphthols in good to excellent yields. Following the successful multicomponent approach, intramolecular acylation was performed at high temperature, again with the contribution of T3P®, resulting in naphthoxazinone derivatives in moderate yields. These two steps were optimized together in one-pot as well, and the sequential rise in the requisite temperature eventuated the optimal procedure for the multistep cascade.",
           1,
           "chemistry"
          ],
          [
           "Rolling-Circle-Amplification-Assisted DNA Biosensors for Sensitive and Specific Detection of Hypochlorous Acid and Myeloperoxidase",
           "10.3390/chemistry5020098",
           2023,
           "Hypochlorous acid (HClO) is a common reactive oxygen species (ROS), with a high chemical reactivity. Myeloperoxidase (MPO) is an enzyme that catalyzes in vivo redox reactions between H2O2 and Cl− to produce HClO. Abnormal levels of HClO and MPO may lead to oxidative stress, irreversible tissue damage and, thus, serious diseases; they are thus becoming important biomarkers and therapeutic targets. In this work, using HClO-induced site-specific cleavage of phosphorothioate-modified DNA to trigger rolling circle amplification (RCA), RCA-assisted biosensors have been developed for the highly sensitive and specific detection of HClO and MPO. Only two DNA oligonucleotides are used in the sensing systems. The powerful signal-amplification capability of RCA endows the sensing systems with a high sensitivity, and the specific fluorescent response of thioflavin T (ThT) to G-quadruplexes in RCA products makes a label-free signal output possible. The proposed biosensors were demonstrated to work well not only for the sensitive and specific quantitation of HClO and MPO with detection limits of 1.67 nM and 0.33 ng/mL, respectively, but also for the screening and inhibitory capacity evaluation of MPO inhibitors, thus holding great promise in disease diagnosis and drug analysis.",
           0,
           "chemistry"
          ],
          [
           "When Stereochemistry Raised Its Ugly Head in Coordination Chemistry—An Appreciation of Howard Flack",
           "10.3390/chemistry2030049",
           2020,
           "Chiral compounds have played an important role in the development of coordination chemistry. Unlike organic chemistry, where mechanistic rules allowed the establishment of absolute configurations for numerous compounds once a single absolute determination had been made, coordination compounds are more complex. This article discusses the development of crystallographic methods and the interplay with coordination chemistry. Most importantly, the development of the Flack parameter is identified as providing a routine method for determining the absolute configuration of coordination compounds.",
           7,
           "chemistry"
          ],
          [
           "Platform Chemicals from Ethylene Glycol and Isobutene: Thermodynamics “Pays” for Biomass Valorisation and Acquires “Cashback”",
           "10.3390/chemistry5020079",
           2023,
           "Ethylene glycol (EG) produced from biomass is a promising candidate for several new applications. In this paper, EG derivatives such as mono- and di-tert-butyl ethers are considered. However, accurate thermodynamic data are essential to optimise the technology of the direct tert-butyl ether EG synthesis reaction or reverse process isobutene release. The aim of this work is to measure the vapour pressures and combustion energies for these ethers and determine the vaporisation enthalpies and enthalpies of formation from these measurements. Methods based on the First and Second Law of Thermodynamics were combined to discover the reliable thermodynamics of ether synthesis reactions. The thermochemical data for ethylene glycol tert-butyl ethers were validated using structure–property correlations and quantum chemical calculations. The literature results of the equilibrium study of alkylation of EG with isobutene were evaluated and the thermodynamic functions of ethylene glycol tert-butyl ethers were derived. The energetics of alkylation determined according to the “First Law” and the “Second Law” methods agree very well. Some interesting aspects related to the entropy of ethylene glycol tert-butyl ethers were also revealed and discussed.",
           0,
           "chemistry"
          ],
          [
           "Tribute to Josef Michl",
           "10.3390/chemistry3010032",
           2021,
           "It is our great pleasure to introduce the Festschrift of Chemistry to honor professor Josef Michl (Figure 1) on the occasion of his 80th birthday and to recognize his exceptional contributions to the fields of organic photochemistry, quantum chemistry, biradicals and biradicaloids, electronic and vibrational spectroscopy, magnetic circular dichroism, silicon and boron chemistry, supramolecular chemistry, singlet fission, and molecular machines [...]",
           1,
           "chemistry"
          ],
          [
           "A New Study on the Eastern Flank of the Loma Blanca Deposit (Cuba) to Establish the Mineralogical, Chemical, and Pozzolanic Properties of Zeolitised Tuffs",
           "10.3390/chemistry4030048",
           2022,
           "The geological nature of the territory of the Republic of Cuba has favoured the formation of large and varied deposits of volcanic tuffs enriched by various species of zeolites. Today, new zeolite deposits continue to be discovered in the country. This work aims to present the results of a study carried out in an unexplored area that is located approximately 1.2 km east of the Loma Blanca deposit, outside the mining operation limits. To carry out this research and to establish a qualitative comparison between both sample populations, four samples were taken from the study area, and another four were taken from the Loma Blanca deposit. The characterisation of the samples was performed by XRD, SEM, and XRF. The pozzolan quality was determined by the pozzolanicity test (PT) and quality chemical analysis (QCA). Finally, a study of the mechanical strength (MST) was performed at 7, 28, and 90 days, using mortar specimens made with PC/ZT: 75–25% and PC/ZT: 70–30%, respectively. The results of the studies using XRD, SEM, and XRF indicated that both groups of samples had a similar complex mineralogical composition, consisting mainly of mordenite and clinoptilolite accompanied by secondary phases such as quartz and amorphous materials in the form of altered glass. The pozzolanicity test showed that both the samples from the study area and those from the Loma Blanca deposit behaved like typical pozzolans, which is a trend that can be seen in the high values of mechanical strength to compression up to 72 MPa for the PC/ZT: 75–25% formulation and 66 MPa for the PC/ZT: 70–30%. The results obtained establish that the zeolite varieties detected in the study area are similar to those of the Loma Blanca deposit, which could have a positive impact on the increase in current reserves, especially for manufacturing pozzolanic cements with properties that contribute to the preservation of the environment.",
           0,
           "chemistry"
          ],
          [
           "Synthetic and Structural Chemistry of Uranyl-Amidoxime Complexes: Technological Implications",
           "10.3390/chemistry5020097",
           2023,
           "Resource shortage is a major problem in our world. Nuclear energy is a green energy and because of this and its high energy density, it has been attracting more and more attention during the last few decades. Uranium is a valuable nuclear fuel used in the majority of nuclear power plants. More than one thousand times more uranium exists in the oceans, at very low concentrations, than is present in terrestrial ores. As the demand for nuclear power generation increases year-on-year, access to this reserve is of paramount importance for energy security. Water-insoluble polymeric materials functionalized with the amidoxime group are a technically feasible platform for extracting uranium, in the form of {UO2}2+, from seawater, which also contains various concentrations of other competing metal ions, including vanadium (V). An in-depth understanding of the coordination modes and binding strength of the amidoxime group with uranyl and other competing ions is a key parameter for improving extraction efficiency and selectivity. Very limited information on the complexation of {UO2}2+ with amidoximes was available before 2012. However, significant advances have been made during the last decade. This report reviews the solid-state coordination chemistry of the amidoxime group (alone or within ligands with other potential donor sites) with the uranyl ion, while sporadic attention on solution and theoretical studies is also given. Comparative studies with vanadium complexation are also briefly described. Eight different coordination modes of the neutral and singly deprotonated amidoxime groups have been identified in the structures of the uranyl complexes. Particular emphasis is given to describing the reactivity of the open-chain glutardiamidoxime, closed-ring glutarimidedioxime and closed-ring glutarimidoxioxime moieties, which are present as side chains on the sorbents, towards the uranyl moiety. The technological implications of some of the observed coordination modes are outlined. It is believed that X-ray crystallography of small uranyl-amidoxime molecules may help to build an understanding of the interactions of seawater uranyl with amidoxime-functionalized polymers and improve their recovery capacity and selectivity, leading to more efficient extractants. The challenges for scientists working on the structural elucidation of uranyl coordination complexes are also outlined. The review contains six sections and 95 references.",
           1,
           "chemistry"
          ],
          [
           "Hydrogen and Halogen Bond Mediated Coordination Polymers of Chloro-Substituted Pyrazin-2-Amine Copper(I) Bromide Complexes",
           "10.3390/chemistry2030045",
           2020,
           "A new class of six mono- (1; 3-Cl-, 2; 5-Cl-, 3; 6-Cl-) and di-(4; 3,6-Cl, 5; 5,6-Cl-, 6; 3,5-Cl-) chloro-substituted pyrazin-2-amine ligands (1–6) form complexes with copper (I) bromide, to give 1D and 2D coordination polymers through a combination of halogen and hydrogen bonding that were characterized by X-ray diffraction analysis. These Cu(I) complexes were prepared indirectly from the ligands and CuBr2 via an in situ redox process in moderate to high yields. Four of the pyrazine ligands, 1, 4–6 were found to favor a monodentate mode of coordination to one CuI ion. The absence of a C6-chloro substituent in ligands 1, 2 and 6 supported N1–Cu coordination over the alternative N4–Cu coordination mode evidenced for ligands 4 and 5. These monodentate systems afforded predominantly hydrogen bond (HB) networks containing a catenated (μ3-bromo)-CuI ‘staircase’ motif, with a network of ‘cooperative’ halogen bonds (XB), leading to infinite polymeric structures. Alternatively, ligands 2 and 3 preferred a μ2-N,N’ bridging mode leading to three different polymeric structures. These adopt the (μ3-bromo)-CuI ‘staircase’ motif observed in the monodentate ligands, a unique single (μ2-bromo)-CuI chain, or a discrete Cu2Br2 rhomboid (μ2-bromo)-CuI dimer. Two main HB patterns afforded by self-complimentary dimerization of the amino pyrazines described by the graph set notation R22(8) and non-cyclic intermolecular N–H∙∙∙N’ or N–H∙∙∙Br–Cu leading to infinite polymeric structures are discussed. The cooperative halogen bonding between C–Cl∙∙∙Cl–C and the C–Cl∙∙∙Br–Cu XB contacts are less than the sum of the van der Waals radii of participating atoms, with the latter ranging from 3.4178(14) to 3.582(15) Å. In all cases, the mode of coordination and pyrazine ring substituents affect the pattern of HBs and XBs in these supramolecular structures.",
           2,
           "chemistry"
          ],
          [
           "Carbon Nanotubes Modified by BiMo Metal Oxides for Oxidative Dehydrogenation of 1-Butene to 1,3-Butadiene without Steam",
           "10.3390/chemistry4020027",
           2022,
           "Oxidative dehydrogenation (ODH) reaction has emerged as a promising route for converting 1-butene to value-added 1,3-butadiene (BD). However, the low BD selectivity of the current catalysts (≤40%) and high steam input are now the challenge of this process. Here, we demonstrate the fabrication BiMo oxides immobilized on carbon nanotubes (BiMo/CNTs), employing the sol–gel method, as a novel catalyst for the ODH of 1-butene without steam in a fixed-bed reactor. The catalytic performances of BiMo/CNTs with different compositions in the absence of steam were investigated. When BiMo/CNTs at a molar ratio of 0.018 were employed in the ODH of 1-butene under reaction conditions of 440 °C, 1-butene/oxygen = 1/0.8, and no steam, the optimal BD yield was achieved as high as 52.2%. Under this reaction condition, the catalyst maintains good stability without steam after 10 h of reaction. This work not only promotes the application of carbon materials in oxidative dehydrogenation reaction, but also accelerates the production of 1,3-butadiene in a more economical way.",
           2,
           "chemistry"
          ],
          [
           "Substrate–Solvent Crosstalk—Effects on Reaction Kinetics and Product Selectivity in Olefin Oxidation Catalysis",
           "10.3390/chemistry3030054",
           2021,
           "In this work, we explored how solvents can affect olefin oxidation reactions catalyzed by MCM-bpy-Mo catalysts and whether their control can be made with those players. The results of this study demonstrated that polar and apolar aprotic solvents modulated the reactions in different ways. Experimental data showed that acetonitrile (aprotic polar) could largely hinder the reaction rate, whereas toluene (aprotic apolar) did not. In both cases, product selectivity at isoconversion was not affected. Further insights were obtained by means of neutron diffraction experiments, which confirmed the kinetic data and allowed for the proposal of a model based on substrate–solvent crosstalk by means of hydrogen bonding. In addition, the model was also validated in the ring-opening reaction (overoxidation) of styrene oxide to benzaldehyde, which progressed when toluene was the solvent (reaching 31% styrene oxide conversion) but was strongly hindered when acetonitrile was used instead (reaching only 7% conversion) due to the establishment of H-bonds in the latter. Although this model was confirmed and validated for olefin oxidation reactions, it can be envisaged that it may also be applied to other catalytic reaction systems where reaction control is critical, thereby widening its use.",
           3,
           "chemistry"
          ],
          [
           "Howard Flack and the Flack Parameter",
           "10.3390/chemistry2040052",
           2020,
           "The Flack Parameter is now almost universally reported for all chiral materials characterized by X-ray crystallography. Its elegant simplicity was an inspired development by Howard Flack, and although the original algorithm for its computation has been strengthened by other workers, it remains an essential outcome for any crystallographic structure determination. As with any one-parameter metric, it needs to be interpreted in the context of its standard uncertainty.",
           10,
           "chemistry"
          ],
          [
           "Neutral and Cationic Chelidonate Coordination Polymers with N,N′-Bridging Ligands",
           "10.3390/chemistry3010019",
           2021,
           "The biomolecule chelidonic acid (H2chel, 4-oxo-4H-pyran-2,6-dicarboxylic acid) has been used to build new coordination polymers with the bridging N,N′-ligands 4,4′-bipyridine (4,4-bipy) and 1,2-bis(4-pyridyl)ethane (bpe). Four compounds have been obtained as single crystals: 1D cationic coordination polymers [M(4,4-bipy)(OH2)4]2+ with chelidonate anions and water molecules in the second coordination sphere in 1∞[Zn(4,4-bipy)(H2O)4]chel·3H2O (2) and in the two pseudopolymorphic 1∞[Cu(4,4-bipy)(H2O)4]chel·nH2O (n = 3, 4a; n = 6, 4b), and the 2D neutral coordination polymers 2∞[Zn(chel)(4,4-bipy)(H2O)]·2H2O (1) and 2∞[Zn(chel)(bpe)(H2O)]·H2O (3) where the chelidonate anion acts as a bridging ligand. The effects of the hydrogen bonds on the crystal packing were analyzed. The role of the water molecules hosted within the crystals lattices was also studied.",
           1,
           "chemistry"
          ],
          [
           "Topological Dynamics of a Radical Ion Pair: Experimental and Computational Assessment at the Relevant Nanosecond Timescale",
           "10.3390/chemistry2020014",
           2020,
           "Chemical processes mostly happen in fluid environments where reaction partners encounter via diffusion. The bimolecular encounters take place at a nanosecond time scale. The chemical environment (e.g., solvent molecules, (counter)ions) has a decisive influence on the reactivity as it determines the contact time between two molecules and affects the energetics. For understanding reactivity at an atomic level and at the appropriate dynamic time scale, it is crucial to combine matching experimental and theoretical data. Here, we have utilized all-atom molecular-dynamics simulations for accessing the key time scale (nanoseconds) using a QM/MM-Hamiltonian. Ion pairs consisting of a radical ion and its counterion are ideal systems to assess the theoretical predictions because they reflect dynamics at an appropriate time scale when studied by temperature-dependent EPR spectroscopy. We have investigated a diketone radical anion with its tetra-ethylammonium counterion. We have established a funnel-like transition path connecting two (equivalent) complexation sites. The agreement between the molecular-dynamics simulation and the experimental data presents a new paradigm for ion–ion interactions. This study exemplarily demonstrates the impact of the molecular environment on the topological states of reaction intermediates and how these states can be consistently elucidated through the combination of theory and experiment. We anticipate that our findings will contribute to the prediction of bimolecular transformations in the condensed phase with relevance to chemical synthesis, polymers, and biological activity.",
           0,
           "chemistry"
          ],
          [
           "Condensed DNA Nanosphere for DNA Origami Cryptography",
           "10.3390/chemistry5040159",
           2023,
           "Maintaining the confidentiality and integrity of the messages during a transmission is one of the most important aims of encrypted communication systems. Many achievements were made using biomolecules to improve the quality of the messages in communication. At the same time, it is still a challenge to construct cooperative communications based on the interactions between biomolecules to achieve the confidentiality and integrity of the transmitted messages. DNA-based encrypted communications have been developed, and in particular, DNA-origami-based message encryption can combine steganography and pattern encryption and exhibits extremely high confidentiality. Nevertheless, limited by biological characteristics, encrypted messages based on DNA require a strict storage environment in the process of transmission. The integrity of the message encoded in the DNA may be damaged when the DNA is in an unfriendly and hard environment. Therefore, it is particularly significant to improve the stability of DNA when it is exposed to a harsh environment during transmission. Here, we encoded the information into the DNA strands that were condensed for encryption to form a nanosphere covered with a shell of SiO2, which brings high-density messages and exhibits higher stability than separated DNA. The solid shell of SiO2 could prevent DNA from contacting the harsh environment, thereby protecting the DNA structure and maintaining the integrity of the information. At the same time, DNA nanospheres can achieve high throughput input and higher storage density per unit volume, which contribute to confusing the message strand (M-strand) with the interference strand in the stored information. Condensing DNA into the nanosphere that is used for DNA origami cryptography has the potential to be used in harsh conditions with higher confidentiality and integrity for the transmitted messages.",
           0,
           "chemistry"
          ],
          [
           "Solvation Effects on the Thermal Helix Inversion of Molecular Motors from QM/MM Calculations",
           "10.3390/chemistry4010016",
           2022,
           "Molecular motors convert light and thermal energies into mechanical work, offering good opportunities to design novel molecular devices. Among them, molecular motors alternate a photoisomerization and a thermal helix inversion to achieve unidirectional rotation. The rotational speed is limited by the helix inversion step, which in turn is governed by a barrier in the electronic ground state. In this work, we systematically study the solvation effect on the thermal process of selected molecular motors, comparing reaction barriers obtained from both density functional theory (DFT) in the isolated system and umbrella sampling within a hybrid quantum mechanics/molecular mechanics (QM/MM) model in solution. We find more prominent solvation effects on those molecular motors with larger dipole moments. The results could provide insight into how to functionalize molecular motors to speed up their rotation.",
           5,
           "chemistry"
          ],
          [
           "Combining the Sensitivity of LAMP and Simplicity of Primer Extension via a DNA-Modified Nucleotide",
           "10.3390/chemistry2020029",
           2020,
           "LAMP is an approach for isothermal nucleic acids diagnostics with increasing importance but suffers from the need of tedious systems design and optimization for every new target. Here, we describe an approach for its simplification based on a single nucleoside-5′-O-triphosphate (dNTP) that is covalently modified with a DNA strand. We found that the DNA-modified dNTP is a substrate for DNA polymerases in versatile primer extension reactions despite its size and that the incorporated DNA indeed serves as a target for selective LAMP analysis.",
           0,
           "chemistry"
          ],
          [
           "Synthesis, Structures and Photophysical Properties of Tetra- and Hexanuclear Zinc Complexes Supported by Tridentate Schiff Base Ligands",
           "10.3390/chemistry5020070",
           2023,
           "The synthesis, structure and photophysical properties of two polynuclear zinc complexes, namely [Zn6L2(µ3-OH)2(OAc)8] (1) and [Zn4L4(µ2-OH)2](ClO4)2 (2), supported by tridentate Schiff base ligand 2,6-bis((N-benzyl)iminomethyl)-4-tert-butylphenol (HL) are presented. The synthesized compounds were investigated using ESI-MS, IR, NMR, UV-vis absorption spectroscopy, photoluminescence spectroscopy and single-crystal X-ray crystallography. The hexanuclear neutral complex 1 comprises six-, five- and four-coordinated Zn2+ ions coordinated by O and N atoms from the supporting ligand and OH- and acetate ligands. The Zn2+ ions in complex cation [Zn4L4(µ2-OH)2]2+ of 2 are all five-coordinated. The complexation of ligand HL by Zn2+ ions leads to a six-fold increase in the intensity and a large blue shift of the ligand-based 1(π-π)* emission. Other biologically relevant ions, i.e., Na+, K+, Mg2+, Ca2+, Mn2+, Fe2+, Co2+, Ni2+ and Cu2+, did not give rise to a fluorescence enhancement.",
           0,
           "chemistry"
          ],
          [
           "A Sustainable Synthetic Approach to the Indaceno[1,2-b:5,6-b′]dithiophene (IDT) Core through Cascade Cyclization–Deprotection Reactions",
           "10.3390/chemistry4010018",
           2022,
           "Bulk heterojunction organic solar cells (BHJs) are competitive within the emerging photovoltaic technologies for solar energy conversion because of their unique advantages. Their development has been boosted recently by the introduction of nonfullerene electron acceptors (NFAs), to be used in combination with a polymeric electron donor in the active layer composition. Many of the recent advances in NFAs are attributable to the class of fused-ring electron acceptors (FREAs), which is now predominant, with one of the most notable examples being formed with a fused five-member-ring indaceno[1,2-b:5,6-b′]dithiophene (IDT) core. Here, we propose a novel and more sustainable synthesis for the IDT core. Our approach bypasses tin derivatives needed in the Stille condensation, whose byproducts are toxic and difficult to dispose of, and it makes use of cascade reactions, effectively reducing the number of synthetic steps.",
           2,
           "chemistry"
          ],
          [
           "Activated Carbon from Sugarcane Bagasse: A Low-Cost Approach towards Cr(VI) Removal from Wastewater",
           "10.3390/chemistry5020077",
           2023,
           "The potential of pretreated sugarcane bagasse (SCB) as a low-cost and renewable source to yield activated carbon (AC) for chromate CrO42− removal from an aqueous solution has been investigated. Raw sugarcane bagasse was pretreated with H2SO4, H3PO4, HCl, HNO3, KOH, NaOH, or ZnCl2 before carbonization at 700 °C. Only pretreatments with H2SO4 and KOH yield clean AC powders, while the other powders still contain non-carbonaceous components. The point of zero charge for ACs obtained from SCB pretreated with H2SO4 and KOH is 7.71 and 2.62, respectively. Batch equilibrium studies show that the most effective conditions for chromate removal are a low pH (i.e., below 3) where >96% of the chromate is removed from the aqueous solution.",
           0,
           "chemistry"
          ],
          [
           "Degradation of Polypropylene and Jute Fiber-Reinforced Composites Exposed to Natural and Accelerated Aging: Mechanical Properties and Wettability",
           "10.3390/chemistry3040100",
           2021,
           "Population growth and the way resources are being exploited are directly affecting the environment. The natural fiber market, for example, is worth billions of dollars and a huge amount of the fibers becomes waste. This considerable amount of waste motivates the study of the fibers as a reinforcement in polymeric matrix, which benefits both the environmental sustainability and technical-commercial development of new materials with good properties and reduced cost. In this study, jute fiber-reinforced composites previously manufactured from an industrial waste (W), polypropylene, compatibilizer, and nano-calcium carbonate (N), were exposed to natural and accelerated aging. The composites were tested by infrared spectroscopy, contact angle (CA) measurement, and tensile test. Infrared analysis showed greater oxidative degradation after accelerated aging. All CA values continued above 90° after natural aging. Among all compositions, the ones with the presence of N had the highest CA values, showing that N acted as a waterproofing agent. After accelerated aging, a significant decrease in all CA values was observed. The composites did not show significant variation in the elastic modulus after either aging. Deformation at break decreased significantly for compositions with no jute fiber in both aging programs. No remarkable reduction was observed in the compositions with jute fibers.",
           4,
           "chemistry"
          ],
          [
           "Preparation and Chiral HPLC Separation of the Enantiomeric Forms of Natural Prostaglandins",
           "10.3390/chemistry2030047",
           2020,
           "Four enantiomeric forms of natural prostaglandins, ent-PGF2α ((−)-1), ent-PGE2 ((+)-2) ent-PGF1α ((−)-3), and ent-PGE1 ((+)-4) have been synthetized in gram scale by Corey synthesis used in the prostaglandin plants of CHINOIN, Budapest. Chiral HPLC methods have been developed to separate the enantiomeric pairs. Enantiomers of natural prostaglandins can be used as analytical standards to verify the enantiopurity of synthetic prostaglandins, or as biomarkers to study oxidation processes in vivo.",
           0,
           "chemistry"
          ],
          [
           "New Materials and Phenomena in Membrane Distillation",
           "10.3390/chemistry5010006",
           2023,
           "In recent decades, membrane-based processes have been extensively applied to a wide range of industrial processes, including gas separation, food industry, drug purification, and wastewater treatment. Membrane distillation is a thermally driven separation process, in which only vapour molecules transfer through a microporous hydrophobic membrane. At the operational level, the performance of membrane distillation is negatively affected by wetting and temperature polarization phenomena. In order to overcome these issues, advanced membranes have been developed in recent years. This review, which focuses specifically on membrane distillation presents the basic concepts associated with the mass and heat transfer through hydrophobic membranes, membrane properties, and advances in membrane materials. Photothermal materials for solar-driven membrane distillation applications are also presented and discussed.",
           2,
           "chemistry"
          ],
          [
           "Exchange Speed of Four-Component Nanorotors Correlates with Hammett Substituent Constants",
           "10.3390/chemistry3010009",
           2021,
           "Three distinct four-component supramolecular nanorotors were prepared, using, for the first time, bipyridine instead of phenanthroline stations in the stator. Following our established self-sorting protocol to multicomponent nanodevices, the nanorotors were self-assembled by mixing the stator, rotators with various pyridine head groups, copper(I) ions and 1,4-diazabicyclo[2.2.2]octane (DABCO). Whereas the exchange of a phenanthroline vs. a bipyridine station did not entail significant changes in the rotational exchange frequency, the para-substituents at the pyridine head group of the rotator had drastic consequences on the speed: 4-OMe (k298 = 35 kHz), 4-H (k298 = 77 kHz) and 4-NO2 (k298 = 843 kHz). The exchange frequency (log k) showed an excellent linear correlation with both the Hammett substituent constants and log K of the copper(I)–ligand interaction, proving that rotator–copper(I) bond cleavage is the key determining factor in the rate-determining step.",
           3,
           "chemistry"
          ],
          [
           "Effect of Hydrazine Pretreatment on the Activity, Stability and Active Sites of Cobalt Species for Preferential Oxidation (PROX) of CO in H2-Rich Stream",
           "10.3390/chemistry1010011",
           2019,
           "The as-prepared (Co3O4) and hydrazine-treated (Co3O4(H)) cobalt catalysts were prepared using the precipitation method and evaluated at a temperature range of 40–220 °C for preferential oxidation (PROX) of CO in excess hydrogen. An improved surface reducibility with smaller crystallite size was noted on hydrazine-treated cobalt species (i.e., Co3O4(H) catalyst), which indicates some surface transformation. This finding correlates with the surface roughness formation (as depicted by scanning electron microscope (SEM) and transmission electron microscope (TEM) data), which was further confirmed by an increase in the Brunauer–Emmett–Teller (BET) surface area. The mesoporous structure of the Co3O4(H) catalyst remained intact, as compared to that of the Co3O4 catalyst. Interestingly, the in situ treatment of the standalone Co3O4(H) catalyst decreased the maximum CO conversion temperature (T100%) from 160 °C (over Co3O4) to 100 °C, with good selectivity. The Co3O4(H) catalyst showed good stability, with approximately 85% CO conversion at 100 °C for 21 h, as compared to a faster deactivation of the Co3O4 catalyst. However, the Co3O4(H) catalyst was unstable in both CO2 and the moisture environment. Based on the evaluation of spent hydrazine-treated (CoO(H)) cobalt catalyst, the high PROX activity is associated with the formation of Co3+ species as confirmed by X-ray diffraction (XRD), X-ray photoelectron spectra (XPS), and temperature-programmed reduction (TPR) data.",
           1,
           "chemistry"
          ],
          [
           "Kinetic and Spectroscopic Studies of Methyl Ester Promoted Methanol Dehydration to Dimethyl Ether on ZSM-5 Zeolite",
           "10.3390/chemistry5010037",
           2023,
           "Methyl carboxylate esters have been shown to be potent promoters of low-temperature methanol dehydration to dimethyl ether (DME) using various zeolite catalysts. In the present work, catalytic kinetic studies, in-situ Fourier-transform infrared spectroscopy (FT-IR) and solid-state nuclear magnetic resonance spectroscopy (NMR) techniques were used to elucidate the promotional mechanism of methyl carboxylate esters on methanol dehydration to DME, using the medium pore zeolite H-ZSM-5 (MFI) as the catalyst. Kinetic studies were performed using the very potent methyl n-hexanoate promoter. The DME yield was dependent on both the methanol and methyl n-hexanoate partial pressures across the temperature ranges used in this study (110 to 130 °C). This is consistent with the promoted reaction being a bimolecular reaction between methanol and ester species adsorbed at the catalyst active sites, via an SN2 type reaction, as previously postulated. The in-situ FT-IR studies reveal that the Brønsted acid (BA) sites on H-ZSM-5 were very rapidly titrated by ester carbonyl group adsorption and bonded more strongly with esters than with methanol. Upon methanol addition, an even lower DME formation temperature (30 °C) was observed with methyl n-hexanoate pretreated H-ZSM-5 samples in the in-situ NMR studies, further confirming the strong promotion of this methyl ester on methanol dehydration to DME. The adsorption and reactivity of different methyl esters on H-ZSM-5 indicates that while methyl formate more easily dissociates into a surface methoxy species, [Si(OMe)Al], and carboxylic acid, it is a less potent promoter than alkyl-chain-containing methyl esters in methanol dehydration to DME, which in turn did not show this dissociative behavior in the low-temperature NMR studies. This indicates that methyl alkyl carboxylates do not need to be dissociated to a surface methoxy species to promote the methanol dehydration reaction and that a bimolecular associative mechanism plays an important role in promoting DME formation.",
           0,
           "chemistry"
          ],
          [
           "Microwave-Assisted Synthesis, Optical and Theoretical Characterization of Novel 2-(imidazo[1,5-a]pyridine-1-yl)pyridinium Salts",
           "10.3390/chemistry3030050",
           2021,
           "In the last few years, imidazo[1,5-a]pyridine scaffolds and derivatives have attracted growing attention due to their unique chemical structure and optical behaviors. In this work, a series of pyridylimidazo[1,5-a]pyridine derivatives and their corresponding pyridinium salts were synthesized and their optical properties investigated to evaluate the effect of the quaternization on the optical features both in solution and polymeric matrix. A critical analysis based on the spectroscopic data, chemical structures along with density functional theory calculation is reported to address the best strategies to prevent aggregation and optimize the photophysical properties. The obtained results describe the relationship between chemical structure and optical behaviors, highlighting the role of pendant pyridine. Finally, the presence of a positive charge is fundamental to avoid any possible aggregation process in polymeric films.",
           7,
           "chemistry"
          ],
          [
           "Trinuclear and Cyclometallated Organometallic Dinuclear Pt-Pyrazolato Complexes: A Combined Experimental and Theoretical Study",
           "10.3390/chemistry5010016",
           2023,
           "Two differently substituted pyrazole ligands have been investigated with regard to the topology of their Pt complexes: upon deprotonation, two mononuclear 1:2 PtII-pyrazole complexes—one of the sterically unhindered 4-Me-pzH and one of the bulky 3,5-tBu-pzH (pzH = pyrazole)—yield the corresponding 1:2 PtII-pyrazolato species; the former a triangular, trinuclear metallacycle (1), and the latter a dinuclear, half-lantern species (2) formed via the unprecedented cyclometallation of a butyl group. Stoichiometric oxidation of the colorless PtII2 complex produces the deep-blue, metal–metal bonded PtIII2 analog (3) with a rarely encountered unsymmetrical coordination across the Pt-Pt bond. All three complexes have been characterized by single crystal X-ray structure determination, 1H-NMR, IR, and UV-vis-NIR spectroscopic methods. The XPS spectra of the PtII2 and PtIII2 species are also reported. Density functional theory calculations were carried out to investigate the electronic structure, spectroscopic properties, and chemical bonding of the new complexes. The calculated natural population analysis charges and Wiberg bonding indices indicate a weak σ-interaction in the case of 2 and a formal Pt-Pt single bond in 3.",
           0,
           "chemistry"
          ],
          [
           "Crystallization- and Metal-Driven Selection of Discrete Macrocycles/Cages and Their Metallosupramolecular Polymers from Dynamic Systemic Networks",
           "10.3390/chemistry4040084",
           2022,
           "Reversible imine- and metal-coordination reactions are dynamic enough to produce complex libraries of macrocycles, cages, and supramolecular polymers in solution, from which amplification effects have been identified in solution or during crystallization in response to ligand- and metal-driven selection modes. Crystallization-driven selection can lead to the amplification of unexpected metallosupramolecular architectures. The addition of Ag+ triggered the change of the optimal components, so that the crystallization process showed different ligand preferences than in solution. The most packed constituents are amplified in the solid state, taking into account the optimal coordination of metal ions together with non-specific non-covalent interactions between the macrocycle packed in dimers or trimers in the solid state.",
           0,
           "chemistry"
          ],
          [
           "A Greener Technique for Microwave-Assisted O-Silylation and Silyl Ether Deprotection of Uridine and Other Substrates",
           "10.3390/chemistry4040112",
           2022,
           "A single clean, good-yielding, environment-friendly microwave-assisted procedure for O-silylation of uridine with tert-butyldimethylsilyl chloride (TBDMSCl), 1,8-Diazabicyclo(5.4.0)undec-7-ene (DBU) and potassium nitrate as catalyst under solvent-free conditions is reported. Subsequent silyl ether deprotection is accomplished with a reusable acidic resin via microwave irradiation. Both the silylation and desilylation protocols have been applied to a panel of alcohols of pharmaceutical interest.",
           0,
           "chemistry"
          ],
          [
           "Membrane-Supported Recovery of Homogeneous Organocatalysts: A Review",
           "10.3390/chemistry2030048",
           2020,
           "As catalysis plays a significant role in the development of economical and sustainable chemical processes, increased attention is paid to the recovery and reuse of high-value catalysts. Although homogeneous catalysts are usually more active and selective than the heterogeneous ones, both catalyst recycling and product separation pose a challenge for developing industrially feasible methods. In this respect, membrane-supported recovery of organocatalysts represents a particularly useful tool and a valid option for organocatalytic asymmetric synthesis. However, catalyst leaching/degradation and a subsequent decrease in selectivity/conversion are significant drawbacks. As the effectivity of the membrane separation depends mainly on the size of the catalyst in contrast to the other solutes, molecular weight enlargement of small organocatalysts is usually necessary. In the last few years, several synthetic methodologies have been developed to facilitate their recovery by nanofiltration. With the aim of extending the possibilities for the membrane-supported recovery of organocatalysts further, this contribution presents a review of the existing synthetic approaches for the molecular weight enlargement of organocatalysts.",
           9,
           "chemistry"
          ],
          [
           "On the Redox Equilibrium of TPP/TPPO Containing Cu(I) and Cu(II) Complexes",
           "10.3390/chemistry5020087",
           2023,
           "Copper(II) clusters of the type [CuII4OCl6L4] (L = ligand or solvent) are a well-studied example of inverse coordination compounds. In the past, they have been studied because of their structural, magnetic, and spectroscopic features. They have long been believed to be redox-inactive compounds, but recent findings indicate a complex chemical equilibrium with diverse mononuclear as well as multinuclear copper(I) and copper(II) compounds. Furthermore, depending on the ligand system, such cluster compounds have proven to be versatile catalysts, e.g., in the oxidation of cyclohexane to adipic acid. This report covers a systematic study of the formation of [CuII4OCl6(TPP)4] and [CuII4OCl6(TPPO)4] (TPP = triphenylphosphine, PPh3; TPPO = triphenylphosphine oxide, O=PPh3) as well as the redox equilibrium of these compounds with mononuclear copper(I) and copper(II) complexes such as [CuIICl2(TPPO)2], [{CuIICl2}2(TPPO)2], [{CuIICl2}3(TPPO)2], [{CuII4Cl4}(TPP)4], and [CuICl(TPP)n] (n = 1–3).",
           0,
           "chemistry"
          ],
          [
           "Pioneering Synthetic Strategies of 2-Substituted Benzothiazoles Using 2-Aminothiophenol",
           "10.3390/chemistry6010009",
           2024,
           "Heterocycles, compounds featuring heteroatoms like nitrogen, sulfur, and oxygen, are integral in fields such as synthesis, pharmacology, and medicine. Among these, benzothiazoles, formed by fusing thiazole with benzene, hold significant prominence. Their unique reactivity, especially at the carbon position between nitrogen and sulfur, has sparked wide interest. Notably, 2-substituted benzothiazoles exhibit diverse biological activities, including anticonvulsant, antimicrobial, and antioxidant properties, making them valuable in drug discovery. This review unveils an array of mesmerizing methods employed by chemists to prepare these compounds using 2-aminothiophenol as one of the precursors with other varied reactants. From novel strategies to sophisticated methodologies, each section of this review provides a glimpse into the fascinating world of synthetic chemistry of 2-substituted benzothiazoles. Delving into the diverse synthetic applications of 2-substituted benzothiazoles, this paper not only enriches our understanding of their synthesis but also sparks the imagination with the possibilities for future advancements.",
           0,
           "chemistry"
          ],
          [
           "Structure and Bonding in Planar Hypercoordinate Carbon Compounds",
           "10.3390/chemistry4040113",
           2022,
           "The term hypercoordination refers to the extent of the coordination of an element by its normal value. In the hypercoordination sphere, the element can achieve planar and/or non-planar molecular shape. Hence, planar hypercoordinate carbon species violate two structural rules: (i) The highest coordination number of carbon is four and (ii) the tetrahedral orientation by the connected elements and/or groups. The unusual planar orientations are mostly stabilized by the electronic interactions of the central atom with the surrounding ligands. In this review article, we will talk about the current progress in the theoretical prediction of viable planar hypercoordinate carbon compounds. Primary knowledge of the planar hypercoordinate chemistry will lead to its forthcoming expansion. Experimental and theoretical interests in planar tetracoordinate carbon (ptC), planar pentacoordinate carbon (ppC), and planar hexacoordinate carbon (phC) are continued. The proposed electronic and mechanical strategies are helpful for the designing of the ptC compounds. Moreover, the 18-valence electron rule can guide the design of new ptC clusters computationally as well as experimentally. However, the counting of 18-valence electrons is not a requisite condition to contain a ptC in a cluster. Furthermore, this ptC idea is expanded to the probability of a greater coordination number of carbon in planar orientations. Unfortunately, until now, there are no such logical approaches to designing ppC, phC, or higher-coordinate carbon molecules/ions. There exist a few global minimum structures of phC clusters identified computationally, but none have been detected experimentally. All planar hypercoordinate carbon species in the global minima may be feasible in the gas phase.",
           9,
           "chemistry"
          ],
          [
           "Exploring the Potential Energy Surface of Medium-Sized Aromatic Polycyclic Systems with Embedded Planar Tetracoordinate Carbons: A Guided Approach",
           "10.3390/chemistry5030105",
           2023,
           "This study scrutinizes the complexities of designing and exploring the potential energy surfaces of systems containing more than twenty atoms with planar tetracoordinate carbons (ptCs). To tackle this issue, we utilized an established design rule to design a Naphtho [1,2-b:3,4-b′:5,6-b″:7,8-b′′′]tetrathiophene derivative computationally. This process began with substituting S atoms with CH− units, then replacing three sequential protons with two Si2+ units in the resultant polycyclic aromatic hydrocarbon polyanion. Despite not representing the global minimum, the newly designed Si8C22 system with four ptCs provided valuable insights into strategic design and potential energy surface exploration. Our results underscore the importance of employing adequate methodologies to confirm the stability of newly designed molecular structures containing planar hypercoordinate carbons.",
           0,
           "chemistry"
          ],
          [
           "Acknowledgement to Reviewers of Chemistry in 2019",
           "10.3390/chemistry2010001",
           2020,
           "The editorial team greatly appreciates the reviewers who have dedicated their considerable time and expertise to the journal’s rigorous editorial process over the past 12 months, regardless of whether the papers are finally published or not [...]",
           1,
           "chemistry"
          ],
          [
           "Low-Temperature Properties of the Sodium-Ion Electrolytes Based on EC-DEC, EC-DMC, and EC-DME Binary Solvents",
           "10.3390/chemistry5030109",
           2023,
           "Sodium-ion batteries are a promising class of secondary power sources that can replace some of the lithium-ion, lead–acid, and other types of batteries in large-scale applications. One of the critical parameters for their potential use is high efficiency in a wide temperature range, particularly below 0 °C. This article analyzes the phase equilibria and electrochemical properties of sodium-ion battery electrolytes that are based on NaPF6 solutions in solvent mixtures of ethylene carbonate and diethyl carbonate (EC:DEC), dimethyl carbonate (EC:DMC), and 1,2-dimethoxyethane (EC:DME). All studied electrolytes demonstrate a decrease in conductivity at lower temperatures and transition to a quasi-solid state resembling “wet snow” at certain temperatures: EC:DEC at −8 °C, EC:DMC at −13 °C, and EC:DME at −21 °C for 1 M NaPF6 solutions. This phase transition affects their conductivity to a different degree. The impact is minimal in the case of EC:DEC, although it partially freezes at a higher temperature than other electrolytes. The EC:DMC-based electrolyte demonstrates the best efficiency at temperatures down to −20 °C. However, upon further cooling, 1 M NaPF6 in EC:DEC retains a higher conductivity and lower resistivity in symmetrical Na3V2(PO4)3-based cells. The temperature range from −20 to −40 °C is characterized by the strongest deterioration in the electrochemical properties of electrolytes: for 1 M NaPF6 in EC:DMC, the charge transfer resistance increased 36 times, and for 1 M NaPF6 in EC:DME, 450 times. For 1 M NaPF6 in EC:DEC, the growth of this parameter is much more modest and amounts to only 1.7 times. This allows us to consider the EC:DEC-based electrolyte as a promising basis for the further development of low-temperature sodium-ion batteries.",
           0,
           "chemistry"
          ],
          [
           "Derivatization Strategies in Flavor Analysis: An Overview over the Wine and Beer Scenario",
           "10.3390/chemistry4040109",
           2022,
           "Wine and beer are the most appreciated and consumed beverages in the world. This success is mainly due to their characteristic taste, smell, and aroma, which can delight consumer’s palates. These olfactory characteristics are produced from specific classes of volatile compounds called “volatile odor-active compounds” linked to different factors such as age and production. Given the vast market of drinking beverages, the characterization of these odor compounds is increasingly important. However, the chemical complexity of these beverages has led the scientific community to develop several analytical techniques for extracting and quantifying these molecules. Even though the recent “green-oriented” trend is directed towards direct preparation-free procedures, for some class of analytes a conventional step like derivatization is unavoidable. This review is a snapshot of the most used derivatization strategies developed in the last 15 years for VOAs’ determination in wine and beer, the most consumed fermented beverages worldwide and among the most complex ones. A comprehensive overview is provided for every method, whereas pros and cons are critically analyzed and discussed. Emphasis was given to miniaturized methods which are more consistent with the principles of “green analytical chemistry”.",
           2,
           "chemistry"
          ],
          [
           "Polyprotic Acids and Beyond—An Algebraic Approach",
           "10.3390/chemistry3020034",
           2021,
           "For an N-protic acid–base system, the set of nonlinear equations (i.e., mass action and balance laws) provides a simple analytical solution/formula for any integer N ≥ 1. The approach is applicable for the general case of zwitterionic acids HNA+Z (e.g., amino acids, NTA, and EDTA), which includes (i) the “ordinary acids” as a special case (Z = 0) and (ii) surface complexation. Examples are presented for N = 1 to 6. The high-N perspective allows the classification of equivalence points (including isoionic and isoelectric points). Principally, there are two main approaches to N-protic acids: one from hydrochemistry and one “outside inorganic hydrochemistry”. They differ in many ways: the choice of the reference state (either HNA or A−N), the reaction type (dissociation or association), the type/nature of the acidity constants, and the structure of the formulas. Once the (nonlinear) conversion between the two approaches is established, we obtain a systematics of acidity constants (macroscopic, microscopic, cumulative, and Simms). Finally, from the viewpoint of statistical mechanics (canonical isothermal–isobaric ensemble), buffer capacities, buffer intensities, and higher pH derivatives are actually fluctuations in the form of variance, skewness, and kurtosis.",
           3,
           "chemistry"
          ],
          [
           "Facile Solvent-Free Mechanochemical Synthesis of UI3 and Lanthanoid Iodides",
           "10.3390/chemistry4040108",
           2022,
           "Lewis base-free lanthanoid (Ln) and actinoid (An) iodides are difficult to obtain, as standard protocols describe syntheses in solutions of donor solvents which are ultimately hard to remove. We have now established a mechanochemical approach towards the synthesis of Lewis base-free f-block metal iodides with excellent yields. In particular, we describe herein the synthesis of EuI2 as an example of a divalent lanthanoid iodide, of CeI3 as an example of a trivalent lanthanoid iodide, and of UI3 as the most important actinoid iodide. Each can be obtained in high yield with minimal work-up, presenting the most efficient and simple synthetic route to access these materials to date.",
           1,
           "chemistry"
          ],
          [
           "Polymerization Behavior and Rheological Properties of a Surfactant-Modified Reactive Hydrophobic Monomer",
           "10.3390/chemistry5040168",
           2023,
           "The structures and properties of hydrophobic association polymers can be controlled using micelles. In this work, we synthesize a reactive hydrophobic surfactant monomer, KS-3, from oleic acid, N,N-dimethylpropylenediamine, and allyl chloride. A strong synergistic effect between KS-3 and cocamidopropyl betaine in aqueous solution enhances the hydrophilic dispersibility of KS-3, thereby transforming spherical micelles into cylindrical micelles. KS-3 was grafted onto a polyacrylamide chain via aqueous free-radical polymerization to obtain RES, a hydrophobic association polymer. Structural analysis revealed that the RES polymers assembled in wormlike micelles were more tightly arranged than those assembled in spherical micelles, resulting in a compact network structure in water, smooth surface, and high thermal stability. Rheological tests revealed that the synthesized polymers with wormlike and spherical micelles exhibited shear-thinning properties along with different structural strengths and viscoelasticities. Therefore, controlling the micellar state can effectively regulate the polymer properties. The polymers obtained through wormlike micelle polymerization have potential applications in fields with high demands, such as drug release, water purification, and oilfield development.",
           0,
           "chemistry"
          ],
          [
           "Graphene Oxide-Assisted Aptamer-Based Fluorescent Detection of Tetracycline Antibiotics",
           "10.3390/chemistry5020056",
           2023,
           "Tetracyclines are a group of common antibiotics, but owing to their toxicity, most of them are only used in animal husbandry and veterinary medicine. A DNA aptamer for tetracyclines has recently been reported. Upon aptamer binding, the fluorescence of tetracyclines was enhanced. This unique fluorescence enhancement was used to selectively detect the tetracyclines. The purpose of this study was to use graphene oxide (GO) to suppress the background fluorescence for enhanced detection. First, the adsorption of doxycycline on GO was studied. At pH 8.0, 82.7% of doxycycline was adsorbed by GO, and adding 2 µM aptamer desorbed 55.4% of doxycycline. With GO, the signal increase was comparable from pH 6 to 8, whereas without GO, the increase was significantly lower at pH 8. Under optimized condition, a detection limit of 1.6 nM doxycycline was achieved at pH 8.0 in the presence of GO, whereas without GO, the detection limit was 18.9 nM. This is an interesting example of the use of nanomaterials to enhance the performance of aptamer-based biosensors.",
           1,
           "chemistry"
          ],
          [
           "Molecular Docking and Molecular Dynamics Simulation Studies of Quinoline-3-Carboxamide Derivatives with DDR Kinases–Selectivity Studies towards ATM Kinase",
           "10.3390/chemistry3020036",
           2021,
           "Quinoline-3-carboxamides are an essential class of drug-like small molecules that are known to inhibit the phosphatidylinositol 3-kinase-related kinases (PIKK) family kinases. The quinoline nitrogen is shown to bind to the hinge region of the kinases, making them competitive inhibitors of adenosine triphosphate (ATP). We have previously designed and synthesized quinoline-3-carboxamides as potential ataxia telangiectasia mutated (ATM) kinase inhibitors to function as an adjuvant treatment with DNA damaging agents. This article discusses the molecular docking studies performed with these derivatives with the DNA damage and response (DDR) kinases-ATM, ataxia telangiectasia and rad3 related (ATR), and DNA dependent protein kinase catalytic subunit (DNA-PKcs) and highlights their selectivity towards ATM kinase. Docking studies were also performed with mTOR and PI3Kγ, which are close homologs of the DDR kinases. Molecular dynamics simulations were performed for one of the inhibitors against all the enzymes to establish the stability of the interactions involved. Finally, the absorption, distribution, metabolism, and excretion (ADME) properties of the inhibitors were predicted using the QikProp manual in Maestro. In conclusion, the molecules synthesized showed high selectivity towards the ATM kinase in comparison with the other kinases, though the sequence similarity between them was relatively high.",
           3,
           "chemistry"
          ],
          [
           "Biofabrication of Silver Nanoparticles Using Teucrium Apollinis Extract: Characterization, Stability, and Their Antibacterial Activities",
           "10.3390/chemistry5010005",
           2023,
           "Medical science has paid a great deal of attention to green synthesis silver nanoparticles (AgNPs) because of their remarkable results with multidrug-resistant bacteria. This study was conducted on the preparation of AgNPs, using the teucrium apollinis extract as a reducing agent and a capping ligand. The AgNP produced was stable in room condition up to 10 weeks. The AgNP was characterized using UV-visible absorption spectroscopy (UV-Vis), attenuated Fourier transform infrared (ATR-FTIR), transmission electron microscopy (TEM), and dynamic light scattering (DLS). The study confirms the ability of teucrium apollinis to produce AgNPs with high stability. The influence of pH was studied over a pH range of (2–12) on the stability of synthesized AgNPs. The best value of pH was 7.2, where AgNP showed a good stability with high antibacterial activity against Pseudomonas aeruginosa. AgNP synthesis is confirmed by a strong peak in the UV-Vis due to surface plasmon resonance (SPR) at 379 nm. Based on TEM findings, monodispersed AgNP has a spherical shape with a small size of 16 ± 1.8 nm. In this study, teucrium apollinis extract was used for the first time, which could be a good environmental method for synthesizing AgNP, which offers a possible alternative to chemical AgNPs.",
           8,
           "chemistry"
          ],
          [
           "Characterizing the Properties of Anion-Binding Bis(cyclopeptides) with Solvent-Independent Energy Increments",
           "10.3390/chemistry4020031",
           2022,
           "The binding energies of 121 complexes between anions and bis(cyclopeptides) differing in the structure and the number of linking units between the two cyclopeptide rings were analyzed. These Gibbs free energies were obtained in earlier work for different anions, under different conditions, and with different methods. The multiparametric analysis of a subset of 42 binding energies afforded linear relationships that allowed the relatively reliable estimation of the iodide and sulfate affinity of three structurally related bis(cyclopeptides) in water/methanol and water/acetonitrile mixtures at different solvent compositions. Three parameters were required to achieve a satisfactory correlation, namely, the Gibbs free energy of transferring the respective anion from water into the solvent mixture in which complex stability was determined, and the Kamlet–Taft parameters α and β. Based on these relationships, the anion affinities of the other bis(cyclopeptides) were evaluated, giving rise to a set of energy increments that allow quantifying the effects of the linker structure or the nature of the anion on binding affinity relative to the reference system.",
           1,
           "chemistry"
          ],
          [
           "Acid Site Density as a Kinetic Descriptor of Catalytic Reactions over Zeolites",
           "10.3390/chemistry4040105",
           2022,
           "A mathematical framework for the quantitative description of site density dependence of catalytic data (activity and selectivity) was developed considering that changes in the electrostatic contribution to the Gibbs energy of an elementary reaction on the acid sites in zeolites depend on the proximity of these sites. For the two-step sequence with the most abundant surface intermediate, an expression for turnover frequency explicitly containing the acid site density was derived. The treatment was extended to linear sequences of elementary reaction and analysis of the acid site density on selectivity in parallel and consecutive reactions, allowing to quantitatively relate the ratio between products for such reactions. Experimental data on Prins condensation of isopulegol with acetone and transformations of syngas over mesoporous H-ZSM-5 supported cobalt nanoparticles to a mixture of iso- and normal hydrocarbons were used as a show case.",
           4,
           "chemistry"
          ],
          [
           "A Pathway for Aldol Additions Catalyzed by l-Hydroxyproline-Peptides via a β-Hydroxyketone Hemiaminal Intermediate",
           "10.3390/chemistry5020081",
           2023,
           "While the use of l-proline-derived peptides has been proven similarly successful with respect to enantioselectivity, the physico-chemical and conformational properties of these organocatalysts are not fully compatible with transition state and intermediate structures previously suggested for l-proline catalysis. l-Proline or l-4-hydroxyproline catalysis is assumed to involve proton transfers mediated by the carboxylic acid group, whereas a similar mechanism is unlikely for peptides, which lack a proton donor. Herein, we prepared an array of hydroxyproline-based dipeptides through amide coupling of Boc-protected cis- or trans-4-l-hydroxyproline (cis- or trans-4-Hyp) to benzylated glycine (Gly-OBn) and l-valine (l-Val-OBn) and used these dipeptides as catalysts for a model aldol reaction. Despite the lack of a proton donor in the catalytic site, we observed good stereoselectivities for the R-configured aldol product both with dipeptides formed from cis- or trans-4-Hyp at moderate conversions after 24 h. To explain this conundrum, we modeled reaction cycles for aldol additions in the presence of cis-4-Hyp, trans-4-Hyp, and cis- and trans-configured 4-Hyp-peptides as catalysts by calculation of free energies of conformers of intermediates and transition states at the density functional theory level (B3LYP/6-31G(d), DMSO PCM as solvent model). While a catalytic cycle as previously suggested with l-proline is also plausible for cis- or trans-4-Hyp, with the peptides, the energy barrier of the first reaction step would be too high to allow conversions at room temperature. Calculations on modeled transition states suggest an alternative pathway that would explain the experimental results: here, the catalytic cycle is entered by the acetone self-adduct 4-hydroxy-4-methylpentan-2-one, which forms spontaneously to a small extent in the presence of a base, leading to considerably reduced calculated free energy levels of transition states of reaction steps that are considered rate-determining.",
           1,
           "chemistry"
          ],
          [
           "Growing Gold Nanostars on SiO2 Nanoparticles: Easily Accessible, NIR Active Core–Shell Nanostructures from PVP/DMF Reduction",
           "10.3390/chemistry4030046",
           2022,
           "A new synthesis strategy towards gold-coated silica nanoparticles is presented. The method provides an efficient, reliable and facile-coating process of well-defined star-shaped shell structures, characterized by UV-Vis, TEM, PXRD, DLS and zeta-potential measurements. A marked red shift of the Au-based plasmonic band to the region of the first biological window is observed offering great potential for future research of biological applications.",
           1,
           "chemistry"
          ],
          [
           "Effects of Substituents on Photophysical and CO-Photoreleasing Properties of 2,6-Substituted meso-Carboxy BODIPY Derivatives",
           "10.3390/chemistry3010018",
           2021,
           "Carbon monoxide (CO) is an endogenously produced signaling molecule involved in the control of a vast array of physiological processes. One of the strategies to administer therapeutic amounts of CO is the precise spatial and temporal control over its release from photoactivatable CO-releasing molecules (photoCORMs). Here we present the synthesis and photophysical and photochemical properties of a small library of meso-carboxy BODIPY derivatives bearing different substituents at positions 2 and 6. We show that the nature of substituents has a major impact on both their photophysics and the efficiency of CO photorelease. CO was found to be efficiently released from π-extended 2,6-arylethynyl BODIPY derivatives possessing absorption spectra shifted to a more biologically desirable wavelength range. Selected photoCORMs were subjected to in vitro experiments that did not reveal any serious toxic effects, suggesting their potential for further biological research.",
           6,
           "chemistry"
          ],
          [
           "Bis(diphenylphosphino)methane Dioxide Complexes of Lanthanide Trichlorides: Synthesis, Structures and Spectroscopy",
           "10.3390/chemistry2040060",
           2020,
           "Bis(diphenylphosphino)methane dioxide (dppmO2) forms eight-coordinate cations [M(dppmO2)4]Cl3 (M = La, Ce, Pr, Nd, Sm, Eu, Gd) on reaction in a 4:1 molar ratio with the appropriate LnCl3 in ethanol. Similar reaction in a 3:1 ratio produced seven-coordinate [M(dppmO2)3Cl]Cl2 (M = Sm, Eu, Gd, Tb, Dy, Ho, Er, Tm, Yb), whilst LuCl3 alone produced six-coordinate [Lu(dppmO2)2Cl2]Cl. The complexes have been characterised by IR, 1H and 31P{1H}-NMR spectroscopy. X-ray structures show that [M(dppmO2)4]Cl3 (M = Ce, Sm, Gd) contain square antiprismatic cations, whilst [M(dppmO2)3Cl]Cl2 (M = Yb, Dy, Lu) have distorted pentagonal bipyramidal structures with apical Cl. The [Lu(dppmO2)2Cl2]Cl has a cis octahedral cation. The structure of [Yb(dppmO2)3(H2O)]Cl3·dppmO2 is also reported. The change in coordination numbers and geometry along the series is driven by the decreasing lanthanide cation radii, but the chloride counter anions also play a role.",
           6,
           "chemistry"
          ],
          [
           "Preparation of Activated Carbon from Coffee Waste as an Adsorbent for the Removal of Chromium (III) from Water. Optimization for an Experimental Box-Behnken Design",
           "10.3390/chemistry2010002",
           2020,
           "Coffee grounds are an organic waste consisting of the ground, roasted and processed grain for the extraction of coffee, being of great volume the waste obtained, which, if not treated and preserved for a long time, emanates unpleasant aromas and becomes an optimal means for the proliferation of flies, and other pests. Activated carbon has the characteristic of being a material that has a large surface area; because of this, it is used in adsorption, which refers to the retention of atoms, ions, and molecules on its surface. In this paper, the production of activated carbon is presented by means of the physicochemical activation of coffee waste by calcining at 900 °C and subsequent activation with sulfuric acid, as well as the Box–Behnken design of three factors for chromium (III) adsorption optimization. It is determined that the optimal conditions for performing the adsorption are pH = 3 and a contact time of 140 min. According to the analysis of variance for the experimental design, it is determined that the initial chromium formation is not significant for the adsorption process. Under the optimal adsorb conditions of 96%, an application is given to the erasure of coffee for the production of activated carbon, which serves as the adsorbent agent applied to the removal of chromium (III) aqueous. The area of activated carbon obtained is 13657.89 ± 251.09 m2/g determined by the acetic acid adsorption isotherm method.",
           7,
           "chemistry"
          ],
          [
           "Pectin Microspheres: Synthesis Methods, Properties, and Their Multidisciplinary Applications",
           "10.3390/chemistry4010011",
           2022,
           "There is great contemporary interest in using cleaner technologies through green chemistry and utilizing biopolymers as raw material. Pectin is found on plant cell walls, and it is commonly extracted from fruit shells, mostly apples or citrus fruits. Pectin has applications in many areas of commercial relevance; for this reason, it is possible to find available information about novel methods to transform pectin and pursuing enhanced features, with the structuring of biopolymer microspheres being highly cited to enhance its activity. The structuring of polymers is a technique that has been growing in recent decades, due to its potential for diverse applications in various fields of science and technology. Several techniques are used for the synthesis of microspheres, such as ionotropic gelation, extrusion, aerosol drying, or emulsions, with the latter being the most commonly used method based on its reproducibility and simplicity. The most cited applications are in drug delivery, especially for the treatment of colon diseases and digestive-tract-related issues. In the industrial field, it is used for protecting encapsulated compounds; moreover, the environmental applications mainly include the bioremediation of toxic substances. However, there are still many possibilities for expanding the use of this biopolymer in the environmental field.",
           9,
           "chemistry"
          ],
          [
           "Unusual Phase Behaviour for Organo-Halide Perovskite Nanoparticles Synthesized via Reverse Micelle Templating",
           "10.3390/chemistry5040163",
           2023,
           "Micelle templating has emerged as a powerful method to produce monodisperse nanoparticles. Herein, we explore unconventional phase transformations in the synthesis of organo-halide perovskite nanoparticles utilizing reverse micelle templates. We employ diblock-copolymer reverse micelles to fabricate these nanoparticles, which confines ions within micellar nanoreactors, retarding reaction kinetics and facilitating perovskite cage manipulation. The confined micellar environment exerts pressure on both precursors and perovskite crystals formed inside, enabling stable phases not typically observed at room temperature in conventional synthesis. This provides access to perovskite structures that are otherwise challenging to produce. The hydrophobic shell of the micelle also enhances perovskite stability, particularly when combined with anionic exchange approaches or large aromatic cations. This synergy results in long-lasting stable optical properties despite environmental exposure. Reverse micelle templates offer a versatile platform for modulating perovskite structure and behavior across a broad spectrum of perovskite compositions, yielding unique phases with diverse emission characteristics. By manipulating the composition and properties of the reverse micelle template, it is possible to tune the characteristics of the resulting nanoparticles, opening up exciting opportunities for customizing optical properties to suit various applications.",
           1,
           "chemistry"
          ],
          [
           "Electronically Excited States of Closed-Shell, Cyano-Functionalized Polycyclic Aromatic Hydrocarbon Anions",
           "10.3390/chemistry3010022",
           2021,
           "Few anions exhibit electronically excited states, and, if they do, the one or two possible excitations typically transpire beyond the visible spectrum into the near-infrared. These few, red-shifted electronic absorption features make anions tantalizing candidates as carriers of the diffuse interstellar bands (DIBs), a series of mostly unknown, astronomically ubiquitous absorption features documented for over a century. The recent interstellar detection of benzonitrile implies that cyano-functionalized polycyclic aromatic hydrocarbon (PAH) anions may be present in space. The presently reported quantum chemical work explores the electronic properties of deprotonated benzene, naphthalene, and anthracene anions functionalized with a single cyano group. Both the absorption and emission properties of the electronically excited states are explored. The findings show that the larger anions absorption and emission energies possess both valence and dipole bound excitations in the 450–900 nm range with oscillator strengths for both types of >1×10−4. The valence and dipole bound excited state transitions will produce slightly altered substructure from one another making them appear to originate with different molecules. The known interstellar presence of related molecules, the two differing natures of the excited states for each, and the wavelength range of peaks for these cyano-functionalized PAH anions are coincident with DIB properties. Finally, the methods utilized appear to be able to predict the presence of dipole-bound excited states to within a 1.0 meV window relative to the electron binding energy.",
           6,
           "chemistry"
          ],
          [
           "Questions in the Chemical Enzymology of MAO",
           "10.3390/chemistry3030069",
           2021,
           "We have structure, a wealth of kinetic data, thousands of chemical ligands and clinical information for the effects of a range of drugs on monoamine oxidase activity in vivo. We have comparative information from various species and mutations on kinetics and effects of inhibition. Nevertheless, there are what seem like simple questions still to be answered. This article presents a brief summary of existing experimental evidence the background and poses questions that remain intriguing for chemists and biochemists researching the chemical enzymology of and drug design for monoamine oxidases (FAD-containing EC 4.1.3.4).",
           5,
           "chemistry"
          ],
          [
           "Towards a Generalized Synthetic Strategy for Variable Sized Enantiopure M4L4 Helicates",
           "10.3390/chemistry2030038",
           2020,
           "The reliable and predictable synthesis of enantiopure coordination cages is an important step towards the realization of discrete cages capable of enantioselective discrimination. We have built upon our initial report of a lantern-type helical cage in attempts to expand the synthesis into a general approach. The use of a longer, flexible diacid ligand results in the anticipated cage [Cu4(L1)4(solvent)4] with a similar helical pitch to that previously observed and a cavity approximately 30% larger. Using a shorter, more rigid ligand gave rise to a strained, conjoined cage-type complex when using DABCO as an internal bridging ligand, [{Co4(L2)4(DABCO)(OH2)x}2 (DABCO)]. The expected paddlewheel motif only forms for one of the Co2 units within each cage, with the other end adopting a “partial paddlewheel” with aqua ligands completing the coordination sphere of the externally facing metal ion. The generic approach of using chiral diacids to construct lantern-type cages is partially borne out, with it being apparent that flexibility in the core group is an essential structural feature.",
           7,
           "chemistry"
          ],
          [
           "A Family of Externally-Functionalised Coordination Cages",
           "10.3390/chemistry3040088",
           2021,
           "New synthetic routes are presented to derivatives of a (known) M8L12 cubic coordination cage in which a range of different substituents are attached at the C4 position of the pyridyl rings at either end of the bis(pyrazolyl-pyridine) bridging ligands. The substituents are (i) –CN groups (new ligand LCN), (ii) –CH2OCH2–CCH (containing a terminal alkyne) groups (new ligand LCC); and (iii) –(CH2OCH2)3CH2OMe (tri-ethyleneglycol monomethyl ether) groups (new ligand LPEG). The resulting functionalised ligands combine with M2+ ions (particularly Co2+, Ni2+, Cd2+) to give isostructural [M8L12]16+ cage cores bearing 24 external functional groups; the cages based on LCN (with M2+ = Cd2+) and LCC (with M2+ = Ni2+) have been crystallographically characterised. The value of these is twofold: (i) exterior nitrile or alkene substituents can provide a basis for further synthetic opportunities via ‘Click’ reactions allowing in principle a diverse range of functionalisation of the cage exterior surface; (ii) the exterior –(CH2OCH2)3CH2OMe groups substantially increase cage solubility in both water and in organic solvents, allowing binding constants of cavity-binding guests to be measured under an increased range of conditions.",
           8,
           "chemistry"
          ],
          [
           "Results in Chemistry of Natural Organic Compounds. Synthesis of New Anticancer Vinca Alkaloids and Flavone Alkaloids",
           "10.3390/chemistry2030046",
           2020,
           "The antitumor indole–indoline alkaloids of the evergreen Catharanthus roseus—namely vinblastine and vincristine—are widely used in chemotherapy of cancer. Many efforts were made to synthesize more efficient derivatives with less side-effect. The 14,15-cyclopropane derivative of vinblastine was synthesized successfully by a five-step procedure starting from vindoline. Vincristine, vinorelbine and several derivatives condensed with a cyclopropane ring were synthesized. Various hybrid molecules were prepared by the coupling reaction of vindoline and methyl ester of tryptophan, which were conjugated by carrier peptides of octaarginine. Studying the halogenation reactions of vindoline and catharanthine some fluorine derivatives were obtained which showed promising antitumor activity on various tumor types. The synthesis of the Aspidospermane alkaloid bannucine and 5′-epibannucine were carried out using N-acyliminium intermediates. The same intermediate was also applied in the first synthesis of sessiline. The research group have synthesized of flavonoid alkaloids: dracocephins A and B. Further three flavonoid alkaloids, namely 8-(2”-pyrrolidinon-5′′-yl)quercetin, 6-(2′′-pyrrolidinon-5′′-yl)-(−)- and 8-(2′′-pyrrolidinon-5′′-yl)-(−)-epicatechin were prepared by acid-catalyzed regioselective Mannich reaction starting from the corresponding flavonoid precursor. Vindoline was also coupled to synthetic pharmacophores, such as triphenylphosphine and various N-heterocycles. Some of these hybrid molecules showed significant antitumor activity. Furthermore, 7-OH and 7-NH modified flavonoid derivatives were synthesized by a regioselective alkylation followed by Smiles rearrangement and hydrolysis.",
           6,
           "chemistry"
          ],
          [
           "Hydrogen Evolution upon Ammonia Borane Solvolysis: Comparison between the Hydrolysis and Methanolysis Reactions",
           "10.3390/chemistry5020060",
           2023,
           "Hydrogen (H2) production is a key challenge for green carbon-free sustainable energy. Among the H2 evolution methods from H-rich materials, ammonia borane (AB) solvolysis stands as a privileged source under ambient and sub-ambient conditions given its stability, non-toxicity, and solubility in protic solvents, provided suitable and optimized nanocatalysts are used. In this paper dedicated to Prof. Avelino Corma, we comparatively review AB hydrolysis and alcoholysis (mostly methanolysis) in terms of nanocatalyst performances and discuss the advantages and inconveniences of these two AB solvolysis methods including AB regeneration.",
           6,
           "chemistry"
          ],
          [
           "High Thermal Stability of Enzyme-MOF Composites at 180 °C",
           "10.3390/chemistry5030137",
           2023,
           "Encapsulating enzymes in a tailored scaffold is of great potential in industrial enzymatic catalysis, which can enhance the stability of enzymes thus expanding their applications. Metal–organic frameworks (MOFs) are emerging as promising candidates for enzyme encapsulation due to their precise pore structure, ease of synthesis and good biocompatibility. Despite the fact that enzymes encapsulated in MOFs can obtain enhanced stability, there has been little discussion about the thermal stability of enzyme-MOF composites in solid state under extremely high temperatures. Herein, we fabricated the enzyme-MOF composites, CALB-ZIF-8, via a convenient coprecipitation method in aqueous solution, which exhibited good thermal stability at 180 °C. It was found that the activity of CALB encapsulated in ZIF-8 retained nearly ~80% after heating for 10 min at 180 °C. A finite element method was applied to investigate the heat transfer process within a ZIF-8 model, indicating that the air filled in cavities of ZIF-8 played a significant role in hindering the heat transfer and this may be an important reason for the outstanding thermal stability of CALB-ZIF-8 at 180 °C, which paves a new path for expanding the industrial application of enzyme-MOF composites.",
           1,
           "chemistry"
          ],
          [
           "hERG Blockade Prediction by Combining Site Identification by Ligand Competitive Saturation and Physicochemical Properties",
           "10.3390/chemistry4030045",
           2022,
           "The human ether-a-go-go-related gene (hERG) potassium channel is a well-known contributor to drug-induced cardiotoxicity and therefore is an extremely important target when performing safety assessments of drug candidates. Ligand-based approaches in connection with quantitative structure active relationships (QSAR) analyses have been developed to predict hERG toxicity. The availability of the recent published cryogenic electron microscopy (cryo-EM) structure for the hERG channel opened the prospect of using structure-based simulation and docking approaches for hERG drug liability predictions. In recent times, the idea of combining structure- and ligand-based approaches for modeling hERG drug liability has gained momentum offering improvements in predictability when compared to ligand-based QSAR practices alone. The present article demonstrates uniting the structure-based SILCS (site-identification by ligand competitive saturation) approach in conjunction with physicochemical properties to develop predictive models for hERG blockade. This combination leads to improved model predictability based on Pearson’s R and percent correct (represents rank-ordering of ligands) metric for different validation sets of hERG blockers involving a diverse chemical scaffold and wide range of pIC50 values. The inclusion of the SILCS structure-based approach allows determination of the hERG region to which compounds bind and the contribution of different chemical moieties in the compounds to the blockade, thereby facilitating the rational ligand design to minimize hERG liability.",
           4,
           "chemistry"
          ],
          [
           "Experimental and Computational Studies on N-alkylation Reaction of N-Benzoyl 5-(Aminomethyl)Tetrazole",
           "10.3390/chemistry3030049",
           2021,
           "The N-alkylation reaction of N-benzoyl 5-(aminomethyl)tetrazole (5-AMT) with benzyl bromide was carried out in the presence of K2CO3 as a base. Two separable regioisomers were obtained, thus their purification led to determine the proportion of each of them, and their structures were attributed essentially based on 1H and 13C NMR spectroscopy in addition to the elemental analysis and MS data. In order to confirm the results obtained at the synthesis level, a computational study was carried out by application of density functional theory (DFT) using the Becke three-parameter hybrid exchange functional and the Lee-Yang-Parr correlation functional (B3LYP).",
           5,
           "chemistry"
          ],
          [
           "Preparation and Application of Green Sustainable Solvent Cyrene",
           "10.3390/chemistry5040154",
           2023,
           "The bio-based solvent dihydrolevoglucosenone (Cyrene) is a green and sustainable alternative to petroleum-based dipolar aprotic solvents. Cyrene can be prepared from cellulose in a simple two-step process and can be produced in a variety of yields. Cyrene is compatible with a large number of reactions in the chemical industry and can be applied in organic chemistry, biocatalysis, materials chemistry, graphene and lignin processing, etc. It is also green, non-mutagenic and non-toxic, which makes it very promising for applications. In this paper, we have also screened all articles related to Cyrene on the Web of Science and visualised them through Cite Space.",
           1,
           "chemistry"
          ],
          [
           "Spectrophotometric Determination of Formation Constants of Iron(III) Complexes with Several Ligands",
           "10.3390/chemistry4030050",
           2022,
           "Dye-sensitized solar cells transform solar light into electricity. One commonly used dye is a ruthenium complex. However, the use of ruthenium has been shown to have several disadvantages. In this study, via singular spectrum analysis using HypSpec software, we determined the formation constants and calculated individual electronic spectra of species of iron(III) with several ligands (1,2-diaminoethane, 1,3-diaminopropane, 1,4-diaminobutane, 2,2′-bipyridyl, 5,5-dimethyl-2,2′-bipyridyl, 4,4′-di-tert-butyl-2,2′-bipyridyl, 1,10-phenanthroline, and 3,4,7,8-tetramethyl-1,10-phenanthroline) in methanol solution. We present a spectral comparison of the complexes reported here to the ruthenium complex: tris-(2,2′-bipyridyl)ruthenium(II).",
           3,
           "chemistry"
          ],
          [
           "Structure, Stability and Binding Properties of Collagen-Binding Domains from Streptococcus mutans",
           "10.3390/chemistry5030130",
           2023,
           "Collagen-binding proteins (CBP), Cnm and Cbm, from Streptococcus mutans are involved in infective endocarditis caused by S. mutans because of their collagen-binding ability. In this study, we focused on the collagen-binding domain (CBD), which is responsible for the collagen-binding ability of CBP, and analyzed its structure, binding activity, and stability using CBD domain variants. The CBD consists of the N1 domain, linker, N2 domain, and latch (N1-N2~) as predicted from the amino acid sequences. The crystal structure of the Cnm/CBD was determined at a 1.81 Å resolution. N1_linker_N2 forms a ring structure that can enfold collagen molecules, and the latch interacts with N1 to form a ring clasp. N1 and N2 have similar immunoglobulin folds. The collagen-binding activities of Cbm/CBD and its domain variants were examined using ELISA. N1-N2~ bound to collagen with KD = 2.8 μM, and the latch-deleted variant (N1-N2) showed weaker binding (KD = 28 μM). The linker-deleted variant (N1N2~) and single-domain variants (N1 and N2) showed no binding activity, whereas the domain-swapped variant (N2-N1~) showed binding ability, indicating that the two N-domains and the linker are important for collagen binding. Thermal denaturation experiments showed that N1-N2 was slightly less stable than N1-N2~, and that N2 was more stable than N1. The results of this study provide a basis for the development of CBD inhibitors and applied research utilizing their collagen-binding ability.",
           1,
           "chemistry"
          ],
          [
           "Biogenic Silver Nanoparticles Conjugated with Nisin: Improving the Antimicrobial and Antibiofilm Properties of Nanomaterials",
           "10.3390/chemistry3040092",
           2021,
           "Microbial technology offers a green alternative for the synthesis of value-added nanomaterials. In particular, fungal compounds can improve silver nanoparticle production, stabilizing colloidal nanoparticles. Based on a previous study by our group, silver nanoparticles obtained using the extracellular cell-free extracts of Phanerochaete chrysosporium (PchNPs) have shown antimicrobial and antibiofilm activity against Gram-negative bacteria. Moreover, nisin—a bacteriocin widely used as a natural food preservative—has recently gained much attention due its antimicrobial action against Gram-positive bacteria in biomedical applications. Therefore, the aim of this work was to conjugate biogenic silver nanoparticles (PchNPs) with nisin to obtain nanoconjugates (PchNPs@nis) with enhanced antimicrobial properties. Characterization assays were conducted to determine physicochemical properties of PchNPs@nis, and also their antibacterial and antibiofilm activities were studied. The formation of PchNPs@nis was confirmed by UV-Vis, TEM, and Raman spectroscopy analysis. Different PchNPs@nis nanobioconjugates showed diameter values in the range of 60–130 nm by DLS and surface charge values between −20 and −13 mV. Nisin showed an excellent affinity to PchNPs, with binding efficiencies higher than 75%. Stable synthesized PchNPs@nis nanobioconjugates were not only able to inhibit biofilm formation by S. aureus, but also showed inhibition of the planktonic cell growth of Staphyloccocus aureus and Escherichia coli, broadening the spectrum of action of the unconjugated antimicrobials against Gram-positive and Gram-negative bacteria. In conclusion, these results show the promising application of PchNPs@nis, prepared via green technology, as potential antimicrobial nanomaterials.",
           11,
           "chemistry"
          ],
          [
           "Hypervalence: A Useful Concept or One That Should Be Gracefully Retired?",
           "10.3390/chemistry4040082",
           2022,
           "In this essay the origins of the term hypervalence and its application in p-block element chemistry are considered and it is argued that the term should now be consigned to the graveyard of concepts that no longer afford any discernible value or insight, certainly from an educational perspective. In contrast, the educational merits of the octet rule are also examined where it is concluded that this rule does have significant pedagogical value, albeit mostly within the ambit of introductory level explanations. For a few of the chosen exemplar compounds, a selection of orbital-based analyses, at different levels of sophistication, are also considered, and their values appraised together with a brief survey of some of the more general computational studies which have been employed in relation to this topic.",
           7,
           "chemistry"
          ],
          [
           "Head vs. Tail Squaramide–Naphthalimide Conjugates: Self-Assembly and Anion Binding Behaviour",
           "10.3390/chemistry4040085",
           2022,
           "The syntheses of two squaramide–naphthalimide conjugates (SN1 and SN2) are reported; the structures of SN1 and SN2 differ by the attachment of a squaramide—either at the ‘head’ or the ‘tail’ of the naphthalimide fluorophore. Both compounds displayed weak fluorescence due to the inclusion of a nitro-aromatic squaramide which efficiently quenches the emission of the naphthalimide. Both compounds were also shown to undergo self-aggregation as studied by 1H NMR and scanning electron microscopy (SEM). Furthermore, SN1 and SN2 gave rise to stark colourimetric changes in response to basic anions such as AcO−, SO42− HPO42−, and F−. The observed colour changes are thought to be due to deprotonation of a squaramide NH. The same basic anions also result in a further quenching of the naphthalimide emission. No colour change or emission modulations were observed in the presence of Cl−; however, 1H NMR studies suggest that moderate H-bonding occurs between this anion and both SN1 and SN2.",
           3,
           "chemistry"
          ],
          [
           "Diverse Biological Activities of 1,3,4-Thiadiazole Scaffold",
           "10.3390/chemistry4040107",
           2022,
           "The chemistry of 1,3,4-thiadiazole is one of the most interesting scaffolds for synthesizing new drug molecules due to their numerous pharmacological activities. Several modifications in the thiadiazole ring have been made, proving it to be more potent and highly effective with a less toxic scaffold for various biological activities. There are several marketed drugs containing 1,3,4-thiadiazole ring in their structure. In this review article, we have tried to compile the newly synthesized 1,3,4-thiadiazole derivatives possessing important pharmaceutical significance since 2014.",
           20,
           "chemistry"
          ],
          [
           "Equilibrium Swelling of Thermo-Responsive Gels in Mixtures of Solvents",
           "10.3390/chemistry4030049",
           2022,
           "Thermo-responsive (TR) gels of the LCST (lower critical solution temperature) type swell in water at temperatures below their volume phase transition temperature Tc and collapse above the critical temperature. When water is partially replaced with an organic liquid, these materials demonstrate three different types of equilibrium solvent uptake diagrams at temperatures below, above, in the close vicinity of Tc. A model is developed for equilibrium swelling of TR gels in binary mixtures of solvents. It takes into account three types of phase transitions in TR gels driven by (i) aggregation of hydrophobic side groups into clusters from which solvent molecules are expelled, (ii) replacement of water with cosolvent molecules in cage-like structures surrounding these groups, and (iii) replacement of water with cosolvent as the main element of hydration shells around backbone chains. The model involves a relatively small number of material constants that are found by matching observations on covalently cross-linked poly(N-isopropylacrylamide) macroscopic gels and microgels. Good agreement is demonstrated between the experimental data and results of numerical analysis. Classification is provided of the phase transition points on equilibrium swelling diagrams.",
           0,
           "chemistry"
          ],
          [
           "OH Group Effect in the Stator of β-Diketones Arylhydrazone Rotary Switches",
           "10.3390/chemistry2020024",
           2020,
           "The properties of several hydrazon-diketone rotary switches with OH groups in the stators (2-(2-(2-hydroxy-4-nitrophenyl)hydrazono)-1-phenylbutane-1,3-dione, 2-(2-(2-hydroxyphenyl)hydrazono)-1-phenylbutane-1,3-dione and 2-(2-(4-hydroxyphenyl)hydrazono)-1-phenylbutane-1,3-dione) were investigated by molecular spectroscopy (UV-Vis and NMR), DFT calculations (M06-2X/TZVP) and X-ray analysis. The results show that, when the OH group is in ortho position, the E’ and Z’ isomers are preferred in DMSO as a result of a stabilizing intermolecular hydrogen bonding with the solvent. The availability, in addition, of a nitro group in para position increases the possibility of deprotonation of the OH group in the absence of water. All studied compounds showed a tendency towards formation of associates. The structure of the aggregates was revealed by theoretical calculation and confirmed by X-ray analysis.",
           4,
           "chemistry"
          ],
          [
           "Tris(3-nitropentane-2,4-dionato-κ2 O,O′) Complexes as a New Type of Highly Energetic Materials: Theoretical and Experimental Considerations",
           "10.3390/chemistry5030126",
           2023,
           "Decreasing the sensitivity towards detonation of high-energy materials (HEMs) is the ultimate goal of numerous theoretical and experimental studies. It is known that positive electrostatic potential above the central areas of the molecular surface is related to high sensitivity towards the detonation of high-energy molecules. Coordination compounds offer additional structural features that can be used for the adjustment of the electrostatic potential values and sensitivity towards detonation of this class of HEM compounds. By a careful combination of the transition metal atoms and ligands, it is possible to achieve a fine-tuning of the values of the electrostatic potential on the surface of the chelate complexes. Here we combined Density Functional Theory calculations with experimental data to evaluate the high-energy properties of tris(3-nitropentane-2,4-dionato-κ2 O,O′) (nitro-tris(acetylacetonato)) complexes of Cr(III), Mn(III), Fe(III), and Co(III). Analysis of the Bond Dissociation Energies (BDE) of the C-NO2 bonds and Molecular Electrostatic Potentials (MEP) showed that these compounds may act as HEM molecules. Analysis of IR spectra and initiation of the Co(AcAc-NO2)3 complex in the open flame confirmed that these compounds act as high-energy molecules. The measured heat of combustion for the Co(AcAc-NO2)3 complex was 14,133 J/g, which confirms the high-energy properties of this compound. The results also indicated that the addition of chelate rings may be used as a new tool for controlling the sensitivity towards the detonation of high-energy coordination compounds.",
           0,
           "chemistry"
          ],
          [
           "Publisher's Notice: Chemistry—An International Journal",
           "10.3390/chemistry1010001",
           2018,
           "MDPI is launching Chemistry—An International Journal [...]",
           8,
           "chemistry"
          ],
          [
           "Justus von Liebig",
           "10.3390/chemistry5020071",
           2023,
           "This is a short overview of the life and achievements of Justus von Liebig. Clearly, this can only be an incomplete and somewhat personal view of the author, who has been a professor of inorganic chemistry at Justus Liebig University since 2002. Having already been interested in the work of Liebig for many years, and with a strong connection to the Liebig Museum in Giessen, the author hopes to provide some useful information about this great chemist, one of the founders of modern chemistry. The reader should find many interesting, probably new, facts about Liebig’s major impact on chemistry, agriculture, nutrition, and pharmacology.",
           0,
           "chemistry"
          ],
          [
           "Spin-Crossover 2-D Hofmann Frameworks Incorporating an Amide-Functionalized Ligand: N-(pyridin-4-yl)benzamide",
           "10.3390/chemistry3010026",
           2021,
           "Two analogous 2-D Hofmann-type frameworks, which incorporate the novel ligand N-(pyridin-4-yl)benzamide (benpy) [FeII(benpy)2M(CN)4]·2H2O (M = Pd (Pd(benpy)) and Pt (Pt(benpy))) are reported. The benpy ligand was explored to facilitate spin-crossover (SCO) cooperativity via amide group hydrogen bonding. Structural analyses of the 2-D Hofmann frameworks revealed benpy-guest hydrogen bonding and benpy-benpy aromatic contacts. Both analogues exhibited single-step hysteretic spin-crossover (SCO) transitions, with the metal-cyanide linker (M = Pd or Pt) impacting the SCO spin-state transition temperature and hysteresis loop width (Pd(benpy): T½↓↑: 201, 218 K, ∆T: 17 K and Pt(benpy): T½↓↑: 206, 226 K, ∆T: 20 K). The parallel structural and SCO changes over the high-spin to low-spin transition were investigated using variable-temperature, single-crystal, and powder X-ray diffraction, Raman spectroscopy, and differential scanning calorimetry. These studies indicated that the ligand–guest interactions facilitated by the amide group acted to support the cooperative spin-state transitions displayed by these two Hofmann-type frameworks, providing further insight into cooperativity and structure–property relationships.",
           3,
           "chemistry"
          ],
          [
           "Hydrophobin-Coated Perfluorocarbon Microbubbles with Strong Non-Linear Acoustic Response",
           "10.3390/chemistry6020016",
           2024,
           "Gas-filled microbubbles are well-established contrast agents for ultrasound imaging and widely studied as delivery systems for theranostics. Herein, we have demonstrated the promising potential of the hydrophobin HFBII—a fungal amphiphilic protein—in stabilizing microbubbles with various fluorinated core gases. A thorough screening of several experimental parameters was performed to find the optimized conditions regarding the preparation technique, type of core gas, HFBII initial concentration, and protein dissolution procedure. The best results were obtained by combining perfluorobutane (C4F10) gas with 1 mg/mL of aqueous HFBII, which afforded a total bubble concentration higher than 109 bubbles/mL, with long-term stability in solution (at least 3 h). Acoustic characterization of such microbubbles in the typical ultrasound frequency range used for diagnostic imaging showed the lower pressure resistance of HFBII microbubbles, if compared to conventional ones stabilized by phospholipid shells, but, at the same time, revealed strong non-linear behavior, with a significant harmonic response already at low acoustic pressures. These findings suggest the possibility of further improving the performance of HFBII-coated perfluorinated gas microbubbles, for instance by mixing the protein with other stabilizing agents, e.g., phospholipids, in order to tune the viscoelastic properties of the outer shell.",
           0,
           "chemistry"
          ],
          [
           "Phytochemicals from Rhizophora mucronata Propagules, Its In Vitro Anti-Cancer and In Silico Drug-Likeness Potential",
           "10.3390/chemistry3030070",
           2021,
           "This is the first report to identify the presence of 3-O-caffeoyl quinic acid (1), 4-O-caffeoyl quinic acid (2), 5-O-caffeoyl quinic acid (3), epi-catechin (4), and procyanidin B2 (5) in the young propagules of Rhizophora mucronata. Compounds 2–5 were purified and then treated against breast, colorectal, and ovarian cancer cell lines for 72 h and the results of the Sulphorhodomine-B (SRB) assay were evaluated for percent cell viability and IC50 values. Epi-catechin, 4-O-caffeoyl quinic acid, 5-O-caffeoyl quinic acid and procyanidin B2 showed strong to moderate inhibitory effects when treated on breast (T47D), colorectal (HT29), and ovarian (A2780, SKOV3) cancer cell lines with IC50 values ranging from 16.77 ± 0.58 to 28.28 ± 0.89 μg/mL. In silico evaluation was performed to evaluate the drug-likeness and toxicological effects of these compounds using Molinspiration calculation and OSIRIS program. It was found that compounds 2, 3, and 4 have the potential to be orally active and have a low risk in exerting the mutagenic, tumorigenic, irritant, and reproductive effects.",
           3,
           "chemistry"
          ],
          [
           "Synthesis, Structural, Magnetic and Computational Studies of a One-Dimensional Ferromagnetic Cu(II) Chain Assembled from a New Schiff Base Ligand",
           "10.3390/chemistry5010007",
           2023,
           "A new asymmetrically substituted ONOO Schiff base ligand N-(2′-hydroxy-1′-naphthylidene)-3-amino-2-naphthoic acid (nancH2) was prepared from the condensation of 2–hydroxy–1–naphthaldehyde and 3–amino–2–naphthoic acid. nancH2 reacts with Cu2(O2CMe)4·2H2O in the presence of Gd(O2CMe)3·6H2O to afford a uniform one-dimensional homometallic chain, [CuII(nanc)]n (1). The structure of 1 was elucidated via single crystal X-ray diffraction studies, which revealed that the Cu(II) ions adopt distorted square planar geometries and are coordinated in a tridentate manner by an [ONO] donor set from one nanc2− ligand and an O− of a bridging carboxylate group from a second ligand. The bridging carboxylato group of the nanc2− ligand adopts a syn, anti-η1:η1:μ conformation linking neighboring Cu(II) ions, forming a 1D chain. The magnetic susceptibility of 1 follows Curie–Weiss law in the range 45–300 K (C = 0.474(1) emu K mol-1, θ = +7.9(3) K), consistent with ferromagnetic interactions between S = ½ Cu(II) ions with g = 2.248. Subsequently, the data fit well to the 1D quantum Heisenberg ferromagnetic (QHFM) chain model with g = 2.271, and J = +12.3 K. DFT calculations, implementing the broken symmetry approach, were also carried out on a model dimeric unit extracted from the polymeric chain structure. The calculated exchange coupling via the carboxylate bridge (J = +13.8 K) is consistent with the observed ferromagnetic exchange between neighbouring Cu(II) centres.",
           0,
           "chemistry"
          ],
          [
           "Potentiometric Determination of Free Fluoride Content in Wines from Dalmatia Region (Croatia)—A Comparative Study of Direct Potentiometry and Standard Addition Method",
           "10.3390/chemistry5010003",
           2022,
           "The aim of this study was to investigate 30 different types of Dalmatian wines as a potential source of fluoride. A fluoride ion selective electrode was used to measure the fluoride concentration in each sample. The direct potentiometric method and the standard addition method were evaluated, the latter being suggested as more accurate and precise. Measurements were performed in two buffers, acetate buffer and total ionic strength adjustment buffer (TISAB), to compare their influence on fluoride determination. The obtained results show that TISAB is a better choice than acetate buffer as a medium for fluoride determination. According to the proposed method, mass concentrations of fluoride of 0.19 and 0.18 mg/L were found in the studied red and white wines, with standard deviations of 0.04 and 0.03 mg/L, respectively. All determined fluorine levels in the tested wines were within the recommended limits and do not pose a risk to human health. No significant difference was found between the fluorine content in white and red wines, but there was a difference depending on the place of origin of the wine. The measured pH values for all the wines studied (except one sample) are very similar and show no significant correlation with the fluoride content.",
           1,
           "chemistry"
          ],
          [
           "Sweet, Sugar-Coated Hierarchical Platinum Nanostructures for Easy Support, Heterogenization and Separation",
           "10.3390/chemistry4040078",
           2022,
           "Metal nanoparticles are increasingly gaining interest in the field of heterogeneous catalysis. Here, we present a novel strategy for synthesizing sugar-coated platinum nanostructures (SC-Pt-NS) from the carbohydrates sucrose and D(-)-fructose. In the synthesis from a mixture of H2PtCl6·6H2O, the carbohydrate in an ionic liquid (IL) yielded primary particles of a homogeneous average size of ~10 nm, which were aggregated to hierarchical Pt nanostructures of ~40–65 nm and surrounded or supported by the carbohydrate. These sugar-coated platinum nanostructures present a facile way to support and heterogenize nanoparticles, avoid leaching and enable easier separation and handling. The catalytic activity of the SC-Pt-NS was shown in the hydrosilylation test reaction of phenylacetylene with triethylsilane, where very high turnover frequency (TOF) values of up to 87,200 h−1 could be achieved, while the platinum metal leaching into the product was very low.",
           1,
           "chemistry"
          ],
          [
           "Exploiting In-Situ Characterization for a Sabatier Reaction to Reveal Catalytic Details",
           "10.3390/chemistry3040084",
           2021,
           "In situ characterization of catalysts provides important information on the catalyst and the understanding of its activity and selectivity for a specific reaction. TPX techniques for catalyst characterization reveal the role of the support on the stabilization and dispersion of the active sites. However, these can be altered at high temperature since sintering of active species can occur as well as possible carbon deposition through the Bosch reaction, which hinders the active species and deactivates the catalyst. In situ characterization of the spent catalyst, however, may expose the causes for catalyst deactivation. For example, a simple TPO analysis on the spent catalyst may produce CO and CO2 via a reaction with O2 at high temperature and this is a strong indication that deactivation may be due to the deposition of carbon during the Sabatier reaction. Other TPX techniques such as TPR and pulse chemisorption are also valuable techniques when they are applied in situ to the fresh catalyst and then to the catalyst upon deactivation.",
           0,
           "chemistry"
          ],
          [
           "Chemistry, Synthesis, and Structure Activity Relationship of Anticancer Quinoxalines",
           "10.3390/chemistry5040166",
           2023,
           "Quinoxaline is a fused heterocycle system of a benzene ring and pyrazine ring. It has earned considerable attention due to its importance in the field of medicinal chemistry. The system is of extensive importance due to its comprehensive array of biological activities. Quinoxaline derivatives have been used as anticancer, anticonvulsant, anti-inflammatory, antidiabetic, antioxidant, antibacterial, anti-TB, antimalarial, antiviral, anti-HIV, and many other uses. Variously substituted quinoxalines are significant therapeutic agents in the pharmaceutical industry. This review spotlights on the chemistry, physiochemical characters, synthesis, pharmaceutical products, and medicinal chemistry of various anticancer quinoxaline derivatives that were developed in the last period. It covers the period from 2016 to 2023.",
           0,
           "chemistry"
          ],
          [
           "Quantitative Determination of Fluoride Mass Concentration in Beers Produced in Croatia Using the Standard Addition Method in Potentiometry",
           "10.3390/chemistry5040167",
           2023,
           "It is well known that beer is more than 90% water, and therefore, water can be one of the main sources of fluoride in beers. With this in mind, the goal of the present study was to determine the mass concentration of fluoride in 53 beer samples. Using the recently published standard addition method in potentiometry, the fluoride content of 28 samples of the most consumed beers in the Republic of Croatia was determined. The remaining 25 beer samples tested came from so-called microbreweries, which together account for less than 10% of the Croatian market. Fluoride concentrations in light beers ranged from 49 to 180 μg L−1, with a mean value of 95 ± 34 μg L−1, and from 52 to 164 μg L−1, with a mean value of 89 ± 29 μg L−1 in dark beers. The mean value of fluoride content in beers from large producers was 100 ± 38 μg L−1 and 89 ± 38 μg L−1 in beers from small producers. All values are within the recommended range and thus do not pose a risk to human health. The statistical analysis showed no correlation between the mass concentration of fluoride and pH, i.e., alcohol content in beers.",
           0,
           "chemistry"
          ],
          [
           "Special Issue “Functional Biomolecule-Based Composites and Nanostructures: Current Developments and Applications—A Themed Issue in Honor of Prof. Dr. Itamar Willner”",
           "10.3390/chemistry6010006",
           2024,
           "This Special Issue of Chemistry is a themed issue of “Functional Biomolecule-Based Composites and Nanostructures: Current Developments and Applications” in honor of Itamar Willner to celebrate his innovative research career [...]",
           0,
           "chemistry"
          ],
          [
           "Before Radicals Were Free – the Radical Particulier of de Morveau",
           "10.3390/chemistry2020019",
           2020,
           "Today, we universally understand radicals to be chemical species with an unpaired electron. It was not always so, and this article traces the evolution of the term radical and in this journey, monitors the development of some of the great theories of organic chemistry.",
           4,
           "chemistry"
          ],
          [
           "A Prediction for the Conversion Performance of H2S to Elemental Sulfur in an Ionic-Liquid-Incorporated Transition Metal Using COSMO-RS",
           "10.3390/chemistry4030058",
           2022,
           "In the present study, the conversion performance of hydrogen sulfide (H2S) to elemental sulfur in ionic-liquid-incorporated transition metals (ILTMs) is predicted using a conductor-like screening model for realistic solvents (COSMO-RS). The predictions were made via the establishment of a correlation between the conversion performance and solubility of H2S in ionic liquids (ILs). All molecules involved were optimized at the DFT/TZVP/M06 computational level and imported on the COSMOtherm program at equimolar conditions. For validation purposes, the solubility of ILs was predicted at 1 bar pressure. Simple regression analysis was used to establish a relationship between the solubility and conversion performance of H2S. The results indicate that the solubility prediction of ILs is accurate (R2 = 93.40%) with a p-value of 0.0000000777. Additionally, the conversion performance is generally found to be dependent on the solubility value. Furthermore, 1-butyl-3-methylimidazolium chloride [bmim][Cl] was chosen as the base IL for incorporating the transition metal, owing to its solubility and selectivity to H2S. The solubility trend of ILTMs is found to follow the following order: [bmim][NiCl3] > [bmim][FeCl4] > [bmim][CoCl3] > [bmim][CuCl3]. According to the viscosity measurements of ILTMs, [bmim][NiCl3] and [bmim][FeCl4] exhibited the highest and lowest viscosity values, respectively. Therefore, [bmim][FeCl4] is a promising ILTM owing to its higher solubility and low viscosity for the application studied.",
           0,
           "chemistry"
          ],
          [
           "Synthesis of Nitroarenes by Oxidation of Aryl Amines",
           "10.3390/chemistry4010007",
           2022,
           "Nitro compounds are an important class of organic molecules with broad application in organic synthesis, medicinal chemistry, and materials science. Among the variety of methodologies available for their synthesis, the direct oxidation of primary amines represents an attractive alternative route. Efforts towards the development of oxidative procedures for the synthesis of nitro derivatives have spanned over the past decades, leading to a wide variety of protocols for the selective oxidative conversion of amines to nitro derivatives. Methods for the synthesis of nitroarenes via oxidation of aryl amines, with particular emphasis on recent advances in the field, are summarised in this review.",
           5,
           "chemistry"
          ],
          [
           "From Frustrated Packing to Tecton-Driven Porous Molecular Solids",
           "10.3390/chemistry2010011",
           2020,
           "Structurally divergent molecules containing bulky substituents tend to produce porous materials via frustrated packing. Two rigid tetrahedral cores, tetraphenylmethane and 1,3,5,7-tetraphenyladamantane, grafted peripherally with four (trimethylsilyl)ethynyl moieties, were found to have only isolated voids in their crystal structures. Hence, they were modified into tecton-like entities, tetrakis(4-(iodoethynyl)phenyl)methane [I4TEPM] and 1,3,5,7-tetrakis(4-(iodoethynyl)phenyl)adamantane [I4TEPA], in order to deliberately use the motif-forming characteristics of iodoethynyl units to enhance crystal porosity. I4TEPM not only holds increased free volume compared to its precursor, but also forms one-dimensional channels. Furthermore, it readily co-crystallizes with Lewis basic solvents to afford two-component porous crystals.",
           7,
           "chemistry"
          ],
          [
           "Green Synthesis of Gold Nanoparticles: An Eco-Friendly Approach",
           "10.3390/chemistry4020026",
           2022,
           "By virtue of their unique physicochemical properties, gold nanoparticles (AuNPs) have gained significant interest in a broad range of biomedical applications such as sensors, diagnosis, and therapy. AuNPs are generally synthesized via different conventional physical and chemical methods, which often use harmful chemicals that induce health hazards and pollute the environment. To overcome these issues, green synthesis techniques have evolved as alternative and eco-friendly approaches to the synthesis of environmentally safe and less-expensive nanoparticles using naturally available metabolites from plants and microorganisms such as bacteria, fungi, and algae. This review provides an overview of the advances in the synthesis of AuNPs using different biological resources with examples, and their profound applications in biomedicine. A special focus on the biosynthesis of AuNPs using different medicinal plants and their multifunctional applications in antibacterial, anti-inflammatory, and immune responses are featured. Additionally, the applications of AuNPs in cancer theranostics, including contrast imaging, drug delivery, hyperthermia, and cancer therapeutics, are comprehensively discussed. Moreover, this review will shed light on the importance of the green synthesis approach, and discuss the advantages, challenges, and prospects in this field.",
           48,
           "chemistry"
          ],
          [
           "Supramolecular Assemblies of Trinuclear Copper(II)-Pyrazolato Units: A Structural, Magnetic and EPR Study",
           "10.3390/chemistry2030039",
           2020,
           "Two anionic complexes, {[Cu3(µ3-OH)(µ-4-Ph-pz)3Cl3]2[Cu(4-Ph-pzH)4](µ-Cl)2}2− (1) and [Cu3(µ3-OH)(µ-pz)3(µ1,1-N3)2(N3)]− (2), crystallize as one-dimensional polymers, held together by weak Cu-(µ-Cl) and Cu-(µ-N3) interactions, respectively. Variable temperature magnetic susceptibility analyses determined the dominant antiferromagnetic intra-Cu3 exchange parameters in the solid state for both complexes, whereas the weak ferromagnetic inter-Cu3 interactions manifested also in the solid state EPR spectra, are absent in the corresponding frozen solution spectra. DFT calculations were employed to support the results of the magnetic susceptibility analyses.",
           4,
           "chemistry"
          ],
          [
           "Divalent Europium, NIR and Variable Emission of Trivalent Tm, Ho, Pr, Er, Nd, and Ce in 3D Frameworks and 2D Networks of Ln–Pyridylpyrazolates",
           "10.3390/chemistry5020069",
           2023,
           "The redox reactions of various lanthanide metals with 3-(4-pyridyl)pyrazole (4-PyPzH) or 3-(3-pyridyl)pyrazole (3-PyPzH) ligands yield the 2D network ∞2[Eu(4-PyPz)2(Py)2] containing divalent europium, the 3D frameworks ∞3[Ln(4-PyPz)3] and ∞3[Ln(3-PyPz)3] for trivalent cerium, praseodymium, neodymium, holmium, erbium, and thulium as well as ∞3[La(4-PyPz)3], and the 2D networks ∞2[Ln(4-PyPz)3(Py)] for trivalent cerium and thulium and ∞2[Ln2(4-PyPz)6]·Py for trivalent ytterbium and lutetium. The 18 lanthanide coordination polymers were synthesized under solvothermal conditions in pyridine (Py), partly acting as a co-ligand for some networks. The compounds exhibit a variety of luminescence properties, including metal-centered 4f–4f/5d–4f emission in the visible and near-infrared spectral range, metal-to-ligand energy transfer, and ligand-centered fluorescence and phosphorescence. The anionic ligands 3-PyPz− and 4-PyPz− serve as suitable antennas for lanthanide-based luminescence in the visible and near-infrared range through effective sensitization followed by emission through intra–4f transitions of the trivalent thulium, holmium, praseodymium, erbium, and neodymium. ∞2[Ce(4-PyPz)3(Py)], ∞3[Ce(4-PyPz)3], and ∞3[Ce(3-PyPz)3] exhibit strong degrees of reduction in the 5d excited states that differ in intensity compared to the ligand-based emission, resulting in a distinct emission ranging from pink to orange. The direct current magnetic studies show magnetic isolation of the lanthanide centers in the crystal lattice of ∞3[Ln(3-PyPz)3], Ln = Dy, Ho, and Er.",
           0,
           "chemistry"
          ],
          [
           "Complexation Behavior of Pinene–Bipyridine Ligands towards Lanthanides: The Influence of the Carboxylic Arm",
           "10.3390/chemistry4010002",
           2022,
           "The complexation behavior of two novel, chiral pinene–bipyridine-type ligands ((–)-HL1 and (–)-HL2) containing a carboxylic arm towards lanthanide Ln(III) (Ln = La, Eu, Lu) ions was investigated through spectroscopic methods. The association constants of the mononuclear complexes determined from the UV-Vis titrations indicated that the ligand (–)-HL1 possessing a shorter carboxylic arm formed more stable complexes compared with (–)-HL2, whose carboxylic arm had one more methylene unit. This is due to the formation of more stable seven-member metal chelate rings in the first case as compared with the eight-member metal chelate rings in the second. IR and fluorescence spectroscopy provided additional information about the structure of these complexes.",
           1,
           "chemistry"
          ],
          [
           "Fully Biobased Reactive Extrusion of Biocomposites Based on PLA Blends and Hazelnut Shell Powders (HSP)",
           "10.3390/chemistry3040104",
           2021,
           "The production of biocomposites based on natural fiber waste and biopolymers is constantly increasing because of their renewability, biodegradability, and the accordance with the circular economy principles. The aim of this work is to contrast the disadvantages in the production of biocomposites, such as reduction of molecular weight through the use of biobased chain extenders. For this purpose, epoxidized soybean oil (ESO) and dicarboxylic acids (DCAs) were used to contrast the slight chain scission observed in a poly(lactic acid) (PLA)/poly(butylene succinate-co-adipate) (PBSA) binary blend caused by the melt mixing with hazelnut shell powder (HSP). Two different dimensions of HSPs were considered in this study as well as different concentrations of the ESO/DCA system, comparing succinic acid and malic acid as dicarboxylic acids. Melt viscosity parameters, such as torque and melt volume rate (MVR), were measured to investigate the chain extender effect during the extrusion. In addition, the reactivity of the ESO/DCA system was investigated through infrared spectroscopy. The effect of chain extenders on thermal properties, in particular on the crystallinity of PLA, and on mechanical properties of final biocomposites was investigated to understand their potentialities in industrial application. Results of this study evidenced a modest increase in melt viscosity due to ESO/malic acid chain extension system, but only for the HSP with the lower dimension (so the higher surface area) and adding 0.5 wt.% of ESO/malic acid. Thus, the slight chain scission of polyesters, not significantly affecting the final properties of these biocomposites, is the most relevant effect that was revealed in this complex reactive system.",
           4,
           "chemistry"
          ],
          [
           "Suzuki–Miyaura Reaction in the Presence of N-Acetylcysteamine Thioesters Enables Rapid Synthesis of Biomimetic Polyketide Thioester Surrogates for Biosynthetic Studies",
           "10.3390/chemistry5020096",
           2023,
           "Biomimetic N-acetylcysteamine thioesters are essential for the study of polyketide synthases, non-ribosomal peptide synthetases and fatty acid synthases. The chemistry for their preparation is, however, limited by their specific functionalization and their susceptibility to undesired side reactions. Here we report a method for the rapid preparation of N-acetylcysteamine (SNAC) 7-hydroxy-2-enethioates, which are suitable for the study of various enzymatic domains of megasynthase enzymes. The method is based on a one-pot sequence of hydroboration and the Suzuki–Miyaura reaction. The optimization of the reaction conditions made it possible to suppress potential side reactions and to introduce the highly functionalized SNAC methacrylate unit in a high yield. The versatility of the sequence was demonstrated by the synthesis of the complex polyketide-SNAC thioesters 12 and 33. Brown crotylation followed by the hydroboration to Suzuki–Miyaura reaction sequence enabled the introduction of the target motif in significantly fewer steps and with a higher overall yield and stereoselectivity than previously described approaches. This is the first report of a transition-metal-catalyzed cross-coupling reaction in the presence of an SNAC thioester.",
           1,
           "chemistry"
          ],
          [
           "Acknowledgment to Reviewers of Chemistry in 2020",
           "10.3390/chemistry3010012",
           2021,
           "Peer review is the driving force of journal development, and reviewers are gatekeepers who ensure that Chemistry maintains its standards for the high quality of its published papers [...]",
           0,
           "chemistry"
          ],
          [
           "Novel Ansa-Chain Conformation of a Semi-Synthetic Rifamycin Prepared Employing the Alder-Ene Reaction: Crystal Structure and Absolute Stereochemistry",
           "10.3390/chemistry3030052",
           2021,
           "Rifamycins are an extremely important class of antibacterial agents whose action results from the inhibition of DNA-dependent RNA synthesis. A special arrangement of unsubstituted hydroxy groups at C21 and C23, with oxygen atoms at C1 and C8 is essential for activity. Moreover, it is known that the antibacterial action of rifamycin is lost if either of the two former hydroxy groups undergo substitution and are no longer free to act in enzyme inhibition. In the present work, we describe the successful use of an Alder-Ene reaction between Rifamycin O, 1 and diethyl azodicarboxylate, yielding 2, which was a targeted introduction of a relatively bulky group close to C21 to protect its hydroxy group. Many related azo diesters were found to react analogously, giving one predominant product in each case. To determine unambiguously the stereochemistry of the Alder-Ene addition process, a crystalline zwitterionic derivative 3 of the diethyl azodicarboxylate adduct 2 was prepared by reductive amination at its spirocyclic centre C4. The adduct, as a mono chloroform solvate, crystallized in the non-centrosymmetric Sohnke orthorhombic space group, P212121. The unique conformation and absolute stereochemistry of 3 revealed through X-ray crystal structure analysis is described.",
           1,
           "chemistry"
          ],
          [
           "Total Synthesis of Floyocidin B: 4,5-Regioselective Functionalization of 2-Chloropyridines",
           "10.3390/chemistry5010014",
           2023,
           "The recently discovered natural product (NP) (+)-floyocidin B with antimicrobial activity against Mycobacterium tuberculosis displays a hitherto unknown dihydroisoquinolinone scaffold in the class of the epoxyquinone NPs. The 4,5-regioselective functionalization of 2-chloropyridines was identified as a suitable strategy leading to the total syntheses of (+)-floyocidin B and analogs. In this paper, we present the long and winding evolution process to the final synthetic pathway, including model systems for route scouting and elucidation of side products, which enabled us to understand the unique reactivity of this unprecedented scaffold. A special focus was laid on method studies with different 2-chloropyridines, disclosing an unexpected effect of the 2-chloro substituent on the regioselectivity compared to 2-unsubstituted or carbon-substituted pyridines. Finally, a head-to-head comparison with the previously described synthesis of all four stereoisomers of the NP (−)-avicennone C revealed significant differences in the reactivity of these structurally closely related scaffolds.",
           0,
           "chemistry"
          ],
          [
           "A New Unnatural Amino Acid Derived from the Modification of 4′-(p-tolyl)-2,2′:6′,2″-terpyridine and Its Mixed-Ligand Complexes with Ruthenium: Synthesis, Characterization, and Photophysical Properties",
           "10.3390/chemistry5010012",
           2023,
           "The modification of the methyl group of 4′-(p-tolyl)-2,2′:6′,2″-terpyridine produced the novel unnatural amino acid 3-(4-([2,2′:6′,2″-terpyridin]-4′-yl)phenyl)-2-aminopropanoic acid (phet). Mononuclear heteroleptic ruthenium complexes of the general formulae [Ru(L1)(L2)](PF6)2 (L1 = 2-acetylamino-2-(4-[2,2′:6′,2″]terpyridine-4′-yl-benzyl)-malonic acid diethyl ester, (phem), 3-(4-([2,2′:6′,2″-terpyridin]-4′-yl)phenyl)-2-aminopropanoic acid, (phet), and L2 = 2,2′:6′,2″-terpyridine (tpy), 4′-phenyl-2,2′:6′,2″-terpyridine (ptpy), 4′-(p-tolyl)-2,2′:6′,2″-terpyridine (mptpy)), as well as the homoleptic [Ru(phem)2](PF6)2 and [Ru(phet)2](PF6)2, were synthesized and characterized by means of NMR spectroscopic techniques, elemental analysis, and high-resolution mass spectrometry. The photophysical properties of the synthesized complexes were also studied.",
           0,
           "chemistry"
          ],
          [
           "Synthesis of 5-Metalla-Spiro[4.5]Heterodecenes by [1,4]-Cycloaddition Reaction of Group 13 Diyls with 1,2-Diketones",
           "10.3390/chemistry5020064",
           2023,
           "Monovalent group 13 diyls are versatile reagents in oxidative addition reactions. We report here [1,4]-cycloaddition reactions of β-diketiminate-substituted diyls LM (M = Al, Ga, In, Tl; L = HC[C(Me)NDipp]2, Dipp = 2,6-iPr2C6H3) with various 1,2-diketones to give 5-metalla-spiro[4.5]heterodecenes 1, 4–6, and 8–10, respectively. In contrast, the reaction of LTl with acenaphthenequinone gave the [2,3]-cycloaddition product 7, with Tl remaining in the +1 oxidation state. Compound 1 also reacted with a second equivalent of butanedione as well as with benzaldehyde in aldol-type addition reactions to the corresponding α,β-hydroxyketones 2 and 3, while a reductive activation of a benzene ring was observed in the reaction of benzil with two equivalents of LAl to give the 1,4-aluminacyclohex-2,4-dien 12. In addition, the reaction of L’BCl2 (L = HC[C(Me)NC6F5]2) with one equivalent of benzil in the presence of KC8 gave the corresponding 5-bora-spiro[4.5]heterodecene 13, whereas the hydroboration reaction of butanedione with L’BH2 (14), which was obtained from the reaction of L’BCl2 with L-selectride, failed to give the saturated 5-bora-spiro[4.5]heterodecane.",
           0,
           "chemistry"
          ],
          [
           "Coordination Chemistry of Polynitriles, Part XI. Influence of 4,4′-Bipyridine and Solvent on the Crystal and Molecular Structures of Alkaline Earth Pentacyanocyclopentadienides",
           "10.3390/chemistry4040101",
           2022,
           "The reaction of alkaline earth pentacyanocyclopentadienides with 4,4′-bipyridine in MeOH yielded undefined products of composition [M(PCC)2(Bipy)x(MeOH)y(H2O)z] (PCC = [C5(CN)5]−). Recrystallization from MeOH, EtOH, or n-BuOH gave crystals of [Mg(H2O)4(4,4′-bipy)2](PCC)2∙2BuOH (1), [Ca(H2O)4(4,4′-bipy)2](PCC)2∙(4,4′-bipy) (2), [Sr(MeOH)8](PCC)2∙3(4,4′-bipy) (3), [Sr2(H2O)4(BuOH)4(PCC)2(µ-PCC)2 (µ-4,4′-bipy)]∙4 (4,4′-bipy)∙0.29 (BuOH) (4), [Ba3(H2O)4(EtOH)10 (PCC)2(µ-PCC)2 (µ-4,4′-bipy)2(4,4′-bipy)](PCC)2 ∙3(4,4′-bipy)∙2EtOH∙H2O (5) and [Ba4(H2O)8(BuOH)6 (PCC)2(µ-PCC)6 (4,4′-bipy)6]∙3(4,4′-bipy) (6). 4,4′-Bipyridine functions either as monodentate or bidentate ligand and is present in all cases except for 2 as lattice guest. While in compounds 1 and 2 only water is present as O-donor, the alcohol coordinates in the other compounds either exclusively (3) or together with water (4–6). The pentacyanocyclopentadienide does not coordinate in 1–3, but is present as mono-, bi-, or tridentate ligand in 4–6. In all compounds, a more or less complicated interplay of hydrogen bridges and π–π stacking is observed.",
           0,
           "chemistry"
          ],
          [
           "Defects and Calcium Diffusion in Wollastonite",
           "10.3390/chemistry2040059",
           2020,
           "Wollastonite (CaSiO3) is an important mineral that is widely used in ceramics and polymer industries. Defect energetics, diffusion of Ca ions and a solution of dopants are studied using atomistic-scale simulation based on the classical pair potentials. The energetically favourable defect process is calculated to be the Ca-Si anti-site defect cluster in which both Ca and Si swap their atomic positions simultaneously. It is calculated that the Ca ion migrates in the ab plane with an activation energy of 1.59 eV, inferring its slow diffusion. Favourable isovalent dopants on the Ca and Si sites are Sr2+ and Ge4+, respectively. Subvalent doping by Al on the Si site is a favourable process to incorporate additional Ca in the form of interstitials in CaSiO3. This engineering strategy would increase the capacity of this material.",
           0,
           "chemistry"
          ],
          [
           "Exploring the Structural Chemistry of Pyrophosphoramides: N,N′,N″,N‴-Tetraisopropylpyrophosphoramide",
           "10.3390/chemistry3010013",
           2021,
           "N,N′,N″,N‴-Tetraisopropylpyrophosphoramide 1 is a pyrophosphoramide with documented butyrylcholinesterase inhibition, a property shared with the more widely studied octamethylphosphoramide (Schradan). Unlike Schradan, 1 is a solid at room temperature making it one of a few known pyrophosphoramide solids. The crystal structure of 1 was determined by single-crystal X-ray diffraction and compared with that of other previously described solid pyrophosphoramides. The pyrophosphoramide discussed in this study was synthesised by reacting iso-propyl amine with pyrophosphoryl tetrachloride under anhydrous conditions. A unique supramolecular motif was observed when compared with previously published pyrophosphoramide structures having two different intermolecular hydrogen bonding synthons. Furthermore, the potential of a wider variety of supramolecular structures in which similar pyrophosphoramides can crystallise was recognised. Proton (1H) and Phosphorus 31 (31P) Nuclear Magnetic Resonance (NMR) spectroscopy, infrared (IR) spectroscopy, mass spectrometry (MS) were carried out to complete the analysis of the compound.",
           1,
           "chemistry"
          ],
          [
           "Comparison of Cu-CHA-Zeolites in the Hybrid NSR-SCR Catalytic System for NOx Abatement in Mobile Sources",
           "10.3390/chemistry5010043",
           2023,
           "DeNOx activity in a NSR–SCR hybrid system of two copper-containing chabazite-type zeolitic catalysts was addressed. A Pt-Ba-K/Al2O3 model catalyst was used as the NSR (NOx storage and reduction) catalyst. For the SCR (selective catalytic reduction) system, two Cu-CHA zeolites were synthesized employing a single hydrothermal synthesis method assisted with ultrasound and incorporating Cu in a 2 wt.%, 2Cu-SAPO-34 and 2Cu-SSZ-13. The prepared catalysts were characterized, and the crystallinity, surface area, pore size, HR-TEM and EDX mapping, coordination of Cu ions and acidity were compared. The NH3 storage capacity of the SCR catalysts was 1890 and 837 μmol NH3·gcat−1 for 2Cu-SAPO-34 and 2Cu-SSZ-13, respectively. DeNOx activity was evaluated for the single NSR system and the double-bed NSR–SCR by employing alternating lean (3%O2) and rich (1%H2) cycles, maintaining a concentration of 600 ppm NO, 1.5% H2O and 0.3% CO2 between 200 and 350 °C. The addition of the SCR system downstream of the NSR catalyst significantly improved NOx conversion mainly at low temperature, maintaining the selectivity to N2 above 80% and reaching values above 90% at 250 °C when the 2Cu-SSZ-13 catalyst was located. The total reduction in the production of NH3 and ~2% of N2O was observed when comparing the NSR–SCR configuration with the single NSR catalyst.",
           0,
           "chemistry"
          ],
          [
           "Self-Assembly of a Rare High Spin FeII/PdII Tetradecanuclear Cubic Cage Constructed via the Metalloligand Approach",
           "10.3390/chemistry4020038",
           2022,
           "Polynuclear heterobimetallic coordination cages in which different metal cations are connected within a ligand scaffold are known to adopt a variety of polyhedral architectures, many of which display interesting functions. Within the extensive array of coordination cages incorporating Fe(II) centres reported so far, the majority contain low-spin (LS) Fe(II), with high-spin (HS) Fe(II) being less common. Herein, we present the synthesis and characterisation of a new tetradecanuclear heterobimetallic [Fe8Pd6L8](BF4]28 (1) cubic cage utilising the metalloligand approach. Use of the tripodal tris-imidazolimine derivative (2) permitted the formation of the tripodal HS Fe(II) metalloligand [FeL](BF4)2·CH3OH (3) that was subsequently used to form the coordination cage 1. Magnetic and structural analyses gave insight into the manner in which the HS environment of the metalloligand was transferred into the cage architecture along with the structural changes that accompanied its occupancy of the eight corners of the discrete cubic structure.",
           5,
           "chemistry"
          ],
          [
           "Bioactive Pyrrolo[2,1-f][1,2,4]triazines: Synthesis, Molecular Docking, In Vitro Cytotoxicity Assay and Antiviral Studies",
           "10.3390/chemistry5040171",
           2023,
           "A series of 2,4-disubstituted pyrrolo[2,1-f][1,2,4]triazines containing both aryl and thienyl substituents were synthesized by exploiting the 1,3-cycloaddition reaction of N(1)-ethyl-1,2,4-triazinium tetrafluoroborates with dimethyl acetylenedicarboxylate. The antiviral activity of the synthesized compounds against influenza virus strain A/Puerto Rico/8/34 (H1N1) was studied in experiments on Madin-Darby canine kidney (MDCK) cell culture. Among the pyrrolo[2,1-f][1,2,4]triazine derivatives, compounds with low toxicity and high antiviral activity were identified. Dimethyl 4-(4-methoxyphenyl)-7-methyl-2-p-tolylpyrrolo[2,1-f][1,2,4]triazine-5,6-dicarboxylate was found to demonstrate the best antiviral activity (IC50 4 µg/mL and selectivity index 188). Based on the results of in vitro tests and molecular docking studies performed, a plausible mechanism of action for these compounds was suggested to involve inhibition of neuraminidase.",
           0,
           "chemistry"
          ],
          [
           "Nature Inspired Manganese(III)-Calcium Complexes: Towards Synthetic Models for the WOC of PSII",
           "10.3390/chemistry5020049",
           2023,
           "For some time, the presence of high oxidation state Mn ions and Ca(II) in the active center of Photosystem II has been known. However, coordination complexes that combine both Mn(III) and Ca(II) have been difficult to obtain, with only a handful of examples reported. In this paper we report the synthesis of two new Mn(III)-Ca(II) complexes, 1 [Pr2NH2]3[Mn6CaO2(OH)(OMe)3(SALO)6 (SALOH)3] and 2 [Mn18Ca6O12(OH)6(MeO)12(PhCOO)18(MeOH)6]. The complexes have been characterized by single-crystal X-ray diffraction to establish the oxidation state of manganese. The use of salicylato ligands with tert-butyl substituents leads to effective encapsulation of a Ca(II) ion in a cavity that has both hydrophobic and hydrophilic regions, mimicking the enzyme environment.",
           0,
           "chemistry"
          ],
          [
           "Selective Fluorimetric Detection of Pyrimidine Nucleotides in Neutral Aqueous Solution with a Styrylpyridine-Based Cyclophane",
           "10.3390/chemistry5020082",
           2023,
           "A styrylpyridine-containing cyclophane with diethylenetriamine linkers is presented as a host system whose association with representative nucleotides was examined with photometric and fluorimetric titrations. The spectrometric titrations revealed the formation of 1:1 complexes with log Kb values in the range of 2.3–3.2 for pyrimidine nucleotides TMP (thymidine monophosphate), TTP (thymidine triphosphate) and CMP (cytidine monophosphate) and 3.8–5.0 for purine nucleotides AMP (adenosine monophosphate), ATP (adenosine triphosphate), and dGMP (deoxyguanosine monophosphate). Notably, in a neutral buffer solution, the fluorimetric response to the complex formation depends on the type of nucleotide. Hence, quenching of the already weak fluorescence was observed with the purine bases, whereas the association of the cyclophane with pyrimidine bases TMP, TTP, and CMP resulted in a significant fluorescence light-up effect. Thus, it was demonstrated that the styrylpyridine unit is a useful and complementary fluorophore for the development of selective nucleotide-targeting fluorescent probes based on alkylamine-linked cyclophanes.",
           0,
           "chemistry"
          ],
          [
           "Structural Characterization, Antioxidant, and Antiviral Activity of Sulfated Polysaccharide (Fucoidan) from Sargassum asperifolium (Turner) J. Agardh",
           "10.3390/chemistry5040176",
           2023,
           "Brown algae possess a diverse array of acidic polysaccharides, including fucoidan. The present research intends to investigate the extraction and characterization of algal polysaccharides to explore their antiviral activity. A light brown sulfated polysaccharide was extracted (with a yield of 18% of dry weight) from Sargassum asperifolium algal powder. The results of fractionation of sulfated polysaccharide revealed the occurrence of two primary fractions: low-sulfated polysaccharides (SPF1) and high-sulfated polysaccharides (SPF2). The bioassays conducted on SPF2 demonstrated a greater level of antioxidant activity compared to SPF1, with respective IC50 values of 17 ± 1.3 µg/mL and 31 ± 1.1 μg/mL after a duration of 120 min. The cytotoxicity of SPF2 on Vero cells was determined, and the calculated half-maximal cytotoxic concentration (CC50) was found to be 178 ± 1.05 µg/mL. Based on these results, an antiviral activity assay was conducted on SPF2. The results demonstrated that SPF2 had greater efficacy against Hepatitis A Virus (HAV) compared to Herpes Simplex Virus Type 1 (HSV-1), with corresponding half-maximal inhibitory concentrations (IC50) of 48 ± 1.8 µg/mL and 123 ± 2.6 µg/mL, respectively. The active SPF2 was characterized by FT-IR, 1H, and 13C NMR spectroscopy. The extracted fucoidan can be used as a natural therapeutic agent in combating various viral infections.",
           0,
           "chemistry"
          ],
          [
           "Short I⋯O Interactions in the Crystal Structures of Two 2-Iodo-Phenyl Methyl-Amides as Substrates for Radical Translocation Reactions",
           "10.3390/chemistry5020083",
           2023,
           "Radical translocation reactions are finding various uses in organic synthesis, in particular the stereospecific formation of complex natural products. In this work, the syntheses and single-crystal structures of two substituted 2-iodo-phenyl methyl-amides are reported, namely cyclo-propane carboxylic acid (2-iodo-phenyl)-methyl-amide, C11H12INO (1), and cyclo-heptane carboxylic acid (2-iodo-phenyl)-methyl-amide, C15H20INO (2). In each case, the methyl-amide group has a syn conformation, and this grouping is perpendicular to the plane of the benzene ring: these solid-state conformations appear to be well setup to allow an intramolecular hydrogen atom transfer to take place as part of a radical translocation reaction. Short intermolecular I⋯O halogen bonds occur in each crystal structure, leading to [010] chains in 1 [I⋯O = 3.012 (2) Å] and isolated dimers in 2 [I⋯O = 3.024 (4) and 3.057 (4) Å]. The intermolecular interactions are further quantified by Hirshfeld surface analyses.",
           0,
           "chemistry"
          ],
          [
           "Environmental Applications of Zeolites: Preparation and Screening of Cu-Modified Zeolites as Potential CO Sensors",
           "10.3390/chemistry5010024",
           2023,
           "This work is focused on the application of Cu-containing zeolites as potential environmental sensors for monitoring carbon monoxide. A number of commercial zeolites with different structural properties (NaX, NaY, MOR, FER, BEA and ZSM-5) were modified using CuSO4, Cu(NO3)2 and Cu(OAc)2 solutions as copper sources to prepare Cu+-containing zeolites, since Cu+ forms stable complexes with CO at room temperature that can be monitored by infrared spectroscopy. Zeolite impregnation with Cu(NO3)2 resulted in the highest total Cu-loadings, while the Cu(OAc)2-treated samples had the highest Cu+/Cutotal ratio. Cu(NO3)2-impregnated MOR, which displayed the highest concentration of Cu+, was subjected to a number of tests to evaluate its performance as a potential CO sensor. The working temperature and concentration ranges of the sensor were determined to be from 20 to 300 °C and from 10 to 10,000 ppm, respectively. The stepwise CO desorption experiments indicated that the sensor can be regenerated at 400 °C if required. Additional analyses under realistic flow conditions demonstrated that for hydrophilic zeolites, the co-adsorption of water can compromise the sensor’s performance. Therefore, a hydrophobic Sn-BEA was utilised as a parent material for the preparation of an impregnated Cu-Sn-BEA zeolite, which exhibited superior resistance to interfering water while maintaining its sensing properties. Overall, the prepared Cu-modified zeolites showed promising potential as environmental CO sensors, displaying high sensitivity and selectivity under representative testing conditions.",
           1,
           "chemistry"
          ],
          [
           "Towards a Better Understanding of the Interaction of Fe66Cr10Nb5B19 Metallic Glass with Aluminum: Growth of Intermetallics and Formation of Kirkendall Porosity during Sintering",
           "10.3390/chemistry5010011",
           2023,
           "Metallic-glass-reinforced metal matrix composites are a novel class of composite materials, in which particles of alloys with an amorphous structure play the role of reinforcement. During the fabrication of these composites, a crystalline metal is in contact with a multicomponent alloy of an amorphous structure. In the present work, the morphological features of the reaction products formed upon the interaction of Fe66Cr10Nb5B19 metallic glass particles with aluminum were studied. The composites were processed via spark plasma sintering (SPS), hot pressing or a combination of SPS and furnace annealing. The reaction products in composites with different concentrations of the metallic glass and different transformation degrees were examined. The products of the interaction of the Fe66Cr10Nb5B19 metallic glass with Al were observed as dense layers covering the residual alloy cores, needles of FeAl3 protruding from the dense shells as well as needles and platelets of FeAl3 distributed in the residual Al matrix. The possible role of the liquid phase in the structure formation of the reaction products is discussed. The formation of needle- and platelet-shaped particles presumably occurred via crystallization from the Al-Fe-based melt, which formed locally due to the occurrence of the exothermic reactions between aluminum and iron. At the same time, aluminum atoms diffused into the solid Fe-based alloy particles, forming an intermetallic layer, which could grow until the alloy was fully transformed. When aluminum melted throughout the volume of the composite during heating of the sample above 660 °C, a similar microstructure developed. In both Al–Fe66Cr10Nb5B19 and Al–Fe systems, upon the reactive transformation, pores persistently formed in locations occupied by aluminum owing to the occurrence of the Kirkendall effect.",
           3,
           "chemistry"
          ],
          [
           "DNA Nanotechnology-Empowered Fluorescence Imaging of APE1 Activity",
           "10.3390/chemistry5030124",
           2023,
           "Apurinic/apyrimidinic endonuclease 1 (APE1), also known as redox factor-1 (Ref-1), is a multifunctional protein that exists widely in living organisms. It can specifically recognize and cleave the DNA in apurinic/apyrimidinic (AP) sites in the base excision repair (BER) pathway, as well as regulate the expression of genes to activate some transcription factors. The abnormal expression and disruptions in the biological functions of APE1 are linked to a number of diseases, including inflammation, immunodeficiency, and cancer. Hence, it is extremely desired to monitor the activity of APE1, acquiring a thorough understanding of the healing process of damaged DNA and making clinical diagnoses. Thanks to the advent of DNA nanotechnology, some nanodevices are used to image the activity of APE1 with great sensitivity and simplicity. In this review, we will summarize developments in DNA-nanotechnology-empowered fluorescence imaging in recent years for APE1 activity according to different types of DNA probes, which are classified into linear DNA probes, composite DNA nanomaterials, and three-dimensional (3D) DNA nanostructures. We also highlight the future research directions in the field of APE1 activity imaging.",
           0,
           "chemistry"
          ],
          [
           "Study of the Performance of Particles Based on Modified Starches Containing Potassium Sorbate and Incorporated into Biodegradable Films: Physicochemical Characterization and Antimicrobial Action",
           "10.3390/chemistry3020046",
           2021,
           "Ultrasound technique was used to produce native and acetylated cassava starch particles containing potassium sorbate (KS). In order to obtain an active packaging, films with addition of native starch particles containing KS (NKSPF) or added with acetylated starch particles containing KS (AKSPF) were formulated. As control systems, films without KS (CF) or added with KS that was not retained in particles (KSF), were produced. The NKSPF and AKSPF microstructure was consistent with composite materials. Tensile test revealed that CF and KSF were ductile and extensible (stress at break (σb) 2.8–2.5 MPa and strain at break (εb) 284–206%), while NKSPF and AKSPF were more resistant films with higher Young’s Modulus (148–477 MPa) and σb (3.6–17 MPa) but lower εb (40–11%). Moreover, NKSPF and AKSPF developed lower Yellowness Index (6.6–6.5) but higher opacity (19–23%) and solubility in water (31–35%) than KSF (9, 10.8% and 9%, respectively). It was observed that KSF and NKSPF moderately reduced the Zygosaccharomyces bailii growth while AKSPF showed the highest yeast inhibition, three Log-cycles, compared to CF. Additionally, FTIR spectroscopy revealed intensified interactions between KS and modified starch. It was concluded that starch sonication and acetylation were useful modifications to produce particles carrier of KS that improved the physical and antimicrobial performance of active films.",
           1,
           "chemistry"
          ],
          [
           "Self-Assembled DNA Nanospheres: Design and Applications",
           "10.3390/chemistry5030129",
           2023,
           "Self-assembled DNA nanospheres, as versatile and ideal vehicles, have offered new opportunities to create intelligent delivery systems for precise bioimaging and cancer therapy, due to their good biostability and cell permeability, large loading capacity, and programmable self–assembly behaviors. DNA nanospheres can be synthesized by the self–assembly of Y–shaped DNA monomers, ultra–long single-stranded DNA (ssDNA), and even metal–DNA coordination. Interestingly, they are size–controllable by varying some parameters including concentration, reaction time, and mixing ratio. This review summarizes the design of DNA nanospheres and their extensive biomedical applications. First, the characteristics of DNA are briefly introduced, and different DNA nanostructures are mentioned. Then, the design of DNA nanospheres is emphasized and classified into three main categories, including Y–shaped DNA unit self-assembly by Watson–Crick base pairing, liquid crystallization and the dense packaging of ultra–long DNA strands generated via rolling circle amplification (RCA), and metal–DNA coordination–driven hybrids. Meanwhile, the advantages and disadvantages of different self–assembled DNA nanospheres are discussed, respectively. Next, the biomedical applications of DNA nanospheres are mainly focused on. Especially, DNA nanospheres serve as promising nanocarriers to deliver functional nucleic acids and drugs for biosensing, bioimaging, and therapeutics. Finally, the current challenges and perspectives for self-assembled DNA nanospheres in the future are provided.",
           0,
           "chemistry"
          ],
          [
           "Solvatochromism and Selective Sorption of Volatile Organic Solvents in Pyridylbenzoate Metal-Organic Frameworks",
           "10.3390/chemistry1010009",
           2019,
           "Using cobalt(II) as a metal centre with different solvent systems afforded the crystallization of isomorphous metal-organic frameworks {[Co(34pba)(44pba)]·DMF}n (1) and {[Co(34pba)(44pba)]·(C3H6O)}n (2) from mixed 4-(4-pyridyl)benzoate (44pba) and 3-(4-pyridyl)benzoate (34pba) ligands. Zinc(II) under the same reaction conditions that led to the formation of 1 formed an isostructural {[Zn(34pba)(44pba)]·DMF}n framework (3). Crystal structures of all three MOFs were elucidated and their thermal stabilities were determined. The frameworks of 1, 2, and 3 were activated under vacuum to form the desolvated forms 1d, 2d, and 3d, respectively. PXRD results showed that 1d and 2d were identical, consequently, 1d and 3d were then investigated for sorption of volatile organic compounds (VOCs) containing either chloro or amine moieties. Thermogravimetric analysis (TGA) and nuclear magnetic resonance (NMR) were used to determine the sorption capacity and selectivity for the VOCs. Some sorption products of 1d with amines became amorphous, but the crystalline framework could be recovered on desorption of the amines. Investigation of the sorption of water (H2O) and ammonia (NH3) in 1d gave rise to new phases identifiable by means of a colour change (solvatochromism). The kinetics of desorption of DMF, water and ammonia from frameworks 1d and 3d were studied using non-isothermal TGA. Activation energies for both cobalt(II) and zinc(II) frameworks are in the order NH3 < H2O < DMF, with values for the 1d analogue always higher than those for 3d.",
           4,
           "chemistry"
          ],
          [
           "Wasteless Synthesis and Properties of Highly Dispersed MgAl2O4 Based on Product of Thermal Activation of Gibbsite",
           "10.3390/chemistry4020024",
           2022,
           "The study showed that the interaction of the product of centrifugal thermal activation of gibbsite with an aqueous solution of magnesium nitrate at a cationic ratio Mg:Al = 1:2 leads to the formation of mixed double hydroxides both under hydrothermal treatment at 150 °C and at room temperature. The subsequent thermal treatment at 550 °C of the product of mild interaction leads to ~90% alumina-magnesia spinel and ~10% MgO, while the treatment of the hydrothermal interaction product leads to ~100% spinel with the stoichiometric composition MgAl2O4. The obtained spinel samples possess a high specific surface area (above 100 m2/g) and a hierarchical pore structure formed by the micron-level particles of different sizes (1–2 and 10–20 μm) consisting of ~70 nm crystallites with ~3 nm pores; the samples differ mostly in the total volume and quantitative ratio of the pores. The samples have Lewis acid sites of moderate strength on the surface, the amount of which is much lower to how it is when compared with a sample prepared by precipitation in that they also differ by quantity from each other as well (503 μmol/g for stoichiometric spinel and 304 μmol/g for sample with admixture of MgO). As the calcination temperature is raised to 850 °C, the acidity decreases—only weak Lewis acid sites are observed, the amount of which is also higher for stoichiometric spinel (161 and 39 μmol/g, respectively). The method proposed for the synthesis of alumina-magnesia systems provides a high dispersion and a much lower surface acidity for the oxides; in addition, it minimizes or completely excludes wash water, in distinction to the precipitation method.",
           1,
           "chemistry"
          ],
          [
           "Natural and Engineered Electron Transfer of Nitrogenase",
           "10.3390/chemistry2020021",
           2020,
           "As the only enzyme currently known to reduce dinitrogen (N2) to ammonia (NH3), nitrogenase is of significant interest for bio-inspired catalyst design and for new biotechnologies aiming to produce NH3 from N2. In order to reduce N2, nitrogenase must also hydrolyze at least 16 equivalents of adenosine triphosphate (MgATP), representing the consumption of a significant quantity of energy available to biological systems. Here, we review natural and engineered electron transfer pathways to nitrogenase, including strategies to redirect or redistribute electron flow in vivo towards NH3 production. Further, we also review strategies to artificially reduce nitrogenase in vitro, where MgATP hydrolysis is necessary for turnover, in addition to strategies that are capable of bypassing the requirement of MgATP hydrolysis to achieve MgATP-independent N2 reduction.",
           14,
           "chemistry"
          ],
          [
           "New Functionalized Chitosan with Thio-Thiadiazole Derivative with Enhanced Inhibition of Pathogenic Bacteria, Plant Threatening Fungi, and Improvement of Seed Germination",
           "10.3390/chemistry5030118",
           2023,
           "In this study, a new modified chitosan conjugate (Chito-TZ) was developed via amide coupling between the acid chloride derivative of the methylthio-thidiazole compound and the free primary amino groups of chitosan. The product was characterized using several instrumental investigations, including Fourier-transform infrared spectroscopy (FT-IR), 1H-Nuclear magnetic resonance, X-ray photoelectron spectroscopy (XPS), thermogravimetric analysis (TGA), and X-ray diffraction (XRD). XRD indicated that the crystalline pattern of chitosan was interrupted after chemical modification with the thiadiazole derivative. Broido’s model was used to determine the thermal activation energy Ea, and the results showed that the Ea for the first decomposition region of Chito-TZ is 24.70 KJ mol−1 lower than that required for chitosan (95.57 KJ mol−1), indicating the accelerating effect of the thiadiazole derivative on the thermal decomposition of Chito-TZ. The modified chitosan showed better antibacterial and antifungal activities than the non-modified chitosan; except for seed germination, chitosan was better. The Chito-TZ showed a low MIC value (25–50 µg mL−1) compared to Chito (50–100 µg mL−1). Moreover, the maximum inhibition percentages for plant-pathogenic fungi, Aspergillus niger, Fusarium oxysporum, and Fusarium solani, were attained at a concentration of 300 µg mL−1 with values of 35.4 ± 0.9–39.4 ± 1.7% for Chito and 45.2 ± 1.6–52.1 ± 1.3% for Chito-TZ. The highest germination percentages (%) of broad bean, shoot and root length and weight, and seed vigor index were obtained after Chito treatment with a concentration of 200 µg mL−1 compared to Chito-TZ.",
           2,
           "chemistry"
          ],
          [
           "Mechanochemistry through Extrusion: Opportunities for Nanomaterials Design and Catalysis in the Continuous Mode",
           "10.3390/chemistry5030120",
           2023,
           "The potentialities of mechanochemistry trough extrusion have been investigated for the design of nanosized catalysts and their use in C-C bond-forming reactions. The mechanochemical approach proved successful for the synthesis of supported palladium nanoparticles with mean diameter within 6–10 nm, achieved by the reduction of Pd(II) acetate with ethylene glycol, in the absence of any solvent. A mesoporous N-doped carbon derived from chitin as a renewable biopolymer, was used as a support. Thereafter, the resulting nanomaterials were tested as catalysts to implement a second extrusion based-protocol for the Suzuki-Miyaura cross-coupling reaction of iodobenzene and phenylboronic acid. The conversion and the selectivity of the reaction were 81% and >99%, respectively, with a productivity of the desired derivative, biphenyl, of 41 mmol gcat−1 h−1.",
           2,
           "chemistry"
          ],
          [
           "Interval Type-2 Fuzzy Multiattribute Group Decision-Making for Logistics Services Providers Selection by Combining QFD with Partitioned Heronian Mean Operator",
           "10.1155/2019/6727259",
           2019,
           "Logistics service (LS) has key impacts on customers’ satisfaction. Quality function deployment (QFD) can guarantee that logistic services provider’s (LSP) attributes are in accordance with the customer’s preferences for the LS. The partitioned Heronian mean (PHM) operator assumes that all attributes are partitioned into several clusters. Herein, the attributes in the same clusters are interrelated, while the attributes in different clusters are independent, and the operator can be utilized to solve LSP selection (LSPS) problems in which all attributes are partitioned into several clusters. Interval type-2 fuzzy sets (IT2FSs) can more competently express the ambiguity and vagueness and have more powerful processing abilities. In this paper, we propose a novel LSPS method from the customers’ perspective by combining QFD with the PHM operator in IT2FSs environments. First, we develop the interval type-2 fuzzy PHM (IT2FPHM) operator and the interval type-2 fuzzy weighted PHM (IT2FWPHM) operator and discuss some properties of them. Then, based on the relationships between the customer requirements (CRs) and the technical attributes (TAs), QFD is utilized in order to convert the CRs for LS concerns into multiple attributes for LSP’s TAs. Finally, a case of a fresh E-business LSPS is used in order to demonstrate the validity and rationality of the proposed method, and some comparisons are used in order to show the superiority of the proposed method.",
           0,
           "complexity"
          ],
          [
           "3D Reconstruction of Pedestrian Trajectory with Moving Direction Learning and Optimal Gait Recognition",
           "10.1155/2018/8735846",
           2018,
           "An inertial measurement unit-based pedestrian navigation system that relies on the intelligent learning algorithm is useful for various applications, especially under some severe conditions, such as the tracking of firefighters and miners. Due to the complexity of the indoor environment, signal occlusion problems could lead to the failure of certain positioning methods. In complex environments, such as those involving fire rescue and emergency rescue, the barometric altimeter fails because of the influence of air pressure and temperature. This paper used an optimal gait recognition algorithm to improve the accuracy of gait detection. Then a learning-based moving direction determination method was proposed. With the Kalman filter and a zero-velocity update algorithm, different gaits could be accurately recognized, such as going upstairs, downstairs, and walking flat. According to the recognition results, the position change in the vertical direction could be reasonably corrected. The obtained 3D trajectory involving both horizontal and vertical movements has shown that the accuracy is significantly improved in practical complex environments.",
           3,
           "complexity"
          ],
          [
           "Integrated Estimation/Guidance Law against Exoatmospheric Maneuvering Targets",
           "10.1155/2018/7470823",
           2018,
           "An integrated guidance integrated estimation/guidance law is designed for exoatmospheric interceptors equipped with divert thrusters and optical seekers to intercept maneuvering targets. This paper considers an angles-only guidance problem for exoatmospheric maneuvering targets. A bounded differential game-based guidance law is derived against maneuvering targets using zero-effort-miss (ZEM). Estimators based the extended Kalman filter (EKF) and the unscented Kalman filter (UKF) are designed to estimate LOS rates that are contaminated by noise and target maneuver. Furthermore, to improve the observability of the range, an observability enhancement differential game guidance law is derived. The guidance law and the estimator are integrated together in the guidance loop. The proposed integrated estimation/guidance law has been tested in several three-dimensional nonlinear interception scenarios. Numerical simulations on a set of Monte-Carlo simulations prove the validity and superiority of the proposed guidance law in hit-to-kill interception.",
           1,
           "complexity"
          ],
          [
           "An Empirical Study on the Agglomeration Characteristics of China’s Construction Industry Based on Spatial Autocorrelation and Spatiotemporal Transition",
           "10.1155/2021/5539047",
           2021,
           "The spatiotemporal agglomeration of industries is the most prominent geographical feature of economic activities. Based on the analysis of the spatiotemporal distribution of China’s construction industry agglomeration, this paper analyzes the characteristics and evolution trend of the spatiotemporal agglomeration of construction industry in 31 provinces and cities of China from 2010 to 2019 by using Moran’s index and the spatiotemporal transition measurement model. The findings are as follows: (1) China’s construction industry has experienced two stages in terms of time: steady rise and turbulent rise. Spatially, China’s construction industry, as a whole, the space takes the shape of one horizontal and two vertical, similar to the letter “H” being crossed. And the difference of “East-West” two ends of the industrial agglomeration level is obvious. (2) The Yangtze River Delta Urban Agglomerations (Shanghai, Jiangsu, and Zhejiang), the Pearl River Delta Urban Agglomerations (Guangdong), Beijing-Tianjin-Hebei Urban Agglomerations, and the western region (Xinjiang and Tibet) have significant local features. The four major types of China’s construction industry cluster, which are H-H, H-L, L-H, and L-L, are formed. (3) The time-space transition of China’s construction industry is dominated by the “stable transition” mode. The transition inertia is significant. The regional development has strong path dependence and spatial locking characteristics.",
           0,
           "complexity"
          ],
          [
           "How Price-Based Frequency Regulation Impacts Stability in Power Grids: A Complex Network Perspective",
           "10.1155/2020/6297134",
           2020,
           "With the deregulation of modern power grids, electricity markets are playing a more and more important role in power grid operation and control. However, it is still questionable how the real-time electricity price-based operation affects power grid stability. From a complex network perspective, here we investigate the dynamical interactions between price-based frequency regulations and physical networks, which results in an interesting finding that a local minimum of network stability occurs when the response strength of generators/consumers to the varying price increases. A case study of the real world-based China Southern Power Grid demonstrates the finding and exhibits a feasible approach to network stability enhancement in smart grids. This also provides guidance for potential upgrade and expansion of the current power grids in a cleaner and safer way.",
           4,
           "complexity"
          ],
          [
           "Two-Parameter Regularization Method for a Nonlinear Backward Heat Problem with a Conformable Derivative",
           "10.1155/2020/4143930",
           2020,
           "In this paper, we consider the nonlinear inverse-time heat problem with a conformable derivative concerning the time variable. This problem is severely ill posed. A new method on the modified integral equation based on two regularization parameters is proposed to regularize this problem. Numerical results are presented to illustrate the efficiency of the proposed method.",
           0,
           "complexity"
          ],
          [
           "Comprehensive Utilization Pattern of the Bohai Rim Coastline Using the Restrictive Composite Index Method",
           "10.1155/2021/3402516",
           2021,
           "Coastlines play an important role in human activity and economic development. Reasonably allocating shoreline resources and addressing contradictions between ecological protection and development are critical issues. In this study, positive and negative factors affecting the natural, environmental, and socioeconomic status of the coastal zone while considering land and sea effects were comprehensively analyzed using ecological theories and methods, and an improved restrictive composite index model was constructed. We quantitatively analyzed the comprehensive utilization pattern of the Bohai Rim coastline, China, in terms of the coastline utilization type and spatial agglomeration characteristics. The comprehensive utilization pattern of the Bohai Rim coastline is as follows: ecological areas are present in the north and south, and industrial areas are present in the east and west. Industrial production areas along the coastline are mainly distributed in the East Liaodong and Bohai bays, and ecological protection areas are located in the estuaries of the Liaohe and Yellow River. The improved restricted comprehensive index method model weakens the interaction among variables and makes the calculation results closer to the real situation. The results of the comprehensive utilization pattern of Bohai Rim coastline obtained by quantitative evaluation are of great significance for the coordinated development of coastline ecological protection and development and utilization.",
           0,
           "complexity"
          ],
          [
           "Application of Taiwan’s Human Rights-Themed Cultural Assets and Spatial Information",
           "10.1155/2020/5205970",
           2020,
           "Cultural assets preserve the traces of people’s life history around the world. With an understanding of the historical context and meaning of cultural assets, people would cherish their value and then adopt appropriate cultural resource preservation strategies. Human rights as the universal value refer to the inalienable and basic rights of human beings. This article uses the National Cultural Assets Network to query Taiwan’s human rights-themed cultural assets, and I apply the spatial information technology of the DocuSky digital humanities academic research platform to draw the maps with GIS and visualization tools. Also, I apply spatial information to the academic research of human rights-themed cultural assets, aiming to deepen local cultural identity and unveiling that human studies influence spatial practice. Tourism is an important experience economy. Based on the value of Taiwan’s human rights-themed cultural assets, I plan to guide the human rights journey in Taipei to share Taiwan’s experience of happiness with the world, as well.",
           0,
           "complexity"
          ],
          [
           "Economic Development Forecast of China’s General Aviation Industry",
           "10.1155/2020/3747031",
           2020,
           "Aiming at solving the problem of system external impact on China’s general aviation industry, combining functional theory and grey system theory, and applying Bayesian network reasoning technology, a grey Bayesian network reasoning prediction model of system impact and system control is established. Based on the dynamic deduction of the functional analysis factor of system impact evolution, the flight time of general aviation production operation is selected to predict the development trend of the system. Based on the current period information of the general aviation industry, the grey Bayesian network inference prediction model is used to predict the current and future trends, so as to predict the economic development trend of the general aviation industry in China. The prediction results are more accurate than those of other existing models.",
           2,
           "complexity"
          ],
          [
           "Agent-Oriented Software Engineering Methodologies: Analysis and Future Directions",
           "10.1155/2021/1629419",
           2021,
           "The Internet of Things (IoT) facilitates in building cyber-physical systems, which are significant for Industry 4.0. Agent-based computing represents effective modeling, programming, and simulation paradigm to develop IoT systems. Agent concepts, techniques, methods, and tools are being used in evolving IoT systems. Over the last years, in particular, there has been an increasing number of agent approaches proposed along with an ever-growing interest in their various implementations. Yet a comprehensive and full-fledged agent approach for developing related projects is still lacking despite the presence of agent-oriented software engineering (AOSE) methodologies. One of the moves towards compensating for this issue is to compile various available methodologies, ones that are comparable to the evolution of the unified modeling language (UML) in the domain of object-oriented analysis and design. These have become de facto standards in software development. In line with this objective, the present research attempts to comprehend the relationship among seven main AOSE methodologies. More specifically, we intend to assess and compare these seven approaches by conducting a feature analysis through examining the advantages and limitations of each competing process, structural analysis, and a case study evaluation method. This effort is made to address the significant characteristics of AOSE approaches. The main objective of this study is to conduct a comprehensive analysis of selected AOSE methodologies and provide a proposal of a draft unified approach that drives strengths (best) of these methodologies towards advancement in this area.",
           3,
           "complexity"
          ],
          [
           "Some Existence Results for a System of Nonlinear Sequential Fractional Differential Equations with Coupled Nonseparated Boundary Conditions",
           "10.1155/2022/8992894",
           2022,
           "This article concerns with the existence and uniqueness theory of solutions for sequential fractional differential system involving Caputo fractional derivatives of order 1<alpha, beta<2 with coupled nonseparated boundary conditions. The standard tools of the fixed point theory were used to establish the main results. Application is introduced to show the validity of our results.",
           3,
           "complexity"
          ],
          [
           "A New Scheme for Solving Multiorder Fractional Differential Equations Based on Müntz–Legendre Wavelets",
           "10.1155/2021/9915551",
           2021,
           "In this study, we apply the pseudospectral method based on Müntz–Legendre wavelets to solve the multiorder fractional differential equations with Caputo fractional derivative. Using the operational matrix for the Caputo derivative operator and applying the Chebyshev and Legendre zeros, the problem is reduced to a system of linear algebraic equations. We illustrate the reliability, efficiency, and accuracy of the method by some numerical examples. We also compare the proposed method with others and show that the proposed method gives better results.",
           3,
           "complexity"
          ],
          [
           "Research on Behavior Model of Rumor Maker Based on System Dynamics",
           "10.1155/2017/5094218",
           2017,
           "Laws of rumor makers’ behaviors are the root of curbing rumor and effective way to block rumor occurrence. Therefore, based on system dynamics model, this paper proposed the rumors behavior evolution model of rumor makers, aimed at discovering the laws of rumor makers’ behaviors to achieve rumors blocking. First, by refining the driving factors in disinformation behavior, we constructed causal diagram of disinformation behavior evolution; secondly, by means of causal diagram, we constructed stock-flow diagram for quantitative analysis; finally, simulation experiment was carried out by using Vensim Personal Learning Edition software (Vensim PLE). The results showed that negative attitude is a major factor in the occurrence of disinformation behavior; personal factors are more pronounced than the factors of social and government on the impact of disinformation propensity score.",
           9,
           "complexity"
          ],
          [
           "Follow Me Going Out: Cross-Border Investment of Domestic Venture Capital and Overseas Listing of Portfolio Companies",
           "10.1155/2023/4496136",
           2023,
           "This paper investigates the impact of cross-border investment of domestic venture firms (VCs) on the overseas listings of their domestic portfolio companies. Using a sample of 1,439 domestic VCs’ first-round domestic investment events collected by Crunchbase and PEDATA, we find that the more cross-border investment experience domestic VCs have, the more likely their domestic portfolio companies are to go public outside China. The findings remain robust after using the instrumental variable method to eliminate endogeneity, the Heckman two-stage regression method to eliminate sample selection bias, and the exclusion of a portion of the sample for reregression. In addition, we further find that foreign VCs participating in follow-on financing play a mediating role in the relationship between the cross-border investments of domestic VCs and the overseas listings of their portfolio companies. This paper reveals the critical path for domestic VCs to go out and bring in foreign VCs to promote overseas listings of domestic firms. The findings of this paper are critical to the layout of domestic VCs’ internationalization strategy and the sustainable development of domestic firms.",
           0,
           "complexity"
          ],
          [
           "An Evaluation Study on Investment Efficiency: A Predictive Machine Learning Approach",
           "10.1155/2021/6658516",
           2021,
           "This paper proposes a nonlinear autoregressive neural network (NARNET) method for the investment performance evaluation of state-owned enterprises (SOE). It is different from the traditional method based on machine learning, such as linear regression, structural equation, clustering, and principal component analysis; this paper uses a regression prediction method to analyze investment efficiency. In this paper, we firstly analyze the relationship between diversified ownership reform, corporate debt leverage, and the investment efficiency of state-owned enterprises (SOE). Secondly, a set of investment efficiency evaluation index system for SOE was constructed, and a nonlinear autoregressive neural network approach was used for verification. The data of A-share state-owned listed companies in Shanghai and Shenzhen stock exchanges from 2009 to 2018 are taken as a sample. The experimental results show that the output value from the NARNET is highly fitted to the actual data. Based on the neural network model regression analysis, this paper conducts a descriptive statistical analysis of the main variables and control variables of the evaluation indicators. It verifies the direct impact of diversified ownership reform on the investment efficiency of SOE and the indirect impact on the investment efficiency of SOE through corporate debt leverage.",
           0,
           "complexity"
          ],
          [
           "Performance Evaluation of an Ironmaking System with Environmental Costs",
           "10.1155/2020/2793580",
           2020,
           "This paper proposes an exergoeconomic analysis method that considers environmental costs to make up for the lack of description of environmental costs in the traditional matrix model exergoeconomic analysis method. This method tracks the formation process of the product cost through life cycle and makes a useful exploration for revealing the true cost of the system product. According to actual needs, the principles for the construction of environmental emissions of products are proposed, and a detailed exergoeconomic analysis model is established by taking the iron smelting system as an example. Through calculation and analysis, the formation process and change rule of unit exergoeconomic cost of products in the system are revealed. Especially, considering the exergoeconomic cost of carbon emissions, the results show that the three most influential substances are sinter, coke, and pellets. When carbon dioxide emissions are considered, the total cost will increase by 165.3 CNY/t iron, and unit exergoeconomic cost gradually increases with the progress of the production process.",
           0,
           "complexity"
          ],
          [
           "Leader-Following Bounded Consensus and Multiconsensus of Multiagent Systems",
           "10.1155/2020/8814455",
           2020,
           "This paper investigates the problem of leader-following consensus and multiconsensus of multiagent systems. A leader-following and bounded consensus protocol via impulsive control for multiagent systems is proposed by using sampled position and velocity data. Consensus and multiconsensus commutative evolution stimulated by varying intelligence degrees of each agent can be achieved to avoid obstacles. Especially, the multiconsensus leader-following can be obtained without grouping the multiagent networks in advance. The necessary and sufficient condition is given to the leader-following bounded consensus tracking of the system by using the Hurwitz criterion and properties of the Laplacian matrix. A simulation is provided to verify the availability of the proposed impulsive control protocol. Furthermore, the result can be applied in obstacle avoidance and round up of target by regulating the intelligence degrees.",
           0,
           "complexity"
          ],
          [
           "Data-Driven Approximated Optimal Control of Sulfur Flotation Process",
           "10.1155/2019/4754508",
           2019,
           "Sulfur flotation process is a typical industry process with complex dynamics. For a sulfur flotation cell, the structure of the system model could be derived using first-principles and reaction kinetics. However, the model parameters cannot be obtained under certain working conditions. In this paper, by using adaptive dynamic programming (ADP), we establish a data-driven optimal control approach for the operation of a sulfur flotation cell without knowing the model parameters. By learning from the online production data, an initial admissible control policy iteratively converges to an approximated optimal control law, and the dependence of optimal control design on the full model knowledge is eliminated. A simulation environment of sulfur flotation process is constructed based on phenomenological model and industrial data. Some practical problems in the implementation of ADP, i.e., selection of basis functions, how to use the model structural information in the ADP-based control design, are investigated. The feasibility and performance of the proposed data-driven optimal control are tested in the simulation environment. The results indicate the potential of applying bioinspired control methods in flotation process.",
           0,
           "complexity"
          ],
          [
           "A Flexible Polynomial Expansion Method for Response Analysis with Random Parameters",
           "10.1155/2018/7471460",
           2018,
           "The generalized Polynomial Chaos Expansion Method (gPCEM), which is a random uncertainty analysis method by employing the orthogonal polynomial bases from the Askey scheme to represent the random space, has been widely used in engineering applications due to its good performance in both computational efficiency and accuracy. But in gPCEM, a nonlinear transformation of random variables should always be used to adapt the generalized Polynomial Chaos theory for the analysis of random problems with complicated probability distributions, which may introduce nonlinearity in the procedure of random uncertainty propagation as well as leading to approximation errors on the probability distribution function (PDF) of random variables. This paper aims to develop a flexible polynomial expansion method for response analysis of the finite element system with bounded random variables following arbitrary probability distributions. Based on the large family of Jacobi polynomials, an Improved Jacobi Chaos Expansion Method (IJCEM) is proposed. In IJCEM, the response of random system is approximated by the Jacobi expansion with the Jacobi polynomial basis whose weight function is the closest to the probability density distribution (PDF) of the random variable. Subsequently, the moments of the response can be efficiently calculated though the Jacobi expansion. As the IJCEM avoids the necessity that the PDF should be represented in terms of the weight function of polynomial basis by using the variant transformation, neither the nonlinearity nor the errors on random models will be introduced in IJCEM. Numerical examples on two random problems show that compared with gPCEM, the IJCEM can achieve better efficiency and accuracy for random problems with complex probability distributions.",
           0,
           "complexity"
          ],
          [
           "Output Feedback Recursive Dynamic Surface Control with Antiwindup Compensation",
           "10.1155/2021/8870659",
           2021,
           "Actuator saturation phenomenon often exists in the actual control system, which could destroy the closed-loop performance of the system and even lead to unstable behavior. Our main contribution is to provide an antiwindup recursive dynamic surface control (RDSC) for a discrete-time system with an unknown state and actuator saturation. The fuzzy compensator is added to perform as an active disturbance rejection term in the feedforward path to avoid windup caused by input saturation. To construct output feedback control, the system is transformed into the form of pure-feedback and an improved HOSM observer is designed to carry out future output prediction. Based on which RDSC is synthesized, only one fuzzy logic system (FLS) is used and the controller singularity is completely avoided. In addition, the simulation and numeral examples using a continuous stirred tank reactors (CSTRs) system with actuator saturation are provided and the results show that the strategy owns good robustness and effectively compensates for the disturbance caused by actuator saturation in the presence of a discrete-time system with an unmeasurable state.",
           1,
           "complexity"
          ],
          [
           "Semi-Supervised Cross-Modal Retrieval Based on Discriminative Comapping",
           "10.1155/2020/1462429",
           2020,
           "Most cross-modal retrieval methods based on subspace learning just focus on learning the projection matrices that map different modalities to a common subspace and pay less attention to the retrieval task specificity and class information. To address the two limitations and make full use of unlabelled data, we propose a novel semi-supervised method for cross-modal retrieval named modal-related retrieval based on discriminative comapping (MRRDC). The projection matrices are obtained to map multimodal data into a common subspace for different tasks. In the process of projection matrix learning, a linear discriminant constraint is introduced to preserve the original class information in different modal spaces. An iterative optimization algorithm based on label propagation is presented to solve the proposed joint learning formulations. The experimental results on several datasets demonstrate the superiority of our method compared with state-of-the-art subspace methods.",
           1,
           "complexity"
          ],
          [
           "Prediction and Classification of Financial Criteria of Management Control System in Manufactories Using Deep Interaction Neural Network (DINN) and Machine Learning",
           "10.1155/2022/2295105",
           2022,
           "The management control system aids administrators in guiding a business toward its organizational plans; as a result, management control is primarily concerned with the execution of the plan and plans. Financial and nonfinancial criteria are used to create management control systems. The financial element focuses on net income, earnings, and other financial metrics. The two components of leadership strategy in this study are cost and differentiation, which highlight the strategy of differentiation in attaining higher quality due to the robust strategy’s attention on a particular area of the company. In this study, we presented a novel method named deep interaction neural network to predict the performance of the manufacturing companies based on their leading competitors using features cost leadership and differentiation strategies. Moreover, the management control system is classified into two financial and nonfinancial factors based on machine learning methods. Based on the results, the presented factors can accurately estimate the company’s performance based on management control criteria with a 93.48% R-square. Moreover, it can be seen that the DT method is presented with higher classification performance values.",
           0,
           "complexity"
          ],
          [
           "Some Chemistry Indices of Clique-Inserted Graph of a Strongly Regular Graph",
           "10.1155/2021/7671212",
           2021,
           "In this paper, we give the relation between the spectrum of strongly regular graph and its clique-inserted graph. The Laplacian spectrum and the signless Laplacian spectrum of clique-inserted graph of strongly regular graph are calculated. We also give formulae expressing the energy, Kirchoff index, and the number of spanning trees of clique-inserted graph of a strongly regular graph. And, clique-inserted graph of the triangular graph \n\nT\n\n\nt\n\n\n\n, which is a strongly regular graph, is enumerated.",
           0,
           "complexity"
          ],
          [
           "Beamforming Design and Covert Performance Analysis for Full-Duplex Multiantenna System",
           "10.1155/2021/8806874",
           2021,
           "In this work, a wireless covert communication system with full-duplex (FD) multiantenna receiver is considered. In order to improve the convert performance of the wireless communication system in the FD mode, a scheme based on selection combining/zero forcing beamforming (SC/ZFB) is proposed. More specifically, a covert message receiver with a FD multiantenna uses the zero forcing beamforming method to transmit randomly varying noise power to the adversary while receiving covert information from the sender. Firstly, we derive the optimal detection threshold and the corresponding closed expression of the minimum detection error rate of the warden. Secondly, the transmission interruption probability is explored to measure the communication reliability between the sender and the receiver of the covert message. Finally, the throughput performance of the covert communication system is analyzed under random geometry. Our analysis shows that the proposed SC/ZFB scheme can achieve the positive effective convert rate while interfering with the detection of the warden as much as possible. It is worth noting that the increase of the number of antennas and the power of covert message transmission can improve the convert performance of the system.",
           0,
           "complexity"
          ],
          [
           "A New Lifetime Distribution: Properties, Copulas, Applications, and Different Classical Estimation Methods",
           "10.1155/2021/6657172",
           2021,
           "A new continuous version of the inverse flexible Weibull model is proposed and studied. Some of its properties such as quantile function, moments and generating functions, incomplete moments, mean deviation, Lorenz and Bonferroni curves, the mean residual life function, the mean inactivity time, and the strong mean inactivity time are derived. The failure rate of the new model can be “increasing-constant,” “bathtub-constant,” “bathtub,” “constant,” “J-HRF,” “upside down bathtub,” “increasing,” “upside down-increasing-constant,” and “upside down.” Different copulas are used for deriving many bivariate and multivariate type extensions. Different non-Bayesian well-known estimation methods under uncensored scheme are considered and discussed such as the maximum likelihood estimation, Anderson Darling estimation, ordinary least square estimation, Cramér-von-Mises estimation, weighted least square estimation, and right tail Anderson Darling estimation methods. Simulation studies are performed for comparing these estimation methods. Finally, two real datasets are analyzed to illustrate the importance of the new model.",
           1,
           "complexity"
          ],
          [
           "Flocking Behavior of Cucker–Smale Model with Processing Delay",
           "10.1155/2020/2724806",
           2020,
           "The dynamics of a delay multiparticle swarm, which contains symmetric and asymmetric pairwise influence functions, are analyzed. Two different sufficient conditions to achieve conditional flocking are obtained. One does not have a clear relationship with this delay, and the other proposes a range of processing delays that affect the emergence of a flock. It is also pointed out that if the interparticle communication function has tail dissipation, unconditional flocking can be guaranteed. Compared with the previous results, the range of the communication rate β that allows a flock to emerge has been expanded from 1/4 to 1/2.",
           0,
           "complexity"
          ],
          [
           "Control Scheme for a Fractional-Order Chaotic Genesio-Tesi Model",
           "10.1155/2019/4678394",
           2019,
           "In this paper, based on the earlier research, a new fractional-order chaotic Genesio-Tesi model is established. The chaotic phenomenon of the fractional-order chaotic Genesio-Tesi model is controlled by designing two suitable time-delayed feedback controllers. With the aid of Laplace transform, we obtain the characteristic equation of the controlled chaotic Genesio-Tesi model. Then by regarding the time delay as the bifurcation parameter and analyzing the characteristic equation, some new sufficient criteria to guarantee the stability and the existence of Hopf bifurcation for the controlled fractional-order chaotic Genesio-Tesi model are derived. The research shows that when time delay remains in some interval, the equilibrium point of the controlled chaotic Genesio-Tesi model is stable and a Hopf bifurcation will happen when the time delay crosses a critical value. The effect of the time delay on the stability and the existence of Hopf bifurcation for the controlled fractional-order chaotic Genesio-Tesi model is shown. At last, computer simulations check the rationalization of the obtained theoretical prediction. The derived key results in this paper play an important role in controlling the chaotic behavior of many other differential chaotic systems.",
           3,
           "complexity"
          ],
          [
           "An Accurate Approximate-Analytical Technique for Solving Time-Fractional Partial Differential Equations",
           "10.1155/2017/8718209",
           2017,
           "The demand of many scientific areas for the usage of fractional partial differential equations (FPDEs) to explain their real-world systems has been broadly identified. The solutions may portray dynamical behaviors of various particles such as chemicals and cells. The desire of obtaining approximate solutions to treat these equations aims to overcome the mathematical complexity of modeling the relevant phenomena in nature. This research proposes a promising approximate-analytical scheme that is an accurate technique for solving a variety of noninteger partial differential equations (PDEs). The proposed strategy is based on approximating the derivative of fractional-order and reducing the problem to the corresponding partial differential equation (PDE). Afterwards, the approximating PDE is solved by using a separation-variables technique. The method can be simply applied to nonhomogeneous problems and is proficient to diminish the span of computational cost as well as achieving an approximate-analytical solution that is in excellent concurrence with the exact solution of the original problem. In addition and to demonstrate the efficiency of the method, it compares with two finite difference methods including a nonstandard finite difference (NSFD) method and standard finite difference (SFD) technique, which are popular in the literature for solving engineering problems.",
           10,
           "complexity"
          ],
          [
           "RAEF: An Imputation Framework Based on a Gated Regulator Autoencoder for Incomplete IIoT Time-Series Data",
           "10.1155/2021/3320402",
           2021,
           "The number of intelligent applications available for IIoT environments is growing, but when the time-series data these applications rely on are incomplete, their performance suffers. Unfortunately, incomplete data are all too frequent to a phenomenon in the world of IIoT. A common workaround is to use imputation. However, the current methods are largely designed to reconstruct a single missing pattern, where a robust and flexible imputation framework would be able to handle many different missing patterns. Hence, the framework presented in this study, RAEF, is capable of processing multiple missing patterns. Based on a recurrent autoencoder, RAEF houses a novel neuron structure, called a gated regulator, which reduces the negative impact of different missing patterns. In a comparison of the state-of-the-art time-series imputation frameworks at a range of different missing rates, RAEF yielded fewer errors than all its counterparts.",
           1,
           "complexity"
          ],
          [
           "Bayesian Estimations under the Weighted LINEX Loss Function Based on Upper Record Values",
           "10.1155/2021/9982916",
           2021,
           "The essential objective of this research is to develop a linear exponential (LINEX) loss function to estimate the parameters and reliability function of the Weibull distribution (WD) based on upper record values when both shape and scale parameters are unknown. We perform this by merging a weight into LINEX to produce a new loss function called the weighted linear exponential (WLINEX) loss function. Then, we utilized WLINEX to derive the parameters and reliability function of the WD. Next, we compared the performance of the proposed method (WLINEX) in this work with Bayesian estimation using the LINEX loss function, Bayesian estimation using the squared-error (SEL) loss function, and maximum likelihood estimation (MLE). The evaluation depended on the difference between the estimated parameters and the parameters of completed data. The results revealed that the proposed method is the best for estimating parameters and has good performance for estimating reliability.",
           6,
           "complexity"
          ],
          [
           "Development and Evaluation of a Rehabilitation Wheelchair with Multiposture Transformation and Smart Control",
           "10.1155/2021/6628802",
           2021,
           "Stroke and other neurological disorders have an effect on mobility which has a significant impact on independence and quality of life. The core rehabilitation requirements for patients with lower limb motor dysfunction are gait training, restand, and mobility. In this work, we introduce a newly developed multifunctional wheelchair that we call “ReChair” and evaluated its performance preliminarily. ReChair seamlessly integrates the mobility, gait training, and multiposture transformation. ReChair driving and multiposture transformation are done using the voice, button, and mobile terminal control. This work describes the functional requirements, mechanical structure, and control system and the overall evaluation of ReChair including the kinematic simulation of the multiposture transformation and passive lower limb rehabilitation training to quantitatively verify the motion capability of ReChair, the voice control system evaluation that shows how the voice recognition system is suitable for home environment, the sensorless speed detection test results that indicate how the wheel speeds measured by sensorless method are appropriate for travelling control, and the passive and balance training test results that show how the lower limb rehabilitation training in daily life by ReChair is convenient. Finally, the experimental results show that ReChair meets the patients’ requirements and has practical significance. It is cost-effective, easy to use, and supports multiple control modes to adapt to different rehabilitation phases.",
           3,
           "complexity"
          ],
          [
           "Bubbles in Agricultural Commodity Markets of China",
           "10.1155/2019/2896479",
           2019,
           "We employ the generalized supremum augmented Dickey–Fuller test to examine whether there are multiple bubbles in Chinese agricultural commodities. The proposed approach is suitable for time series data and identifies the origination and termination of multiple bubbles. The results indicate the existence of bubbles for some agricultural commodity prices, such as garlic, ginger, corn, and wheat prices, that deviate from their intrinsic values upon market fundamentals. The bubbles in the garlic and ginger market are related to speculative activities. The other bubbles, in the corn and wheat market, are associated with the rising oil price, international market, and the negative effect of stockpiling policy. The authorities should recognize bubbles and observe their evolutions, leading to Chinese agricultural commodity price stabilization. These findings suggest corresponding measures to be implemented. China should establish a unified market information release platform to avoid speculative activities and formulate a market-oriented agricultural policy to enhance competitiveness among the international markets.",
           6,
           "complexity"
          ],
          [
           "Entrepreneurs’ Social Network and Corporate Risk Contagion: A Dynamic Evaluation and Simulation Approach",
           "10.1155/2020/6679502",
           2020,
           "Interactions of entrepreneurs through social networks provide an available path for corporate risk contagions. However, the issue how entrepreneurs’ social networks influence on corporate risk contagion is still received limited attention from scholars. In this study, a framework is proposed to describe entrepreneurs’ interaction and corporate value creation. The main results of multiagent simulations indicate the following. First, either weak ties or strong connections of social networks can enhance density of corporate risk contagion. However, only strong connections can be moderated by entrepreneurs’ risk preference. Second, weak ties improve risk exposure of individual corporations, while strong connections may probably decrease systematical risk of the market. Third, weak ties are important for mature corporations to achieve business success. However, for startups, strong connections are more valuable to maintain. The findings of this study not only provide theoretical support from some widely accepted economic phenomenon but also provide explanations for conflicting results from some previous literatures.",
           0,
           "complexity"
          ],
          [
           "The “Invisible Hand” of Economic Markets Can Be Visualized through the Synergy Created by Division of Labor",
           "10.1155/2017/4753863",
           2017,
           "Inspired by Adam Smith and Friedrich Hayek, economists promoting free markets postulate the existence of invisible forces that drive economic growth. Simulations with Sociodynamica allowed the emergence of market forces in virtual economies, showing that the synergistic working of division of labor in complex settings favors a stable state where all actors benefit (win-win interaction). By visualizing the detailed dynamics underlying this phenomenon in a simple virtual economy, the elements underpinning the synergistic effect on economic output produced by the division of labor between agents could be dissected. These are heterogeneity or spatial or temporal heterogeneous environment and/or agents; complementary activities of agents, with divergent optimization options; and synchrony. Markets help synchronize agent’s actions. The larger the contact horizon between participants of the market is, the more efficient the market forces act. These features allow for social processes that increase the information available and increase simultaneously the capacity of producing useful economic work, that is, synergy. This insight, although trivial if viewed a posteriori, improves our understanding of the source and nature of synergies in real economic markets and might render economic and natural sciences more consilient.",
           2,
           "complexity"
          ],
          [
           "Passenger Behavior Simulation in Congested Urban Rail Transit System: A Capacity-Limited Optimal Strategy Model for Passenger Assignment",
           "10.1155/2022/5975866",
           2022,
           "Optimal strategy, one of the main transit assignment models, can better demonstrate the flexibility for passengers using routes in a transit network. According to the basic optimal strategy model, passengers can board trains based on their frequency without any capacity limitation. In the metropolitan cities such as Beijing, Shanghai, and Hong Kong, morning commuters face huge transit problems. Especially for the metro system, there is heavy rush in metro stations. Owing to the limited train capacity, some passengers cannot board the first coming train and need to wait for the next one. To better demonstrate the behavior of passengers pertaining to the limited train capacity, we consider capacity constraints for the basic optimal strategy model to represent the real situation. We have proposed a simulation-based algorithm to solve the model and apply it to the Beijing Subway to demonstrate the feasibility of the model. The application of the proposed approach has been demonstrated using the computational results for transit networks originating from practice.",
           0,
           "complexity"
          ],
          [
           "Rigorous Solution of Slopes’ Stability considering Hydrostatic Pressure",
           "10.1155/2018/2829873",
           2018,
           "According to characteristics of soils in failure, a sliding mechanism of slopes in limit state is divided into five parts, for building a slip line field satisfying all possible boundary conditions. An algorithm is built to obtain the rigorous solution approaching upper and lower bound values simultaneously, which satisfies the static boundary and the kinematical boundary based on the slip line field, while stress discontinuity line and velocity discontinuity line are key points. This algorithm is copared with the Spencer method to prove its feasibility with a special example. The variation of rigorous solution, including an ultimate load and a sliding belt the rigid body sliding along rather than a single slip surface for friction-type soils, is achieved considering hydrostatic pressure with soil parameters changing.",
           0,
           "complexity"
          ],
          [
           "Automatic Integrated Scoring Model for English Composition Oriented to Part-Of-Speech Tagging",
           "10.1155/2021/5544257",
           2021,
           "Part-of-speech tagging for English composition is the basis for automatic correction of English composition. The performance of the part-of-speech tagging system directly affects the performance of the marking and analysis of the correction system. Therefore, this paper proposes an automatic scoring model for English composition based on article part-of-speech tagging. First, use the convolutional neural network to extract the word information from the character level and use this part of the information in the coarse-grained learning layer. Secondly, the word-level vector is introduced, and the residual network is used to establish an information path to integrate the coarse-grained annotation and word vector information. Then, the model relies on the recurrent neural network to extract the overall information of the sequence data to obtain accurate annotation results. Then, the features of the text content are extracted, and the automatic scoring model of English composition is constructed by means of model fusion. Finally, this paper uses the English composition scoring competition data set on the international data mining competition platform Kaggle to verify the effect of the model.",
           0,
           "complexity"
          ],
          [
           "Continuous-Time Insider Trading with Risk-Neutral Insider under Imperfect Observation",
           "10.1155/2021/3549962",
           2021,
           "A model of insider trading in continuous time in which a risk-neutral insider possesses long-lived imperfect information on a risk asset is studied. By conditional expectation theory and filtering theory, we turn it into a model with insider knowing complete information about the asset with a revised risky value and deduce its linear Bayesian equilibrium consisting of optimal insider trading strategy and semistrong pricing rule. It shows that, in the equilibrium, as the degree of insider observing the signal of the risky asset value is more and more accurate, market depth, trading intensity, and residual information are all decreasing and the total expectation profit of the insider is increasing and that the information about the asset value incorporated into the equilibrium price, which has nothing to do with the volatility of noise trades, is increasing as time goes by, but not all information of asset value is incorporated into the price in the final disclosed time due to the incompleteness of insider’s observation, though the market depth is still a time-independent constant. Some simulations are illustrated to show these features. However, it is an open question of how to make maximal profit if the insider is risk-averse.",
           0,
           "complexity"
          ],
          [
           "A Novel Angular-Guided Particle Swarm Optimizer for Many-Objective Optimization Problems",
           "10.1155/2020/6238206",
           2020,
           "Most multiobjective particle swarm optimizers (MOPSOs) often face the challenges of keeping diversity and achieving convergence on tackling many-objective optimization problems (MaOPs), as they usually use the nondominated sorting method or decomposition-based method to select the local or best particles, which is not so effective in high-dimensional objective space. To better solve MaOPs, this paper presents a novel angular-guided particle swarm optimizer (called AGPSO). A novel velocity update strategy is designed in AGPSO, which aims to enhance the search intensity around the particles selected based on their angular distances. Using an external archive, the local best particles are selected from the surrounding particles with the best convergence, while the global best particles are chosen from the top 20% particles with the better convergence among the entire particle swarm. Moreover, an angular-guided archive update strategy is proposed in AGPSO, which maintains a consistent population with balanceable convergence and diversity. To evaluate the performance of AGPSO, the WFG and MaF test suites with 5 to 10 objectives are adopted. The experimental results indicate that AGPSO shows the superior performance over four current MOPSOs (SMPSO, dMOPSO, NMPSO, and MaPSO) and four competitive evolutionary algorithms (VaEA, θ-DEA, MOEA\\D-DD, and SPEA2-SDE), when solving most of the test problems used.",
           3,
           "complexity"
          ],
          [
           "Atmospheric Dynamics Leading to West European Summer Hot Temperatures Since 1851",
           "10.1155/2018/2494509",
           2018,
           "Summer hot temperatures have many impacts on health, economy (agriculture, energy, and transports), and ecosystems. In Western Europe, the recent summers of 2003 and 2015 were exceptionally warm. Many studies have shown that the genesis of the major heat events of the last decades was linked to anticyclonic atmospheric circulation and to spring precipitation deficit in Southern Europe. Such results were obtained for the second part of the 20th century and projections into the 21st century. In this paper, we challenge this vision by investigating the earlier part of the 20th century from an ensemble of 20CR reanalyses. We propose an innovative description of Western-European heat events applying the dynamical system theory. We argue that the atmospheric circulation patterns leading to the most intense heat events have changed during the last century. We also show that the increasing temperature trend during major heatwaves is encountered during episodes of Scandinavian Blocking, while other circulation patterns do not yield temperature trends during extremes.",
           25,
           "complexity"
          ],
          [
           "Ripple-Spreading Network of China’s Systemic Financial Risk Contagion: New Evidence from the Regime-Switching Model",
           "10.1155/2024/5316162",
           2024,
           "A better understanding of financial contagion and systemically important financial institutions (SIFIs) is essential for the prevention and control of systemic financial risk. Considering the ripple effect of financial contagion, we integrate the relevant spatiotemporal information that affects financial contagion and propose to use the ripple-spreading network to simulate the dynamic process of risk contagion in China’s financial system. In addition, we introduce the smooth-transition vector autoregression (STVAR) model to identify “high” and “low” systemic risk regimes and set the relevant parameters of the ripple-spreading network on this basis. The results show that risk ripples spread much faster in high than in low systemic risk regimes. However, systemic shocks can also trigger large-scale risk contagion in the financial system even in a low systemic risk regime as the risk ripple continues. In addition, whether the financial system is in a high or low systemic risk regime, the risk ripples from a contagion source (i.e., a real estate company) spread first to the real estate sector and the banking sector. The network centrality results of the heterogeneous ripple-spreading network indicate that most securities and banks and some real estate companies have the highest systemic importance, followed by the insurance, and finally the diversified financial institutions. Our study provides a new perspective on the regulatory practice of systemic financial risk and reminds regulators to focus not only on large institutions but also on institutions with strong ripple capacity.",
           0,
           "complexity"
          ],
          [
           "Structural Analysis of Factual, Conceptual, Procedural, and Metacognitive Knowledge in a Multidimensional Knowledge Network",
           "10.1155/2020/9407162",
           2020,
           "Discovering the most suitable network structure of the learning domain represents one of the main challenges of knowledge delivery and acquisition. We propose a multidimensional knowledge network (MKN) consisting of three components: multilayer network and its two projections. Each network layer constitutes factual, conceptual, procedural, or metacognitive knowledge within the domain of databases as a standard course of computer science study. In the MKN layer, nodes are concepts or knowledge units and the edges are weighted with regard to Bloom's cognitive learning level. The projected network layers are contrasted with a monolayer network by comparing characterizations of the centrality measures: degree centrality, closeness centrality, betweenness centrality, and eccentricity. The study revealed indications of how concepts, supported with the higher number of previously introduced concepts, have a dominant role in knowledge acquisition, from a view of knowledge structure and content. The analysis of communities, assortativity coefficient, and overlap between MKN layers contributes to better structuring of knowledge. MKN enables systematic insights into the efficiency of knowledge integration across metacognitive layers, as well as the detection of crucial cognitive concepts that reduce/increase the cognitive load during learning.",
           11,
           "complexity"
          ],
          [
           "Hybridized Deep Learning Model for Perfobond Rib Shear Strength Connector Prediction",
           "10.1155/2021/6611885",
           2021,
           "Accurate and reliable prediction of Perfobond Rib Shear Strength Connector (PRSC) is considered as a major issue in the structural engineering sector. Besides, selecting the most significant variables that have a major influence on PRSC in every important step for attaining economic and more accurate predictive models, this study investigates the capacity of deep learning neural network (DLNN) for shear strength prediction of PRSC. The proposed DLNN model is validated against support vector regression (SVR), artificial neural network (ANN), and M5 tree model. In the second scenario, a comparable AI model hybridized with genetic algorithm (GA) as a robust bioinspired optimization approach for optimizing the related predictors for the PRSC is proposed. Hybridizing AI models with GA as a selector tool is an attempt to acquire the best accuracy of predictions with the fewest possible related parameters. In accordance with quantitative analysis, it can be observed that the GA-DLNN models required only 7 input parameters and yielded the best prediction accuracy with highest correlation coefficient (R = 0.96) and lowest value root mean square error (RMSE = 0.03936 KN). However, the other comparable models such as GA-M5Tree, GA-ANN, and GA-SVR required 10 input parameters to obtain a relatively acceptable level of accuracy. Employing GA as a feature parameter selection technique improves the precision of almost all hybrid models by optimally removing redundant variables which decrease the efficiency of the model.",
           11,
           "complexity"
          ],
          [
           "Dynamic Safety Assessment in Nonlinear Hydropower Generation Systems",
           "10.1155/2018/5369253",
           2018,
           "This paper focuses on the stability problems in a hydropower station. To enable this study, we consider a nonlinear hydropower generation system for the load rejection transient process based on an existing hydropower station. Herein we identify four critical variables of the generation system. Then, we carry out the dynamic safety assessment based on the Fisher discriminant method. The dynamic safety level of the system is determined, and the evolution behavior in the transient process is also performed. The result demonstrates that the hydropower generation system in this study case can operate safely, which is in a good agreement with the corresponding theory and actual engineering. Thus, the framework of dynamic safety assessment aiming at transient processes will not only provide the guidance for safe operation, but also supply the design standard for hydropower stations.",
           1,
           "complexity"
          ],
          [
           "Stationary Distribution and Extinction of a Stochastic Microbial Flocculation Model with Regime Switching",
           "10.1155/2021/4920018",
           2021,
           "In this paper, a stochastic microbial flocculation model with regime switching is developed and analyzed. By proposing a suitable stochastic Lyapunov function, the existence and ergodicity of a stationary distribution for the system are proved. Then, the extinction of microorganisms is discussed under appropriate conditions and sufficient conditions for extinction are obtained. Finally, the results of the theoretical analysis are illustrated by numerical simulation.",
           0,
           "complexity"
          ],
          [
           "Dynamic Characteristic Analysis and Clutch Engagement Test of HMCVT in the High-Power Tractor",
           "10.1155/2021/8891127",
           2021,
           "Hydromechanical continuously variable transmission (HMCVT) is capable of bearing large torque and has wide transmission range, which is suitable for high-power tractors. Dynamic characteristics could influence the tractor life, especially in a high-power tractor. Wet clutch is the crucial component in the HMCVT, which could smooth and soft power transmission. Therefore, it is important to study the dynamic characteristics and implement the wet clutch test of HMCVT. In this paper, AMESim is used to establish virtual models of gearbox, pump-controlled hydraulic motor system, and shifting hydraulic system. Then, a simulation study of tractor operation under working condition is carried out. The internal and external meshing forces of the planetary row are analyzed. Finally, the wet clutch engagement process of HMCVT  in the high-power tractor is tested to verify the oil pressure. The simulation results show that the values of internal and external meshing force become larger as the throttle opening increases. At the moment of shifting change, the meshing forces of the planetary gear have great impact. The clutch test shows that the trend of the oil filling curve obtained from the bench test is similar to that obtained from the theoretical curve, which verifies the simulation results.",
           1,
           "complexity"
          ],
          [
           "Time-Varying Impedance Control of Port Hamiltonian System with a New Energy-Storing Tank",
           "10.1155/2018/8134230",
           2018,
           "In order to guarantee the passivity of a kind of conservative system, the port Hamiltonian framework combined with a new energy tank is proposed in this paper. A time-varying impedance controller is designed based on this new framework. The time-varying impedance control method is an extension of conventional impedance control and overcomes the singularity problem that existed in the traditional form of energy tank. The validity of the controller designed in this paper is shown by numerical examples. The simulation results show that the proposed controller can not only eliminate the singularity problem but can also improve the control performance.",
           4,
           "complexity"
          ],
          [
           "Multityped Community Discovery in Time-Evolving Heterogeneous Information Networks Based on Tensor Decomposition",
           "10.1155/2018/9653404",
           2018,
           "The heterogeneous information networks are omnipresent in real-world applications, which consist of multiple types of objects with various rich semantic meaningful links among them. Community discovery is an effective method to extract the hidden structures in networks. Usually, heterogeneous information networks are time-evolving, whose objects and links are dynamic and varying gradually. In such time-evolving heterogeneous information networks, community discovery is a challenging topic and quite more difficult than that in traditional static homogeneous information networks. In contrast to communities in traditional approaches, which only contain one type of objects and links, communities in heterogeneous information networks contain multiple types of dynamic objects and links. Recently, some studies focus on dynamic heterogeneous information networks and achieve some satisfactory results. However, they assume that heterogeneous information networks usually follow some simple schemas, such as bityped network and star network schema. In this paper, we propose a multityped community discovery method for time-evolving heterogeneous information networks with general network schemas. A tensor decomposition framework, which integrates tensor CP factorization with a temporal evolution regularization term, is designed to model the multityped communities and address their evolution. Experimental results on both synthetic and real-world datasets demonstrate the efficiency of our framework.",
           3,
           "complexity"
          ],
          [
           "Adaptive Event-Triggered Finite-Time Tracking of Output-Constrained High-Order Nonlinear Systems with Time-Varying Powers",
           "10.1155/2022/7466780",
           2022,
           "This paper studies the adaptive event-triggered finite-time tracking of output-constrained high-order nonlinear systems with time-varying powers. Due to the presence of multiple unknown powers and the consideration of event-triggered control, all the existing control methods of output-constrained nonlinear systems are inapplicable. By introducing nonlinear mappings, finite-time performance functions, and low-power and high-power terms into adding a power integrator technique and the relative threshold strategy, an adaptive state-feedback controller is designed to eliminate the effects caused by the output constraint and time-varying powers. It is proved that all the closed-loop signals are bounded, the asymmetric time-varying output constraint is not violated, and the tracking error converges to a prescribed arbitrarily small region around zero in a preassigned finite time. Furthermore, the Zeno phenomenon can be avoided. Two simulation examples demonstrate the effectiveness of this control scheme.",
           0,
           "complexity"
          ],
          [
           "Vulnerability Evaluation and Improvement Method of Civil Aviation Navigation Network",
           "10.1155/2022/4032957",
           2022,
           "Due to events such as natural disasters and navigation equipment failures, enormous calamity may be caused by the interruption of the navigation network which is a guarantee for the flight safety of civil aviation aircraft. The navigation network consists of the navigation stations as nodes and the routes between them as edges. Different nodes have different effects on the vulnerability of the network due to their different abilities to maintain the stability of the network topology and the normal function of the network. To quantify this difference and identify key nodes that have a greater impact on the vulnerability of the navigation network, an indicator to assess the importance of a navigation station is proposed which combines the structural importance reflected by node topology centrality and functional importance reflected by node weight. The structural importance of a node corresponds to its topology features including local dominance of the node and its global influence, and the important contribution to both adjacent and nonadjacent nodes from this node, while the functional importance is indicated by the flight flow serviced by the node during a fixed period of time. Vulnerability evaluation shows that the navigation network is more vulnerable when subject to the intentional attack of nodes with higher comprehensive node importance than an intentional attack of nodes with a larger value of indicators used in previous literature. Finally, the vulnerability of the navigation network is improved through changing the topology of the most critical node and balancing the node importance of the whole network.",
           0,
           "complexity"
          ],
          [
           "Randomized and Efficient Time Synchronization in Dynamic Wireless Sensor Networks: A Gossip-Consensus-Based Approach",
           "10.1155/2018/4283087",
           2018,
           "This paper proposes novel randomized gossip-consensus-based sync (RGCS) algorithms to realize efficient time calibration in dynamic wireless sensor networks (WSNs). First, the unreliable links are described by stochastic connections, reflecting the characteristic of changing connectivity gleaned from dynamic WSNs. Secondly, based on the mutual drift estimation, each pair of activated nodes fully adjusts clock rate and offset to achieve network-wide time synchronization by drawing upon the gossip consensus approach. The converge-to-max criterion is introduced to achieve a much faster convergence speed. The theoretical results on the probabilistic synchronization performance of the RGCS are presented. Thirdly, a Revised-RGCS is developed to counteract the negative impact of bounded delays, because the uncertain delays are always present in practice and would lead to a large deterioration of algorithm performances. Finally, extensive simulations are performed on the MATLAB and OMNeT++ platform for performance evaluation. Simulation results demonstrate that the proposed algorithms are not only efficient for synchronization issues required for dynamic topology changes but also give a better performance in terms of converging speed, collision rate, and the robustness of resisting delay, and outperform other existing protocols.",
           5,
           "complexity"
          ],
          [
           "Synergistic Evaluation and Constraint Factor Analysis on Urban Industrial Ecosystems of Traditional Industrial Area in China",
           "10.1155/2020/3805454",
           2020,
           "Industrial ecology is an advanced form and ideal model of modern industrial development, in which the industrial ecosystem is the core. Based on the PSR model, this paper builds a comprehensive evaluation index system for urban industrial ecosystem development and selects 14 prefecture-level cities in Liaoning Province of the traditional industrial area in Northeastern China as cases to calculate the development level of its industrial ecosystem during 2000–2018 using an improved Topsis method and then to conduct a spatial visualization analysis. Finally, based on the “stress-state-response” subsystem, this paper diagnoses the constraints for industrial ecosystem development, which can provide a reference basis for decision-making in industrial ecology of traditional industrial area represented by those in Northeast China. The results show the following: (1) From 2000 to 2018, the industrial ecology of the 14 cities in Liaoning Province was at a medium level. Except for Shenyang and Dalian with the rapid development, the difference of industrial ecosystem development for other cities was relatively small. (2) From 2000 to 2018, the industrial ecosystem development of each city was in a status of “either increasing, or decreasing, or fluctuating,” which generally raised first and then decreased. Regarding spatial difference, the development exhibited a “center-periphery” pattern, with Shenyang and Dalian as the “dual-core” that were increasingly strengthened with significantly high-level industrial ecology. (3) At system level, PSR constraint grades for the industrial ecosystem development in the 14 cities of Liaoning Province were different. Constraint grades in the pressure subsystem, the state subsystem, and the response subsystem for the industrial ecosystem of Liaoning were 45.73%, 20.01%, and 34.34%, respectively, indicating that the lack of human response to the ecological environment and the pressure of human activities on the ecological environment during the industrial economy development were the main constraints affecting the process of industrial ecology in these cities. (4) Due to the differences in geographical environments, economic bases, industrial structures, and local development contexts, the major constraint factors of industrial ecosystem development in different cities are significantly different and complicated; however, there are five factors that are generally considered as major constraint factors in all cities, i.e., regional GDP, number of labor force employed in the secondary industrial sector, gross investment in fixed assets, amount of industrial sulfur dioxide removal, and production value from “three-wastes” comprehensive utilization. At last, this paper puts forward some recommendations and suggestions for providing scientific support for industrial ecosystem construction in the traditional industrial area of Northeastern China.",
           1,
           "complexity"
          ],
          [
           "Artificial Intelligence-Assisted Fresco Restoration with Multiscale Line Drawing Generation",
           "10.1155/2021/5567966",
           2021,
           "In this article, we study the mural restoration work based on artificial intelligence-assisted multiscale trace generation. Firstly, we convert the fresco images to colour space to obtain the luminance and chromaticity component images; then we process each component image to enhance the edges of the exfoliated region using high and low hat operations; then we construct a multistructure morphological filter to smooth the noise of the image. Finally, the fused mask image is fused with the original mural to obtain the final calibration result. The fresco is converted to HSV colour space, and chromaticity, saturation, and luminance features are introduced; then the confidence term and data term are used to determine the priority of shedding boundary points; then a new block matching criterion is defined, and the best matching block is obtained to replace the block to be repaired based on the structural similarity between the block to be repaired and the matching block by global search; finally, the restoration result is converted to RGB colour space to obtain the final restoration result. An improved generative adversarial network structure is proposed to address the shortcomings of the existing network structure in mural defect restoration, and the effectiveness of the improved modules of the network is verified. Compared with the existing mural restoration algorithms on the test data experimentally verified, the peak signal-to-noise ratio (PSNR) score is improved by 4% and the structural similarity (SSIM) score is improved by 2%.",
           1,
           "complexity"
          ],
          [
           "Mean Square Exponential Stability of Stochastic Complex-Valued Neural Networks with Mixed Delays",
           "10.1155/2019/3429326",
           2019,
           "This paper investigates the mean square exponential stability problem of a class of complex-valued neural networks with stochastic disturbance and mixed delays including both time-varying delays and continuously distributed delays. Under different assumption conditions concerning stochastic disturbance term from the existing ones, some sufficient conditions are derived for assuring the mean square exponential stability of the equilibrium point of the system based on the vector Lyapunov function method and Ito^ differential-integral theorem. The obtained results not only generalize the existing ones, but also reduce the conservatism of the previous stability results about complex-valued neural networks with stochastic disturbances. Two numerical examples with simulation results are given to verify the feasibility of the proposed results.",
           3,
           "complexity"
          ],
          [
           "Evaluation of Residential Housing Prices on the Internet: Data Pitfalls",
           "10.1155/2019/5370961",
           2019,
           "Many studies have used housing prices on the Internet real estate information platforms as data sources, but platforms differ in the nature and quality of the data they release. However, few studies have analysed these differences or their effect on research. In this study, second-hand neighbourhood housing prices and information on five online real estate information platforms in Guangzhou, China, were comparatively analysed and the performance of neighbourhoods’ raw information from four for-profit online real estate information platforms was evaluated by applying the same housing price model. The comparison results show that the official second-hand residential housing prices at city and district level are generally lower than those issued on four for-profit real estate websites. The same second-hand neighbourhood housing prices are similar across each of the four for-profit real estate websites due to cross-referencing among real estate websites. The differences of housing prices in the central city area are significantly fewer than those in the periphery. The variation of each neighbourhood’s housing prices on each website decreases gradually from the city centre to the periphery, but the relative variation stays stable. The results of the four hedonic models have some inconsistencies with other studies’ findings, demonstrating that errors exist in raw information on neighbourhoods taken from Internet platforms. These results remind researchers to choose housing price data sources cautiously and that raw information on neighbourhoods from Internet platforms should be appropriately cleaned.",
           3,
           "complexity"
          ],
          [
           "Spatiotemporal Characteristics and Resilience of Urban Network Structure during the Spring Festival Travel Rush: A Case Study of Urban Agglomeration in the Middle Reaches of Yangtze River in China",
           "10.1155/2021/4923532",
           2021,
           "With the increasing trend of globalization, large-scale and diffuse population flow have become vital carriers characterizing users' spatial behaviors. Network analysis provides a new perspective to uncover the topology and evolution of the population flow and understand its influence on regional development. By gathering the Autonavi migration index during the Spring Festival travel rush (SFTR) in 2019, 2020, and 2021, the population flow networks among 31 cities of urban agglomeration in the middle reaches of the Yangtze River were constructed to analyze spatiotemporal dynamic characteristics and explore the structure resilience. Results show that although the changing trends of population flow during the 40-day SFTR of 2019, 2020, and 2021 are consistent, the population floating scale in 2020 and 2021 shows remarkable abnormalities before and after the Spring Festival due to the need for prevention and control of COVID-19. The intensity of population floating of the regional urban network in 2020 was the weakest, and Changsha became the focus of most population flow, while Wuhan was the most advantageous city in 2019 and 2021. As the third core city in the regional network, the siphon effect of Nanchang was still weak. A situation of tripartite confrontation in the region is formed. However, the higher intensity of population flow in 2021 increased the instability of the regional urban network, potentially exposing the region to higher risks and pressures. Therefore, it is necessary to pay more attention to the peripheral cities to improve regional resilience.",
           2,
           "complexity"
          ],
          [
           "Novel Method in Induction Heating for Complex Steel Plate Deformation Based on Artificial Neural Network",
           "10.1155/2022/3531980",
           2022,
           "The implementation of an artificial neural network for predicting induction heating region locations is proposed in this research. Steel plate deformations during the induction heating process are produced using an analytical solution derived from electromagnetic and plate theory. The plate transform following vertical displacements in each divided area was used as input of neural following desired shape of the steel plate and the specified heating areas for induction treatment as output parameters to predict and evaluate the model. A dataset used 90% for training and remaining 10% for testing to implement on the efficient models when changing hidden layer and its neurons relatively. The trial and error for analyzing and predicting heating-affected regions with the ANNs model reached the high average accuracy and lowest mean square error at 98.08% and 0.00913, respectively. Consequently, the feasibility test indicates that the developed approach may be well utilized to identify the heating positions by grid area in order to achieve the desired plate deformation. Moreover, the analysis of vertical displacement during induction heating and its response behaviour of steel plate based on thermo-mechanical are also addressed.",
           0,
           "complexity"
          ],
          [
           "A Pinning Actor-Critic Structure-Based Algorithm for Sizing Complex-Shaped Depth Profiles in MFL Inspection with High Degree of Freedom",
           "10.1155/2021/9995033",
           2021,
           "One of the most efficient nondestructive methods for pipeline in-line inspection is magnetic flux leakage (MFL) inspection. Estimating the size of the defect from MFL signal is one of the key problems of MFL inspection. As the inspection signal is usually contaminated by noise, sizing the defect is an ill-posed inverse problem, especially when sizing the depth as a complex shape. An actor-critic structure-based algorithm is proposed in this paper for sizing complex depth profiles. By learning with more information from the depth profile without knowing the corresponding MFL signal, the algorithm proposed saves computational costs and is robust. A pinning strategy is embedded in the reconstruction process, which highly reduces the dimension of action space. The pinning actor-critic structure (PACS) helps to make the reward for critic network more efficient when reconstructing the depth profiles with high degrees of freedom. A nonlinear FEM model is used to test the effectiveness of algorithm proposed under 20 dB noise. The results show that the algorithm reconstructs the depth profile of defects with good accuracy and is robust against noise.",
           1,
           "complexity"
          ],
          [
           "Robust Switching Gain-Based Fractional-Order Sliding Mode Control for Wind-Powered Microgrids",
           "10.1155/2021/6697792",
           2021,
           "This study proposes a novel fractional-order sliding-mode control strategy with robust switching gain to achieve reliable and high quality of wind-powered microgrid systems. Three fractional-order sliding mode controllers are designed to generate continuous control signals and regulate the outer DC-link voltage loop and inner current loop in the grid-side inverters. High robustness and stability of the grid-side inverter can be guaranteed even in the presence of parameter variations and external disturbances. Owing to the fractional-order sliding manifold and fractional-order integral control law, the chattering is attenuated. The fractional-order robust adaptive switching gain is designed to avoid overestimating the upper bound of matched/unmatched uncertainties, save the control energy, and guarantee the rapidity and robustness of the convergence. Simulations validate the proposed method.",
           2,
           "complexity"
          ],
          [
           "Determinants of Intercity Air-Passenger Flows in the “Belt and Road” Region",
           "10.1155/2021/5514135",
           2021,
           "Air-passenger flow, denoting intercity connections, has been a focal point of studies pertaining to urban networks. While most existing studies include only the geoeconomic characteristics of nodes as explanatory variables, this analysis developed a gravity model by incorporating further factors (e.g., cultural disparity and institutional disparity) that might influence air-passenger flows in the “Belt and Road” region. The primary findings are as follows: (1) The cultural and institutional disparities correlate negatively with the air-passenger flows in this region; (2) air-passenger flows are positively related to border, population and economy size, and economic disparity; (3) flows tend to first increase and then subsequently decrease as geographical distance increases; (4) the impact of the factors on the flows varies by subregion. This study could serve as a reference for those interested in gaining a greater insight into air-passenger flows and could also help improve regional strategies for air-transportation development.",
           3,
           "complexity"
          ],
          [
           "Common Weak Linear Copositive Lyapunov Functions for Positive Switched Linear Systems",
           "10.1155/2018/1365960",
           2018,
           "Lyapunov functions play a key role in the stability analysis of complex systems. In this paper, we study the existence of a class of common weak linear copositive Lyapunov functions (CWCLFs) for positive switched linear systems (PSLSs) which generalize the conventional common linear copositive Lyapunov functions (CLCLFs) and can be used as handy tool to deal with the stability of PSLSs not covered by CLCLFs. We not only establish necessary and sufficient conditions for the existence of CWCLFs but also clearly describe the algebraic structure of all CWCLFs. Numerical examples are also given to demonstrate the effectiveness of the obtained results.",
           11,
           "complexity"
          ],
          [
           "Cognitive Driven Multilayer Self-Paced Learning with Misclassified Samples",
           "10.1155/2019/8127869",
           2019,
           "In recent years, self-paced learning (SPL) has attracted much attention due to its improvement to nonconvex optimization based machine learning algorithms. As a methodology introduced from human learning, SPL dynamically evaluates the learning difficulty of each sample and provides the weighted learning model against the negative effects from hard-learning samples. In this study, we proposed a cognitive driven SPL method, i.e., retrospective robust self-paced learning (R2SPL), which is inspired by the following two issues in human learning process: the misclassified samples are more impressive in upcoming learning, and the model of the follow-up learning process based on large number of samples can be used to reduce the risk of poor generalization in initial learning phase. We simultaneously estimated the degrees of learning-difficulty and misclassified in each step of SPL and proposed a framework to construct multilevel SPL for improving the robustness of the initial learning phase of SPL. The proposed method can be viewed as a multilayer model and the output of the previous layer can guide constructing robust initialization model of the next layer. The experimental results show that the R2SPL outperforms the conventional self-paced learning models in classification task.",
           0,
           "complexity"
          ],
          [
           "Hyperchaotic Oscillation in the Deformed Rikitake Two-Disc Dynamo System Induced by Memory Effect",
           "10.1155/2020/8418041",
           2020,
           "The fundamental dynamics of the deformed Rikitake two-disc dynamo system is explored in this paper. Memory effect on the dynamical behavior of the generator system is studied by introducing a quadratic flux-controlled memristor. Hyperchaotic oscillation in the deformed Rikitake two-disk coupled generator is therefore firstly found. Lyapunov exponents, bifurcation diagram, and phase portraits prove the abundant dynamic behavior consistently.",
           3,
           "complexity"
          ],
          [
           "An Iterative Learning Scheme-Based Fault Estimator Design for Nonlinear Systems with Randomly Occurring Parameter Uncertainties",
           "10.1155/2018/7280182",
           2018,
           "This paper deals with fault estimation problem for a class of nonlinear system with parameter uncertainties subjecting to Bernoulli-distributed white sequences with known conditional probabilities. In order to reflect the reality more closely, parameter uncertainties are considered in both the state parameter matrix and the output parameter matrix. Compared with existing observer-based fault estimation approaches, the proposed iterative learning observer considers the state error information and fault estimating information from the previous iteration to improve the fault estimation performance in the current iteration. Simultaneously, the stability and convergence of the designed observer are achieved by employing the Lyapunov stability theory. On the other hand, a novel optimal function using expectation is presented to ensure the uniform convergence of the fault estimation scheme, thus reducing the impact of randomly occurring parameter uncertainties. Finally, linear matrix inequality (LMI) is employed to obtain the solutions of sufficient condition for further improvement of iterative learning law performance. The results are suitable for the systems with time-varying uncertainties as well as constant uncertainties. Additionally, a numerical example is given to demonstrate the effectiveness of the proposed design scheme.",
           4,
           "complexity"
          ],
          [
           "Global External Stochastic Stabilization of Linear Systems with Input Saturation: An Alternative Approach",
           "10.1155/2017/3517280",
           2017,
           "This paper presents results concerning the global external stochastic stabilization for linear systems with input saturation and stochastic external disturbances under random Gaussian distributed initial conditions. The objective is to construct a class of control laws that achieve global asymptotic stability in the absence of disturbances, while guaranteeing a bounded variance of the state for all the time in the presence of disturbances. By using an alternative approach, a new class of scheduled control laws are proposed, and the global external stochastic stabilization problem can be solved only through some routine manipulations. Furthermore, the reported approach allows a larger range of the design parameter. Finally, two numerical examples are provided to validate the theoretical results.",
           1,
           "complexity"
          ],
          [
           "Further Investigations on the Dynamics and Multistability Coexisted in a Memory-Based Cobweb Model",
           "10.1155/2021/6642706",
           2021,
           "Based on a nonlinear demand function and a market-clearing price, a cobweb model is introduced in this paper. A gradient mechanism that depends on the marginal profit is adopted to form the 1D discrete dynamic cobweb map. Analytical studies show that the map possesses four fixed points and only one attains the profit maximization. The stability/instability conditions for this fixed point are calculated and numerically studied. The numerical studies provide some insights about the cobweb map and confirm that this fixed point can be destabilized due to period-doubling bifurcation. The second part of the paper discusses the memory factor on the stabilization of the map’s equilibrium point. A gradient mechanism that depends on the marginal profit in the past two time steps is adopted to incorporate memory in the model. Hence, a 2D discrete dynamic map is constructed. Through theoretical and numerical investigations, we show that the equilibrium point of the 2D map becomes unstable due to two types of bifurcations that are Neimark–Sacker and flip bifurcations. Furthermore, the influence of the speed of adjustment parameter on the map’s equilibrium is analyzed via numerical experiments.",
           0,
           "complexity"
          ],
          [
           "Research on the Disease Intelligent Diagnosis Model Based on Linguistic Truth-Valued Concept Lattice",
           "10.1155/2021/6630077",
           2021,
           "Uncertainty natural language processing has always been a research focus in the artificial intelligence field. In this paper, we continue to study the linguistic truth-valued concept lattice and apply it to the disease intelligent diagnosis by building an intelligent model to directly handle natural language. The theoretical bases of this model are the classical concept lattice and the lattice implication algebra with natural language. The model includes the case library formed by patients, attributes matching, and the matching degree calculation about the new patient. According to the characteristics of the patients, the disease attributes are firstly divided into intrinsic invariant attributes and extrinsic variable attributes. The calculation algorithm of the linguistic truth-valued formal concepts and the constructing algorithm of the linguistic truth-valued concept lattice based on the extrinsic attributes are proposed. And the disease bases of the different treatments for different patients with the same disease are established. Secondly, the matching algorithms of intrinsic attributes and extrinsic attributes are given, and all the linguistic truth-valued formal concepts that match the new patient’s extrinsic attributes are found. Lastly, by comparing the similarity between the new patients and the matching formal concepts, we calculate the best treatment options to realize the intelligent diagnosis of the disease.",
           0,
           "complexity"
          ],
          [
           "Time-Delayed Feedback Control of a Hydraulic Model Governed by a Diffusive Wave System",
           "10.1155/2020/4986026",
           2020,
           "This paper is concerned with the feedback flow control of an open-channel hydraulic system modeled by a diffusive wave equation with delay. Firstly, we put forward a feedback flow control subject to the action of a constant time delay. Thereafter, we invoke semigroup theory to substantiate that the closed-loop system has a unique solution in an energy space. Subsequently, we deal with the eigenvalue problem of the system. More importantly, exponential decay of solutions of the closed-loop system is derived provided that the feedback gain of the control is bounded. Finally, the theoretical findings are validated via a set of numerical results.",
           0,
           "complexity"
          ],
          [
           "Fuzzy Reliability Optimization for 2-Hub Center Problem with Cluster-Based Policy and Application in Cross-Border Supply Chain Network Design Using TS Algorithm",
           "10.1155/2020/5065640",
           2020,
           "As information and communication technology evolves and expands, business and markets are linked to form a complex international network, thus generating plenty of cross-border trading activities in the supply chain network. Through the observations from a typical cross-border supply chain network, this paper introduces the fuzzy reliability-oriented 2-hub center problem with cluster-based policy, which is a special case of the well-studied hub location problem (HLP). This problem differs from the classical HLP in the sense that (i) the hub-and-spoke (H&S) network is grouped into two clusters in advance based on their cross-border geographic features, and (ii) a fuzzy reliability optimization approach based on the possibility measure is developed. The proposed problem is first modeled through a mixed-integer nonlinear programming (MINLP) formulation that maximizes the reliability of the entire cross-border supply chain network. Then, some linearization techniques are implemented to derive a linear model, which can be efficiently solved by exact algorithms run by CPLEX for only small instances. To counteract the difficulty for solving the proposed problem in realistic-sized instances, a tabu search (TS) algorithm with two types of move operators (called “Swap I” and “Swap II”) is further developed. Finally, a series of numerical experiments based on the Turkish network and randomly generated large-scale datasets are set up to verify the applicability of the proposed model as well as the superiority of the TS algorithm compared to the CPLEX.",
           0,
           "complexity"
          ],
          [
           "Optimization for Nonlinear Uncertain Switched Stochastic Systems with Initial State Difference in Batch Culture Process",
           "10.1155/2019/4979580",
           2019,
           "Based on the deterministic description of batch culture expressed in form of switched ordinary differential equations, we introduce a switched stochastic counterpart system with initial state difference together with uncertain switching instants and system parameters to model the process of glycerol biodissimilation to 1,3-propanediol (1,3-PD) induced byKlebsiella pneumoniae(K. pneumoniae). Important properties of the stochastic system are discussed. Our aim is to obtain the unified switched instants and system parameters under the condition of different initial states. To do this, we will formulate a system identification problem in which these uncertain switched instants and system parameters are regarded as decision variables to be chosen such that the relative error between experimental data and computational results is minimized. Such problem governed by the stochastic system is subject to continuous state inequality constraints and box constraints. By performing a time-scaling transformation as well as introducing the constraint transcription and local smoothing approximation techniques, we convert such problem into a sequence of approximation subproblems. Considering both the difficulty of finding analytical solutions and the complex nature of these subproblems, we develop a parallelized differential evolution (DE) algorithm to solve these approximation subproblems. From an extensive simulation, we show that the obtained optimal switched instants and system parameters are satisfactory with initial state difference.",
           1,
           "complexity"
          ],
          [
           "Influence of Bifurcation Structures Revealed by Refinement of a Nonlinear Conductance in JosephsonJunction Element",
           "10.1155/2018/8931525",
           2018,
           "We conduct a bifurcation analysis of a single-junction superconducting quantum interferometer with an external flux. We approximate the current-voltage characteristics of the conductance in the equivalent circuit of the JJ by using two types of functions: a linear function and a piecewise linear (PWL) function. We describe a method to compute the local stability of the solution orbit and to solve the bifurcation problem. As a result, we reveal the bifurcation structure of the systems in a two-dimensional parameter plane. By making a comparison between the linear and PWL cases, we find a difference in the shapes of their bifurcation sets in the two-dimensional parameter plane even though there are no differences in the one-dimensional bifurcation diagrams or the trajectories. As for the influence of piecewise linearization, we discovered that grazing bifurcations terminate the calculation of the local bifurcations, because they drastically change the stability of the periodic orbit.",
           0,
           "complexity"
          ],
          [
           "Loosely Formation-Displaced Geostationary Orbit Optimization with Complex Hybrid Sail Propulsion",
           "10.1155/2018/3576187",
           2018,
           "To explore the performance of hybrid sail and overcome the congestion of geostationary orbit, this work proposes a method intended to optimize the trajectories of the spacecraft formation and extend the concept of displaced geostationary orbit by loosening the relative distance and introducing a station-keeping box. The multispacecraft formation is a typical complex system with nonlinear dynamics, and the hybrid propulsion system introduces additional complexity. To solve this problem, suboptimal trajectories with constant relative distance constraints are first found with inverse methods, which were referred to as ideal displaced geostationary orbits. Then, the suboptimal trajectories are used as a first guess for a direct optimization algorithm based on Gauss pseudospectral algorithm, which loosens the relative distance constraints and allows the spacecraft to be placed anywhere inside the station-keeping box. The optimization results show that the loosely formation and station-keeping box can create more flexible trajectories and achieve higher efficiency of the hybrid sail propulsion system, which can save about 40% propellant consumption.",
           0,
           "complexity"
          ],
          [
           "Optimality Conditions and Scalarization of Approximate Quasi Weak Efficient Solutions for Vector Equilibrium Problem",
           "10.1155/2020/1063251",
           2020,
           "This paper is devoted to the investigation of optimality conditions for approximate quasi weak efficient solutions for a class of vector equilibrium problem (VEP). First, a necessary optimality condition for approximate quasi weak efficient solutions to VEP is established by utilizing the separation theorem with respect to the quasirelative interior of convex sets and the properties of the Clarke subdifferential. Second, the concept of approximate pseudoconvex function is introduced and its existence is verified by a concrete example. Under the assumption of introduced convexity, a sufficient optimality condition for VEP in sense of approximate quasi weak efficiency is also presented. Finally, by using Tammer’s function and the directed distance function, the scalarization theorems of the approximate quasi weak efficient solutions of the VEP are proposed.",
           0,
           "complexity"
          ],
          [
           "A Competitive Swarm Optimizer-Based Technoeconomic Optimization with Appliance Scheduling in Domestic PV-Battery Hybrid Systems",
           "10.1155/2019/4824837",
           2019,
           "A technoeconomic optimization problem for a domestic grid-connected PV-battery hybrid energy system is investigated. It incorporates the appliance time scheduling with appliance-specific power dispatch. The optimization is aimed at minimizing energy cost, maximizing renewable energy penetration, and increasing user satisfaction over a finite horizon. Nonlinear objective functions and constraints, as well as discrete and continuous decision variables, are involved. To solve the proposed mixed-integer nonlinear programming problem at a large scale, a competitive swarm optimizer-based numerical solver is designed and employed. The effectiveness of the proposed approach is verified by simulation results.",
           1,
           "complexity"
          ],
          [
           "Study on the Magnitude of Reservoir-Triggered Earthquake Based on Support Vector Machines",
           "10.1155/2018/2830690",
           2018,
           "An effective approach is introduced to predict the magnitude of reservoir-triggered earthquake (RTE), based on support vector machines (SVM) and fuzzy support vector machines (FSVM) methods. The main influence factors on RTE, including lithology, rock mass integrity, fault features, tectonic stress state, and seismic activity background in reservoir area, are categorized into 11 parameters and quantified by using analytical hierarchy process (AHP). Dataset on 100 reservoirs in China, including the 48 well-documented cases of RTE, are collected and used to train and validate the prediction models established with SVM and FSVM, respectively. Through numerical tests, it is found that both the SVM and FSVM models are effective in the prediction of the magnitude of RTE with high accuracy, provided that sufficient samples are collected. While the results of FSVM which is extended from SVM by introducing a fuzzy membership to reduce the influence of noises or outliers are found to be slightly less accurate than those of SVM in the current analysis of RTE cases. The reason might be attributed to the high discreteness of the sample data in the current study.",
           6,
           "complexity"
          ],
          [
           "On Topological Analysis of Niobium (II) Oxide Network via Curve Fitting and Entropy Measures",
           "10.1155/2022/4112362",
           2022,
           "The remarkable optical features of metallic nanoparticles have extensively developed the interest of scientists and researchers. The generated heat overwhelms cancer tissue incident to nanoparticles with no damage to sound tissues. Niobium nanoparticles have the ability of easy ligands connection so they are very suitable in treating cancer optothermally. A modern field of applied chemistry is chemical graph theory. With the use of combinatorial methods, such as vertex and edge partitions, we explore the connection between atoms and bonds. Topological indices play a vital part in equipping directions to treat cancers or tumors. These indices might be derived experimentally or computed numerically. Although experimental results are worthful but they are expensive as well, so computational analysis provides an economical and rapid way. A topological index is a numerical value that is only determined by the graph. In this paper, we will discuss the chemical graph of niobium (II) oxide. Additionally, each topological index is related with thermodynamical properties of niobium (II) oxide, including entropy and enthalpy. This has been done in MATLAB software, using rational built-in method.",
           0,
           "complexity"
          ],
          [
           "Multisensor-Weighted Fusion Algorithm Based on Improved AHP for Aircraft Fire Detection",
           "10.1155/2021/8704924",
           2021,
           "Aiming at the high false alarm rate when using single sensor to detect fire in aircraft cabin, a multisensor data fusion method is proposed to detect fire. First, the weights of multiple factors, that is, temperature, smoke concentration, CO concentration, and infrared ray intensity in the event of fire, were calculated by using the improved analytic hierarchy process (AHP) method on each sensor node of wireless sensor network, and the probability of fire event in the cabin was evaluated by multivariable-weighted fusion method. Second, based on the mutual support among the evaluation data of fire probabilities of each node, the adaptive weight coefficient is assigned to each evaluation value, and the weighted fusion of all evaluation values of each node is conducted to obtain the fire probability. In the end, compared to the threshold of probability, the fire alarm is determined. Comparing the proposed algorithm to the grey fuzzy neural network fusion algorithm and fuzzy logic fusion algorithm in terms of the time consumption for fire detection and sending alarm and the accuracy of fire alarm perspectives, the experiments demonstrate that the proposed fire detection algorithm can detect the fire within 10s and reduce the false alarm rate to less than 0.5%, which verifies the superiority of the algorithm in promptness and accuracy. In the meanwhile, the fault tolerance of the algorithm is proved as well.",
           3,
           "complexity"
          ],
          [
           "A New Approach to Modeling and Controlling a Pneumatic Muscle Actuator-Driven Setup Using Back Propagation Neural Networks",
           "10.1155/2018/4160504",
           2018,
           "Pneumatic muscle actuators (PMAs) own excellent compliance and a high power-to-weight ratio and have been widely used in bionic robots and rehabilitated robots. However, the high nonlinear characteristics of PMAs due to inherent construction and pneumatic driving principle bring great challenges in applications acquired accurately modeling and controlling. To tackle the tricky problem, a single PMA mass setup is constructed, and a back propagation neural network (BPNN) is employed to identify the dynamics of the setup. An offline model is built up using sampled data, and online modifications are performed to further improve the quality of the model. An adaptive controller based on BPNN is designed using gradient descent information of the built-up model. Experiments of identifying the PMA setup using BPNN and position tracking by adaptive BPNN controller are performed, and results demonstrate the good capacity in accurate controlling of the PMA setup.",
           5,
           "complexity"
          ],
          [
           "Smoothing Connected Ball Bézier Curves by Energy Minimization",
           "10.1155/2022/7669483",
           2022,
           "In this paper, we aim at smoothing two connected ball Bézier curves from Cr−1 to Cr\n\n\n\nr\n≥\n1\n\n\n\n by minimizing the energies of the curves. We propose the algorithms based on internal energy minimization and curve attractor minimization. Then, we combine the internal energy and the curve attractor and give the algorithm based on combined energy minimization. All algorithms are established by solving bi-objective minimizations. Some numerical examples show that the proposed algorithms are effective, making them useful for smoothing 3D objects constructed by connected ball Bézier curves.",
           0,
           "complexity"
          ],
          [
           "The Effect of Specific Risk in Various Stages of the Life Cycle of Companies Listed on the Tehran Stock Exchange",
           "10.1155/2022/9646829",
           2022,
           "This research aims to examine the specific risk of companies and their effectiveness in various stages of the company life cycle on state and nonstate ownership. For this purpose, the specific risk was estimated using Fama and French three-factor models, and the research objective was examined by considering the data panel model during the period 2015 to 2020 in a statistical sample consisting of 136 companies active in the Tehran Stock Exchange. For this purpose, the main contribution of research is evaluation of the effect of specific risk in different stages of the life cycle of companies admitted to the Tehran Stock Exchange. Therefore, the main valuable advantage to helping stock managers is assessing the impact of government ownership and nongovernment ownership on the specific risk of companies at different stages of the life cycle. Also, presenting a model to show the effects of dependent and independent variables in order to evaluate the impact of government and nongovernment ownership. The research results confirmed that the specific risk of the company in the stages of introduction, growth, and decline is higher compared to the stages of maturity and stagnation of the life cycle of companies listed on the Tehran Stock Exchange. Because the coefficients of virtual variables related to the life cycle stages of the company are estimated to be significant. Also, the finding confirmed that government ownership significantly affects the relationship between firm risk and life cycle stages in companies listed on the Tehran Stock Exchange. Because, the coefficient of variable state ownership is negative and significant, indicating a lower specific risk in state-owned companies than in nonstate-owned companies.",
           0,
           "complexity"
          ],
          [
           "A Social Network Analysis on Venture Capital Alliance’s Exit from an Emerging Market",
           "10.1155/2020/4650160",
           2020,
           "This study investigated the impacts of network structure on a venture capital (VC) alliance’s successful exit from an emerging market by empirically analyzing joint VC data in China. We find that, compared to a mature capital market, the mechanism not only has a certain commonality but also shows the emerging market’s particularities. From the commonality perspective, the mechanism has a positive effect on successful exit by obtaining heterogeneity information. These particularities are manifested in the following three aspects. First, the mechanism is not conducive to deepening the enterprise value chain to establish credibility by obtaining short-term cash during an initial public offering with the enhancement of the VC alliance’s intervention ability for enterprise development. In addition, a VC alliance’s independent judgment is bound by the VC market. Furthermore, the problem of over-trust in investees reduces the likelihood of a VC alliance’s successful exit. Therefore, we should pay more attention to the particularity of emerging markets such as China to improve the relevant management mechanism.",
           3,
           "complexity"
          ],
          [
           "Research on a 3D Predator-Prey Evolutionary System in Real Estate Market",
           "10.1155/2018/6154940",
           2018,
           "This paper establishes a model on the upstream and downstream relationship among private enterprises, provincial and local officials, and the central government in the real estate market using the population ecology theory of mutual relations among individual species from the perspective of business ecosystem. A dynamic model is introduced and the complex dynamical behaviors of such a predator-prey model are investigated by means of numerical simulation. The local stability conditions and complex dynamics are investigated, and the existence of chaos is discussed in the sense of Marotto theorem; bifurcation diagrams, Lyapunov exponents, sensitivity analysis for initial values, and time history figure of the system are mapped out and discussed. This shows that there are two routes to complicated dynamics, one of which is the cascade of flip bifurcations resulting in periodic cycles (and chaos), and the other one is Neimark-Sacker bifurcation which produces attractive invariant closed curves. We arrive at conclusions that the phenomenon of chaos is harmful to private enterprises, and unstable behavior is often unfavorable. Thus, linear feedback control is applied to drive the model to a stable state when the system exhibits chaotic behaviors, achieving the goal of eliminating the negative effects to a large extent.",
           1,
           "complexity"
          ],
          [
           "Effective Approach to Calculate Analysis Window in Infinite Discrete Gabor Transform",
           "10.1155/2018/9039240",
           2018,
           "The long-periodic/infinite discrete Gabor transform (DGT) is more effective than the periodic/finite one in many applications. In this paper, a fast and effective approach is presented to efficiently compute the Gabor analysis window for arbitrary given synthesis window in DGT of long-periodic/infinite sequences, in which the new orthogonality constraint between analysis window and synthesis window in DGT for long-periodic/infinite sequences is derived and proved to be equivalent to the completeness condition of the long-periodic/infinite DGT. By using the property of delta function, the original orthogonality can be expressed as a certain number of linear equation sets in both the critical sampling case and the oversampling case, which can be fast and efficiently calculated by fast discrete Fourier transform (FFT). The computational complexity of the proposed approach is analyzed and compared with that of the existing canonical algorithms. The numerical results indicate that the proposed approach is efficient and fast for computing Gabor analysis window in both the critical sampling case and the oversampling case in comparison to existing algorithms.",
           2,
           "complexity"
          ],
          [
           "RLS Impedance Intelligence Control Algorithm for Wire Peeler of Robot in Complex Power Networks",
           "10.1155/2020/8840421",
           2020,
           "Considering the wire core which is easily damaged because of the instability of the power distribution robot during the process of peeling the insulation layer, we have proposed a cutting force tracking control algorithm based on impedance control that is suitable for the end peeling instrument. At present, the task requirement of sudden changes about environment stiffness cannot be accomplished by many impedance control approaches due to the complexity of working environment stiffness about power distribution robot; then, the Recursive Least Square (RLS) method was introduced into the impedance control algorithm to identify the cable insulation layer and cable core stiffness online to achieve accurate and stable tracking of the cutting force. Furthermore, the impedance control of peeling cable insulation layer and the proposed RLS method were simulated and tested contrastively, and the high-voltage cable peeling experiment was performed. The results of simulation and experiment showed that the force control algorithm based on RLS parameter identification still has good force tracking performance during the environment stiffness changes suddenly, and the steady-state error approaches zero, demonstrating the feasibility and effectiveness of the RLS impedance control algorithm, which has important practical significance for improving power distribution efficiency.",
           0,
           "complexity"
          ],
          [
           "Real-Time Height Measurement for Moving Pedestrians",
           "10.1155/2020/5708593",
           2020,
           "Height measurement for moving pedestrians is quite significant in many scenarios, such as pedestrian positioning, criminal suspect tracking, and virtual reality. Although some existing height measurement methods can detect the height of the static people, it is hard to measure height accurately for moving pedestrians. Considering the height fluctuations in dynamic situation, this paper proposes a real-time height measurement based on the Time-of-Flight (TOF) camera. Depth images in a continuous sequence are addressed to obtain the real-time height of the pedestrian with moving. Firstly, a normalization equation is presented to convert the depth image into the grey image for a lower time cost and better performance. Secondly, a difference-particle swarm optimization (D-PSO) algorithm is proposed to remove the complex background and reduce the noises. Thirdly, a segmentation algorithm based on the maximally stable extremal regions (MSERs) is introduced to extract the pedestrian head region. Then, a novel multilayer iterative average algorithm (MLIA) is developed for obtaining the height of dynamic pedestrians. Finally, Kalman filtering is used to improve the measurement accuracy by combining the current measurement and the height at the last moment. In addition, the VICON system is adopted as the ground truth to verify the proposed method, and the result shows that our method can accurately measure the real-time height of moving pedestrians.",
           0,
           "complexity"
          ],
          [
           "Local Similarity-Based Fuzzy Multiple Kernel One-Class Support Vector Machine",
           "10.1155/2020/8853277",
           2020,
           "One-class support vector machine (OCSVM) is one of the most popular algorithms in the one-class classification problem, but it has one obvious disadvantage: it is sensitive to noise. In order to solve this problem, the fuzzy membership degree is introduced into OCSVM, which makes the samples with different importance have different influences on the determination of classification hyperplane and enhances the robustness. In this paper, a new calculation method of membership degree is proposed and introduced into the fuzzy multiple kernel OCSVM (FMKOCSVM). The combined kernel is used to measure the local similarity between samples, and then, the importance of samples is determined based on the local similarity between training samples, so as to determine the membership degree and reduce the impact of noise. The proposed membership requires only positive data in the calculation process, which is consistent with the training set of OCSVM. In this method, the noise has a smaller membership value, which can reduce the negative impact of noise on the classification boundary. Simultaneously, this method of calculating membership has a higher efficiency. The experimental results show that FMKOCSVM based on proposed local similarity membership is efficient and more robust to outliers than the ordinary multiple kernel OCSVMs.",
           4,
           "complexity"
          ],
          [
           "Upper and Lower Bounds for the Kirchhoff Index of the <i>n</i>-Dimensional Hypercube Network",
           "10.1155/2020/5307670",
           2020,
           "The hypercube Qn is one of the most admirable and efficient interconnection network due to its excellent performance for some practical applications. The Kirchhoff index KfG is equal to the sum of resistance distances between any pairs of vertices in networks. In this paper, we deduce some bounds with respect to Kirchhoff index of hypercube network Qn.",
           0,
           "complexity"
          ],
          [
           "Policy Effectiveness Analysis of China’s Circuit Breaker Mechanism",
           "10.1155/2020/9024723",
           2020,
           "From June to August 2015, China’s security market suffered a severe decline due to the impact of the stock market crash. For this reason, the Shanghai Stock Exchange issued a notice on December 4, 2015, deciding to implement the circuit breaker mechanism on January 1, 2016. However, the mechanism was abolished only four days after its implementation. Therefore, this paper provides an empirical effectiveness analysis of this circuit breaker mechanism based on the nine CSI 300 industries using the regression discontinuity design method. The empirical results show that the implementation of the circuit breaker mechanism has led to the breakpoints of volatilities in nine industries and has significantly increased its market fluctuation. Moreover, we also find that the implementation of the circuit breaker mechanism has different impacts on the different industries, such as the effectiveness of the public, and consumer industries are at the medium level and show more stable fluctuations. Therefore, we suggest that the further circuit breaker mechanism in China’s financial markets can be piloted from the public and consumer industries rather than directly implementing it on the whole CSI 300.",
           0,
           "complexity"
          ],
          [
           "Allocation Optimization of Multi-Axis Suspension Dynamic Parameter for Tracked Vehicle",
           "10.1155/2021/8961020",
           2021,
           "The dynamic parameter allocation of the suspension system has an important influence on the comprehensive driving performance of the tracked vehicle. Usually, the allocation of suspension parameters is based on a single performance index, which has the disadvantage of not being able to achieve multi-performance optimization. Therefore, a novel optimization method using multi-performance index-oriented is presented. Firstly, considering the vertical vibration excitation caused by road roughness, the input (excitation) model of road roughness is embedded to establish the parametric dynamic model of the tracked vehicle. Then, the evaluation index and its quantitative algorithm, which reflect the multi-aspect performance of the suspension system, are proposed. Moreover, the parameter allocation objective function based on multi-index information fusion is designed. Finally, two allocation optimization methods are presented to solve the parameter allocation, i.e., equal weight allocation and expert knowledge-based weight allocation. By comparing the results obtained by the two methods, it is found that the performance of the suspension system can be improved effectively by optimizing the parameters of suspension stiffness and damping. Furthermore, the optimization of weight allocation based on expert knowledge is more effective. These provide a better knowledge reference for suspension system design.",
           0,
           "complexity"
          ],
          [
           "Topology-Aware Bus Routing in Complex Networks of Very-Large-Scale Integration with Nonuniform Track Configurations and Obstacles",
           "10.1155/2021/8843271",
           2021,
           "As one of the most important routing problems in the complex network within a very-large-scale integration (VLSI) circuit, bus routing has become much more challenging when witnessing the advanced technology node enters the deep nanometer era because all bus bits need to be routed with the same routing topology in the context. In particular, the nonuniform routing track configuration and obstacles bring the largest difficulty for maintaining the same topology for all bus bits. In this paper, we first present a track handling technique to unify the nonuniform routing track configuration with obstacles. Then, we formulate the topology-aware single bus routing as an unsplittable flow problem (UFP), which is integrated into a negotiation-based global routing to determine the desired routing regions for each bus. A topology-aware track assignment is also presented to allocate the tracks to each segment of buses under the guidance of the global routing result. Finally, a detailed routing scheme is proposed to connect the segments of each bus. We evaluate our routing result with the benchmark suite of the 2018 CAD Contest. Compared with the top-3 state-of-the-art methods, experimental results show that our proposed algorithm achieves the best overall score regarding specified time limitations.",
           1,
           "complexity"
          ],
          [
           "Synchronization and Antisynchronization of <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" id=\"M1\"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:math>-Coupled Complex Permanent Magnet Synchronous Motor Systems with Ring Connection",
           "10.1155/2017/6743184",
           2017,
           "This paper discusses synchronization and antisynchronization of N-coupled complex permanent magnet synchronous motors systems with ring connection. Based on the direct design method and antisymmetric structure, the appropriate controllers are designed to ensure the occurrence of synchronization and antisynchronization in an array of N-coupled general complex chaotic systems described by a unified mathematical expression with ring connection. The proposed method is flexible and is suitable both for design and for implementation in practice. Numerical results are plotted to show the rapid convergence of errors to zero and further verify the effectiveness and feasibility of the theoretical scheme.",
           4,
           "complexity"
          ],
          [
           "An Interview-Based Study of Pioneering Experiences in Teaching and Learning Complex Systems in Higher Education",
           "10.1155/2018/7306871",
           2018,
           "Due to the interdisciplinary nature of complex systems as a field, students studying complex systems at university level have diverse disciplinary backgrounds. This brings challenges (e.g., wide range of computer programming skills) but also opportunities (e.g., facilitating interdisciplinary interactions and projects) for the classroom. However, little has been published regarding how these challenges and opportunities are handled in teaching and learning complex systems as an explicit subject in higher education and how this differs in comparison to other subject areas. We seek to explore these particular challenges and opportunities via an interview-based study of pioneering teachers and learners (conducted amongst the authors) regarding their experiences. We compare and contrast those experiences and analyze them with respect to the educational literature. Our discussions explored approaches to curriculum design, how theories/models/frameworks of teaching and learning informed decisions and experience, how diversity in student backgrounds was addressed, and assessment task design. We found a striking level of commonality in the issues expressed as well as the strategies handling them, for example, a significant focus on problem-based learning and the use of major student-led creative projects for both achieving and assessing learning outcomes.",
           5,
           "complexity"
          ],
          [
           "Universal laws and economic phenomena",
           "10.1002/cplx.20371",
           2011,
           "Despite the idiosyncratic behavior of individuals, empirical regularities exist in social and economic systems. These regularities often arise from simple underlying mechanisms which, analogous to the natural sciences, can be expressed as universal principles or laws. In this essay, I discuss the similarities between economic and natural phenomena and argue that it is advantageous for economists to adopt methods from the natural sciences to discover “universal laws” in economic systems. © 2011 Wiley Periodicals, Inc. Complexity, 2011",
           1,
           "complexity"
          ],
          [
           "Stability Analysis for Differential Equations of the General Conformable Type",
           "10.1155/2022/7283252",
           2022,
           "Fractional calculus is nowadays an efficient tool in modelling many interesting nonlinear phenomena. This study investigates, in a novel way, the Ulam–Hyers (HU) and Ulam–Hyers–Rassias (HUR) stability of differential equations with general conformable derivative (GCD). In our analysis, we employ some version of Banach fixed-point theory (FPT). In this way, we generalize several earlier interesting results. Two examples are given at the end to illustrate our results.",
           2,
           "complexity"
          ],
          [
           "Dynamic Game and Coordination Strategy of Multichannel Supply Chain Based on Brand Competition",
           "10.1155/2019/4802360",
           2019,
           "In is very important for the corresponding author to have a linked ORCID (Open Researcher and Contributor ID) account on MTS. To register a linked ORCID account, please go to the Account Update page (http://mts.hindawi.com/update/) in our Manuscript Tracking System and after you have logged in click on the ORCID link at the top of the page. This link will take you to the ORCID website where you will be able to create an account for yourself. Once you have done so, your new ORCID will be saved in our Manuscript Tracking System automatically.”\"?>this paper, two noncooperative dynamic pricing strategies are used in a supply chain. Two dynamic Stackelberg game models have been built involving both a manufacturer and a retailer assumed to be the leader in order. In the two models, the manufacturer sells national-brand (NB) product to an independent retailer or directly to consumers through a direct channel. The retailers sell a store-brand (SB) product when they sell the NB product coming from the manufacturer. Thus, there is competition both in different channels and in products with different brands. To analyze the complexity of the model, parameter bifurcation diagrams and strange attractor diagrams have been therefore plotted. The results show that the game leader has advantages when the market is stable, but it turns disadvantageous if the state falls into unstable as the game follower can quickly adjust the strategy to seize the market. The wholesale price and the direct selling price are high that they incur larger profits if the manufacturer is dominant, but it gets worse when the adjustment speed increases. While in the model where the retailer plays a dominant role, the increase in the adjustment speed is unfavorable to retailer. By controlling the total cost of the direct channel and increasing channel competition strength and brand competition strength, the manufacturers can increase their profits in the game dominated by the retailer. In addition, the stable region within the system will be narrow since the market is sensitive to the channel competition, brand competition, and advertising indifference.",
           4,
           "complexity"
          ],
          [
           "A New Mathematical Modeling Method for Four-Stage Helicopter Main Gearbox and Dynamic Response Optimization",
           "10.1155/2019/5274712",
           2019,
           "A new mathematical modeling method, namely, the finite element method and the lumped mass method (LMM-FEM) mixed modeling, is applied to establish the overall multinode dynamic model of a four-stage helicopter main gearbox. The design of structural parameters of the shaft is the critical link in the four-stage gearbox; it affects the response of multiple input and output branches; however, only the meshing pairs were frequently shown in the dynamic model in previous research. Therefore, each shaft is also treated as a single node and the shaft parameters are coupled into the dynamic equations in this method, which is more accurate for the transmission chain. The differential equations of the system are solved by the Fourier series method, and the dynamic response of each meshing element is calculated. The sensitivity analysis method and parameter optimization method are applied to obtain the key shaft parameters corresponding to each meshing element. The results show that the magnitude of dynamic response in converging meshing pair and tail output pair is higher than that of other meshing pairs, and the wall thickness has great sensitivity to a rotor shaft. In addition, the sensitivity analysis method can be used to select the corresponding shaft node efficiently and choose parameters appropriately for reducing the system response.",
           3,
           "complexity"
          ],
          [
           "Weibo Attention and Stock Market Performance: Some Empirical Evidence",
           "10.1155/2018/9571848",
           2018,
           "In this paper, we employ Weibo Index as the proxy for investor attention and analyze the relationships between investor attention and stock market performance, i.e., trading volume, return, and volatility. The empirical results firstly show that Weibo attention is positively related to trading volume, intraday volatility, and return. Secondly, there exist bidirectional causal relationships between Weibo attention and stock market performance. Thirdly, we generally find that higher Weibo attention indicates higher correlation coefficients with the quantile regression analysis.",
           3,
           "complexity"
          ],
          [
           "Model-Based Control with Active Disturbance Rejection Algorithm for a Diesel Engine",
           "10.1155/2023/8429922",
           2023,
           "To improve the speed control performance of a diesel engine, the active disturbance rejection controller (ADRC) is designed by adding an arranging transition process to the traditional PID controller, extracting differential signals reasonably, and adopting nonlinear combination process to error signals. The ADRC is composed of a tracking differentiator (TD), an extended state observer (ESO), and a nonlinear state error feedback (NLSEF). Such constructed ADRC can adapt to the strong nonlinear and complicate working conditions of diesel engine for power generation. A simulation model of the diesel engine is built to verify the proposed ADRC, and simulation results are in good accordance with the experimental results. To further validate the advantages of the designed ADRC, the traditional PID is improved by TD. Meanwhile, performance comparisons are carried out between traditional PID controller, improved PID controller, and ADRC. Results present that the improved PID controller can achieve a better control performance than that of the traditional PID controller both in steady state and transient state. However, the ADRC can further improve the speed control performance evidently on the basis of the improved PID controller.",
           0,
           "complexity"
          ],
          [
           "Competition-Based Benchmarking of Influence Ranking Methods in Social Networks",
           "10.1155/2018/4562609",
           2018,
           "The development of new methods to identify influential spreaders in complex networks has been a significant challenge in network science over the last decade. Practical significance spans from graph theory to interdisciplinary fields like biology, sociology, economics, and marketing. Despite rich literature in this direction, we find small notable effort to consistently compare and rank existing centralities considering both the topology and the opinion diffusion model, as well as considering the context of simultaneous spreading. To this end, our study introduces a new benchmarking framework targeting the scenario of competitive opinion diffusion; our method differs from classic SIR epidemic diffusion, by employing competition-based spreading supported by the realistic tolerance-based diffusion model. We review a wide range of state-of-the-art node ranking methods and apply our novel method on large synthetic and real-world datasets. Simulations show that our methodology offers much higher quantitative differentiation between ranking methods on the same dataset and notably high granularity for a ranking method over different datasets. We are able to pinpoint—with consistency—which influence the ranking method performs better against the other one, on a given complex network topology. We consider that our framework can offer a forward leap when analysing diffusion characterized by real-time competition between agents. These results can greatly benefit the tackling of social unrest, rumour spreading, political manipulation, and other vital and challenging applications in social network analysis.",
           5,
           "complexity"
          ],
          [
           "Performance of Finite Precision on Discrete Chaotic Map Based on a Feedback Shift Register",
           "10.1155/2020/4676578",
           2020,
           "The scintillating technological improvements have changed the process of communication in all parts of the world. Shopping, banking, instant communication, and so on can be operated online and do not care about the linkage of those Internet communications. Because of simple chaotic structure, discrete nature, less arithmetic computation, and high complexity, low-dimensional chaotic systems such as a logistic map and tent map are more attractive than a high-dimensional chaotic system. To overcome the disadvantages of a low-dimensional chaotic map with a finite precision in chaos-based application, the chaotic map with a feedback shift register (CMFSR) is proposed. The related properties and performance associated with CMFSR are analysed. The relationship among the precision of the system, the architecture, and the performance are discussed. The experiments about new pseudorandom number generator (PRNG) based on CMFSR show that our scheme is simple, secure, and easy to accomplish. Experiments show that the proposed architecture of CMFSR is secure for random number generation.",
           3,
           "complexity"
          ],
          [
           "Topological Approaches for Rough Continuous Functions with Applications",
           "10.1155/2021/5586187",
           2021,
           "In this paper, we purposed further study on rough functions and introduced some concepts based on it. We introduced and investigated the concepts of topological lower and upper approximations of near-open sets and studied their basic properties. We defined and studied new topological neighborhood approach of rough functions. We generalized rough functions to topological rough continuous functions by different topological structures. In addition, topological approximations of a function as a relation were defined and studied. Finally, we applied our approach of rough functions in finding the images of patient classification data using rough continuous functions.",
           10,
           "complexity"
          ],
          [
           "MAS-Based Interaction Simulation within Asymmetric Information on Emergency Management of Urban Rainstorm Disaster",
           "10.1155/2020/1759370",
           2020,
           "The frequent occurrence of urban waterlogging constantly affects resident living and urban construction. Improved adaptive prevention and control strategies are highly requested due to huge economic losses and casualties caused by flood and waterlogging in China. The urban waterlogging may evolve into a serious emergency, generally characterized by high complexity, uncertainty, and time pressure. Coupled with the asymmetric information, waterlogging often exacerbates the impact of urban rainstorm disasters. Through the multi-agent system simulation with given geographic information, government and residents interact under dynamic risk distribution in rainstorm disaster. The results show that the proactive attitude of residents and the government towards disaster relief could have a promoting effect for both, thereby increasing the disaster relief efficiency. Obviously, rapid accurate information collection and analysis facilitate disaster relief to a large extent. Meanwhile, appropriate supply rather than excessive supply may mobilize residents’ self-help and balance replenishment of relief supplies.",
           6,
           "complexity"
          ],
          [
           "Complex <math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"M1\">\n                     <mi>q</mi>\n                  </math>-Rung Orthopair Fuzzy <math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"M2\">\n                     <mi>N</mi>\n                  </math>-Soft Sets: A New Model with Applications",
           "10.1155/2021/3690597",
           2021,
           "This research article expands the formal representation of human thinking to a most generalized hybrid theory, namely, complex \n\nq\n\n-rung orthopair fuzzy \n\nN\n\n-soft set. It is able to capture a great deal of graded imprecision and vagueness, which so often appear together in human interpretations. This model renders a parameterized mathematical tool for the ranking-based fuzzy modeling of two-dimensional paradoxical data. To that purpose, the proposed theory integrates complex \n\nq\n\n-rung orthopair fuzzy sets with the parametric structure of \n\nN\n\n-soft sets. The framework that arises captures information beyond the confined space of complex intuitionistic fuzzy \n\nN\n\n-soft sets and complex Pythagorean fuzzy \n\nN\n\n-soft sets, with the assistance of a parameter \n\nq\n\n. We establish the basic set-theoretical operations of this model and prove some of its fundamental properties. The Einstein and other elementary algebraic operations on complex \n\nq\n\n-rung orthopair fuzzy \n\nN\n\n-soft values shall be introduced to broaden the mathematical toolbox of this field. Its relationships with contemporary approaches shall demonstrate its outstanding flexibility. Moreover, we establish two competent multicriteria decision-making algorithms that capture the nuances of periodical inconsistent data. Their feasibility shall be demonstrated with an explicit application to the selection of optimum aerospace technology required for the economic development of the Mexican space agency. A comparative analysis of both strategies with the prevailing techniques substantiates their rationality. In addition, we illustrate this comparative study with an explicative bar chart that shows the compatibility of their outcomes. Finally, we examine the functionality of the proposed model and compare it with alternative theories.",
           6,
           "complexity"
          ],
          [
           "Stability Analysis for a Class of Discrete-Time Nonhomogeneous Markov Jump Systems with Multiplicative Noises",
           "10.1155/2018/1586846",
           2018,
           "This paper is concerned with a class of discrete-time nonhomogeneous Markov jump systems with multiplicative noises and time-varying transition probability matrices which are valued on a convex polytope. The stochastic stability and finite-time stability are considered. Some stability criteria including infinite matrix inequalities are obtained by parameter-dependent Lyapunov function. Furthermore, infinite matrix inequalities are converted into finite linear matrix inequalities (LMIs) via a set of slack matrices. Finally, two numerical examples are given to demonstrate the validity of the proposed theoretical methods.",
           9,
           "complexity"
          ],
          [
           "Dynamic Large-Scale Server Scheduling for IVF Queuing Network in Cloud Healthcare System",
           "10.1155/2021/6670288",
           2021,
           "As one of the most effective medical technologies for the infertile patients, in vitro fertilization (IVF) has been more and more widely developed in recent years. However, prolonged waiting for IVF procedures has become a problem of great concern, since this technology is only mastered by the large general hospitals. To deal with the insufficiency of IVF service capacity, this paper studies an IVF queuing network in an integrated cloud healthcare system, where the two key medical services, that is, egg retrieval and transplantation, are assigned to accomplish in the general hospital, while the routine medical tests are assigned into the community hospital. Based on continuous-time Markov procedure, a dynamic large-scale server scheduling problem in this complicated service network is modeled with consideration of different arrival rates of multiple type of patients and different service capacities of multiple servers that can be defined as doctors of the general hospital. To solve this model, a reinforcement learning (RL) algorithm is proposed, where the reward functions are designed for four conflicting subcosts: setup cost, patient waiting cost, penalty cost for unsatisfied patient personal preferences, and medical cost of patient. The experimental results show that the optimal service rule of each server’s queue obtained by the RL method is significantly superior to the traditional service rule.",
           1,
           "complexity"
          ],
          [
           "First-Order and High-Order Repetitive Control for Single-Phase Grid-Connected Inverter",
           "10.1155/2020/1094386",
           2020,
           "With the increasing demand of users for power sources and quality, how to provide high-quality renewable clean energy has become a key issue of power electronics. The main idea of this paper is to develop a composite control including a PI control and repetitive control for a single-phase grid-connected inverter to eliminate the effects of harmonics, which can obtain better steady-state and dynamic responses of the single-phase inverter system and reduce the net current harmonics. The modelling of a single-phase inverter is first introduced; then a first-order repetitive control is developed for the proposed grid-connected inverter. Moreover, a high-order repetitive controller is adopted to further improve the robustness against the uncertainties in the period of signals. The stability and performance analysis are given for the first-order repetitive control and high-order repetitive control. Finally, comparative simulations are conducted in a circuit-level inverter model, which show the effectiveness of the proposed method.",
           2,
           "complexity"
          ],
          [
           "Dynamic Behavior of a Commensalism Model with Nonmonotonic Functional Response and Density-Dependent Birth Rates",
           "10.1155/2018/9862584",
           2018,
           "In this paper, we propose and analyze a commensalism model with nonmonotonic functional response and density-dependent birth rates. The model can have at most four nonnegative equilibria. By applying the differential inequality theory, we show that each equilibrium can be globally attractive under suitable conditions. However, commensalism can be established only when resources for both species are large enough.",
           4,
           "complexity"
          ],
          [
           "Human mate choice is a complex system",
           "10.1002/cplx.21382",
           2011,
           "From a psychological perspective, human mate choice has been viewed as a problem of identifying the individual cognitive preferences and decisions that explain empirical results such as similarity in attractiveness between mates and the right‐skewed unimodal marriage hazard curves for marriage rates. Agent‐based models provide a powerful theoretical tool for investigating this relationship, but until now have not considered the effects of local neighborhoods or mobility on emergent population dynamics. In failing to do so, they have effectively ruled out the population‐level complexity inherent in human mate choice. Real people live in physical space, and their interactions are constrained by their location in and mobility among physical neighborhoods and social networks. We developed a general model of human mate choice in which agents are localized in space, interact with close neighbors, and tend to range either near or far. At the individual level, our model uses two oft‐used but incompletely understood decision rules: one based on preferences for similar partners, the other for maximally attractive partners. We show that space and mobility can interact nonlinearly with these individual decision rules and nonspatial aspects of the population structure. In particular, local interactions and limited mobility decrease interpair matching and increase mate search time. We also show that it is too easy to fit various model configurations to the scant available data. More data and more specific predictions are required. Human mate choice is a complex system with properties that emerge from space, mobility, and other factors that structure social dynamics. © 2011 Wiley Periodicals, Inc. Complexity, 2011.",
           13,
           "complexity"
          ],
          [
           "Natural networks as thermodynamic systems",
           "10.1002/cplx.21428",
           2012,
           "Natural networks are considered as thermodynamic systems that evolve from one state to another by consuming free energy. The least‐time consumption of free energy is found to result in ubiquitous scale‐free characteristics. The network evolution will yield the scale‐independent qualities because the least‐time imperative will prefer attachment of nodes that contribute most to the free‐energy consumption. The analysis of evolutionary equation of motion, derived from statistical physics of open systems, reveals that evolution of natural networks is a path‐dependent and nondeterministic process. Despite the noncomputability of evolution, many mathematical models of networks can be recognized as approximations of the least‐time process as well as many measures of networks can be appreciated as practical assessments of the system's thermodynamic status. © 2012 Wiley Periodicals, Inc. Complexity, 2012",
           35,
           "complexity"
          ],
          [
           "Outlier detection of air temperature series data using probabilistic finite state automata‐based algorithm",
           "10.1002/cplx.21390",
           2012,
           "This article proposes a probability finite state automata‐based algorithm (PFSAA) for detecting outliers of air temperature series data caused by sensor errors. This algorithm first divides the training samples of air temperature series data into subclusters that will be further used to build finite state automata by splitting and combining techniques. Then, it creates a dynamic transition matrix of PFSA based on probability theories. Finally, the outliers of the remaining test samples are detected by PFSAA. The proposed algorithm is quantitatively validated by the reference data and a traditional backpropagation neural net model. © 2012 Wiley Periodicals, Inc. Complexity, 2012",
           4,
           "complexity"
          ],
          [
           "Systems biology reveals biology of systems",
           "10.1002/cplx.20353",
           2010,
           "In the last decades, genomic and postgenomic technologies obtained a great amount of information on molecular bases of cell physiology and organization. In spite of this, the knowledge of cells and living organisms in their entirety, is far from being achieved. In order to deal with biological complexity, Systems Biology uses a new approach to overcome this inadequacy. Despite different definitions, Systems Biology's view of biological phenomena highlights that a holistic perspective is needed to integrate and understand the huge amount of empirical data which have been collected. This is one of the aspects that makes Systems Biology so interesting, from a theoretical and epistemological point of view, and that renders it a useful tool to help students approach living beings' dynamics within a comprehensive framework of their biological features as well. © 2010 Wiley Periodicals, Inc. Complexity, 2010",
           7,
           "complexity"
          ],
          [
           "Nonlinear Torsional Vibration Analysis and Nonlinear Feedback Control of Complex Permanent Magnet Semidirect Drive Cutting System in Coal Cutters",
           "10.1155/2019/9359218",
           2019,
           "The semidirect drive cutting transmission system of coal cutters is prone to unstable torsional vibration when the resistance values of its driving permanent magnet synchronous motor (PMSM) are affected by changes in temperatures and tough conditions. Besides, the system has the properties of complex electromechanically coupling such as the coupling between electrical parameters and mechanical parameters. Therefore, in this study, the nonlinear torsional vibration equation was established on the basis of the Lagrange-Maxwell theory. Moreover, in light of the nonlinear dynamic bifurcation theory, the system stability was analyzed by taking the resistance value of power motor as the bifurcation parameter. In addition, the influence of subcritical bifurcation on the torsional vibration was studied by investigating the necessary and sufficient conditions for dynamic Hopf bifurcation and classifying the bifurcation types. At last, in order to suppress destabilizing oscillation induced by Hopf bifurcation, the nonlinear feedback controller was constructed, with the introduction of feedback from the motor velocity as well as the selection of voltage value on the q shaft as the controlled variable. Meanwhile, the three-order normal form and controlling parameters of the system were obtained with the aid of the multiple scales method and the harmonic balance method. In this way, the Hopf bifurcation point was transferred to control the stability of Hopf bifurcation and the amplitude of limit cycle, thus guaranteeing reliable and safe operation of the system. The numerical simulation results indicate that the designed controller boosts an ideal controlling effect.",
           2,
           "complexity"
          ],
          [
           "Evolutionary Cooperation in Networked Public Goods Game with Dependency Groups",
           "10.1155/2019/8670802",
           2019,
           "Either in microlevel organizations or macrolevel societies, the individuals acquire benefits or payoffs by forming interdependency groups linked by common interests. Conducting research on the effects of interdependency groups on the evolution of cooperation could have a better understanding of the social dilemma problem. In this paper, we studied a spatial public goods game with nonlocal interdependency groups where each of participants is located in a two-dimensional square lattice or Watts–Strogatz small-world network with payoffs obtaining from the interactions with nearest neighbors. In terms of the enhancement factor, the effects of group density on the evolutionary cooperation can be quite different. For a low enhancement factor, the cooperation level is a nonmonotonic function with the varying density of interdependency groups in the system, which means a proper density of interdependency groups can best promote the cooperative level. For a moderate enhancement factor, a higher density of interdependency groups can always correspond to a higher cooperative level. However, if the enhancement factor is too high, a high density of interdependency groups can impede the evolutionary cooperation. We give the explanations for the different roles of group density of interdependency by using the transition probabilities of C players into D players as well as the reverse. Our findings are very helpful for the understanding of emergence cooperation as well as the cooperation regulation in the selfish individuals.",
           0,
           "complexity"
          ],
          [
           "Incremental Matrix-Based Subspace Method for Matrix-Based Feature Extraction",
           "10.1155/2020/8864594",
           2020,
           "The matrix-based features can provide valid and interpretable information for matrix-based data such as image. Matrix-based kernel principal component analysis (MKPCA) is a way for extracting matrix-based features. The extracted matrix-based feature is useful to both dimension reduction and spatial statistics analysis for an image. In contrast, the efficiency of MKPCA is highly restricted by the dimension of the given matrix data and the size of the training set. In this paper, an incremental method to extract features of a matrix-based dataset is proposed. The method is methodologically consistent with MKPCA and can improve efficiency through incrementally selecting the proper projection matrix of the MKPCA by rotating the current subspace. The performance of the proposed method is evaluated by performing several experiments on both point and image datasets.",
           0,
           "complexity"
          ],
          [
           "Dynamic Learning from Adaptive Neural Control of Uncertain Robots with Guaranteed Full-State Tracking Precision",
           "10.1155/2017/5860649",
           2017,
           "A dynamic learning method is developed for an uncertain n-link robot with unknown system dynamics, achieving predefined performance attributes on the link angular position and velocity tracking errors. For a known nonsingular initial robotic condition, performance functions and unconstrained transformation errors are employed to prevent the violation of the full-state tracking error constraints. By combining two independent Lyapunov functions and radial basis function (RBF) neural network (NN) approximator, a novel and simple adaptive neural control scheme is proposed for the dynamics of the unconstrained transformation errors, which guarantees uniformly ultimate boundedness of all the signals in the closed-loop system. In the steady-state control process, RBF NNs are verified to satisfy the partial persistent excitation (PE) condition. Subsequently, an appropriate state transformation is adopted to achieve the accurate convergence of neural weight estimates. The corresponding experienced knowledge on unknown robotic dynamics is stored in NNs with constant neural weight values. Using the stored knowledge, a static neural learning controller is developed to improve the full-state tracking performance. A comparative simulation study on a 2-link robot illustrates the effectiveness of the proposed scheme.",
           3,
           "complexity"
          ],
          [
           "High-Frequency Trading and Its Impact on Exogenous Liquidity Risk of China’s Stock Index Futures Market before and after Trading Restrictions",
           "10.1155/2020/9192841",
           2020,
           "Since China’s first stock index futures, China Securities Index 300 (CSI300) stock index futures were published in 2010, and China’s stock index futures market is now in a period of rapid development and play a key role in price discovery. During 2014 to 2015, China’s stock index futures market fluctuated abnormally, and the overuse of high-frequency trading (HFT) strategies in the stock index futures market was blamed as the main reason of the abnormal volatility. To lower down market fluctuation, the regulatory institute then announced a series of trade restriction policy to prevent the overuse of HFT behaviour. However, until now, the impact of such trade restriction policy for HFT remains uncertain. To tackle this issue, based on minute-level HFT data from the CSI 300 index futures market, this paper aims to investigate the relationship between HFT and the exogenous liquidity risk and how HFT affects China’s stock index futures market on its liquidity using the liquidity-adjusted value at risk (LVaR) model. The findings indicate that HFT improves the return of the liquidity provider and reduces the exogenous liquidity risk significantly.",
           0,
           "complexity"
          ],
          [
           "Parameter Optimization of Droop Controllers for Microgrids in Islanded Mode by the SQP Method with Gradient Sampling",
           "10.1155/2021/5634274",
           2021,
           "For enhancing the stability of the microgrid operation, this paper proposes an optimization model considering the small-signal stability constraint. Due to the nonsmooth property of the spectral abscissa function, the droop controller parameters’ optimization is a nonsmooth optimization problem. The Sequential Quadratic Programming with Gradient Sampling (SQP-GS) is implemented to optimize the droop controller parameters for solving the nonsmooth problem. The SQP-GS method can guarantee the solution of the optimization problem globally and efficiently converges to stationary points with probability of one. In the current iteration, the gradient of the nonsmooth function can be evaluated on a set of randomly generated nearby points by computing closed-form sensitivities. A test on the microgrid system shows that the optimality and the efficiency of the SQP-GS are better than those of the heuristic algorithms.",
           0,
           "complexity"
          ],
          [
           "Data-Driven Finite Element Models of Passive Filamentary Networks",
           "10.1155/2018/6878265",
           2018,
           "A data-driven procedure is introduced to construct finite element models of heterogeneous systems for which an accurate microscopic description is available. A filter to define coarsened finite element nodal values is defined from the principal modes obtained by singular value decomposition of the microscopic data. The resulting finite element nodal values are subsequently used to reconstruct local linearization of the system behavior, defining drag and stiffness matrices for an overdamped system. The procedure is exemplified for an actin mesh described by Brownian dynamics and eight-node cuboid finite elements but is generally applicable with respect to both the microscopic model and the type of finite element approximation. In contrast to standard finite element formulations derived from hypotheses on assumed deformation behavior, the data-driven procedure introduced here is completely determined by the observed behavior be it obtained from simulations or experiment.",
           1,
           "complexity"
          ],
          [
           "Solution Algorithms for Single-Machine Group Scheduling with Learning Effect and Convex Resource Allocation",
           "10.1155/2021/6615824",
           2021,
           "This paper deals with a single-machine resource allocation scheduling problem with learning effect and group technology. Under slack due-date assignment, our objective is to determine the optimal sequence of jobs and groups, optimal due-date assignment, and optimal resource allocation such that the weighted sum of earliness and tardiness penalties, common flow allowances, and resource consumption cost is minimized. For three special cases, it is proved that the problem can be solved in polynomial time. To solve the general case of problem, the heuristic, tabu search, and branch-and-bound algorithms are proposed.",
           1,
           "complexity"
          ],
          [
           "Some Novel Complex Dynamic Behaviors of a Class of Four-Dimensional Chaotic or Hyperchaotic Systems Based on a Meshless Collocation Method",
           "10.1155/2019/5034025",
           2019,
           "In the field of complex systems, there is a need for better methods of knowledge discovery due to their nonlinear dynamics. The numerical simulation of chaotic or hyperchaotic system is mainly performed by the fourth-order Runge–Kutta method, and other methods are rarely reported in previous work. A new method, which divides the entire intervals into N equal subintervals based on a meshless collocation method, has been constructed in this paper. Some new complex dynamical behaviors are shown by using this new approach, and the results are in good agreement with those obtained by the fourth-order Runge–Kutta method.",
           0,
           "complexity"
          ],
          [
           "Synchronous Reluctance Motor: Dynamical Analysis, Chaos Suppression, and Electronic Implementation",
           "10.1155/2022/8080048",
           2022,
           "Dynamical analysis, chaos suppression and electronic implementation of the synchronous reluctance motor (SynRM) without external inputs are investigated in this paper. The different dynamical behaviors (including monostable periodic behaviors, bistable periodic behaviors, monostable chaotic behaviors, and bistable chaotic behaviors) found in the SynRM without external inputs are illustrated in the two parameters largest Lyapunov exponent (LLE) diagrams, one parameter bifurcation diagram, and phase portraits. The three single controllers are designed to suppress the chaotic behaviors found in SynRM without external inputs. The three proposed single controllers are simple and easy to implement. Numerical simulation results show that the three proposed single controllers are effective. Finally, the dynamical behaviors found in the SynRM without external inputs and the physical feasibility of the three proposed single controllers are validated through circuit implementation on OrCAD-PSpice software.",
           0,
           "complexity"
          ],
          [
           "Herd Behavior and Its Effects on Default in Chinese Microcredit",
           "10.1155/2021/9229871",
           2021,
           "Herd behavior means a mode of behavior will be infected among the individuals in a group, and its existence and influence in specific financial market are uncertain. The paper utilizes the logistic model to test the existence and influence of herd behavior of borrowers in Chinese microcredit market. We find that (1) herd behavior exists in Chinese microcredit market, (2) the two most important factors affecting the default of microcredit resulted from herd behavior are the nature of microcredit institutions and the education level of borrowers, and (3) herd behavior will increase the possibility of default, but it is relatively small.",
           0,
           "complexity"
          ],
          [
           "Partial-State-Constrained Adaptive Intelligent Tracking Control of Nonlinear Nonstrict-Feedback Systems with Unmodeled Dynamics and Its Application",
           "10.1155/2020/8835454",
           2020,
           "In this paper, an adaptive intelligent control scheme is presented to investigate the problem of adaptive tracking control for a class of nonstrict-feedback nonlinear systems with constrained states and unmodeled dynamics. By approximating the unknown nonlinear uncertainties, utilizing Barrier Lyapunov functions (BLFs), and designing a dynamic signal to deal with the constrained states and the unmodeled dynamics, respectively, an adaptive neural network (NN) controller is developed in the frame of the backstepping design. In order to simplify the design process, the nonstrict-feedback form is treated by using the special properties of Gaussian functions. The proposed adaptive control scheme ensures that all variables involved in the closed-loop system are bounded, the corresponding state constraints are not violated. Meanwhile, the tracking error converges to a small neighborhood of the origin. In the end, the proposed intelligent design algorithm is applied to one-link manipulator to demonstrate the effectiveness of the obtained method.",
           1,
           "complexity"
          ],
          [
           "Effect of Physically Realistic Potential Energy Form on Spatial Pattern Complexity in a Collective Motion Model",
           "10.1155/2023/8852349",
           2023,
           "Collective motion models most often use self-propelled particles, which are known to produce organized spatial patterns via their collective interactions. However, there is less work considering the possible organized spatial patterns achievable by non-self-propelled particles (nondriven), i.e., those obeying energy and momentum conservation. Moreover, it is not known how the potential energy interaction between the particles affects the complexity of the patterns. To address this, in this paper, a collective motion model with a pairwise potential energy function that conserved the total energy and momentum of the particles was implemented. The potential energy function was derived by generalizing the Lennard–Jones potential to reduce to gravity-like and billiard-ball-like potentials at the extremes of its parameter range. The particle model was simulated under a number of parameterizations of this generalized potential, and the average complexity of the spatial pattern produced by each was computed. Complexity was measured by tracking the information needed to describe the particle system at different scales (the complexity profile). It was found that the spatial patterns of the particles were the most complex around a specific ratio in the parameters. This parameter ratio described a characteristic shape of the potential energy function that is capable of producing complex spatial patterns. It is suggested that the characteristic shape of the potential energy produces complex behavior by balancing the likelihood for particles to bond. Furthermore, these results demonstrate that complex spatial patterns are possible even in an isolated system.",
           0,
           "complexity"
          ],
          [
           "The Orbital Stability of Solitary Wave Solutions for the Generalized Gardner Equation and the Influence Caused by the Interactions between Nonlinear Terms",
           "10.1155/2019/4209275",
           2019,
           "In this paper, the orbital stability of solitary wave solutions for the generalized Gardner equation is investigated. Firstly, according to the theory of orbital stability of Grillakis-Shatah-Strauss, a general conclusion is given to determine the orbital stability of solitary wave solutions. Furthermore, on the basis of the two bell-shaped solitary wave solutions of the equation, the explicit expressions of the orbital stability discriminants are deduced to give the orbitally stable and instable intervals for the two solitary waves as the wave velocity changing. Moreover, the influence caused by the interaction between two nonlinear terms is also discussed. From the conclusion, it can be seen that the influences caused by this interaction are apparently when 0<p<4, which shows the complexity of this system with two nonlinear terms. Finally, by deriving the orbital stability discriminant d′′(c) in the form of Gaussian hypergeometric function, the numerical simulations of several main conclusions are given in this paper.",
           3,
           "complexity"
          ],
          [
           "Symmetry Groups, Similarity Reductions, and Conservation Laws of the Time-Fractional Fujimoto–Watanabe Equation Using Lie Symmetry Analysis Method",
           "10.1155/2020/4830684",
           2020,
           "In this paper, the time-fractional Fujimoto–Watanabe equation is investigated using the Riemann–Liouville fractional derivative. Symmetry groups and similarity reductions are obtained by virtue of the Lie symmetry analysis approach. Meanwhile, the time-fractional Fujimoto–Watanabe equation is transformed into three kinds of reduced equations and the third of which is based on Erdélyi–Kober fractional integro-differential operators. Furthermore, the conservation laws are also acquired by Ibragimov’s theory.",
           6,
           "complexity"
          ],
          [
           "Forecasting Natural Gas Consumption of China Using a Novel Grey Model",
           "10.1155/2020/3257328",
           2020,
           "As is known, natural gas consumption has been acted as an extremely important role in energy market of China, and this paper is to present a novel grey model which is based on the optimized nonhomogeneous grey model (ONGM (1,1)) in order to accurately predict natural gas consumption. This study begins with proving that prediction results are independent of the first entry of original series using the product theory of determinant; on this basis, it is a reliable approach by inserting an arbitrary number in front of the first entry of original series to extract messages, which has been proved that it is an appreciable approach to increase prediction accuracy of the traditional grey model in the earlier literature. An empirical example often appeared in testing for prediction accuracy of the grey model is utilized to demonstrate the effectiveness of the proposed model; the numerical results indicate that the proposed model has a better prediction performance than other commonly used grey models. Finally, the proposed model is applied to predict China’s natural gas consumption from 2019 to 2023 in order to provide some valuable information for energy sectors and related enterprises.",
           7,
           "complexity"
          ],
          [
           "Multiplex Networks of the Guarantee Market: Evidence from China",
           "10.1155/2017/9781890",
           2017,
           "We investigate a multiplex network of the guarantee market with three layers corresponding to different types of guarantee relationships in China. We find that three single-layer networks all have the scale-free property and are of disassortative nature. A single-layer network is not quite representative of another single-layer network. The result of the betweenness centrality shows that central companies in one layer are not necessarily central in another layer. And the eigenvector centrality has the same result of the betweenness centrality except the top central company.",
           12,
           "complexity"
          ],
          [
           "Reconstructing Mesoscale Network Structures",
           "10.1155/2019/5120581",
           2019,
           "When facing the problem of reconstructing complex mesoscale network structures, it is generally believed that models encoding the nodes organization into modules must be employed. The present paper focuses on two block structures that characterize the empirical mesoscale organization of many real-world networks, i.e., the bow-tie and the core-periphery ones, with the aim of quantifying the minimal amount of topological information that needs to be enforced in order to reproduce the topological details of the former. Our analysis shows that constraining the network degree sequences is often enough to reproduce such structures, as confirmed by model selection criteria as AIC or BIC. As a byproduct, our paper enriches the toolbox for the analysis of bipartite networks, still far from being complete: both the bow-tie and the core-periphery structure, in fact, partition the networks into asymmetric blocks characterized by binary, directed connections, thus calling for the extension of a recently proposed method to randomize undirected, bipartite networks to the directed case.",
           13,
           "complexity"
          ],
          [
           "Key Elements Affecting the Library’s CFU Concentration in Taiwan",
           "10.1155/2023/9345311",
           2023,
           "Public libraries are popular gathering places, so understanding the factors that contribute to colony-forming unit (CFU) concentrations and how to minimize them is essential. This study aimed to investigate the factors that affect CFU concentrations in a public library, using air sampling (Bioluminescent ATP-assay) and statistical analysis software (SPSS) to collect and analyze data. The findings indicated that the CFU concentration in the library was significantly influenced by the air quality surrounding the building, the number of library visitors, and the hygiene and health of both visitors and employees. Additionally, indoor temperature and humidity were found to be key factors affecting CFU concentration. These findings suggest the need for better ventilation and air filtration systems, as well as regular cleaning and disinfection in public libraries. Furthermore, research is recommended to investigate other potential factors that may impact indoor air quality in public spaces.",
           0,
           "complexity"
          ],
          [
           "GANs with Multiple Constraints for Image Translation",
           "10.1155/2018/4613935",
           2018,
           "Unpaired image translation is a challenging problem in computer vision, while existing generative adversarial networks (GANs) models mainly use the adversarial loss and other constraints to model. But the degree of constraint imposed on the generator and the discriminator is not enough, which results in bad image quality. In addition, we find that the current GANs-based models have not yet been implemented by adding an auxiliary domain, which is used to constrain the generator. To solve the problem mentioned above, we propose a multiscale and multilevel GANs (MMGANs) model for image translation. In this model, we add an auxiliary domain to constrain generator, which combines this auxiliary domain with the original domains for modelling and helps generator learn the detailed content of the image. Then we use multiscale and multilevel feature matching to constrain the discriminator. The purpose is to make the training process as stable as possible. Finally, we conduct experiments on six image translation tasks. The results verify the validity of the proposed model.",
           7,
           "complexity"
          ],
          [
           "Some Topological Notations via Maki’s Λ-Sets",
           "10.1155/2020/4237462",
           2020,
           "Our purpose is to present the notions of a β-Λ-set and a β-V-sets in topological space. We discuss the basic properties of β-Λ-sets and β-V-sets. Also, the achievement of the topology defined by these families of sets is obtained. Finally, these results are applied to the case of X,τ which is the digital n-space Zn,Kn (cf. Section 4).",
           2,
           "complexity"
          ],
          [
           "The Extended Exponential Weibull Distribution: Properties, Inference, and Applications to Real-Life Data",
           "10.1155/2022/4068842",
           2022,
           "A novel version of the exponential Weibull distribution known as the extended exponential Weibull (ExEW) distribution is developed and examined using the Lehmann alternative II (LAII) generating technique. The new distributions basic mathematical properties are derived. The maximum likelihood estimation (MLE) technique is used to estimate the unknown parameters of the proposed distribution. The estimators’ performance is further assessed using the Monte Carlo simulation technique. Eventually, two real-world data sets are utilized to show the applicability of the new distribution.",
           3,
           "complexity"
          ],
          [
           "A Comparative Study of Three Resolving Parameters of Graphs",
           "10.1155/2021/1927181",
           2021,
           "Graph theory is one of those subjects that is a vital part of the digital world. It is used to monitor the movement of robots on a network, to debug computer networks, to develop algorithms, and to analyze the structural properties of chemical structures, among other things. It is also useful in airplane scheduling and the study of diffusion mechanisms. The parameters computed in this article are very useful in pattern recognition and image processing. A number \n\nd\n\n\nf\n,\nw\n\n\n=\nmin\n\n\nd\n\n\nw\n,\nt\n\n\n,\nd\n\n\nw\n,\ns\n\n\n\n\n\n is referred as distance between \n\nf\n=\nt\ns\n\n an edge and \n\nw\n\n a vertex. \n\nd\n\n\nw\n,\n\n\nf\n\n\n1\n\n\n\n\n≠\nd\n\n\nw\n,\n\n\nf\n\n\n2\n\n\n\n\n\n implies that two edges \n\n\n\nf\n\n\n1\n\n\n,\n\n\nf\n\n\n2\n\n\n∈\nE\n\n are resolved by node \n\nw\n∈\nV\n\n. A set of nodes \n\nA\n\n is referred to as an edge metric generator if every two links/edges of \n\nΓ\n\n are resolved by some nodes of \n\nA\n\n and least cardinality of such sets is termed as edge metric dimension, \n\ne\ndim\n\n\nΓ\n\n\n\n for a graph \n\nΓ\n\n. A set \n\nB\n\n of some nodes of \n\nΓ\n\n is a mixed metric generator if any two members of \n\nV\n∪\nE\n\n are resolved by some members of \n\nB\n\n. Such a set \n\nB\n\n with least cardinality is termed as mixed metric dimension, \n\nm\ndim\n\n\nΓ\n\n\n\n. In this paper, the metric dimension, edge metric dimension, and mixed metric dimension of dragon graph \n\n\n\nT\n\n\nn\n,\nm\n\n\n\n, line graph of dragon graph \n\nL\n\n\n\n\nT\n\n\nn\n,\nm\n\n\n\n\n\n, paraline graph of dragon graph \n\nL\n\n\nS\n\n\n\n\nT\n\n\nn\n,\nm\n\n\n\n\n\n\n\n, and line graph of line graph of dragon graph \n\nL\n\n\nL\n\n\n\n\nT\n\n\nn\n,\nm\n\n\n\n\n\n\n\n have been computed. It is shown that these parameters are constant, and a comparative analysis is also given for the said families of graphs.",
           2,
           "complexity"
          ],
          [
           "An Approach to Interval-Valued Hesitant Fuzzy Multiattribute Group Decision Making Based on the Generalized Shapley-Choquet Integral",
           "10.1155/2018/3941847",
           2018,
           "The purpose of this paper is to develop an approach to multiattribute group decision making under interval-valued hesitant fuzzy environment. To do this, this paper defines some new operations on interval-valued hesitant fuzzy elements, which eliminate the disadvantages of the existing operations. Considering the fact that elements in a set may be interdependent, two generalized interval-valued hesitant fuzzy operators based on the generalized Shapley function and the Choquet integral are defined. Then, some models for calculating the optimal fuzzy measures on the expert set and the ordered position set are established. Because fuzzy measures are defined on the power set, it makes the problem exponentially complex. To simplify the complexity of solving a fuzzy measure, models for the optimal 2-additive measures are constructed. Finally, an investment problem is offered to show the practicality and efficiency of the new method.",
           7,
           "complexity"
          ],
          [
           "Wiener and Hyper-Wiener Indices of Polygonal Cylinder and Torus",
           "10.1155/2021/8882646",
           2021,
           "In this study, we first introduce polygonal cylinder and torus using Cartesian products and topologically identifications and then find their Wiener and hyper-Wiener indices using a quick, interesting technique of counting. Our suggested mathematical structures could be of potential interests in representation of computer networks and enhancing lattice hardware security.",
           1,
           "complexity"
          ],
          [
           "Simulating the Sustainability of Xiong’an New Area Undertaking the Industrial Transfer from Beijing",
           "10.1155/2021/9927397",
           2021,
           "The national new area Xiong’an has been established to take over the noncapital functions of Beijing in China. In light of local resources and environmental constraints, it is important to clarify the mode of industrial transfer for Xiong’an new area (XNA) to achieve the developmental goals. This study simulates and analyzes the speed of industrial transfer and the capacities of XNA in light of resource and environmental constraints. The results show that, to just realize modernization in 2035, the transfer rate of the secondary industry and tertiary industry is annually 3.7 billion yuan and 6.4 billion yuan, respectively. But at this speed, the atmospheric environment will be overloaded by 2028. The minimum and maximum transfer rate to realize modernization in 2035 without overloading resources and environment are also specified as well as the total size of economy and population. The results indicate that land for the construction of XNA is rich, but local water is not sufficient to support industrial growth. The atmospheric environment of XNA is also an important limiting factor. It is thus necessary to reduce air pollution and increase the population and industrial scale of the area by increasing the transfer rate of the tertiary industry.",
           3,
           "complexity"
          ],
          [
           "Some Nonlinear Fractional PDEs Involving<mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" id=\"M1\"><mml:mi>β</mml:mi></mml:math>-Derivative by Using Rational<mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" id=\"M2\"><mml:mi mathvariant=\"normal\">exp</mml:mi><mml:mfenced open=\"(\" close=\")\" separators=\"|\"><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant=\"normal\">Ω</mml:mi><mml:mfenced open=\"(\" close=\")\" separators=\"|\"><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math>-Expansion Method",
           "10.1155/2020/9179826",
           2020,
           "In this article, some new nonlinear fractional partial differential equations (PDEs) (the space-time fractional order Boussinesq equation; the space-time (2 + 1)-dimensional breaking soliton equations; and the space-time fractional order SRLW equation) have been considered, in which the treatment of these equations in the diverse applications are described. Also, the fractional derivatives in the sense ofβ-derivative are defined. Some fractional PDEs will convert to consider ordinary differential equations (ODEs) with the help of transformationβ-derivative. These equations are analyzed utilizing an integration scheme, namely, the rationalexp−Ωη-expansion method. Different kinds of traveling wave solutions such as solitary, topological, dark soliton, periodic, kink, and rational are obtained as a by product of this scheme. Finally, the existence of the solutions for the constraint conditions is also shown. The outcome indicates that some fractional PDEs are used as a growing finding in the engineering sciences, mathematical physics, and so on.",
           1,
           "complexity"
          ],
          [
           "Hybrid-Driven Mechanism Based on Uncertain Network for Markov Jump System with Quantizations and Delay",
           "10.1155/2020/3148252",
           2020,
           "This paper investigates the hybrid-driven mechanism problem for Markov jump system, where both channel quantization (BCQ) and network-induced delay based on uncertain network are considered. Firstly, comparing with the traditional event-triggered scheme, a hybrid-driven mechanism is employed in networked control systems (NCSs) for the finite capacity of communication bandwidth resources and system performance in equilibrium. Then, the quantization technology is applied in the communication channel from sensor-to-controller and controller-to-actuator. The application of BCQ is for further investigation that mitigate data packet transmission rate. Thirdly, Markov jump system is modeled for the hybrid-driven mechanism and network-induced delay. By constructing the Lyapunov–Krasovskii function, a sufficient condition is derived as the stability criterion, and the controller is designed in which the nonlinear term is rewritten for simplifying the calculation. Finally, two simulation examples are provided to demonstrate the effectiveness of the proposed approach.",
           2,
           "complexity"
          ],
          [
           "Incremental Adaptive Control of a Class of Nonlinear Nonaffine Systems",
           "10.1155/2022/2847785",
           2022,
           "As a class of familiar nonlinear systems, nonaffine systems are frequently encountered in practical applications. Currently, in the context of learning control, there is a lack of research results about such general class of nonlinear systems, especially for the case of performing infinite interval tasks. This article focuses on the incremental adaptive control for nonlinear systems in nonaffine form, without requiring periodicity or repeatability. Instead of using the integral adaptation, incremental adaptive mechanisms are developed and the corresponding control schemes are presented, by which the numerical integration for implementation can be avoided. With the proposed incremental adaptation, the implicit function theorem is introduced to solve the intractability problem of the nonaffine structure. The robustness (robust convergence) of the tracking error is characterized, with the aid of a proposed key lemma, while the boundedness of all the variables is examined. Numerical results are presented to verify the effectiveness of the proposed control design.",
           1,
           "complexity"
          ],
          [
           "Information Propagation Influenced by Population Heterogeneity Behavioral Adoption on Weighted Network",
           "10.1155/2022/4217101",
           2022,
           "In the realistic world, various individuals have distinct personalities, preferences, and attitudes toward new information and behavior acceptance, called population heterogeneity. It is seldom taken into account and theoretically analyzed in information propagation on a weighted network. Therefore, we divide individuals into fashionable and conservative individuals according to their passion degree and willingness for novel behaviors acceptance. Then, we build two behavior adoption threshold models corresponding to fashionable and conservative individuals on the weighted network to explore the effect of population heterogeneity on information propagation. Next, a partition theory based on edge weight and population heterogeneity is proposed to qualitatively analyze the information propagation mechanism. The theoretical analyses and simulation results show that fashionable individuals promote information propagation and behavior adoption. More importantly, the crossover phenomena of phase transition appear. When the fraction of fashionable individuals is relatively large, the increasing pattern of the final adoption size shows a second-order continuous phase transition. In comparison, the increasing pattern alters to first-order discontinuous phase transition with the decrease of the fraction of fashionable individuals. Moreover, reducing weight distribution heterogeneity promotes information propagation and slightly accelerates the change of the phase transition pattern from the first-order discontinuous to the second-order continuous. Besides, increasing the degree distribution heterogeneity accelerates the change of the phase transition pattern. Finally, our theoretical analyses coincide well with the simulation results.",
           1,
           "complexity"
          ],
          [
           "Complexity Construction of Intelligent Marketing Strategy Based on Mobile Computing and Machine Learning Simulation Environment",
           "10.1155/2021/9910834",
           2021,
           "Mankind’s research on marketing has a history of hundreds of years, and it has been fruitful in continuous summary and research. Now the theory of marketing has gradually penetrated into the minds of every company and even individual. A successful marketing strategy is the inevitable result of scientific planning and effective implementation. However, the current marketing strategy has gradually failed to meet the needs of corporates. In order to find the best solution for corporate marketing strategy, we built a simulation environment based on mobile computing and machine learning and compared the differences by simulating several companies of the same size in this city (corporate efficiency and revenue and expenditure under the marketing strategy). The results of the study found that intelligent marketing based on machine learning is more suitable for enterprises than general marketing strategies. The efficiency of enterprises has increased by about 20%, and the income of enterprises has increased by more than 30% compared with traditional marketing strategies. This shows that the intelligent marketing strategy based on mobile computing and machine learning to build a simulated environment plays an extremely important role in the peculiarities.",
           1,
           "complexity"
          ],
          [
           "Infrared power generation in an insulated compartment",
           "10.1002/cplx.21484",
           2013,
           "The mechanism that activates a bi‐junction power generator under the effects of heat is the Seebeck effect, that is, the production of voltage difference ΔV(t) is directly proportional to the temperature difference ΔT(t) between the “hot” and “cold” junctions of the device. This phenomenon is well established and is known as thermoelectric power generation. Here, it is shown that, instead, the causal and linear relationship between ΔV(t) and ΔT(t) is lost when continuous broadband infrared (CB‐IR) radiation illuminates a bi‐junction power generator in an insulated compartment. The observed phenomenon is IR power generation. Heat transfer calculations fail in explaining the experimental trends. The interaction between CB‐IR radiation and the charge carriers in the bi‐junction power generator might play a role in the ΔV(t) production, depending upon the geometry of the experimental setup. The longitudinal propagation of collective oscillations, for example, polaritons, in the plates protecting the “hot” and “cold” junctions of the bi‐junction power generator could explain the ΔV(t) production and the characteristic time constants. The findings should be considered in the design, fabrication, and improvement of thermopiles, power meters, and IR energy‐harvesting devices. © 2013 Wiley Periodicals, Inc. Complexity 19: 44–55, 2014",
           4,
           "complexity"
          ],
          [
           "Data analysis using circular causality in networks",
           "10.1002/cplx.21480",
           2013,
           "Complex systems in causal relationships are known to be circular rather than linear; this means that a particular result is not produced by a single cause, but rather that both positive and negative feedback processes are involved. However, although interpreting systemic interrelationships requires a language formed by circles, this has only been developed at the diagram level, and not from an axiomatic point of view. The first difficulty encountered when analysing any complex system is that usually the only data available relate to the various variables, so the first objective was to transform these data into cause‐and‐effect relationships. Once this initial step was taken, our discrete chaos theory could be applied by finding the causal circles that will form part of the system attractor and allow their behavior to be interpreted. As an application of the technique presented, we analyzed the system associated with the transcription factors of inflammatory diseases. © 2013 Wiley Periodicals, Inc. Complexity 19: 15–19, 2014",
           6,
           "complexity"
          ],
          [
           "An Exponential Varying-Parameter Neural Network for Repetitive Tracking of Mobile Manipulators",
           "10.1155/2020/8520835",
           2020,
           "A novel exponential varying-parameter neural network (EVPNN) is presented and investigated to solve the inverse redundancy scheme of the mobile manipulators via quadratic programming (QP). To suspend the phenomenon of drifting free joints and guarantee high convergent precision of the end effector, the EVPNN model is applied to trajectory planning of mobile manipulators. Firstly, the repetitive motion scheme for mobile manipulators is formulated into a QP index. Secondly, the QP index is transformed into a time-varying matrix equation. Finally, the proposed EVPNN method is used to solve the QP index via the matrix equation. Theoretical analysis and simulations illustrate that the EVPNN solver has an exponential convergent speed and strong robustness in mobile manipulator applications. Comparative simulation results demonstrate that the EVPNN possesses a superior convergent rate and accuracy than the traditional ZNN solver in repetitive trajectory planning with a mobile manipulator.",
           1,
           "complexity"
          ],
          [
           "A Quasi-3D Numerical Model for Grout Injection in a Parallel Fracture Based on Finite Volume Method",
           "10.1155/2019/4139616",
           2019,
           "The purpose of the present work is to develop a quasi-3D numerical method that can be used to study the diffusion mechanism of grout injection in a rock fracture based on the collocated structured grid of the finite volume method (FVM). Considering the characteristics of fracture in geometry that the aperture is much less than its length and width, the Hele-Shaw model is introduced to deduce the z-derivatives of velocities u and v at walls, which is a function of the relevant average velocity and the fracture aperture. The traditional difference scheme for the diffusive term is partly substituted with the derived analytical expressions; hence a three-dimensional problem of grout flow in the parallel fracture can be transformed into a two-dimensional one that concerns fracture aperture. The new model is validated by the analytical solution and experimental data on three cases of grouting in the parallel-plate fracture. Compared with the results from ANSYS-Fluent software, the present model shows better agreement with the analytical solution for the distribution of pressure and velocity. Furthermore, the new model needs less grid unit, spends less time, but achieves greater accuracy. The complexity of the grout flow field in the rock fracture is reduced; thus the computational efficiency can be improved significantly.",
           2,
           "complexity"
          ],
          [
           "Inherent Stability of Multibody Systems with Variable-Stiffness Springs via Absolute Stability Theory",
           "10.1155/2021/8662275",
           2021,
           "In this paper, the inherent stability problem for multibody systems with variable-stiffness springs (VSSs) is studied. Since multibody systems with VSSs may consume energy during the variation of stiffness, the inherent stability is not always ensured. The motivation of this paper is to present sufficient conditions that ensure the inherent stability of multibody systems with VSSs. The absolute stability theory is adopted, and N-degree-of-freedom (DOF) systems with VSSs are formulated as a Lur’e form. Furthermore, based on the circle criterion, sufficient conditions for the inherent stability of the systems are obtained. In order to verify these conditions, both frequency-domain and time-domain numerical simulations are conducted for several typical low-DOF systems.",
           0,
           "complexity"
          ],
          [
           "Price Dynamics in an Order-Driven Market with Bayesian Learning",
           "10.1155/2018/8254068",
           2018,
           "In this paper, we have developed a model of limit order book with learning mechanism and investigated its price dynamics. In this model, continuous Bayesian learning is introduced to describe the dynamics of self-adjusting learning mechanism of agents, which can result in some important stylized facts of limit order markets. This study also provides some behavioral explanations for these well-known stylized facts that are commonly observed in the financial markets.",
           0,
           "complexity"
          ],
          [
           "A Virus Propagation Model and Optimal Control Strategy in the Point-to-Group Network to Information Security Investment",
           "10.1155/2021/6612451",
           2021,
           "Epidemiological dynamics is a vital method in studying the spread of computer network viruses. In this paper, an optimal control measure is proposed based on the SEIR virus propagation model in point-to-group information networks. First, considering the need for antivirus measures in reality, an optimal control problem is introduced, and then a controlled computer virus spread model in point-to-group information networks is established. Second, the optimal control measure is formulated by making a tradeoff between control cost and network loss caused by virus intrusion. Third, optimal control strategies are theoretically investigated by Pontryagin’s maximum principle and the Hamiltonian function. Finally, through numerical simulations, effective measures for controlling virus spread in point-to-group information networks are proposed.",
           0,
           "complexity"
          ],
          [
           "A Generalization of the Cauchy-Schwarz Inequality and Its Application to Stability Analysis of Nonlinear Impulsive Control Systems",
           "10.1155/2019/6048909",
           2019,
           "In this paper, we first present a generalization of the Cauchy-Schwarz inequality. As an application of our result, we obtain a new sufficient condition for the stability of a class of nonlinear impulsive control systems. We end up this note with a numerical example which shows the effectiveness of our method.",
           1,
           "complexity"
          ],
          [
           "Bicriterion Optimization for Flow Shop with a Learning Effect Subject to Release Dates",
           "10.1155/2018/9149510",
           2018,
           "This paper investigates a two-machine flow shop problem with release dates in which the job processing times are variable according to a learning effect. The bicriterion is to minimize the weighted sum of makespan and total completion time subject to release dates. We develop a branch-and-bound (B&B) algorithm to solve the problem by using a dominance property, several lower bounds, and an upper bound to speed up the elimination process of the search tree. We further propose a multiobjective memetic algorithm (MOMA), enhanced by an initialization strategy and a global search strategy, to obtain the Pareto front of the problem. Computational experiments are also carried out to examine the effectiveness and the efficiency of the B&B algorithm and the MOMA algorithm.",
           5,
           "complexity"
          ],
          [
           "Vehicle-Mounted Photovoltaic System Energy Management in Intelligent Transportation Systems: A Maximum Power Point Tracking Control",
           "10.1155/2021/5578972",
           2021,
           "Electric vehicles have become the main contributor in terms of reducing fuel consumption and CO2 emission. Although the government is vigorously promoting the use of electric vehicles worldwide, the range anxiety still impedes the rapid development of electric vehicles, especially when air-conditioning also adds battery power consumption and aggravates the range anxiety. To this end, this paper proposes an improved vehicle-mounted photovoltaic system energy management in intelligent transportation systems, which is a maximum power point tracking control system. Meanwhile, since the power of solar panels is usually relatively small and the power changes at any time, low power density and poor controllability are difficult to avoid. In order to solve this problem, this paper offers a tracking control method to improve the output efficiency of solar panels. For improving photovoltaic conversion efficiency and maximizing output power, traditional photovoltaic power panels are often dominated by a centralized maximum power point tracing control, which is named MPPT. Although the cost under this case is lower, the output power of all photovoltaic panels cannot be maximized under the condition of uneven illumination or local mismatch. To improve the situation, a micro-scale inverter is proposed to provide MPPT control of photovoltaic modules, which can effectively improve the output power of each photovoltaic panel. Moreover, our MPPT algorithm is applicable to cloud shadow, building shadow, and shade, and it is more suitable for the car roof. Firstly, the Diode 5-parameter model is used to deduce the I-U equation of the photovoltaic module considering shadow shading, and then the real-time 5 parameter equation is formed by using the measured data group and selected. The reasonable initial value is used to iteratively solve the real-time value of 5 parameters, which is further to judge the masking situation. The maximum power point (MPP) is solved directly by the mathematical method based on the mathematical model of I-U relation mathematics, and the DC-DC circuit is used to adjust the running point to MPP. Unlike the traditional MPPT method, the method in this paper is based on the physical model of solar cells, and MPP tracking is based on mathematical methods. Based on this, it does not need to cause multiple interference to the circuit, and the tracking efficiency is high. Finally, the relative experimental results are provided to verify the performance of the proposed method.",
           0,
           "complexity"
          ],
          [
           "Initial Value Determination of Chua System with Hidden Attractors and Its DSP Implementation",
           "10.1155/2020/7638243",
           2020,
           "In this paper, a method for determining the initial value of the hidden attractors in the Chua system is studied. The initial value of the hidden attractors can be calculated quickly and accurately by the proposed method, and the hidden attractors can be found by numerical simulation. Then, the initial values of the hidden attractors are set accurately by digital signal processor (DSP), so as to the circuit realization of the chaotic system with hidden attractors is performed. The results show that the numerical simulation results of Matlab are consistent with the experimental results of DSP.",
           1,
           "complexity"
          ],
          [
           "Anatomy of Complex System Research",
           "10.1155/2020/5208356",
           2020,
           "Complex systems play important roles in science and economy and have become one of the major intellectual and scientific challenges of the twenty-first century. However, the way complex system research connects to other academic fields is much less well understood, with only anecdotal evidence. In this work, we present an anatomy of complex system research by leveraging a large-scale dataset that contains more than 100 million digitalized publications. First, we find that complex system research shows a steady growth relative to the whole science in the last 60 years, with a sudden burst after 2000, which might be related to the development of computational technologies. Although early complex system study shows strong referencing behaviors to mathematics and physics, it couples significantly with computer science in the twenty-first century and affects engineering strongly. Moreover, we find empirical evidence that complex system research tends to have multidisciplinary nature, as it is often inspired by or affects a diverse set of disciplines. Finally, we find significant positive correlations between fields’ reference broadness and future scientific impacts. Overall, our findings are consistent with several characteristics of complex system research, i.e., its multidisciplinary, quantitative, and computational nature, and may have broad policy implications for supporting and nurturing multidisciplinary research.",
           4,
           "complexity"
          ],
          [
           "Speed Tracking and Synchronization of a Multimotor System Based on Fuzzy ADRC and Enhanced Adjacent Coupling Scheme",
           "10.1155/2018/5632939",
           2018,
           "In this paper, a speed tracking and synchronization control approach is proposed for a multimotor system based on fuzzy active disturbance rejection control (FADRC) and enhanced adjacent coupling scheme. By employing fuzzy logic rules to adjust the coefficients of the extended state observer (ESO), FADRC is presented to guarantee the speed tracking performance and enhance the system robustness against external disturbance and parametric variations. Moreover, an enhanced adjacent coupling synchronization control strategy is proposed to simplify the structure of the speed synchronization controller through introducing coupling coefficients into the conventional adjacent coupling approach. Based on the proposed synchronization control scheme, an adaptive integral sliding mode control (AISMC) is investigated such that the chattering problem in conventional sliding mode control can be weakened by designing an adaptive estimation law of the control gain. Comparative simulations are carried out to prove the superiorities of the proposed method.",
           10,
           "complexity"
          ],
          [
           "A Novel Approach to a Time-Dependent-Coefficient WBK System: Doubly Periodic Waves and Singular Nonlinear Dynamics",
           "10.1155/2018/3158126",
           2018,
           "Under investigation in this paper is a more general time-dependent-coefficient Whitham-Broer-Kaup (tdcWBK) system, which includes some important models as special cases, such as the approximate equations for long water waves, the WBK equations in shallow water, the Boussinesq-Burgers equations, and the variant Boussinesq equations. To construct doubly periodic wave solutions, we extend the generalized F-expansion method for the first time to the tdcWBK system. As a result, many new Jacobi elliptic doubly periodic solutions are obtained; the limit forms of which are the hyperbolic function solutions and trigonometric function solutions. It is shown that the original F-expansion method cannot derive Jacobi elliptic doubly periodic solutions of the tdcWBK system, but the novel approach of this paper is valid. To gain more insight into the doubly periodic waves contained in the tdcWBK system, we simulate the dynamical evolutions of some obtained Jacobi elliptic doubly periodic solutions. The simulations show that the doubly periodic waves possess time-varying amplitudes and velocities as well as singularities in the process of propagations.",
           5,
           "complexity"
          ],
          [
           "Positioning of the Moving and Static Contacts of the Switch Machine Based on Double-Layer Mask R-CNN",
           "10.1155/2021/8655499",
           2021,
           "With the continuous development of rail transit, the maintenance of the switch machine becomes more and more important, and the contact depth of the moving contact and static contact in the switch machine is a key part of it. At present, the manual measurement method is the main measure of contact depth, which has the problems of low efficiency and strong subjectivity. The measurement of contact depth based on machine vision includes two steps: moving and static contact positioning and distance conversion. The positioning result will have an important impact on distance measurement. Therefore, a positioning method for moving and static contact based on double-layer Mask R-CNN (DLM) is proposed in this paper: first, the moving contact is roughly positioned by Mask R-CNN to obtain the predicted target area; second, the subgraph of the target area is preprocessed; finally, the precise positioning is used to determine the precise position of the moving and static contact. The accuracy and robustness of the proposed DLM are verified by the internal image of the switch machine.",
           1,
           "complexity"
          ],
          [
           "Bursting Oscillation and Its Mechanism of a Generalized Duffing–Van der Pol System with Periodic Excitation",
           "10.1155/2021/5556021",
           2021,
           "The complex bursting oscillation and bifurcation mechanisms in coupling systems of different scales have been a hot spot domestically and overseas. In this paper, we analyze the bursting oscillation of a generalized Duffing–Van der Pol system with periodic excitation. Regarding this periodic excitation as a slow-varying parameter, the system can possess two time scales and the equilibrium curves and bifurcation analysis of the fast subsystem with slow-varying parameters are given. Through numerical simulations, we obtain four kinds of typical bursting oscillations, namely, symmetric fold/fold bursting, symmetric fold/supHopf bursting, symmetric subHopf/fold cycle bursting, and symmetric subHopf/subHopf bursting. It is found that these four kinds of bursting oscillations are symmetric. Combining the transformed phase portrait with bifurcation analysis, we can observe bursting oscillations obviously and further reveal bifurcation mechanisms of these four kinds of bursting oscillations.",
           8,
           "complexity"
          ],
          [
           "Interacting neural networks and the emergence of social structure",
           "10.1002/cplx.20163",
           2007,
           "The article describes a computational model for the simulation of the emergence of social structure or social order, respectively. The model is theoretically based on the theory of social typifying by Berger and Luckmann. It consists of interacting artificial actors (agents), which are represented by two neural networks, an action net, and a perception net. By mutually adjusting of their actions, the agents are able to constitute a self‐organized social order in dependency of their personal characteristics and certain features of their environment. A fictitious example demonstrates the applicability of the model to problems of extra‐terrestrial robotics. © 2007 Wiley Periodicals, Inc. Complexity 12: 41–52, 2007",
           1,
           "complexity"
          ],
          [
           "The advantage of complexity in two 2 × 2 games",
           "10.1002/cplx.20038",
           2004,
           "Competing populations of finite automata co‐evolve in an evolutionary algorithm to play two player games. Populations endowed with greater complexity do better against their less complex opponents in a strictly competitive constant sum game. In contrast, complexity determines efficiency levels, but not relative earnings, in a Prisoner's Dilemma game; greater levels of complexity result in mutually higher earnings. With reporting noise, advantages to complexity are lost and efficiency levels are reduced as relatively less complex strategies are selected. © 2004 Wiley Periodicals, Inc. Complexity 9: 71–78, 2004",
           0,
           "complexity"
          ],
          [
           "Distribution Network Reconfiguration for Power Loss Reduction and Voltage Profile Improvement Using Chaotic Stochastic Fractal Search Algorithm",
           "10.1155/2020/2353901",
           2020,
           "This paper proposes a chaotic stochastic fractal search algorithm (CSFSA) method to solve the reconfiguration problem for minimizing the power loss and improving the voltage profile in distribution systems. The proposed method is a metaheuristic method developed for overcoming the weaknesses of the conventional SFSA with two processes of diffuse and update. In the first process, new points will be created from the initial points by the Gaussian walk. For the second one, SFSA will update better positions for the particles obtained in the diffusion process. In addition, this study has also integrated the chaos theory to improve the SFSA diffusion process as well as increase the rate of convergence and the ability to find the optimal solution. The effectiveness of the proposed CSFSA has been verified on the 33-bus, 84-bus, 119-bus, and 136-bus distribution systems. The obtained results from the test cases by CSFSA have been verified to those from other natural methods in the literature. The result comparison has indicated that the proposed method is more effective than many other methods for the test systems in terms of power loss reduction and voltage profile improvement. Therefore, the proposed CSFSA can be a very promising potential method for solving the reconfiguration problem in distribution systems.",
           28,
           "complexity"
          ],
          [
           "Training and Testing Data Division Influence on Hybrid Machine Learning Model Process: Application of River Flow Forecasting",
           "10.1155/2020/8844367",
           2020,
           "The hydrological process has a dynamic nature characterised by randomness and complex phenomena. The application of machine learning (ML) models in forecasting river flow has grown rapidly. This is owing to their capacity to simulate the complex phenomena associated with hydrological and environmental processes. Four different ML models were developed for river flow forecasting located in semiarid region, Iraq. The effectiveness of data division influence on the ML models process was investigated. Three data division modeling scenarios were inspected including 70%–30%, 80%–20, and 90%–10%. Several statistical indicators are computed to verify the performance of the models. The results revealed the potential of the hybridized support vector regression model with a genetic algorithm (SVR-GA) over the other ML forecasting models for monthly river flow forecasting using 90%–10% data division. In addition, it was found to improve the accuracy in forecasting high flow events. The unique architecture of developed SVR-GA due to the ability of the GA optimizer to tune the internal parameters of the SVR model provides a robust learning process. This has made it more efficient in forecasting stochastic river flow behaviour compared to the other developed hybrid models.",
           19,
           "complexity"
          ],
          [
           "A New Metaheuristic-Based Hierarchical Clustering Algorithm for Software Modularization",
           "10.1155/2020/1794947",
           2020,
           "Software refactoring is a software maintenance action to improve the software internal quality without changing its external behavior. During the maintenance process, structural refactoring is performed by remodularizing the source code. Software clustering is a modularization technique to remodularize artifacts of source code aiming to improve readability and reusability. Due to the NP hardness of the clustering problem, evolutionary approaches such as the genetic algorithm have been used to solve this problem. In the structural refactoring literature, there exists no search-based algorithm that employs a hierarchical approach for modularization. Utilizing global and local search strategies, in this paper, a new search-based top-down hierarchical clustering approach, named TDHC, is proposed that can be used to modularize the system. The output of the algorithm is a tree in which each node is an artifact composed of all artifacts in its subtrees and is a candidate to be a software module (i.e., cluster). This tree helps a software maintainer to have better vision on source code structure to decide appropriate composition points of artifacts aiming to create modules (i.e., files, packages, and components). Experimental results on seven folders of Mozilla Firefox with different functionalities and five other software systems show that the TDHC produces modularization closer to the human expert’s decomposition (i.e., directory structure) than the other existing algorithms. The proposed algorithm is expected to help a software maintainer for better remodularization of a source code. The source codes and dataset related to this paper can be accessed at https://github.com/SoftwareMaintenanceLab.",
           6,
           "complexity"
          ],
          [
           "An Efficient CNN Model for COVID-19 Disease Detection Based on X-Ray Image Classification",
           "10.1155/2021/6621607",
           2021,
           "Artificial intelligence (AI) techniques in general and convolutional neural networks (CNNs) in particular have attained successful results in medical image analysis and classification. A deep CNN architecture has been proposed in this paper for the diagnosis of COVID-19 based on the chest X-ray image classification. Due to the nonavailability of sufficient-size and good-quality chest X-ray image dataset, an effective and accurate CNN classification was a challenge. To deal with these complexities such as the availability of a very-small-sized and imbalanced dataset with image-quality issues, the dataset has been preprocessed in different phases using different techniques to achieve an effective training dataset for the proposed CNN model to attain its best performance. The preprocessing stages of the datasets performed in this study include dataset balancing, medical experts’ image analysis, and data augmentation. The experimental results have shown the overall accuracy as high as 99.5% which demonstrates the good capability of the proposed CNN model in the current application domain. The CNN model has been tested in two scenarios. In the first scenario, the model has been tested using the 100 X-ray images of the original processed dataset which achieved an accuracy of 100%. In the second scenario, the model has been tested using an independent dataset of COVID-19 X-ray images. The performance in this test scenario was as high as 99.5%. To further prove that the proposed model outperforms other models, a comparative analysis has been done with some of the machine learning algorithms. The proposed model has outperformed all the models generally and specifically when the model testing was done using an independent testing set.",
           92,
           "complexity"
          ],
          [
           "Neural Personalized Ranking via Poisson Factor Model for Item Recommendation",
           "10.1155/2019/3563674",
           2019,
           "Recommender systems have become indispensable for online services since they alleviate the information overload problem for users. Some work has been proposed to support the personalized recommendation by utilizing collaborative filtering to learn the latent user and item representations from implicit interactions between users and items. However, most of existing methods simplify the implicit frequency feedback to binary values, which make collaborative filtering unable to accurately learn the latent user and item features. Moreover, the traditional collaborating filtering methods generally use the linear functions to model the interactions between latent features. The expressiveness of linear functions may not be sufficient to capture the complex structure of users’ interactions and degrades the performance of those recommender systems. In this paper, we propose a neural personalized ranking model for collaborative filtering with the implicit frequency feedback. The proposed method integrates the ranking-based poisson factor model into the neural networks. Specifically, we firstly develop a ranking-based poisson factor model, which combines the poisson factor model and the Bayesian personalized ranking. This model adopts a pair-wise learning method to learn the rankings of uses’ preferences between items. After that, we propose a neural personalized ranking model on top of the ranking-based poisson factor model, named NRPFM, to capture the complex structure of user-item interactions. NRPFM applies the ranking-based poisson factor model on neural networks, which endows the linear ranking-based poisson factor model with a high level of nonlinearities. Experimental results on two real-world datasets show that our proposed method compares favorably with the state-of-the-art recommendation algorithms.",
           8,
           "complexity"
          ],
          [
           "Comparing Project Complexity across Different Industry Sectors",
           "10.1155/2018/3246508",
           2018,
           "Increasing complexity of projects is mentioned as one of the reasons for project failure—still. This paper presents a comparative research to investigate how project complexity was perceived by project practitioners in different industry sectors. Five sectors were included: process industry, construction industry, ICT, high-tech product development, and food processing industry. In total, more than 140 projects were included in the research, hence providing a broad view on Dutch project practice. From the complexity assessments, it is concluded that only one complexity element was present in the top complexity elements of projects across the five sectors: the high project schedule drive. The variety of external stakeholders’ perspectives, a lack of resources and skills availability, and interference with existing site were found in the top lists of three sectors. It was concluded that a framework to grasp project complexity could support the management of complex projects by creating awareness for the (expected) complexities. Further research could be focused on the subjective character of complexity as well as on the application of cross-sector learning, since this research does show similarities between large technical projects in different sectors.",
           14,
           "complexity"
          ],
          [
           "Complex Brain Network Analysis and Its Applications to Brain Disorders: A Survey",
           "10.1155/2017/8362741",
           2017,
           "It is well known that most brain disorders are complex diseases, such as Alzheimer’s disease (AD) and schizophrenia (SCZ). In general, brain regions and their interactions can be modeled as complex brain network, which describe highly efficient information transmission in a brain. Therefore, complex brain network analysis plays an important role in the study of complex brain diseases. With the development of noninvasive neuroimaging and electrophysiological techniques, experimental data can be produced for constructing complex brain networks. In recent years, researchers have found that brain networks constructed by using neuroimaging data and electrophysiological data have many important topological properties, such as small-world property, modularity, and rich club. More importantly, many brain disorders have been found to be associated with the abnormal topological structures of brain networks. These findings provide not only a new perspective to explore the pathological mechanisms of brain disorders, but also guidance for early diagnosis and treatment of brain disorders. The purpose of this survey is to provide a comprehensive overview for complex brain network analysis and its applications to brain disorders.",
           87,
           "complexity"
          ],
          [
           "Understanding How Short-Termism and a Dynamic Investor Network Affects Investor Returns: An Agent-Based Perspective",
           "10.1155/2019/1715624",
           2019,
           "The unexplained and inconsistent behavior of financial markets provides the motivation to engage interdisciplinary approaches to understand its intricacies better. A proven approach is to consider investors as heterogeneous interacting agents who form information networks to inform their investment decisions. The rationale is that the topology of these networks has contributed to a better understanding of the erratic behavior of financial markets. Introducing investor heterogeneity also allows researchers to identify the characteristics of higher performing investors and the implications of investors exhibiting short-termism, a feature recognized by some as detrimental to the performance of the economy. To address these topics, an agent-based artificial stock market is implemented, where investors utilize various information sources, including advice from investors in their network, to inform their investment decisions. Over time investors update their trust in their information sources and evolve their network by connecting to outperforming investors—Oracles—and discarding poor advisers, thereby simulating the evolution of an investor network. The model’s most significant finding is uncovering how the market’s behavior is materially affected by the time-horizon of investors, with short-term behavior resulting in greater volatility in the market. Another finding is the reason why short-term investors generally outperform their long-term counterparts, particularly in more volatile environments. By providing significant insights into the formation of an investor network and its ramifications for market volatility and wealth creation (destruction), this paper provides crucial clues regarding the empirical data that needs to be collected, assessed, and tracked to ensure policymakers and investors better understand the dynamics of financial markets.",
           3,
           "complexity"
          ],
          [
           "Green Innovation, Green Dynamic Capability, and Enterprise Performance: Evidence from Heavy Polluting Manufacturing Enterprises in China",
           "10.1155/2022/7755964",
           2022,
           "Green innovation is widely regarded as a beneficial strategy for manufacturing enterprises to accelerate green transformation. Drawing the natural resource-based view with dynamic capabilities, this study proposes a model linking green innovation, green dynamic capability, and firm performance. Using survey data from 236 heavy polluting manufacturing firms in China, this study investigates the impact of green innovation on firm performance. The results show that green innovation is positively correlated with both enterprise performance and green dynamic capability, whereas green dynamic capability also has a significant impact on enterprise performance. Furthermore, the survey found that the green resource integration ability, organizational learning capability, and environmental insight capability of green dynamic capability play a moderating effect on the relationship between green innovation and enterprise performance. Additionally, we provide useful enlightenment for policymakers and business managers to stimulate green innovation in enterprises. Our research not only assists managers to better grasp the effects of green innovation practices but also provides some important implications for policymakers.",
           8,
           "complexity"
          ],
          [
           "Tuning Frontiers of Efficiency in Tissue P Systems with Evolutional Communication Rules",
           "10.1155/2021/7120840",
           2021,
           "Over the last few years, a new methodology to address the P versus NP problem has been developed, based on searching for borderlines between the nonefficiency of computing models (only problems in class P can be solved in polynomial time) and the presumed efficiency (ability to solve NP-complete problems in polynomial time). These borderlines can be seen as frontiers of efficiency, which are crucial in this methodology. “Translating,” in some sense, an efficient solution in a presumably efficient model to an efficient solution in a nonefficient model would give an affirmative answer to problem P versus NP. In the framework of Membrane Computing, the key of this approach is to detect the syntactic or semantic ingredients that are needed to pass from a nonefficient class of membrane systems to a presumably efficient one. This paper deals with tissue P systems with communication rules of type symport/antiport allowing the evolution of the objects triggering the rules. In previous works, frontiers of efficiency were found in these kinds of membrane systems both with division rules and with separation rules. However, since they were not optimal, it is interesting to refine these frontiers. In this work, optimal frontiers of the efficiency are obtained in terms of the total number of objects involved in the communication rules used for that kind of membrane systems. These optimizations could be easier to translate, if possible, to efficient solutions in a nonefficient model.",
           5,
           "complexity"
          ],
          [
           "Culture in Conversation: A Commentary on Pontecorvo and Fasulo’s ‘Planning a Typical Italian Meal’",
           "10.1177/1354067x9954005",
           2007,
           "This commentary identifies respects in which the theories of culture adopted in the culture and self and sociocultural traditions of cultural psychology are each constrained, in part, by their psychologically grounded research agendas. While tapping non-rational and thematic aspects of culture, research on culture and the self provides only limited insight into its dynamic and heterogeneous nature and into processes of enculturation. In turn, while capturing the fluid and complex nature of cultural systems, sociocultural work neglects its non-rational and thematic aspects. In both traditions, relatively little attention is given to power. The discourse analysis of family interaction undertaken by Pontecorvo and Fasulo (1999) is shown to overcome many of these limitations. Treating culture as an integrated, complex system which is integral to human interaction, their approach captures processes of cultural creation and change as well as power relations. In conclusion, it is argued that there is a need for greater cross-fertilization of ideas across the diverse traditions of research in culture and psychology, while respecting their distinctive insights and agendas.",
           1,
           "culture_&_psychology"
          ],
          [
           "Ghost: Do Not Forget; This Visitation / Is But to Whet Thy Almost Blunted Purpose",
           "10.1177/1354067x0174002",
           2007,
           "After a brief inspection of some cases where people apparently ‘mis-identify’ others, we draw some initial and tentative conclusions about ways of thinking about ‘who people are’. We then move on to look at underlying assumptions in psychology about this very question; with these assumptions considered under the rubric of psychology’s ‘model of being human’. Locating problems with this model on the basis of its affinity with Kantian thought, we conclude that what it misses is an understanding of cultural order as the primary medium for human existence. Against this, we propose instead—via Harvey Sacks in particular and ethnomethodological thinking in general—that to be in the world is always to be in the cultural world. Consequently, what persons can do and be is never a form of governance or control by fixed rules; rather, it is always already an orientation to publicly known and material forms of cultural order. We end by speculating on the general consequences of such a re-formulated ‘model of being human’ for a paradigm of psychology yet to come.",
           6,
           "culture_&_psychology"
          ],
          [
           "Dialogic Repression and the Oedipus Complex: Reinterpreting the Little Hans Case",
           "10.1177/1354067x9800400102",
           2007,
           "This paper offers a discursive reinterpretation of the psychoanalytic concept of repression. Language is both expressive and repressive, and, therefore, children, in acquiring language, learn to repress rhetorically. The sort of repressions which, according to classic Freudian theory, occur as a result of the Oedipus Complex are themselves dialogically and socially constituted. In consequence, the processes of repression can be examined by extending the techniques of discursive psychology. These ideas are examined in relation to Freud's case of Little Hans, paying attention to the ways that the adults are implicitly practising and teaching repression. It is argued that Freud, in his interpretations, repressed the themes of parental power and desire. The dialogic details show Hans to be developing within a social world in which dialogic repression is habitually practised by adults. The implications of such notions for developmental and discursive psychology are discussed.",
           8,
           "culture_&_psychology"
          ],
          [
           "Beyond Stereotypes",
           "10.1177/1354067x0172004",
           2007,
           "Valsiner (2000) sketched a possible semiotic analysis of how people respond to Others, and the present paper seeks to modify and expand his original scheme slightly. The more usual ‘stereotype’ approach to this issue is critically examined in historical context and current practice. It is shown to be largely descriptive at the collective level, and to focus on cognitive mechanisms rather than content at the individual one. By contrast, semiotic processes operate on both levels, the major one being some form of ‘symbolic inversion’. This is illustrated with references to past images of Africans and Japanese, as well as the recent and current political arena. It is suggested that in such contexts the semiotic approach, invoking general principles, is likely to be more illuminating than the ‘stereotype’ one.",
           3,
           "culture_&_psychology"
          ],
          [
           "The Child's Contribution to Culture: A Commentary on Toomela",
           "10.1177/1354067x9600200306",
           2007,
           "Toomela (1996) has emphasized the psychological dimensions of the process by which human children become participants in cultures. I support his arguments with observations of chimpanzees, which are similar to humans in some ways but still do not live culturally, and of human infants both before and after they have the capacity to participate fully in cultural activities. Toomela also proposes a new account of the process of internalization in which language plays the central role. I disagree somewhat with this account, arguing that whereas language is the most powerful human artifact potentiating internalization, other artifacts both material and symbolic-may serve the same function if children are introduced to them in social interactions in which others have intentions toward their intentional states -and they know this. The central theoretical point of Toomela's paper is that a comprehensive account of the human species as a cultural species must focus not only on the cultural collective, but also on individuals and their psychological capacities.",
           7,
           "culture_&_psychology"
          ],
          [
           "Genital-Shrinking Panic in Ghana: A Cultural Psychological Analysis",
           "10.1177/1354067x07073651",
           2007,
           "The present article applies the theoretical framework of mutual constitution (MC)—the dialectical process by which ‘culture and psyche make each other up’—to analyze an occurrence of genital-shrinking panic (GSP). Although media reports promote interpretation of this event in terms of ignorance and superstition, the MC framework affords a less pathologizing analysis. The first part of this analysis, one that resonates with classic ethnographic perspectives, emphasizes the cultural grounding of psychological experience: how episodes of GSP make sense given local constructions of reality. However, an adequate analysis requires attention not only to cultural realities in which incidents of GSP make sense, but also to the role of psychological activity in reproducing, maintaining and extending those realities. Accordingly, the second part of this analysis emphasizes the less articulated, dynamic-construction side of the MC framework: the role of psychological activity in the reproduction of cultural worlds.",
           9,
           "culture_&_psychology"
          ],
          [
           "Philosophy of friendship with a place as interpretive support for cultural psychology",
           "10.1177/1354067x221111803",
           2022,
           " Why is it important for cultural psychology to look attentively and inspirationally into the depths of the problem of friendship? Focussing on the cultural empowerment of a man, the search for meaning in life, but also in the art of life which binds ars bene vivendi with ars bene moriendi, cultural psychology should not lose sight of the art of friendship, but also of its connection with mobile practices of the contemporary world, for in this space of encounters friendship constitutes a philosophical recommendation and a cultural challenge. I propose therefore turn to the philosophical and cultural space in order to analyse the experience of friendship with a place, interpretively extracting those elements of experience that are crucial for in-depth and contextual thinking about man. Here cultural psychology can find inspiration. I deliberately refer to the transcultural space to indicate the possibilities of experiencing the problem of being in a place. Philosophy of friendship anchored in a transcultural context helps to bring out the multi-dimensionality of the experience of self and the Other, which complements psychological research. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Diverse transnational backgrounds, same master narrative? Constructions of a national past among middle-school students",
           "10.1177/1354067x221135041",
           2022,
           "In this study, we aimed to explore the various ways in which the past is constructed, using or tinkering with a national master narrative, by students surrounded by and immersed in contemporary transnational plurality. Specifically, we studied the permanence of or variations on the Spanish ‘reconquest’ narrative among 14 to 15-year-old students of a public school in Madrid. Semi-structured individual interviews were carried out with 30 students whose families came from Madrid, other regions in Spain and other countries around the world. We carried out a detailed narrative analysis of their constructions of the medieval past on the Iberian Peninsula and found that the ‘reconquest’ narrative still predominates. Few variations in their narratives were found that hint at counternarratives, the ‘travelling’ of narrative schema across national borders, or the transnational trajectories in their families feeding into their constructions. Given these findings, we discuss the role of alternative narrative schema and dynamic concepts of nation and national identity in challenging national master narratives.",
           0,
           "culture_&_psychology"
          ],
          [
           "Reports of the unintelligible: Apperceptive difficulties in descriptions of holocaust survivors’ reactions",
           "10.1177/1354067x17735503",
           2017,
           " This paper presents a study about the psychological state and possibility of reaction of the Jews during the Holocaust. The survivors’ life histories contain expressions that allude to the unintelligible nature of the horrors they endured. We seek to understand the damage to the structure of the psyche revealed in these accounts, given the impact of the violence and trauma experienced, which impairs the apperceptive capacity and the capacity to respond during and after the traumatic experience. In this phenomenological study, structured using the historical–hermeneutical–existential method, we seek to unpick the meaning behind the chains of experiences as well as the difficulty in working through them discursively manifested by the survivors. ",
           1,
           "culture_&_psychology"
          ],
          [
           "Whose memory and why: A commentary on power and the construction of                     memory",
           "10.1177/1354067x17695765",
           2017,
           " The present commentary explores the implicit and explicit role of power in shaping what is remembered and why. By addressing the three papers in this section it argues for the need to more openly consider how power relations, particularly asymmetrical power relations, come to shape the construction of memory. Implications of acknowledging power in memory studies are discussed. ",
           5,
           "culture_&_psychology"
          ],
          [
           "The Interface Work of Narrative",
           "10.1177/1354067x10361393",
           2010,
           "The article explores further Lyra (1999) and Hermans’ (1999, 2001a, 2001b) glossing of complexity terminology within analysis of identity formation, taking a particular interest in differing uses of narrative within identity negotiations. Lyra (1999) draws attention to the importance of using an extended time frame to assess the power dynamics involved within any communicative exchange. The fragments of speech often under consideration in academic texts often preclude an appreciation of such groundwork. This article looks at a group discussion in terms of preceding ethnographic material that contextualises it within a larger socio-educational history. A mapping methodology first traces the power dynamics and different moments of dialogical activity (Lyra, 1999) across the discussion and then details the stances depicted within narratives which have a correspondence to Hermans’ (2001a, 2001b) I-stances. Initially, condensed narratives confirm each other. Subsequently, partial versions of narratives voice divergence. Boje’s (2007) concept of ante-narratives aids the analysis of these latter discursive moves and their role as exploratory devices for considering possible future identity strategies. Taken together these maps contribute to an understanding of selves as dynamic systems (Lyra, 2007, p. 180) tasked with creating coherency and yet responding creatively to uncertainty (Hermans, 2001a).",
           6,
           "culture_&_psychology"
          ],
          [
           "The methodological approaches in an experimental study of cultural transmission process",
           "10.1177/1354067x17729996",
           2017,
           "In this paper, we will discuss the possibility of understanding experimental studies on cultural transmission processes from an articulation between the particular–general relation in the construction of knowledge, with an approximation between the notions of Nomothetic and Idiographic science. For this, we discuss data collected from an experimental project about the cultural transmission process drawing our attention, as much to the continuities as the discontinuities present in the process. Our discussions pointed to the need to consider, in experimental studies, the particular actions and significations of research participants, as well as the generalization that is dialogically constructed in the collectivity. With this in mind, it is proposed that at least three theoretical-methodological aspects cannot be lost sight of when considering the experimental study of the cultural transmission process: (1) the relation between Idiographic and Nomothetic science; (2) interdependent relational processes that occur between particularities and generalities; and (3) the need to appreciate continuities and discontinuities as part of the process of construction and analysis of experimental projects.",
           3,
           "culture_&_psychology"
          ],
          [
           "Situated understanding of human development in Africa: Systematic inquiries at the nexus of psychology, social science and history",
           "10.1177/1354067x18779034",
           2018,
           " Gustav Jahoda contended that mainstream psychology’s contribution to our understanding of human experience has been impoverished by a neglect of culture. Over a long series of publications, he argued that the disciplines of psychology, anthropology and history have much to learn from one another, since socio-cultural and politico-economic contexts have influenced the formulation of theories and the dissemination of ideas about human nature. In light of his analyses, I argue in this article that systematic inquiries aspiring to generate a situated understanding of human development in Africa should acknowledge and seek to synthesize the complementary strengths of different academic disciplines. And I recommend that African researchers resist the pressure of an enduring Western cultural hegemony embedded in the methodological dictates of many international scholarly, professional and administrative organizations. Such pressure often threatens to do epistemological violence to indigenous modes of thought preferred by local families and communities in whose care African children are growing up. I end by briefly describing some African studies that illustrate ways in which researchers can address the challenge of resisting oppressive hegemony without losing the opportunity to learn from the wisdom accumulated by human development researchers in other socio-cultural and historical contexts. ",
           6,
           "culture_&_psychology"
          ],
          [
           "The social psychology of intractable conflicts",
           "10.1177/1354067x14526900",
           2014,
           " The author reviews Daniel Bar-Tal’s summary of the social-psychological research on mass violence, particularly intractable conflicts, and critically examines his synthesis of this large and growing body of literature. What actually defines a conflict as intractable is discussed, and an overview of past research is presented. The author explores Bar-Tal’s thinking on the escalation of conflict, how societies are shaped by conflict, how conflicts come to be sustained over time so as to become intractable, and finally, how such conflicts might be brought to an end. While sustained, large-scale conflicts are truly awful, in that they cause horror but also astonishment, they arise from the normal, mundane processes underlying intergroup dynamics. In this sense, their “normality” offers invaluable insights into how to assuage the suffering caused by what are otherwise mundane and even valuable social-psychological processes. ",
           2,
           "culture_&_psychology"
          ],
          [
           "The Authoring of Institutional Practices: Discourse and Modes of                 Participation of Subjects",
           "10.1177/1354067x05055526",
           2005,
           " In this text I consider authoring as a historically instituted and instituting social practice. The concept of author(ship)—as a social function concerning the action and identification of specific subjects in institutional places—is discussed in relation to authority (power position) and authorization ((dis)empowering position). I highlight Foucault’s and Bakhtin’s most relevant theoretical contributions to the issue, inquiring about the concrete possibilities and conditions of such practice. Within the scope of an empirical research developed with a group of students in a Brazilian public school, attention is drawn to the graduation ceremony as a commonplace within the school scenario. I focus my analyses on discursive practices, highlighting two speeches uttered at the ceremony as particular instances of authorship, and relate them to two students’ informal talk. The analyses point to the interplay of voices and positions in an intricate web of interpersonal relationships interwoven with/in and marked by the institutional loci. ",
           3,
           "culture_&_psychology"
          ],
          [
           "Review Essay: Beyond Bullets, Bombs, and Grassroots",
           "10.1177/1354067x08096515",
           2009,
           " This article addresses several of the most relevant ideas, implicit and explicit, in Judy Kuriansky's collection Beyond Bullets and Bombs. Identity development is highlighted as a key component of peacebuilding attempts; more detail is given on the psychosocial portion, which is elaborated as a dialectic between one's perception of others, one's view of how one is perceived by others, and the relationship between the two. A maturity development model, a dialogical interaction model, and the importance of power dynamics are also explored. The limitations of focusing only on the grassroots level in order to create a culture of peace are discussed, and other areas of investigation, such as tiers of leadership and structural-institutional conditions, are proposed. ",
           3,
           "culture_&_psychology"
          ],
          [
           "Lev S. Vygotsky on the visual arts followed by a translation of the essay: The graphic art of Alexandr Bykhovsky",
           "10.1177/1354067x19871200",
           2019,
           " During his studies at Moscow University and thereafter, Lev S. Vygotsky’s (1896–1934) interests focused mostly on the scholarly study of literary and theatre criticism. Shakespeare’s Hamlet served as a leitmotiv to understand the specificity of the arts within western culture: through analysis of the structural particularities of Hamlet, he provided a model for an understanding of how the mind functions during interactions with artworks and reconstructed the internal activity caused by art. His thoughts on the visual arts are few, but fragments are found in his seminal work entitled Psychology of Art (1926). Here, he showed the function of catharsis, the main concept of his theory of aesthetic experience. This paper presents a translation of Vygotsky’s essay published in 1926, dedicated to the art of Alexandr Bykhovsky (1888–1978), a companion since his Gomel period (1919–1924). The significance of this essay is twofold. First, it represents a concise and lasting testimony to the creativity of an important Russian artist; second, the essay goes beyond formal analysis of the artwork. Instead, Vygotsky’s analysis explains the phenomenon of aesthetic experience as the viewer and the artwork interact and transform each other. The paper is preceded by a note on the contextual and biographical settings in which both Vygotsky and Bykhovsky worked. ",
           0,
           "culture_&_psychology"
          ],
          [
           "The Bakhtinian self and beyond: Towards a dialogical phenomenology of the self",
           "10.1177/1354067x13478988",
           2013,
           " The goal of the present article is to comment and to potentially expand some of the arguments developed in Cresswell’s (2011) Being faithful: Bakhtin and a potential postmodern psychology of self, published in Culture & Psychology. The original work presents the reader with the author’s position about Bakhtin’s elaborations on the meanings of self and on the implications of his elaborations for a Psychology of the self. Although the ideas disposed in the original article are evocative of creative analytical results, in terms of the social constitution of the sense of selfness, the present work presents a different perspective on the topic. Considering the material of a decade of research on verbal reports, I present an alternative proposition, sustaining (together with pragmaticists of the piercean legade) that the temporal organization of personal experience follows a bidirectional direction. ",
           8,
           "culture_&_psychology"
          ],
          [
           "On wabi sabi and the aesthetics of family secrets: Reading Haruki Murakami's<i>Kafka on the shore</i>",
           "10.1177/1354067x16650811",
           2016,
           "Family secrets are commonly considered as a defense mechanism that conceals shameful content and evades guilt. As shame and guilt threaten narcissistic perfection, secrecy functions as a self-protective mechanism by evading acknowledgment of imperfection, thus conceptualizing imperfection as a psychological threat. However, the meaning of perfection and imperfection is culturally grounded, and, therefore, our understanding of family secrets may gain better understanding by examining different cultural perspectives of perfection/imperfection. In this context, we can gain insights to the process of family secrets through wabi sabi, a Japanese aesthetic ideal and philosophy that stresses imperfection as the basis for harmony. In this paper, I suggest an interpretation of family secrets that draws on wabi sabi aesthetics. The paper's main argument is illustrated through a careful reading of Murakami's Kafka on the shore, presenting wabi sabi of family secrets as distinguished aesthetics and a potential source for mental transformation and growth.",
           4,
           "culture_&_psychology"
          ],
          [
           "The addicted self and modernity",
           "10.1177/1354067x11434841",
           2012,
           "In this paper addiction is regarded as a possible pathway to achieve an understanding of modernity. What they both share are ambivalence and ambiguity as basic characteristics. These aspects are also expressed in psychological terms like perception and feelings, which are pursued historically by referring to Leibniz and Kant, by whom they became closely related to change and unpredictability. Thus, feelings understood in terms of inhibition stand out as a core aspect of modernity. Feelings, however, stand in opposition to language. On this basis music may replace texts as an expression for the modern, ambiguous self.",
           0,
           "culture_&_psychology"
          ],
          [
           "Feelings of Quarantine: Allegories for the Lockdown",
           "10.1177/1354067x211004086",
           2021,
           " This case study shows how allegories are a means to express the inexpressible and how Allegory Analysis can be a method to reveal it and bring out the subjective meaning making, life script ideology, and capability to deal with the ambivalent in critical life situations. From a cultural psychological perspective, the research is based on feelings during the quasi-quarantine period of the COVID-19 pandemic. The study tries to understand the coping strategies with which people deal with a psychological crisis in general concerning for the COVID-19 lockdown. It discusses further ways to deal with the ambivalences and subjective meaning making arousing through such a crisis. The case study analysis of Miss K. not only showed her meaning making processes and attitude of life but also showed how to deal with the uncertainty during the critical lockdown period. Through her allegories, she utters her current life script ideology that living nowadays means to function like a machine while being creative, self-reflective at the same time. Her meaning making process counterbalanced between the voice of being delivered to withdrawal or depression versus the voice of being able to learn, connect, and relax. Her coping strategy was bearing the ambivalence in a psychological crisis with faith. ",
           2,
           "culture_&_psychology"
          ],
          [
           "Performing the Past in Electronic Archives: Interdependencies in the Discursive and Non-Discursive Ordering of Institutional Rememberings",
           "10.1177/1354067x0172001",
           2007,
           "This paper examines interdependencies in the discursive and non-discursive ordering of institutional memory in organizational settings. Issues of what happens to historical consciousness in the time of modern technology are examined with reference to how the past is used in the context of electronic archiving of email in corporate cultures. Drawing from ideas in the work of Martin Heidegger concerning interdependencies between the use of technology and the arts of the mind, we examine how the truth of matters is more than an issue of correspondence between language and reality, and more than the rhetorical deployment of what counts as true in establishing stake and interest. We analyse how the work of ordering the archive, which is driven by current projects in the organizations studied, takes place alongside the discursive work of remembering. We illustrate how, without the non-discursive labour of forging relations between components, there is no possibility of playing out evidential strategies that dominate the rhetorical performance of the past. What we call ‘mind’ and what we call ‘society’ emerge in this dual ordering. This dual work of ordering occurs through the joint operation of discursive and non-discursive practices, which together produce remembering and forgetting in a way that draws upon cultural resources at the same time as making sense in the flow of interaction, experiences and events.",
           26,
           "culture_&_psychology"
          ],
          [
           "Revisiting the crowd: Peaceful assembly in Irish water protests",
           "10.1177/1354067x211005414",
           2021,
           " The enactment of the Water Services Bill into Irish law on December 28, 2014, was met with strong opposition from the Irish public, manifesting in local and national demonstrations. This social movement provided an ideal case to examine interactions between protesters and police in different contexts. Ethnographic observations and randomly sampled interviews took place before, and during, seven national demonstrations in Dublin, Ireland. Simultaneously, urban ethnographic research yielded in-depth observational and interview data at local protests in another Irish city. Data from both national and local protests are examined in light of classical and contemporary sociocultural psychological conceptualizations of the crowd. The elaborated social identity model offers most explanatory power to comprehend the observed and reported events between police and protesters in this cultural context during an unprecedented economic recovery following recession. No evidence is found to support classical conceptualizations of the crowd. I describe the consequences of this analysis for conceptualizing police–protester interactions to generate peaceful assembly in liberal democracies. ",
           1,
           "culture_&_psychology"
          ],
          [
           "From Vico to the sociocultural imagination",
           "10.1177/1354067x15575796",
           2015,
           " The papers by Mariagrazia Granatella (2015), Tuuli Pern (2015) and Pablo Rojas (2015), invited by Tateo (2015) engage in a dialogue with the texts of Giambattisto Vico, a philosopher from the 18th century. In this commentary, focusing on imagination, I first follow the authors’ effort to show the compatibility between Vico’s ideas and current cultural psychology; I then highlight two issues of particular interest emerging from this dialogue. ",
           4,
           "culture_&_psychology"
          ],
          [
           "Commentary: Modeling the Dynamics of Meaning Construction: Appropriation of                 the Home Environment",
           "10.1177/1354067x07076605",
           2007,
           " In my commentary regarding Giorgi, Padiglione and Pontecorvo's article, I elaborate on building an initial model for the dynamics of meaning construction of the appropriation process in the home environment. Based on principles from dynamic systems and dialogical perspectives, particularly dialogism, as well as an idiographic science framework, I undertake a re-analysis of the data presented by the authors, with the aim of distinguishing possible general aspects of these dynamics and outlining the principles that guided both this re-analysis and the modeling proposed. The re-analysis suggests that the intensity of the dynamic movement of negotiation is greater at moments when we face discernible, close, triggering partners. More intense dynamics lead to a greater involvement of self-affective dimensions as well as a highlighting and clarifying of the oppositions involved in the mechanism of dialogical tensions. However, these features seem to become less pronounced as the intensity of the dynamics rises even more strongly. ",
           3,
           "culture_&_psychology"
          ],
          [
           "The role of the imagination in transnational relating: The case of Nigerian children and their migrant parent  in Ireland",
           "10.1177/1354067x20922136",
           2020,
           " This paper explores the role of imagination in the lives of Nigerian transnational children and their migrant parent in Ireland. Migration of a parent is a rupture in a child’s life that triggers imaginary processes that are real in their developmental consequences. Following Zittoun and Gillespie, imagination is a process that generates a disjunction from the person’s experience of the “real” world, and uncouples and loops out before it eventually comes back to the actual experience. For the left-behind child, this imaginative loop remains “open” as parents return becomes extended in time. The dilemmas for the migrant parent and child are explored. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Commonalities in Boesch and Murray: Bridging between a European and an American Thinker",
           "10.1177/1354067x9733010",
           2007,
           " Six commonalities in the work of Ernst Boesch and Henry Murray are outlined: a holistic approach to the study of personality; a systematic elaboration of the person-situation interaction; an incorporation of psychoanalytic elements into their theoretical thinking; an emphasis on the cultural foundations of personality; and an intense affinity with novelistic literature. The main part of this article is devoted to the sixth commonality: Boesch's and Murray's ideas on the multiplicity and multivoicedness of the self. ",
           2,
           "culture_&_psychology"
          ],
          [
           "Shame experienced by self and others: A relational approach",
           "10.1177/1354067x211073919",
           2022,
           " Building on Burkitt’s (2014) esthetic and relational theory of emotions, this article presents a study that explores how and when shame is experienced, focusing on the role of social and cultural factors in it. People were asked to describe in detail an occasion in which they experienced shame and an occasion in which they observed someone else experiencing it. Following an Interpretative Phenomenological Analysis in which the focus is on what the experiences mean to the people having them (i.e., their lifeworld) four dominant themes were identified: Expectations, self-control, feeling exposed, and bodily reactions and empathy. The study showed how these themes are interrelated: the expectations function as a normative frame that defines what behavior is appropriate in a certain situation, which is present in all the cases. Self-control is a tool required to stay within the normative frame, and when one steps outside the frame, shame and other negative feelings can occur, which can lead to a feeling of being exposed. When describing observations of shame, many participants focused on visible, bodily reactions, along with a normative interpretation about what the other person might be feeling in that specific situation. Another interesting tendency is that some participants would describe observed shame that is similar to their own experience of shame. The discussion applies positioning theory to shame and reflects on shaming at a broader societal level. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Ragnar Rommetveit: A full life",
           "10.1177/1354067x19898679",
           2020,
           " Over a long professional lifetime, Ragnar Rommetveit contributed to numerous disciplines in the social sciences and humanities, reflecting discussions in global social science and his own unending quest to understand social and individual life. His remarkable career and impact can be outlined in terms of four main phases. The first involved general social psychology in the 1950s and was reflected in Social Norms and Roles (1953/1955). In the second phase during the 1960s and 1970s, he focused on language-related psycholinguistic research leading to publications such as his 1968 volume Words, Meanings and Messages. The third phase came in the 1970s and 1980s and was motivated by his critique of formal linguistics and resulted in his short, magisterial 1974 volume On Message Structure. The fourth phase between 1980 and 2010 focused on “dialogism,” giving rise to works such as his 1992 article “Outlines of a dialogically based social-cognitive approach to human cognition and communication.” Along with his intellectual accomplishments, Rommetveit’s brilliance and generosity inspired students and colleagues at the University of Oslo, as well as from around the world. His capacity to engage with others in unending mediations on communication and mental life ranks among his most important legacies. ",
           0,
           "culture_&_psychology"
          ],
          [
           "‘You Always Need at Least Two Tones to Produce a Harmonious Sound’: The Value of Arendt’s Ideas on Friendship for Thinking in Social Psychology",
           "10.1177/1354067x221097127",
           2022,
           " In this article, we focus on Arendt’s ideas about the relationship between thinking, dialogue and friendship to make the argument that friendship, although undertheorised in its relationship to thinking in social psychology, is a productive concept that captures something important about the argumentative and dialogical character of thinking (both on one’s own, and with other people). We work through Arendt’s ideas and discuss them in relation to social psychological theorising to consider how the concept of friendship can deepen our understanding and analyses of the relationalities that underpin thinking. We specify that whilst thinking in existing social psychological accounts may be read as adversarial in nature (e.g. through a focus on its oppositional character), the relationship between thinking and friendship has been an important idea underlying the perspectives presented in such works. Distinguishing between thinking as friends and thinking in groups, we suggest that there may be something special about the role of friendship in thinking. We draw out this idea by turning to Arendt, and simultaneously use the work of social psychologists to reconsider aspects of The Life of the Mind, in which thinking is mostly conceptualised as a solitary activity. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Conclusion: An invitation to dialogue with <i>The Life of the Mind</i>",
           "10.1177/1354067x221097122",
           2022,
           " In this conclusion to the special issue on The Life of the Mind by Hannah Arendt, we, the authors, reflect back on our dialogue with the philosopher’s text. Our reflexion has two main parts. First, we emphasise transversal themes – themes that most triggered our interrogations and that we as psychologists, all addressed in our separate papers: thinking, of course, but also Arendt’s views on dialogue, her conception of time and temporality, and morality. Second, we emphasise some of the questions emerging from our reading of Arendt, which, we feel, can enrich discussions in psychology, and especially in cultural psychology today. Altogether, we conclude by inviting readers to join in our dialogue. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Hypnogenesis, Chronic Pain and Peircean Habit: Implications for Clinical Endeavors",
           "10.1177/1354067x231172906",
           2023,
           " This study’s objective is to discuss hypnogenesis parting from one of Erickson’s chronic pain cases, analyzing hypnogenesis involvement in iatrogenesis and in the therapeutic interventions. Hypnogenesis is a concept for how clinical relationships tend to reproduce the ideas and theories of the therapist in the subject’s subjectivity. In hypnotherapy, hypnogenesis is implicated in the relational nature of the hypnotic experience, addressing the difficulty in separation between fabricated and revealed realities. A case of trigeminal neuralgia is analyzed and discussed to illustrate the implications of hypnogenesis in iatrogenesis and its therapeutic potential for chronic patients. The study draws a theoretical possibility on how hypnogenesis highlights iatrogenesis by the neglect of the subject’s needs in clinical consultations. Then, the study demonstrates how Erickson uses hypnogenesis in the patient’s therapy, favoring her well-being. To approach hypnogenic communicational processes, Charles Peirce’s concept of habit and is utilized as a complex system of subjective processes. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Introducing <i>Syntheses</i>",
           "10.1177/1354067x221151015",
           2023,
           " In this short Introduction, we introduce the new submission form of Syntheses. The goal of Syntheses is to provide a summary and expansion of 6–8 articles on a selected topic within Culture & Psychology. The articles should not be restricted to any time point, and the first author of the Syntheses must be a master’s level student or below. Topical syntheses are welcome but are not required. Syntheses articles should be short in length, with a maximum of 2500 words, inclusive of references. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Strategic subversions of the sacred: The cultural psychology of religious identities",
           "10.1177/1354067x11427465",
           2012,
           "Traversa’s (2012) study on the Italian Islamic and Catholic women demonstrates that religion is a liberating force rather than the source of entrapping female subjectivities. In this commentary, I situate the participants’ interview responses within the larger debates about modernity, secularism and religious identity. I argue that the Italian and Catholic women’s narratives are a response to the cultural secularization of global modernity. The secular doctrine deploys a new vocabulary of self—where meaning making is detached from the sacred and divine and becomes primarily articulated through the triumph of reason. The participants’ encounter with global modernity and contradictory discourses of religion create ruptures and uncertain social conditions in their lives. I examine how Italian Muslim women strategically use religion to subvert the meaning of hijab, Islam and patriarchy, and the Italian Catholic women challenge orthodox views about abortion, God, and the Catholic Church. I argue that the religious experiences of these women are constantly interacting with location of race, religion and gender and are continually transforming all the ambiguous meanings present in various axes of difference that make up their identity.",
           2,
           "culture_&_psychology"
          ],
          [
           "Commentary on Brockmeier’s remapping memory: The relation between past, present and future as a metaphor of memory",
           "10.1177/1354067x11427463",
           2012,
           "A commentary of Jens Brockmeier’s paper “Remapping memory” (2010) is presented. Also, a number of relations to previous commentaries about the same paper are presented. First, we agree with Brockmeier and Haye with respect to the artificial and useless separation of memory and other psychological functions. On the other hand, five implicit assumptions of the archive model, criticized by Brockmeier, are presented. These assumptions are considered to raise the issue of the need to incorporate a more complex relation of past, present and future, in order to have a better understanding of memory phenomena. The importance of this relation is developed in relation to both collective memory and history teaching, and also in relation to autobiographical memory.",
           4,
           "culture_&_psychology"
          ],
          [
           "Using culture to manage the transition into university: Conceptualising the dynamics of withdrawal and engagement",
           "10.1177/1354067x15621476",
           2016,
           " This conceptual paper explored the purposes of using culture in the process of coping with stress by looking how first-year undergraduate students used cultural elements and activities to aid their transition into university. Results supported two key conceptualisations of the use of culture. First, results indicated that students used culture either for withdrawal purposes, that is, for escaping from the stressful situation, or for engagement purposes, that is, for actively engaging with the stressful situation. Second, the results suggested three different forms of using culture to engage with stressful situations: mood management, learning and personal interaction. While the results of the study resonate with the distinction between avoidance versus approach-oriented coping strategies that are widely explored in the stress and coping literature, they also suggest that the relationship between withdrawal and engagement might be dynamic with those two strategies serving distinct purposes in the process of coping with stress. This paper thus suggests that there is a need to develop process-oriented models of coping that would allow identifying patterns in the way people fluctuate between withdrawal and engagement that support and facilitate their personal growth and development. ",
           9,
           "culture_&_psychology"
          ],
          [
           "Contacting Subjects: The Untold Story",
           "10.1177/1354067x9800400104",
           2007,
           " This personal narrative describes a case of realities in intercultural contact in the context of research. Different cultural patterns of gaining access to research participants-foreigners in the context of the US society at the time of the study-are described. The wider issue of researcher as a migrant between the worlds of research participants and research institutions is discussed. ",
           16,
           "culture_&_psychology"
          ],
          [
           "The culture of family secrets",
           "10.1177/1354067x15568979",
           2015,
           " In mainstream psychology, family secrets are usually discussed in terms of intra-psychological processes. However, the sense making of the family, which is a multilayered system, is mediated through culture. Hence, a complementary intersubjective perspective is inevitable for understanding secrecy formation. Merging psychoanalytic ideas with cultural-semiotic analysis, the current paper explores the relationships between three complementary levels of secrecy formation: the macro-level of cultural mediation, the mesoscopic-level of family dynamics, and the micro-level of intra-psychological processes. This perspective is developed and illustrated through an in-depth reading of Amir Gutfreund’s novel, Our Holocaust. ",
           4,
           "culture_&_psychology"
          ],
          [
           "The borderland",
           "10.1177/1354067x15601199",
           2016,
           " People travel for tourism, for working, for escaping from the home country, for missionary reasons or for exploring new lands. By so doing, they cross borders which make their own identity different from the previous state becoming a migrant, an exiled, a tourist, a helper or a conqueror. Border shows its difficulties in being unambiguously defined. For instance, to which of the contiguous areas it belongs? Neither one of the single-bounded regions is sufficient for that. Border is not just a non-place, but is a space with its own characteristics that makes living there very specific, regulating the dynamic with the surroundings and even the way of thinking, acting and feeling. Living in a borderland makes the identity of the inhabitants and their meaning-making process very peculiar. The way in which the border residents perceive the relationship between the self, the others and the environment, as well as their process of meaning-making is unavoidably linked with the existence of the border itself, with all its ambivalent theoretical features and practical implications in settling the daily activities and the human psychological functioning. ",
           49,
           "culture_&_psychology"
          ],
          [
           "The sound of history and acoustic memory: Where psychology and history converge",
           "10.1177/1354067x12456716",
           2012,
           "Historians have reconstructed the past mainly by the study of texts; only recently have they turned their attention to the analysis of images. They have abstained almost entirely, however, from using their ears when exploring the past: they have been content with the sound of silence. This can be explained in part by the scarcity of authentic acoustic sources which have existed only for the time period since about 1900. Historical studies focusing on the function of listening in the past, the soundscapes of earlier epochs and the significance of acoustic signals are rare. This article attempts to sketch the social and cultural meaning of listening and the impact of our perception of sounds on our view of the world; it shows what historians can hear of the past and what remains inaudible; it discusses the effects of the inaudibility of the past on our historical understanding; and finally it presents some new perspectives for historical research dealing with the history of listening, with historical soundscapes and their meaning.",
           12,
           "culture_&_psychology"
          ],
          [
           "Transnational practices, intergenerational relations and identity construction in a migratory context: The case of young women of Maghrebine origin in France",
           "10.1177/1354067x11427462",
           2012,
           "In France, the issue of young women of Maghrebine origin has received important media coverage, and even become a political issue. In this context, we have conducted a qualitative research to study (1) the transnational practices, (2) the intergenerational relations, and (3) the identity construction of this population, within the dialogical self theory framework. We administered a semi-structured interview to 19 young women (Age range: 16–25 years) born in France of parents who emigrated from the Maghreb (Tunisia, Algeria and Morocco). The interpretative phenomenological analysis of our data reveals two transnational practices as salient issues of the identity construction and the intergenerational relations of young women of Maghrebine origin: the Muslim religion and the norm of virginity. Past and present relations between France and Maghrebine populations have transformed these traditional values into symbolic identity markers. However, these norms are always subject to multiple and creative renegotiations and redefinitions, which reflect the dialogical and multiple self of young women of Maghrebine origin.",
           18,
           "culture_&_psychology"
          ],
          [
           "On the Varieties of Intersubjective Experience",
           "10.1177/1354067x030093008",
           2003,
           " Coelho and Figueiredo (2003) explore the relationship between a heterogeneous collection of theoretical approaches that they term `intersubjectivist'. The authors' aim is not to integrate or synthesize the different dimensions into a coherent framework, but rather to invoke one depiction of subject-other meeting points where another appears incomplete. It is argued in this commentary that the authors do not pay sufficient attention to the incompatibilities between the various projects that they include in their discussion. It is also argued that the metaphor of the autonomously constituted subject may serve important existential and ethical functions. ",
           4,
           "culture_&_psychology"
          ],
          [
           "Social psychology as a developmental discipline in the dynamics of practical life: Gustav Jahoda’s pioneering studies on children’s social thinking",
           "10.1177/1354067x18779035",
           2018,
           " Gustav Jahoda’s research on children’s development of ideas and concepts constitutes a fundamental contribution to social psychology as a developmental and cultural discipline. Jahoda conceived humans in their interdependent relations with socio-cultural and historical environments in which they live, attain knowledge and act. Jahoda’s research on the diversities of thought and agency in children was the subject of meticulous conceptual and methodological rigour. His scholarly work crossed several social and human sciences. This tribute focuses on Jahoda’s early studies of children’s ‘social thinking’ about nationality and economic systems that he carried out in Glasgow. Later in his life Jahoda pursued his ideas on children’s thinking in a close dialogue with other scholars among whom Jean Piaget, Lucien Lévy-Bruhl and Serge Moscovici assumed particular relevance. ",
           2,
           "culture_&_psychology"
          ],
          [
           "Continuing Commentary: Emotions of Guilt and Shame: Towards Historical and Intercultural Perspectives on Cultural Psychology",
           "10.1177/1354067x09337870",
           2009,
           "Cultural psychology, as one of the youngest, yet fastest growing social sciences, has been explored in most parts of the world and approached from a great diversity of angles. What must be continuously researched in the theory, method and critique of cultural psychology, however, are historical, intercultural and political perspectives. To take up this thesis seriously, the present commentary illustrates the fundamentally historical, intercultural and political nature of cultural affect, cognition and behaviour. It concludes with the suggestion of an inbetween cultural and cultural political stance that the critical-intellectual cultural psychologist takes.",
           6,
           "culture_&_psychology"
          ],
          [
           "Mikhail Bakhtin’s contribution to psychotherapy research",
           "10.1177/1354067x11418543",
           2011,
           " Vygotsky clarified the methodological foundation that, in his view, characterizes every scientific discipline by elucidating the concepts of subject matter, explanatory principle, and unit of analysis. In this article, these concepts are used to explore and organize Michael Bakhtin’s relevance for psychotherapy research. Client and therapist utterances can be regarded as the object of research. Bakhtin’s theory of utterance provides the basic abstractions that define the facts, or the subject matter, of the research area. Semiotic mediation will be considered the explanatory principle that accounts for the utterance as a tool of interaction as well as an expression of intra-psychic processes. Neither Vygotsky’s instrumental nor Bakhtin’s dialogic conception of the sign are adequate for explaining the great variety of semiotic mediation in communication, object-oriented actions, and intra-psychic processes. A revised conception that articulates the dual reference of sign meanings will be introduced. Finally, Bakhtin’s contribution to the unit of analysis in psychotherapy research will be illustrated by elaborating his concept of semantic position. ",
           24,
           "culture_&_psychology"
          ],
          [
           "Tailoring identities",
           "10.1177/1354067x11398316",
           2011,
           " In the first part of this article, some consequences of telling truth about history in the Soviet Union and Russia are briefly described: crises of history teaching in schools, and ongoing ‘‘history wars’’ with the neighboring countries that have regained independence. In both cases, the problem is how to use historical knowledge in constructing identity narratives when the knowledge is contradictory. In this context, some issues analyzed in Carretero and Kriger’s and Tileagã’s work are discussed. Carretero and Kriger (2011) demonstrate that students in Argentina are largely unable to present a logically coherent story of the origins of their country. The difficulties the students experienced were related to the fact that the task they had to solve was highly artificial. They had to offer a high-level rational analysis of ideological texts which is not needed for the successful functioning of these texts. Tileagã’s (2011) paper is about how a former secret informer of the KGB-like organization in Communist Romania copes with the fact that his disgusting secret becomes public. In the coping process, the person makes use not only of his own memory, but also of his diaries as well as of the Securitate documents in the archives. All the three sources provide tools for reshaping identity and self-esteem, which can never be totally negative. Elaborating a typology of statements that people use in situations like this one would present further interest. ",
           2,
           "culture_&_psychology"
          ],
          [
           "Life is not chess: Towards a dynamic theory on altruism",
           "10.1177/1354067x20957557",
           2020,
           " Economic theory propagates a model of the human being commonly known as homoeconomicus; an individual with a rational orientation directed towards maximizing his/her preferences. However, our everyday lives involve many altruistic acts. These can range from small gestures of kindness such as holding a door open for another person, to heroic feats such as risking one's life to save a child from drowning. During our lives we also meet certain people that instantly induce our kindness. Our nicety in these moments is not based on a pursuit to optimize our material desires. Rather, we allow our feelings and intuitions to guide the course of our actions. How do we reconcile these experiences against the economic conception of human nature as inherently selfish? Addressing this contradiction, the paper will deconstruct the economic view and repositioning it as the product of an epistemological stance that distorts our view of altruism. An alternative model on altruism will then be developed by merging anthropological theories on value with insights from cultural psychology and grounded cognition. Through this process, a passage will be shown from static and universalizing perspective towards an emergent and dynamic theory on altruism. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Ethnotheories and Childrearing Practices: Some Constraints on Their Investigation",
           "10.1177/1354067x04045744",
           2004,
           " Our comments on Keller et al’s (2004) paper stress that new perspectives on the investigation of ethnotheories and childrearing practices are very much needed. Based on our own assumptions—the ‘network of meanings’ perspective—some constraints of the results reported in the target article are discussed. In order to alter some dominant and traditional Western ethnotheories, suggestions are made for taking into account both parents and relevant kin group members, not just the mother figure. Given the diversity of the existing ethnotheories, and the diversity of social strata, cultural psychology of parenting needs to go beyond the usual middle-class models. The need for an awareness of the dialogical processes established among researchers and participants is also highlighted. Finally, it is suggested that discourse analysis should go far beyond verbal communication, analyzing other kinds of social languages. ",
           2,
           "culture_&_psychology"
          ],
          [
           "Attention operation and language in the learning process in a music lesson",
           "10.1177/1354067x221097612",
           2022,
           " This paper presents an interactive episode analysis which was resulted from a music lesson for children. The idea was to point out the attentional process, in a perspective of Vygotsky and Luria. The study involved a group of three children who weekly had participated in Group Piano lessons at a social project developed in São Paulo State, Brazil. The data were documented by means of a field diary and the transcription of a video recording, and the analyzes were based on studies of historical-cultural approach. It is emphasized that the attention process happens depending on the apparently individual volitional acts but notoriously established during social relationship. Social genesis and perceptions which are expressed in gestures, looks, and speeches point to a complex construction perception of oneself, of the other and of the music in teaching relationships. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Body, Mind and Culture: The Dialogical Nature of Mediated Action",
           "10.1177/1354067x9511007",
           2007,
           " Elaborating on Wertsch's central argument, our thesis is two-fold: (a) mediated action is dialogical; (b) dialogue as a basic feature of the human condition far exceeds the boundaries of verbal conversation. In discussing the difference between logical and dialogical relationships, Bakhtin's 'ventriloquation' is defined as a collective voice. Emphasis is given to the role of the body in pseudo-and pre-hnguistic dialogues. Finally, the central argument is rephrased in terms of Leontiev's three forms of history: evolutional, societal and individual. ",
           21,
           "culture_&_psychology"
          ],
          [
           "Science between Cooperation and Competition: Commentaryon Hurme",
           "10.1177/1354067x9700300202",
           2007,
           " According to Hurme's (1997) production metaphor, competition among researchers plays a central role in scientific enterprise. I argue that competition cannot be excluded from scientific practice and should actually be considered as a significant motivational force. My main thesis, however, is that the production metaphor is blind to the scientific process as a cooperative enterprise guided by a specific set of values. Even in an era in which scientists are under increasing pressure to produce, the original dialogical spirit embodied by the figure of Socrates is at the heart of science as a moral enterprise. ",
           3,
           "culture_&_psychology"
          ],
          [
           "Cultural Psychology and the Problem of Exchange between Individual and Environment: Is There a Common Concept?",
           "10.1177/1354067x9733011",
           2007,
           " The holistic perspective on the person-context exchange conception present in so many current culture-oriented developmental theories has different roots in the history of European psychology. Here, one school assumed to have contributed to the widening of our understanding of the cultural or environmental influence on individual development is presented in some detail. This school of thinking is compared to another European conceptualization of an integrated view on person-culture exchange (discussed in this issue). Biological, cultural-philosophical and psychological aspects were linked together in a school established at the newly founded university at Hamburg, Germany, during the 1920s and early 1930s. Cooperation by three scientists from different disciplines pushed forward the idea of a holistic concept describing the process of development within context. William Stern, the psychologist, Ernst Cassirer, the cultural philosopher, and Jakob Johannes von Uexkull, the biologist, worked together and successfully developed an integrated perspective on the exchange between the individual and his or her environment. Although never manifest as a 'school' in its own right, it is maintained that the three scientists' interdisciplinary efforts to grasp a holistic explanation of the subject-environment relationship is found in many components remaining in contemporary theories exploring links between individual and environment. ",
           5,
           "culture_&_psychology"
          ],
          [
           "To become one with the instrument: The unfolding of a musical topography",
           "10.1177/1354067x15570491",
           2015,
           " The present article advances the notion of musical topography to describe the engagement between a practitioner and the musical instrument, emphasizing its developmental character. From the point of view of semiotic anthropology, it is suggested that the development of such a practical engagement is guided by expressivity, and that the instrument appears not only as an extension of the body, but participates in the generation of a unitary field, where bodily motion, the instrument and the tonal space are intertwined. The development of lived musical practice draws its force from a situated tradition that consists of normative, structural and stylistic elements, and of a constellation of genres and values shaped and reshaped by generations of practitioners. Finally, it is emphasized that the notion of musical topography brings back to musical praxis its long neglected imaginative dimension. ",
           10,
           "culture_&_psychology"
          ],
          [
           "Bakhtin’s realism and embodiment: Towards a revision of the dialogical self",
           "10.1177/1354067x11398308",
           2011,
           "How can we understand socially constituted selfhood? H. Hermans has addressed this question with the notion of the Dialogical Self that he draws from the philosopher Mikhail Bakhtin. We focus on Bakhtin’s discussion of realism in relation to how he has been interpreted by Hermans. This notion of realism (which we coined ‘‘expressive realism’’) highlights how sociality is inseparably related to embodied experience, thus making way for a sociocultural psychology that takes into account life as it is experientially lived. We point out how Hermans’ vision of the Dialogical Self neglects such embodied experience. This discussion leads to the claim that Bakhtin sees the self as social insofar as our most primary embodied experience is social, where Hermans anchors the sociality of self in inter-subjective exchange. Accordingly, an extension of the Dialogical Self is offered through discussion of these points.",
           26,
           "culture_&_psychology"
          ],
          [
           "Imagining cultural psychology",
           "10.1177/1354067x15568981",
           2015,
           " Based on the contributions of Pern, Granatella, and Rojas, I shall develop three Vichian aspects found in the three papers under the headings affective intentionality, expressivity, and creativity, which, I find, should all be treated as central aspects of mental life as studied by cultural psychologists. ",
           8,
           "culture_&_psychology"
          ],
          [
           "The Authoring of School: Between the Official and Unofficial Discourse",
           "10.1177/1354067x05055500",
           2005,
           " Theoretically the paper addresses the question of how official and unofficial discourses are related and what function the unofficial register serves for the official one. It draws on the idea of ‘underlife’ and the heterogeneity of discourse in order to show how the unofficial discourse can be a productive tool for students to both distance themselves from school and negotiate school identities in order to create new, and (for students) more compatible, forms of ‘school’. Institutional settings do not automatically produce the institutional scripts, positions and norms they are associated with; rather, they need to be authored by participants who ‘instantiate’ these scripts, positions and norms. This paper focuses on how students author school (the official) but at the same time produce alternative discourses (the unofficial). A data set of transcribed student group talk in a multi-ethnic classroom in the Netherlands is used for the analysis. ",
           10,
           "culture_&_psychology"
          ],
          [
           "The meaning of work and cultural psychology: Ideas for new directions",
           "10.1177/1354067x17729363",
           2017,
           "Work is one arena in which human beings constitute their identities and participate in collective-cultural enterprises. But research on factors affecting the meaning of work and its outcomes focuses mostly on individual-level variables related to workers’ experience. However, scholars have recently proposed a shift towards a more collective dimension of meaningfulness, in particular, the cultural level. This article discusses and expands on this recent trend, demonstrating how growing attention to cultural factors of work’s meaning raises some problematic, crucial issues about the very definition of culture and its role in meaning-making. A particular issue is the assumption that culture is transmitted to people, that it is primarily a collective endeavour based on shared values and that culture can endow work with meaning. Based on a cultural psychology perspective, we revisit both the relationship between person and culture and the idea of work as a cultural phenomenon. We argue that work is inherently a meaningful activity, mediating between personal and collective culture. We end by proposing some potential new directions to explore.",
           16,
           "culture_&_psychology"
          ],
          [
           "A Review of Controversies about Social Representations Theory: A British Debate",
           "10.1177/1354067x05058586",
           2005,
           "Since its inception more than forty years ago, social representations theory has been subjected to several criticisms, particularly within British discursive psychology. This paper reviews four major controversies that lie in the areas of (a) theoretical ambiguities, (b) social determinism, (c) cognitive reductionism and (d) lack of a critical agenda. A detailed discussion and evaluation of these criticisms reveals that while some can be regarded as misinterpretations, others need to be treated as serious and constructive suggestions for extending and refining the current theoretical framework. The main argument underlying this review is that many of the criticisms are based on the difficulty in understanding and integrating the complex, dynamic and dialectical relationship between individual agency and social structure that forms the core of social representations theory. Engaging with the critics is thus thought to provide clarification and to initiate critical dialogue, which is seen as crucial for theoretical development.",
           134,
           "culture_&_psychology"
          ],
          [
           "Manifestations of Depression: Self-Perception, Culture, and Body",
           "10.1177/1354067x221145898",
           2022,
           " As we emerge in a post-pandemic society, the feelings of isolation present during quarantine persist. But for some, these feelings of isolation have been present long before the pandemic began. The ideal of mental wellness is an important one: depression, anxiety, and persistent feelings of hopelessness severely impact our lives, relationships with loved ones, and our relationship with ourselves. In conjunction with an understanding of mental wellness, there must also be an understanding of mental illness. For in our pursuit of mental wellness after quarantine, we must not forget our compassion for those who have been suffering without. Through this short virtual issue, we invite you to read the following selected articles from Culture & Psychology. Thematically, they may find themselves fitting well with a weekly seminar, or a graduate course on mental health. One may find themselves discovering new insights of theoretical expansion beyond what this Special Issue can provide. Thus, in a quest for the solidification of our compassion, this virtual issue delves into three key aspects of depression: its relationship with ourselves, our cultures, and our bodies. ",
           0,
           "culture_&_psychology"
          ],
          [
           "The Unconstructed Self",
           "10.1177/1354067x0062013",
           2007,
           " Postmodernism proposes that the notion of self is a cultural construction and lacks any substantive or real referent. Chandler (2000) and Shotter (2000) offer challenges to this postmodern destruction of the self. Chandler proposes that within the cultural variety of self notions there is a common theme whose characteristics are ‘permanence within change’ and ‘sameness within becoming’. Shotter suggests that narrative structure opens up a conceptual space through which the self can be known. Support for Chandler and Shotter is provided by Neisser’s notion of five kinds of information about the self and Gendlin’s view that experience is more intricate and complex than the logical configurations provided by language. ",
           6,
           "culture_&_psychology"
          ],
          [
           "Culture of death in Mexico: Psychoanalytic inquiry about mourning rites and the symbolic function of society",
           "10.1177/1354067x20976505",
           2020,
           " Mexico stands out for its unique rites of symbolization of death. Being historically determined by the richness of its pre-Hispanic cultures, and with the fusion of catholic and Mesoamerican rites, Mexicans’ relationship with death is unique. Mourning rites are imbued with a circular worldview of life and death. Some of the basic psychoanalytic components of mourning are present in Mexican mourning rites: symbolic function, cathartic affects, identification, and socialization of signifiers. Nowadays, the massive deaths as a result of violence imposes the encryption of mourning as a perverse demand. The lack of response to the cries for help render useless the symbolic functions of mourning rites, which brings about a new way of socializing the loss, through massive social movements. We inquire, through a psychoanalytic reading of mourning and its socio-historical aspects in Mexico, and by emphasizing the traditions of mourning and its multiple symbolic values, the different ways Mexicans deal with death, in order shed some light into Mexicans’ symbolic responses and relationship with death while facing the perverse challenge of a violent regime. ",
           1,
           "culture_&_psychology"
          ],
          [
           "A Psychological Analysis of the Imagery of Chinese <i>Menshen</i>",
           "10.1177/1354067x221097607",
           2022,
           " The prominent imagery of Menshen (门神door gods) within traditional Chinese culture has led to the development of a variety of cultural symbols, including military door gods, civil door gods, praying door gods, and other related ones, such as stone lions and Shigandang (stone tablets). This article studies the impact of the belief in Door Gods and their worship on Chinese psychology and behaviour on both a conscious and unconscious level. At the conscious level, from its first articulation to its development into a cultural image and related myths and legends, the belief in Door Gods can be said to have gone through four stages: a primitive worship of reproduction in ancient times, animal worship during the Zhou Dynasty, the worship of anthropomorphic gods during the Han Dynasty and the worship of hero gods worship during the Tang Dynasty. This process corresponds to the four specific symbols of ‘peach branch’, ‘tiger/chicken’, ‘Shēn Shū(神荼)’ and ‘Yù Lǜ(郁垒)’ (‘鬼’: the two spirits guarding the entrance of the house), and ‘hero’. On an unconscious level, the psychological symbolism of the belief in Door Gods belief is interpreted through the Door Gods sacrifice and the Fu(复)” hexagram. Closing the door is related to Kun (坤, the receptive, earth), while opening the door is related to Qian (乾, the creative, heaven). Together, Kun and Qian were held to be in a state of continual transition, one changing into the other, which reflects Chinese philosophy’s emphasis on movement. Traditionally, Chinese people held more than 10 kinds of door-related sacrificial activities every year. Although some of these activities have gradually fallen out of use, the traditional custom of pasting door couplets and images of Door Gods to doorways has been preserved. By repeating the ritual every year, the Chinese gain the strength to protect themselves and their family members. Clinical studies of sandplay therapy have found that the image of Door Gods constitutes a ‘patron saint’ on an unconscious level. Door gods guard the boundary between consciousness and unconsciousness (the inner and outer worlds), thereby protecting the spiritual strength of those who supplicate them. This suggests that using their images in a therapeutic context could help individuals to maintain boundaries and protect themselves. The emergence of the Door Gods image can transform the guardian energy hidden at the border between unconsciousness and consciousness, help the clients keep the boundary and protect themselves. ",
           1,
           "culture_&_psychology"
          ],
          [
           "“A man doesn’t drink from a straw. Never!” the experience of coming out as gay to oneself and to others",
           "10.1177/1354067x241226450",
           2024,
           " We examine in this paper the individual and social process of coming out as gay. Through a sociocultural and developmental psychology theoretical lens, we unfold the process as a liminal experience that starts within the individual and is continuously negotiated in between the person, the social others, and the broader society. Through interviews and autoethnography, we look at this process through the experiences of three young men coming out in Denmark. The findings highlight how coming out is a complex process that starts before one comes out to others and continues to develop as a meaning-making process as the person starts coming out to others, where others’ responses are internalized and continue to form this person’s identification within society. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Contingency and plasticity: The dialectical re-construction of the concept of home in forced displacement",
           "10.1177/1354067x19871203",
           2019,
           "The loss of home as a consequence of war, conflict and displacement urges us to question the concept’s very construction. Although existing spatial and cultural studies on the subject have explored the immaterial characteristics of the construct, they have overlooked its connection to the consciousness and agency of the displaced, which are quintessentially contingent. This article presents a theoretical inquiry into the influence of the processual ambiguity of our cognitive system on the positioning of the concept of home between the temporality of its construct and the plasticity of its agency. Using connections between cognitive plasticity (based on Catherine Malabou’s concept of the freedom of the brain) and spatial plasticity (influenced by Vilém Flusser’s notion of the freedom of the migrant and the construction of the concepts of home), it establishes that the plasticity of migrants’ agency in displacement is an instrumental process in encoding new spatial practices of home-making.",
           3,
           "culture_&_psychology"
          ],
          [
           "Towards a dialogical methodology for single case studies",
           "10.1177/1354067x19894925",
           2020,
           "This special issue has explored a range of means of ‘generalising’ or ‘re-situating knowledge’ through the intensive, dialogical, examination of single cases. The papers elaborate aspects of the methodology of dialogical case studies without asking the traditional question: ‘of what is this a case?’ In this concluding article, we look across the papers to draw out methodological considerations for dialogical single case studies, comparing how the papers deal with four key dialogically informed methodological concerns: the primacy of self-other interdependencies; dynamics; ethics; and modes of writing. We then turn to the question of generalising, or re-situating, knowledge. Across the papers, three different, but overlapping, approaches to re-situating knowledge are taken, implying alternative possible questions: (i) How does the case participate in epistemic or narrative genres? (ii) How does the case contribute to a genealogy? (iii) In what ways is the case generative? We offer these concepts and questions as methodological prompts for case study researchers to conceptualise their knowledge-making as a dialogical endeavour.",
           9,
           "culture_&_psychology"
          ],
          [
           "Life Course Staging as Cultural and Subjective Practice: Review, Critique, and Theoretical Possibilities",
           "10.1177/1354067x09344885",
           2009,
           "This paper identifies and critically assesses various research approaches to subjective and cultural-historical notions of life stages through the lens of comparative-cultural, psychometric, discursive psychological and ethnographic perspectives. Included is an overview of 48 studies of subjective attributions of life stages (1984—2007) covering 14 national settings, with a discussion of their limitations. Possibilities for cross-fertilizing critical gender theory with life stage theory are briefly discussed. It is suggested that analytic notions of citationality and hegemony, both pioneered in the context of gender studies, may be productively appropriated in cultural psychology.",
           4,
           "culture_&_psychology"
          ],
          [
           "The Structuring Process of the Social Representation of Violence in Abusive Men",
           "10.1177/1354067x0394003",
           2004,
           " This paper examines the process of the emergence of new social representation among abusive men vis-‡-vis their own behavior. The discussion focuses on a group of 65 men who were sent to a closed hostel (Beit Noam) for intensive therapy for habitual violence. The paper argues that there was no possibility of the existence of such a representation at the beginning of therapy because there was no relevant group to create the discourse necessary for the structuring of social representations. The creation of the group and the ensuing discourse helped the men construct a social representation of their own violence. Such a representation enabled them to complete therapy successfully. ",
           4,
           "culture_&_psychology"
          ],
          [
           "Body Odor: The International Student and Cross-Cultural Communication",
           "10.1177/1354067x9514006",
           2007,
           " This article examines body odor and the cultural values that come into play in determining the limits of acceptability in body odor, as well as the issue confronting the person identified as 'the source of the problem'. A brief review of the literature is presented to acquaint the reader with values and meanings associated with odors. Detweiler's category width construct is used to examine intolerance to body odor. Neurological factors of smell are also discussed. Finally, a number of suggestions are presented to assist in making cross-cultural conflicts about body odor into worthwhile learning experiences about ethnocentrism. ",
           4,
           "culture_&_psychology"
          ],
          [
           "Boesch’s Symbolic Action Theory in Interaction",
           "10.1177/1354067x0174006",
           2007,
           " Some remarks are presented reflecting recent implications of Boesch’s symbolic action theory for the development of studies concerned with the relationship between verbal interaction and knowledge construction. In doing so, attempts are made to improve the interlocution of Boesch’s account with other significant semiotic-constructivist propositions. ",
           13,
           "culture_&_psychology"
          ],
          [
           "Review Essay: Racial Relations and Racism in Brazil",
           "10.1177/1354067x07082805",
           2007,
           " Edward Telles' book Race in Another America: The Significance of Skin Color in Brazil (2006) has contributed to the understanding of racial and skin color relations in Brazil. The main aspects of the past and present of racism in Brazil are discussed, such as whitening, mestizaje , and the ideology of racial democracy, and some additional data are presented. This work reflects on and brings to light the reflections of Telles and of other researchers of racism about a future of more equalitarian racial and social relations in Brazil. ",
           6,
           "culture_&_psychology"
          ],
          [
           "The concept of hysteria as mirror of the relation between clinical and cultural psychology",
           "10.1177/1354067x231185723",
           2023,
           " This paper theoretically examines how the psycho-pathological concept of hysteria has evolved since its emergence in antiquity, what causes contributed to it and how nowadays meaning-making systems of clinical psychology are mirrored through it. As has been shown, the transformation of hysteria is more closely related to the cultural psychology of feminism than any other disease before it. The 20th century in particular marked a significant change in the conceptualization of hysteria. From a highly sexist and paternalistic it became a political diagnose and finally was used, after getting banished from the psychological dictionary as an everyday pejorative personality adjective. It underwent a transformation within its gender classification, which was initially limited exclusively to women. Later, it became a psychiatric diagnosis, which was no longer durable nowadays and has finally changed into the concept of histrionic today. The analysis shows how, on the one hand, medical and biopsychological findings and, on the other hand, especially political movements and their cultural psychological processes of change form the basis of psychopathological concepts. It will be shown to what extent hysteria is exceptionally exemplary for this change in psychological meaning-making. In this context, the close connection between hysteria and the emancipatory development of our society could be emphasized. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Conceptualizing the mediating role of power asymmetries in research communication: A social representations approach",
           "10.1177/1354067x14542528",
           2014,
           " While the issue of power within the research relationship has been evoking constructive discussions for over two decades in qualitative research, existing approaches fail to understand power both as macro-socially determined and interpersonally negotiated in the micro-space of research communication. In this article, I use ideas from Social Representations Theory (SRT) to conceptualize the macro-social conditions that give meaning to power asymmetries expressed through the identities in the micro-space of the research relationship and to examine how these identities and their power asymmetries mediate research communication. Three instances of research between a local researcher and immigrant participants are analyzed. Analysis shows that the identities of a Greek researcher and immigrant participants introduce power asymmetries in the research communication due to the meanings they carry in the Greek social context. These asymmetries mediate communication by evoking reflection, challenge, resistance and reversal of positions. It is suggested that this double micro and macro focus achieved through SRT contributes to qualitative methodology by inviting important questions regarding data construction (under which identities are data constructed, how are they constructed and why are they constructed in such a way) and by advancing an epistemologically reflective stance to research. Further, the present approach contributes to SRT by advancing a power-inclusive understanding of interpersonal dynamics, which is considered underdeveloped by SR theorists. ",
           3,
           "culture_&_psychology"
          ],
          [
           "Commentary: Framing Sympathy",
           "10.1177/1354067x10361399",
           2010,
           " The expression of emotion takes many forms and their linguistic expression is one of the key ways they are articulated. The study of the semantic fields in which the expression of emotion takes place is in need of an appropriate methodology and a sufficiently broad set of examples. Anna Gladkova’s attempt to use the methodology of Natural Semantic Metalanguage to explore the semantics of certain emotion terms in English and Russian is examined and evaluated in light of certain philosophical and semiotic categories and considerations. Of principal interest is the bearing of the work of C.S. Peirce and John Dewey, from the American pragmatist tradition, and of Karl Bühler, from the psychological tradition, on such a methodology. It appears that the expression of emotion in language is embedded in multiple fields of rather different types and performs different semantic functions. I indicate how this would modify, without reducing the need for, the types of analyses undertaken by Gladkova. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Iranian homosexuals; social identity formation and question of femininity",
           "10.1177/1354067x14551296",
           2016,
           " Homosexuality and homosexual subjects have been oppressed during the sociocultural transformations of contemporary Iran while femiphobic attitudes have been central to this marginalization. Notwithstanding the profound distortion of the concepts of femininity and masculinity in the course of the modernization and islamization of the country, defeminization of the public space and prioritization of the masculinity in gender discourses have been crucial to all social transitions that intend to feed their desired social-ideal identity. Iranian homosexuals, who are condemned both for their sexuality and nonconformist gender effeminacy, have recently formed fictive kinships and backstage friendship groups in order to negotiate and attain a new social identity. In this paper I will examine the basic reasons behind the rejection of homosexuality in Iran and the ventures of the Iranian gays into cyberspace and back to society, while struggling to construct a new feminine-admissive social identity. The final part of this study is devoted to the discussion of the seat of femininity, particularly effeminacy, among Iranians. The paper concludes with demonstrating the incomplete social identity formation of gays, but also envisages a rising divergence in Iranian youths’ gender behaviors which grants the likelihood of negotiating the newly developed social identity to homosexuals. ",
           7,
           "culture_&_psychology"
          ],
          [
           "Gender in culture-inclusive psychologies: A situated and selective mapping of historical and contemporary territories",
           "10.1177/1354067x16650833",
           2016,
           "Culture-inclusive psychologies, despite large theoretical and methodological differences, agree on the importance of culture for shaping mental phenomena, human behavior, and actions. How do these psychologists address gender? It is very common in psychology to frame gender as innate and determined by a male–female schema of reproduction. Do culture-inclusive psychologies depart from this schema and look into ways in which gender-related phenomena are culturally shaped? This article overviews two types of psychological texts. First, it examines classic psychological texts belonging to four selected schools of thought: cultural-historical psychology (Leont’ev, Luria, Vygotsky), critical psychology (Holzkamp, Holzkamp-Osterkamp), social constructionism (Mary and Kenneth Gergen), and action-oriented cultural psychology (Boesch, Straub). Second, it compares articles published in the Journal of Cross-Cultural Psychology and Culture & Psychology. This overview reveals that differences in conceptualizing gender are significant, covering a spectrum ranging from naturalistic to constructionist frameworks.",
           3,
           "culture_&_psychology"
          ],
          [
           "Situational selves of online identity and rationality in choosing – More examples of the college students’ online identity in China",
           "10.1177/1354067x20976514",
           2021,
           " The Internet has provided a new context for the exploration of the concept of identity. Different identities were expressed on different online settings, which indicates the feature of ‘situational selves’ of online identities. By comparing the differences among WeChat identity, Weibo identity and offline identity, more examples were introduced not only to explain ‘situational selves’, but also the ‘rationality’ in choosing among different online identities. ",
           1,
           "culture_&_psychology"
          ],
          [
           "On Jon Snow’s death: Plot twist and global fandom in<i>Game of Thrones</i>",
           "10.1177/1354067x19845062",
           2019,
           "The death of Jon Snow at the end of the fifth season of the TV serial Game of Thrones prompted an intense reaction among the fans of the serial on social media. Thousands of viewers all over the world contributed to the discussion of the meaning and implications of this event, turning it into a global event in the participatory culture of contemporary seriality. In this article, we propose an explanation of this remarkable cultural phenomenon. Based on a theory of plot twists as surprise structures, we argue that the reactions of fans can be understood as concrete, contextually adapted realizations of the characteristic cognitive reactions evoked by the emotions of surprise and shock caused by unexpected negative events. Our analysis focuses in particular on the contributions of viewers to the establishment of the beliefs disconfirmed by the plot twist and on the cognitive activities that served to adapt their minds to the new reality revealed by the twist, which also included reflections on the aesthetic aspects of the plot twist and the narrative in which it was embedded. By providing a public platform for these reflections, the fan forums allowed the individual attempts to adapt to the plot twist to become a collective endeavor. The study illustrates how universal cognitive mechanisms interact with culturally produced contents to generate similar reactions to a fictional event across the globe.",
           4,
           "culture_&_psychology"
          ],
          [
           "The decay of signs’ semiotic value: A cultural psychology interpretation of the contemporary social scenario",
           "10.1177/1354067x211027276",
           2021,
           " The article provides an analysis of the affective polarization of the public sphere, namely, the increasing momentum gained by affective sensemaking in the current socio-institutional scenario (e.g. raise of populism, distrust in democracy and spreading xenophobia). To this end, the Semiotic Cultural Psychology Theory (SCPT) is outlined. The SCPT focuses on the embodied micro-mechanisms bridging the intra- and inter-psychological levels of analysis of the semiotic dynamics. The article is composed of two parts. First, the SCPT is outlined in terms of its nine underlying tenets. Then, SCPT is used to frame an interpretation of the psycho-social dynamics underpinning the current socio-political scenario. Based on the SCPT model, the spread of affective sensemaking in current societal dynamics is interpreted as being due to the capacity of affects to work as semiotic stabilizers, enabling people to face the deep uncertainty fostered by the economic and political turmoil associated with globalization. ",
           5,
           "culture_&_psychology"
          ],
          [
           "What it is like to be a pickpocket",
           "10.1177/1354067x19894934",
           2019,
           "This study aims to show the socio-cognitive engineering of the pickpocket craft from the point of view of cognitive ecology. Being a pickpocket has a wider, existential status; studying it goes beyond the field of cognitive sciences. My ambitions are more modest: I try to show that the question about what it is like to be someone like a pickpocket is also a question about the cognitive structure of his or her activity space. In this light, I analyze some aspects of the reality presented in the movie Pickpocket by Robert Bresson. From the ecological point of view, scenes from the old movie present pickpocketing techniques in the context of the opportunities and constraints of a given environment. I claim that studies like this require integrating certain conceptual tools, like distributed cognition approach, ecological psychology, and cognitive studies of design.",
           0,
           "culture_&_psychology"
          ],
          [
           "Imaginative universals and human cognition in<i>The New Science</i>of Giambattista Vico",
           "10.1177/1354067x15575795",
           2015,
           "Universals have occupied a central role in philosophy ever since the Socratic quest for definitions. The need to find concepts both universal and shareable is rooted in the Western philosophical tradition, in order to capture and control the disorder that besets human life. In other words, Universals occur as part of a rational attitude by which to substantiate knowledge and its evaluation. My aim in this paper is to confront Vico’s discovery of imaginative universals with the classical paradigm of rational thought that, formed by abstraction from empirical experience, reduces the knowledge to a rigorous process of inference. Against this barbarism of reflection, what Vico does in his works is to chart out possible new ways in which science can innovate itself.",
           7,
           "culture_&_psychology"
          ],
          [
           "Me, myself, and God: Religion as a psychocultural resource of meaning in later life",
           "10.1177/1354067x14551294",
           2016,
           "The present paper addressed the different meanings attached to religion as cultural resource in the course of life. Indeed, abundant cultural research has confirmed that religion could be a powerful symbolic system that shapes people’s beliefs and attitudes. Its significance may depend on contextual factors and may vary over time and place, thus showing different implications across cultures and group cohorts. To better investigate such assumption, this paper involved a group of elderly believers (convinced Catholic believers and converted to Buddhism believers) as to analyze the role played by religion in their life experience. Narrative interview, content, and diatextual analysis helped reconstructing different cultural interpretative repertoires of religion in late life: a source to answer to the essential questions about life, an anchor to face the present and the future, a sociocultural resource for well-being.",
           19,
           "culture_&_psychology"
          ],
          [
           "Re-theorising the funds of identity concept from the perspective of subjectivity",
           "10.1177/1354067x19839070",
           2019,
           "This paper is a theoretical response to recent developments in the funds of identity literature which has seen the introduction of two interconnected concepts, ‘dark funds of identity’ and ‘existential funds of identity’. While these recent concepts may expand the canvas from which researchers draw in developing interventionist approaches for minoritised students, they nevertheless polarise positive and negative emotions and experiences which is problematic on a conceptual level. This paper addresses this issue by first presenting how funds of identity and existential funds of identity have been theorised, arguing that there remains a tension between the distributed theory of the original conceptualisation of funds of identity and the phenomenological and subjective dimension that underpins existential funds of identity. In order to resolve this tension, I situate the funds of identity concept within a cultural historical tradition, drawing upon González Rey’s work on subject sense and subjectivity in order to propose an alternative conceptualisation of funds of identity that allows researchers to transcend the dichotomy of positive and negative emotions.",
           11,
           "culture_&_psychology"
          ],
          [
           "What Characterizes Language That Can Be Internalized: A Reply to Tomasello",
           "10.1177/1354067x9600200307",
           2007,
           " Tomasello disagrees with my position that language is the only human artefact that potentiates internalization. Tomasello's position seems to imply that language can be only verbal. My position is that every object or behavioural act is a symbol if it has all of the following characteristics: symbol must be an object or phenomenon that can be directly perceived through sense organs; meaning of symbols must be shared by organisms; symbols must refer to objects, events or phenomena; it must be possible to use a symbol differently from its referents. Internalization is possible only by means of symbols with such characteristics. ",
           18,
           "culture_&_psychology"
          ],
          [
           "Review symposium: Encountering Objects and Others as a Means of Passage",
           "10.1177/1354067x07079889",
           2007,
           " Zittoun's Transitions investigates how young people use cultural elements, like movies and novels, to manage ruptures as a specific moment in their life span, leading to transitions from one socio-psychological location to another. Zittoun's perspective is cultural as well as developmental, and can thus make visible the dynamicity of individual meaning-making processes, a semiosis taking place in the field of self, other, culture and objects which are used as symbolic resources in constructing identity. Zittoun proposes a three-dimensional model of the use of symbolic resources ( aboutness , time and distancing), accompanied by two theoretical constructs: the semiotic prism and the spheres of experience. This complex and transparent architecture is investigated empirically through the case studies of thirty young people whose interviews are thoughtfully analysed. Although Zittoun relates a person, others, a cultural element and the meaning of this element for the person in a dynamic semiotic movement of change, she does not elaborate on the dialogical dimension of this movement of change. It is otherness of and `in' objects which then comes to the foreground. This opened but not developed path is taken up by the reviewer, leading to the notion of dialogical objects: objects which are actually dialogical processes, developing in time within an exchange of voices and positions. Using a dialogical object as symbolic resource means activating the dialogical self; and investigating these uses gives the opportunity to observe the dialogical self in construction. Semioticity, accompanying and forming identity processes, is thus to be completed with alterity, giving these processes orientation and sociocultural value. ",
           14,
           "culture_&_psychology"
          ],
          [
           "Revisiting “The Art of Being Fragile”: Why cultural psychology needs literature and poetry",
           "10.1177/1354067x19862183",
           2019,
           "Writers devote their lives to find words that faithfully resemble what is at the core of human experience and existence. Thus, psychologists interested in understanding human development in everyday life could turn toward writers and poets with humble curiosity. In this article, we illustrate how a narrative analysis of a work of art can be done, taking “ The Art of Being Fragile. How Leopardi can Save your Life” by the Italian writer and teacher Alessandro D’Avenia as a case. In addition, we reflect upon the mastery with which the author sheds light on aspects that theories in cultural psychology have tried to unveil. Such aspects are: (a) poetic activism: a revolution of the poetics of everyday life; (b) the poetics of human development; (c) the beauty within the fragile as a master; and (d) the intuition of the spirit as an invitation.",
           10,
           "culture_&_psychology"
          ],
          [
           "The Wandering Soul in Relation to Time",
           "10.1177/1354067x06064576",
           2006,
           " The unidirectional, linear-progressive view of time for psychology may need an overhaul. In this article, I comment upon Yamada and Kato’s (2006) findings and further discuss the underlying axiom that gives time its structure: We stand in relation to things. This relationship is key to understanding the world in which we are embedded. The trajectories of time reveal the course of a particular development, be it the psyche in the historical-cultural temporal context as illustrated through Wilhelm Wundt’s Elemente der Völkerpsychologie (1912), or how certain people conceive of their soul’s voyage through life and death cycles. However, the supposedly ‘observed’ developmental trajectories—of whatever nature they may be—emerge due to our situatedness towards a particular event. In the end, we must remember that time is nothing but an ‘infused’ component of the complex qualities of phenomena, whose Gestalt reveals itself once the researcher’s finite perspective has cut somewhere into the spatio-temporal totality of the objective world ",
           6,
           "culture_&_psychology"
          ],
          [
           "Either scholar or activist? Thinking cultural psychology beyond academia",
           "10.1177/1354067x16645296",
           2016,
           "Both Robert Innis’s and Svend Brinkmann’s works bring to the fore a notorious, but usually forgotten, topic on cultural psychology: the normative framework that regulates the relation between the researcher and the phenomena studied. In fact, these ‘models of human flourishing’, using authors’ terminology, are scarcely discussed in comparison to theoretical, methodological, and empirical issues. In the present paper, a number of potential reasons for this omission are explored. In particular, it is argued that discussing the normative and pragmatic side of the discipline appears as risky in two directions: turning cultural psychology into activism, and conducting value-laden research. For this purpose, the case of Arthur Jensen's 1969 controversial publication on IQ is discussed. This example is useful to reveal the challenges that cultural psychology must face in order to become more aware of its normative orientations; particularly the pragmatic, social impact associated to conduct research on human issues. Ultimately, it is shown that the apparent risks mentioned before emerge from implicit, outdated conceptions of both activism and scientific activity.",
           3,
           "culture_&_psychology"
          ],
          [
           "Commentary: Opening Up Perspectives on Autonomy and Relatedness in Parent—Children Dynamics: Anthropological Insights",
           "10.1177/1354067x09344893",
           2009,
           "Many studies have shown widely varying human child-rearing practices; no child is ever a tabula rasa in the eyes of the culture. The article by McShane et al. (2009) on parenting themes of autonomy and relatedness among Inuit migrants from the northern countryside to Ottawa, a medium-sized city and the capital of Canada, offers important findings on previously less-studied child-rearing among Inuit in that southern urban setting. More broadly, the article contributes insights into how child-rearing practices and beliefs reflect local conceptions of the person and the world, and how the child should be prepared to live in it. Issues raised here include the challenges of distinguishing among cultural, psychological, and political economic influences of migration, urbanization, and globalization, and delineating the ways in which intimate personal concepts interweave with wider forces in child-rearing. Also at issue are definitions of relatedness and autonomy, concepts which are widely deployed in cross-cultural studies of child-rearing, but which are based upon Western philosophical formulations, and which McShane et al. analyze in the Inuit urban case. These concepts are difficult to formulate in culture-’neutral’ or ‘etic’ terms. The article shows both the uses and the limitations of retaining analytical ‘odd-job’ concepts for heuristic purposes. The present commentary argues that it is necessary to deconstruct critically such concepts as relatedness and autonomy, and to approach them as tendencies contingent upon context, rather than as universal polarized basic needs.",
           2,
           "culture_&_psychology"
          ],
          [
           "The Veil: A Silhouette of Autonomy and Empowerment",
           "10.1177/1354067x221115852",
           2023,
           " This study inspects controversies in the Western World about the veil worn by Muslim women in public. It merges two separate domains, Islamic Feminism and Western Feminism. These two domains need to be addressed to generate new opinions. Western Feminism believes that veil is a sign of oppression and masculinity. However, Islamic Feminists find the veil empowering and a sign of dignity. This study aims to unravel the underlying contradictions and blind spots that characterize the arguments in favor and against the veil. This juxtaposition can provide insight into new theoretical and empirical points of departure. All oppressions result from the political dynamics of the state in which the individual is living. It is utterly reductionist to criticize the choice to veil, which is an instrument of autonomy. This paper emphasizes that Islam does not oblige women to be victimized and dissatisfied. However, Islam strives to promote the autonomy of Muslim women. It is safe to say that Islam describes women as beauty with a brain. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Telling a national narrative that is not your own. Does it enable critical historical consumption?",
           "10.1177/1354067x14554156",
           2014,
           "National narratives are a key element in the process of history consumption and production. These master narratives have been analyzed in both theoretical and empirical studies as general schematic templates producing an essentialist and nationalist representation of the own past. The majority of studies examining historical representations of national narratives have used historical content of the students’ own nation. This study, on the other hand, analyzed the historical understanding of 34 Spanish university students concerning three dimensions of historical narratives about a nation other than their own. These dimensions were: the establishment of the historical subject, the moral judgment about the national group actions, and the legitimacy of the ownership of the territory. The distinction among three different dimensions is presented as providing a better both theoretical and empirical comprehension of master narratives as sociocultural devices. Our results indicated that participants had a more critical representation about the second and third mentioned features, whereas they had a romantic conception about the first one, suggesting then that the establishment of the historical subject could be the core dimension of the master narrative. Finally, some considerations about the process of history consumption and its relations to national identity are presented.",
           14,
           "culture_&_psychology"
          ],
          [
           "The veil and the search for the self: From identity politics to cultural expression",
           "10.1177/1354067x15606861",
           2015,
           "Wagner, Sen, Permanadeli and Howarth compare the reasons for wearing the veil of Muslim women in a Muslim majority society, Indonesia and in a society with a Muslim minority, India. They conclude that particularly Muslim minority women display a variety of reasons and strategies with regards to the headscarf, which according to Wagner et al. serve in the construction of identity and as a means of opposition against stereotypes and prejudice. Taking the case of Muslim women in Western societies, I argue that the language of identity, stereotypes and prejudice is insufficient for understanding the agency of women donning the veil. Instead I propose a genetic cultural psychological approach focused on the cultivation of affect and the acquisition of durable bodily dispositions through cultural training. The veil is part of an entire expressive style and discursive accounts are only a minor part of that style. Recognizing that style – unlike propositional accounts – is inherently ambiguous and polysemic allows us to see how Muslim women are creating for themselves the space of an agency that is not primarily defined in terms of opposition or of other people's demands for proper reasons.",
           6,
           "culture_&_psychology"
          ],
          [
           "Comparison of Public and Academic Discourses: Estonian Individualism and Collectivism Revisited",
           "10.1177/1354067x03009001004",
           2003,
           "The article studies the meaning of individualism and collectivism from two different perspectives—from the viewpoints of the academic discipline of cross-cultural psychology and of Estonian public discourse. More specifically, the aim of this study is to explore and understand the difference between Estonians' autostereotype of their extreme individualism and the opposing opinion held by the cross-cultural research community that sees Estonia as a collectivistic country. The findings show that the definitions and conceptualizations of individualism and collectivism by cross-cultural psychologists and Estonian lay-people are indeed only partially overlapping. If Estonians speak about their individualism or collectivism, they seem to emphasize their being/acting alone versus being/working in groups, whereas for cross-cultural researchers the defining attributes of individualism are striving for affective and intellectual autonomy and egalitarian values versus conservatism. Moreover, the findings clearly suggest that the concepts of individualism and collectivism are conceptualized differently not only in Estonian public discourse and academic discourse, but also within academic discourse in cross-cultural psychology. It seems that behind the solid and broad façade of individualism-collectivism, multiple concepts co-habit with rather diverse meanings. Future research should redirect its focus on the core elements of individualism and collectivism in order to clean the concepts of the deposited layers of meanings and implications and to help them to win back their status of principal cultural dimensions.",
           34,
           "culture_&_psychology"
          ],
          [
           "Social-ecological semiotics and the complex organization of psyche, language, and culture",
           "10.1177/1354067x241236726",
           2024,
           " In each given situation, our words and deeds carry signs and meanings that are contingent on, and reflect, the social-ecological semiotic settings. The purpose of this work is to better understand the complex organization of psyche, language, and culture. The process of hyper-generalization brings affective and cognitive opposites into the whole sign field and guides the whole relating with the world. As well, the process of semiotic mediation entails signs constraining and enhancing both interpersonal and intrapersonal psychological processes and experiences, including through nested systems (the levels of the individual-the relationship-the community-the societal). We present data for Australia and Thailand on Hofstede’s six culture dimensions, that is, power distance, uncertainty avoidance, masculinity/femininity, individualism/collectivism, short-term/long-term orientation & restraint/indulgence. An idealized and dynamic model of relations of Hofstede’s six culture dimensions and four indeterminate pronouns (e.g., ‘every’-one, ‘some’-one, ‘any’-one, ‘no’ one) is proposed. As a framework for construing the complex semiotic organization of (western, English-speaking) culture and psyche, four “cyclical” regulatory statements are outlined, regarding personal constraint, personal enhancement, cultural constraint, and cultural enhancement in language and culture, that is, in semiotic cultural psychology. Examples on the values of caring for people and planet are given to illustrate the social-ecological semiotic framework. ",
           0,
           "culture_&_psychology"
          ],
          [
           "The role of “responsiveness” within the self in transitions to university",
           "10.1177/1354067x17713928",
           2017,
           " Entering university is a complex psychosocial phenomenon that can create several new stressful situations that students need to face. The transition into university may be accompanied by some psychosocial problems such as reduced self-esteem and academic achievement, increased social anxiety, and a critical rise in the probability of dropout. How does a person use cultural elements to cope with stress? Responding to this question requires an understanding of the multivocal and ambivalent self. The paper aims at introducing and discussing the concept of Educational Self and the role of the responsiveness for explaining the complexity of the transition to a new educational context in Cultural Psychology perspective. The notion of responsiveness plays a crucial role in the “reconfiguration” of the multivocal and ambivalent self in transition. ",
           15,
           "culture_&_psychology"
          ],
          [
           "Cultural Psychology and Qualitative Methodology: Scientific and Political Considerations",
           "10.1177/1354067x08088557",
           2008,
           "An important feature of cultural psychology is its embrace of qualitative methodology. This methodology distinguishes cultural psychology from cross-cultural psychology, which embraces positivistic methodology. It is important to assess the use of qualitative methodology by cultural psychologists. However, cultural psychology consists of diverse theoretical perspectives which utilize qualitative methods differently. This article articulates a typology of qualitative research methodologies that have been used in conjunction with cultural-psychological approaches. The typology compares macro and micro theories of cultural psychology, and the ways in which they utilize formal and informal qualitative methodology. Examples of research illustrate each approach. Social science approaches are grounded in political assumptions and have political implications. I shall elucidate the politics of cultural-psychological theories and methodologies in order to enrich their description and explanation.",
           36,
           "culture_&_psychology"
          ],
          [
           "Relational individuality among Native American academics: Popular dichotomies reconsidered",
           "10.1177/1354067x18763799",
           2018,
           "An interdisciplinary qualitative study working with 40 Native American academics, who were selected for their specific diverse backgrounds, focused on selected aspects of subjective experiencing they generally had in common. Participants experienced the socio-cultural contexts of mainstream academia and tribal communities as incongruent and based on conflicting values associated with the conceptualizations of individualism versus relationality and communal cooperation. Viewing these seemingly dichotomous concepts from the perspective of Native American tribal world views, however, enabled meaningful integration of these concepts. The innovative relational individuality conceptualization allows for appreciation of uniqueness and self-improvement efforts without adherence to the mainstream principle of competitive individualism. At the core of the involved conceptualization of relationality, with preference for communal cooperation, is the experience of one’s embeddedness in personal relationships and one’s involvement within groups as a valuable member, which cannot be explained by either the necessity of socio-economic and ecological factors or the imperative of conformity to collective conventions. The extent to which the independence–interdependence and individualism–collectivism dichotomies apply to this case is limited. The discussed relational individuality conceptualization, facilitated by Native American tribal world views and culturally specific narratives, extend the repertoire of thus far recognized mechanisms that underlie the existing cultural variation.",
           5,
           "culture_&_psychology"
          ],
          [
           "Identity in heterogeneous socio-cultural contexts: Implications of the Native American master narrative",
           "10.1177/1354067x19877913",
           2019,
           " This interdisciplinary conceptual study discusses significant implications for psychological functioning of the heterogeneous historically based socio-cultural contexts that are intrinsic to different societies and cultures. Promoting deeper inquiry into the complexity of diversity viewed as a resource, this article elucidates its propositions by examples using observable circumstances concerning various populations, previous literature relevant to the topic, and selected findings from research conducted with 40 Native American academics. In particular, this article contributes novel insights concerning the importance for identity construction and experiencing of the fact that the status of Native American tribal nations is politically and legally unique, and their situation historically and socio-culturally in many regards different from that of ethnic minority populations. Correspondingly, master narratives that fundamentally favor either full inclusion into the dominant society or the idea of tribal sovereignty and self-determination seem to facilitate distinct ways of construction and experiencing of qualitatively different identities. Some of these are conducive to constructive interpretation, integration, and coping within mutually incongruent socio-cultural contexts. Master narratives that carry such potential under adverse circumstances constitute an important asset within the contemporary ever more diverse, yet interconnected societies. ",
           3,
           "culture_&_psychology"
          ],
          [
           "Scientific concepts and public policies: Semiotic-cultural obstacles concerning intergroup and intercultural relationships",
           "10.1177/1354067x12446235",
           2012,
           " I attempt to articulate Jahoda’s (2012) critical reflections regarding definitions of culture in recent cross-cultural studies and Moghaddam’s (2012) claims of an omnicultural imperative to guide the elaboration of public policies for managing relationships among human groups from different cultural origins. For this, I will approach some aspects of the socio-historical and ontogenetic roots of the notion of culture. The notion of culture and the consequent public policies involving intercultural managing are being transformed as our global society develops. It has been proposed that some ways of dealing with the culture of the other are crucial to achieve awareness in respect of one’s own cultural positioning when making science and attempting social interventions. Finally, the experience of Brazilian psychologists working on challenges faced by Amerindians dealing with the national society they live in will be presented as a pioneering work aiming to interfere in the development of public policies ethically concerned with the assurance of cultural integrity of currently marginalized social groups. ",
           7,
           "culture_&_psychology"
          ],
          [
           "Grief, photography and meaning making: A psychological constructivist approach",
           "10.1177/1354067x211015416",
           2021,
           "This article examines the value of using photography as both a methodological and therapeutic tool for the construction – and study – of meanings after a death-related loss. A study case, consisting of narratives of mourning elicited through a personal photo diary and a follow-up interview, will be analysed in light of five key advantages of using photography to study grief experiences according to a social constructivist approach. These advantages are (1) agency in the search for meaning; (2) the role of photography as a tool for scaffolding narratives of loss; (3) the role of photography in preserving the continuing bonds with the deceased; (4) the role of photography as technology of the self for emotional self-regulation and (5) photography as a process in the reviewing of the contextualised experience.",
           12,
           "culture_&_psychology"
          ],
          [
           "Diasporic virginities: Social representations of virginity and identity formation amongst British Arab Muslim women",
           "10.1177/1354067x14551297",
           2015,
           "This study compares how practising and non-practising British Arab Muslim women position themselves in relation to representations of virginity. Overall, in our qualitative study, we found that representations of culture and religion influenced social practices and social beliefs in different ways: non-practising Muslim women felt bound by culture to remain virgins, while practising Muslim women saw it as a religious obligation but were still governed by culture regarding the consequences of engaging in premarital sex. Interestingly, some practising Muslim participants used Mut’a (a form of temporary ‘marriage’) to justify premarital sex. This, however, did not diminish the importance of virginity in their understanding and identification as Arab women. In fact, this study found that virginity, for the British Arabs interviewed, embodied a sense of ‘Arabness’ in British society. Positioning themselves as virgins went beyond simply honour; it was a significant cultural symbol that secured their sense of cultural identity. In fact this cultural identity was often so powerful that it overrode their Islamic identities, prescribing their behaviour even if religion was seen as more ‘forgiving’.",
           16,
           "culture_&_psychology"
          ],
          [
           "Subjectivity and discourse: Complementary topics for a critical psychology",
           "10.1177/1354067x18754338",
           2018,
           "This paper aims to discuss the rejection of subjectivity by psychologists dominantly oriented towards concepts like discourse and deconstruction, as well as communicative and relational activities. The recognition of the symbolic character of human phenomena by psychology occurred relatively late in relation to philosophy, linguistics and anthropology. Nonetheless, this entrance was so radical that it led psychologists to deny most of the concepts that have traditionally been used by psychology. This paper departs from theoretical traditions that advanced a step further in the comprehension of the human psyche as a cultural-historically engendered phenomenon. On this basis, a new definition of subjectivity is advanced as a phenomenon that emerges as a result of the symbolical forms which are socially and historically situated, from which concepts like discourse, deconstruction and dialogical-communicative systems also appeared. Subjectivity, as treated in this paper, is oriented toward specifying human processes that are not exhausted in these concepts, being complementary to them in a broader and complex approach to the study of human realities.",
           29,
           "culture_&_psychology"
          ],
          [
           "On the Alert in an Unpredictable Environment",
           "10.1177/1354067x08088553",
           2008,
           " A fundamental tenet of much sociological, psychological and educational literature assumes that the creation of a predictable environment is crucial for nurturing a sense of well-being, as well as for generating a sense of trust in the wider social order. Still, the ways in which the environment is structured, and the very importance attached to the notion of predictability, will vary in different cultural contexts. Findings from an ethnography of daily life at an Israeli kindergarten over the 2001 school year show how the teacher, albeit unwittingly, shaped an environment that was inherently unpredictable . This unpredictability, in turn, served to mobilize personal resources and social practices among the children as a means not only of coping with the unpredictability, but of turning it to their advantage. Studies of Israeli Jewish youth reveal that the resources that are appropriate for successfully managing in an unpredictable environment are indeed salient and positively valued also at later stages in life. It is argued that socialization into an unpredictable environment at an early age reflects an enduring and characteristic facet of Israeli culture with regards to child-rearing. ",
           8,
           "culture_&_psychology"
          ],
          [
           "Maintaining the future through recurrent crises",
           "10.1177/1354067x231204298",
           2023,
           " Einar, a 94-year-old Faroese man who has always resided on the island of Suðuroy, has lived through several societal crises. In this article, I explore his experiences of living through three of them, highlighting his ability to maintain an imagination of in the future and detailing how crises interact over time. I propose that Einar’s upbringing in the cycles of crisis characterising fishery, combined with other factors, led him to develop a particular engagement with the future that mitigated crisis-induced uncertainties. Previous crises served as resources to address current calamities, as such experiences taught Einar that, in even the direst situations, the future will eventually improve. However, Einar temporarily sight of the future when the Faroese fishery industry imploded in the 1990s. Einar questioned whether sufficient resources existed to allow him and the village to recover. The 1990s crisis momentarily gained a personal character; however, due to his age, stable socioeconomic position, and close social and affective ties to the people on Suðuroy, he reaffirmed his decision to stay on the island. Einar’s story showcases the importance of considering people’s experiences and unique positions amidst societal crises—be they temporary, slow, recurrent, or chronic, but also of studying experiences of time. Numerous factors constitute the membrane regulating when societal crises become personal. Crises cannot be understood as singular or isolated events. Instead, crises must be comprehended through their cumulations and entanglements, which involve people’s imagination of the future in unpredictable ways. ",
           0,
           "culture_&_psychology"
          ],
          [
           "From Bakhtinian theory to a dialogical psychology",
           "10.1177/1354067x11418546",
           2011,
           " The analysis of the different articles in this special issue gives a rather promising but complex image of a dialogical approach to psychology. Mikael Leiman proposed utterances as the object of study for psychotherapy research, semiotic mediation as the explanatory principle, and semiotic position as the unit of analysis. Frank Richardson cautioned us about how dialogical proposals can become entrapped by the extreme decentering tendency of social constructionism. James Cresswell, in his turn, claimed that Bakhtin's work is precisely a way of avoiding the unbalanced account of personal vacuity and freedom found in many constructionist accounts: it is precisely because we are bound to social ties that we become ethically involved with others and, indeed, with ourselves. Michèle Grossen and Anne Salazar Orvig claimed that otherness and the institutional, transpersonal dimensions are also present in every dialogical act, something that tends to be overlooked. Moore et al., following this suggestion, pointed to the multiplicity of institutional social frames, adding to the potential tension between the different available ways of interpreting self and context. Following these various contributions, the authors argue that a dialogical conception implies a relational self in constant dialogical and ethical involvement with society. They further argue that to respect the complexity of the whole in each lived situation, we need different, and more conversational, research strategies. In a final synthesis, centrifugal and centripetal movements of the self are conceived as mutually dependent in a fundamentally temporal conception of psychological becoming. ",
           13,
           "culture_&_psychology"
          ],
          [
           "Geocentric Dead Reckoning in Sanskrit- and Hindi-Medium School Children",
           "10.1177/1354067x09343330",
           2009,
           "A linguistic and cognitive process that has received scant attention in mainstream developmental psychology is the use of a geocentric frame of spatial reference, which amounts to using a large-scale orientation system (such as cardinal directions) in describing and encoding the location of objects on table space, inside a room. As part of a larger cross-cultural study of the development of this process, in India, Indonesia and Nepal, we present here a study on the possible implications of using a geocentric frame of reference in developing an accurate dead-reckoning skill. Children aged 11 to 15 years in two types of schools in Varanasi, India, who were known from a pretest to use a geocentric frame in language and cognition, were blindfolded, spun around and led blindfolded to a second room. A majority of them were able to keep track of cardinal directions despite these disorienting procedures. They were interviewed about the processes and sources of their skill.",
           10,
           "culture_&_psychology"
          ],
          [
           "Social construction, evolution and cultural universals",
           "10.1177/1354067x14542524",
           2014,
           " This paper discusses the connection between social constructionism and universals in the generation of mind. It proposes a new concept of Cultural Construction, distinct from social construction, and suggests that the latter succumbs to a Paradox of Sociality in which a socially constructed mind is non-social. Cultural construction avoids this paradox, and is best explained by an approach that roots learning in flexible evolutionary dispositions to possess culture. It also offers a novel perspective on traditional and more recent social constructionist accounts of psychological universals (e.g. omniculture) and has different implications for the prospects of reducing conflict in inter-cultural encounters. ",
           7,
           "culture_&_psychology"
          ],
          [
           "Rewriting Memories: Family Recollections of the National Socialist Past in Germany",
           "10.1177/1354067x02008001625",
           2003,
           "This article deals with the question of how personal memories of the national socialist past in Germany are passed on to younger generations. Rather than viewing this process as an unidirectional handing down of memories from generation to generation, examination is made of how memories are negotiated and re-created in intergenerational discourse. Drawing on a series of case studies, there is discussion of how the meaning of past experiences is construed and organized within particular narrative genres. In order to understand the ways memories are recomposed in the course of social transmission, the analysis highlights the role of group concerns. Against this backdrop, Bartlett’s observations on the repeated reproduction of narratives and Halbwachs’ ideas on the collective memory of the family are presented and discussed as early versions of a sociocultural approach in psychology.",
           23,
           "culture_&_psychology"
          ],
          [
           "The Multi-voicedness of Independence and Interdependence: The Case of the Cameroonian Nso",
           "10.1177/1354067x07082752",
           2008,
           "It is often claimed that independence and interdependence are two dimensions that are part of any culture and the psychology of any human being. While previous studies have considered these two concepts merely as a matter of degree, this article argues that, in fact, they can be of different quality and have a variety of meanings depending on the specific socio-cultural context. From a systemic approach, the study addresses the dialogical co-existence of these dimensions and views culture as an open system that allows for adaptation and constant reorganization according to the given context. Interviews with 10 mothers from the ethnic group of the Cameroonian Nso on their ideas on childrearing revealed that different conceptions of autonomy and interpersonal relatedness not only co-exist in this ethnic group but may serve different purposes and change depending on the specific socio-cultural conditions in which the mother lives.",
           28,
           "culture_&_psychology"
          ],
          [
           "The use of branded clothing in identity development and social relations between adolescents",
           "10.1177/1354067x241236721",
           2024,
           " Branded clothes and accessories are objects whose meaning extends beyond their use value. Branded items are widely used and consumed by adolescents worldwide, affecting their perception of themselves and of others. Then, how does the use of branded clothes and accessories relate to the identity development and the social relations between adolescents? To answer, we present the result of a netnographic case study focusing on a Brazilian young man, using a mixed-method approach involving observation, social media analysis and semi-structured interviews. First, we develop an innovative theoretical framework in which cultural psychology of semiotic dynamics and psychoanalysis enter in dialogue to understand identity development. Then, we analyse how branded clothes and accessories function as an identifying sign, for both the construction of the participant’s own identity and in relation to others. Finally, we discuss identity beyond the tautology of the self-identical subject, supporting the development of the concept of identity as an identifying mosaic, where identifications are organized fluidly and dynamically throughout an individual’s life. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Being, Feeling and Doing: Discourses and Ethnic Self-Definitions among Minority Group Members",
           "10.1177/1354067x0284001",
           2007,
           "In psychology there is a growing research interest in issues of ethnic minority identity and acculturation. In this research the emphasis is on relatively stable or enduring internal dispositions and attitudes. Studies on the way ethnic minorities define and account for their identity are scarce. However, ethnic minority members often have to explain and justify their identity, not only in interactions with dominant group members but also in relation to their own group. The present study examines how Chinese people living in the Netherlands account for their ethnic identity. The focus is on the actual accomplishment and manifestation of ethnic self-definitions in talks with other Chinese. The analysis highlights the different resources the participants use to manage the normative issues and personal responsibilities involved. Accounts were accomplished by stressing the significance of appearance, the importance of early socialization and the (non-)possession of critical attributes. However, these deterministic accounts leave little room for personal agency, and the participants also tried to define an active and constructive role for themselves. It is concluded that discursive psychology can make an important contribution to our understanding of ethnic minority identity.",
           63,
           "culture_&_psychology"
          ],
          [
           "Understanding Chinese international students’ perception of cultural conflicts in Canada: Through the case of cannabis use",
           "10.1177/1354067x231169287",
           2023,
           " The legalization of recreational cannabis consumption in Canada created a cultural conflict for international students from China, where the use of cannabis is heavily criminalized and deemed immoral. This conceptual paper theorizes this cultural conflict experienced by Chinese international students in Canada by applying three theories from macro to micro levels. Neoliberalism is first used to understand how this cultural conflict exposes collisions between the neoliberal West and the rising economic power of China as illustrated through Chinese students studying in Canada. Next, acculturation theory focuses on these students’ cultural transition and provides further insight into potential strategies for their handling of specific cultural conflicts such as cannabis use. Lastly, Cloninger’s theory of substance use is adopted to explore Chinese international students’ individual reasoning about cannabis use, particularly how they make decisions based on evaluations of various conditions. Building upon the above analyses, an integrated conceptual model is further formed to help us understand Chinese students’ potential perception of cannabis use in Canada. This conceptual framework provides an important theoretical and conceptual base for future research and practice, from which to further explore cannabis use in the context of cultural transition of different immigrant and migrant groups. ",
           2,
           "culture_&_psychology"
          ],
          [
           "Primary and Secondary Control in East Asia: Comments on Oerter et al. (1996)",
           "10.1177/1354067x9621004",
           2007,
           "Oerter, Oerter, Agostiani, Kim and Wibowo (1996) present an intriguing framework for studying concepts of human nature, and they offer thought-provoking applications of that framework to culture and to the primary-secondary control model. Their evidence that primary control is more characteristic of American subjects than those in Japan, Korea and Indonesia harmonizes well with our view (see Weisz, Rothbaum, & Blackburn, 1984a, 1984b). The work raises important issues for the assessment of control orientation. In addressing these issues, we (a) argue for methodological consistency across comparison cultures; (b) stress the need to know both an individual's actions and goals for accurate assessment of primary and secondary control; (c) note the need to assess steps or sequences in the pursuit of control; (d) discuss control as it relates to religion, and to individualism-collectivism; and (e) note the potential relevance of primary and secondary control to all stage levels in the Oerter et al. model. Studying the concept of human nature is a complex task, and the Oerter et al. analysis suggests key issues that need to be addressed in the process.",
           6,
           "culture_&_psychology"
          ],
          [
           "Work and culture: Approaching cultural and work psychology",
           "10.1177/1354067x16682939",
           2017,
           "In this article, we aim to explore the potential consequences of an approach to the theme of work that lies between culture psychology and work psychology. We argue that culture and work, considered as entities, have suffered from a process of mutual distancing over the course of history. Our first argument is to show the fallacy underlying this distancing, by arguing that culture is not an entity, but rather a process by which we use signs as tools to mediate our relationship with the environment and to regulate our own action in irreversible time. We also argue that work is a sign-mediated activity that occurs through culture. Most importantly, we advance the urgency of considering work as a cultural phenomenon, whose specific role is to make culture by getting things transformed into objects. The second argument we put forward is that work is a meaning-making complex. We further develop this concept by claiming that work should be analysed at the general level of the semiotic principles of meaning-making.",
           7,
           "culture_&_psychology"
          ],
          [
           "The First Six Years: Culture’s Adventures in Psychology",
           "10.1177/1354067x0171002",
           2007,
           "The first six years of Culture & Psychologyhave been productive in the creation of an international forum of scholarly interchanges where the notion of ‘culture’ occurs in a number of different ways. Selected themes that can be productively developed further are analyzed: historicity; dialogical perspectives in cultural psychology; social representing; activity orientations. Attention is directed towards careful reconstruction of methodological rules of psychology to accommodate to the need to investigate complex, dynamic and meaningful phenomena.",
           45,
           "culture_&_psychology"
          ],
          [
           "Culture As Patterns: An Alternative Approach to the Problem of Reification",
           "10.1177/1354067x0173002",
           2007,
           "To challenge the treatment of culture and self as reified entities, Hermans (2001) proposes a model of both culture and self as a multiplicity of dialogical positions. We question whether this model fully responds to his challenge. First, the notion of positioningitself appears to reify culture by treating flowing patterns as fixed locations. Second, the notion of dialogueappears to neglect the possibility of automatic influence from implicit cultural patterns. This implies a core, universal self whose functioning is insensitive to cultural variation. We suggest an alternative approach to the problem of reification: to conceive of culture not as group, but as patterns. Corresponding to this shift, we propose a distinction between the negotiation of cultural identity and the cultural grounding of self. As a model of identity negotiation, Hermans’ dialogical self makes important contributions: it emphasizes the multiplicity of identity, highlights the agency of the self as a constructor of identity, and suggests the importance of psychology—and the study of self, in particular— for the study of culture.",
           51,
           "culture_&_psychology"
          ],
          [
           "The veil and Muslim women’s identity: Cultural pressures and resistance to stereotyping",
           "10.1177/1354067x12456713",
           2012,
           "This study compares Muslim women’s views on wearing the veil in a Muslim majority society, Indonesia, with the Muslim minority in India. In-depth interviews reveal significant differences between the two: Majority women talk in terms of convenience, fashion, and modesty with little reference to religion as their reasons for veiling. The responses of Muslim minority women are diverse: their account of veiling stretches from religiously inspired arguments through to reasons of convenience, and to opposition against stereotypes and discrimination. Most minority women see the veil as a way of affirming their cultural identity. We argue that religious minorities are forced into constructing their cultural identity in ways that exaggerate their group belonging and difference from broader society. This may be motivated either by falling back on religious resources or by using ethnic markers to overtly oppose endemic prejudice. No such identity issue exists for the Muslim majority women. This contradicts the dominant view in non-Muslim countries in the West, where the female scarf is primarily considered a symbol of religious fundamentalism and patriarchal oppression.",
           76,
           "culture_&_psychology"
          ],
          [
           "Constructing Identity as a Second-Generation Cypriot Turkish in Australia: The Multi-hyphenated Other",
           "10.1177/1354067x10361398",
           2010,
           "This article explores how Cypriot Turkish people in Australia construct their multi-hyphenated identity and the implications this has for their sense of belonging. Ethnic identity is conceptualized as a set of social and cultural understandings, shaped by historical processes, positions of power and patterns of privilege, which people draw on to understand and experience themselves. Ten Cypriot Turkish people’s identities were explored through semi-structured interviews. Discourse analysis was used to identify the discursive constructions of identity and belongingness. Discourses that constructed the Cypriot Turkish Australian identity were: modern Muslim, language, phenotype and ancestry and generation discourse. These discourses give rise to the multi-hyphenation of this identity, positioning them as either Cypriot Turkish Australians or Cypriot Turkish in Australia. The discourses have highlighted not only the current socio-political context as shaping subjectivities, but also the historical and political collective memory that continues in the construction of ethnic identities.",
           34,
           "culture_&_psychology"
          ],
          [
           "Conscious and Non-Conscious Representation in Social Representations Theory: Social Representations from the Phenomenological Point of View",
           "10.1177/1354067x09343704",
           2009,
           " Verheggen and Baerveldt’s (2007) recent paper critiques the concept of ‘sharedness’ in Social Representations Theory (SRT). However, these arguments against sharedness are themselves founded upon an implicit argument against the role of ‘representation’ in SRT. This constitutes what I call the phenomenological critique of SRT. From a discussion of Heidegger’s phenomenology one can better understand Verheggen and Baerveldt’s argument. By concentrating on anchoring and objectification, the notion of ‘representation’ can be conceived as both a ‘conscious’ and a ‘non-conscious’ account of meaning. A Heideggerian phenomenological approach can unify the conscious and non-conscious elements of SRT into a common framework. Such phenomenological appreciation of SRT can contribute to a theory of meaning for cultural psychology. ",
           18,
           "culture_&_psychology"
          ],
          [
           "Cultural Psychology Today: Innovations and Oversights",
           "10.1177/1354067x08101427",
           2009,
           "Culture & Psychology has developed from a small start-up journal in 1995 into the key trend-setter in the field. This editorial analysis continues the tradition of inquiry started in previous efforts (Valsiner, 2001, 2004a) and extends it to the needs of psychology as a whole for the study of dynamic, meaning-making human beings. Cultural psychology—using the term culture as a generic term in various versions—continues to be an arena where innovations can occur. Separate research fields— such as the dialogical self, social representation processes, semiotic mediation, symbolic action, and actuation theories—have all been co-participants in this new advancement of ideas. Yet the central problem—an innovation of empirical research methodology which would appropriately capture human active meaning-making—has not been solved. Likewise, cultural psychology has only marginally touched upon the lessons from indigenous psychologies—the richness of folk psychological terms, and the cultural over-determination of objects used in human everyday living. Contemporary cultural psychology turns increasingly towards the study of objects as cultural constructs. Editing a journal is itself an act of construction of a cultural object, and the current state of contemporary scientific journals indicates a re-construction of the social nature of knowledge. Moving beyond its postmodernist and empiricist confines, psychology is set to return to the level of an abstracted generalization of its culture-inclusive theories. Culture—in terms of semiotic mediators and meaningful action patterns—is the inherent core of human psychological functions, rather than an external causal entity that has `effects' on human emotion, cognition, and behavior.",
           75,
           "culture_&_psychology"
          ],
          [
           "The Ancestry of a Model",
           "10.1177/1354067x9511002",
           2007,
           " After a brief initial consideration of historical aspects of the concept of 'culture', the focus is on the eco-cultural model originally developed by Berry (1976) and subsequently incorporated in the text by Berry, Poortinga, Segall and Dasen (1992). It is shown that several of the basic ideas underlying the model, notably those relating mind and behaviour to eco-cultural settings, have been frequently discussed over several centuries. From the Enlightenment onwards quite sophisticated schemes have been put forward, and some of these bear a close resemblance to salient aspects of the Berry et al. model. The status of that model is discussed in the light of its historical background, which also indicates that the current division between universalist and particularistic approaches to psychology and culture can be found to some extent in the writings of past thinkers. ",
           21,
           "culture_&_psychology"
          ],
          [
           "Commentary: Vygotskian Cultural-Historical and Sociocultural Approaches Represent Two                 Levels of Analysis: Complementarity Instead of Opposition",
           "10.1177/1354067x07085812",
           2008,
           " Matusov distinguishes two usually counterposed modern schools of psychology that stem from Vygotsky's theory, the sociocultural and cultural-historical. I suggest that the sociocultural approach is fundamentally deficient in ignoring a need for cognitive analysis and not taking seriously the notion of hierarchical development. Problems that arise from the acognitive-adevelopmental position of the sociocultural approach are analyzed in respect of three issues: ethnocentrism, the natural-cultural line of development, and testing in education. The cultural-historical approach, in turn, is deficient in ignoring cultural diversity and the content of the psyche. The superficially opposed sociocultural and cultural-historical Vygotskian schools complement each other if it is realized that both schools represent different levels of analysis. ",
           15,
           "culture_&_psychology"
          ],
          [
           "Poetic destroyers. Vico, Emerson and the aesthetic dimension of experiencing",
           "10.1177/1354067x17701270",
           2017,
           " The aesthetic dimension of meaning-making in human conduct has been often overlooked. In this article, “aesthetic” refers to an immediate form of experiencing in which affective, ethical and cognitive dimensions are experienced as a totality, rather than a more restrictive meaning of artistic experience. The philosopher Giambattista Vico (1670–1744) developed the concept of “poetic logic,” that is a specific mode of thought typical of early stages of civilization. Poetic logic is the first form of collective elaboration of experience, a way of creating universals concepts based on sensory, affective sense-making and religious thinking. Vico claims that poetic logic was the cornerstone for the elaboration of whole systems of collective knowledge (poetic economy, science, geography, history, law, etc.) crystallized in myths. Poetic logic, based on imaginative function is a proper epistemological stance that, though overcome by rationality at a later stage of civilization, still plays an important function in keeping alive the ethical dimensions of collective life against the “barbarism of reflection.” Two centuries later, Ralph Waldo Emerson (1803–1882), one of the fathers of Pragmatism, developed an idea of poetic and imagination as forms of knowledge. Though echoing Vico’s ideas, he represents the aggressiveness of modernity. From the discussion of their ideas, I will try to sketch the psychological aspects of the aesthetic dimension of experience that can be found in a wide range of human activities, including actions of killing, overpowering and social injustice. I will try to argue that meaning-making is oriented through processes that affect such aesthetic dimension. ",
           23,
           "culture_&_psychology"
          ],
          [
           "(Re)defining disability culture: Perspectives from the Americans with Disabilities Act generation",
           "10.1177/1354067x18799714",
           2018,
           " The present study examined the views of students with varying physical disabilities on disability culture in a post-Americans with Disability Act society. Qualitative, participatory research methods were used to observe approximately 30 disabled students and conduct in-depth interviews with four disabled students. The main objective was initially to answer the following question: Do disabled students recognize an identifiable disability culture at that particular university, and if so, what does it look like? While the sheer presence of disabled students does not automatically equate to a robust disability culture, it became apparent that there was a disability culture at this site, and therefore the research question was refined to: What are the features of disability culture according to this population? The participants were all students at an institute of higher education in the Midwestern United States. The researcher self-identifies as having a disability. Using in vivo coding for analysis to preserve the voices of the participants themselves, the results indicated that there was a disability culture and the key values defining this culture included independence, social justice, and giving back to others. ",
           14,
           "culture_&_psychology"
          ],
          [
           "Dialogism and dialogicality in the study of the self",
           "10.1177/1354067x11418541",
           2011,
           "This article stems from the statement that dialogical approaches to a study of the self face a double challenge: that of developing a conception of the self that both avoids social reductionism and accounts for the stability of the self. In discussing this double challenge, we identify three much debated issues: (a) To what does the notion of “Alter” exactly refer? (b) How could we conceptualize the fact that Subject–Alter interactions are not only interpersonal but entail larger social entities, in particular institutions? (c)What importance should we attach to the materiality of objects? We discuss these three questions from two standpoints – that of linguistics and that of psychology – and illustrate our theoretical proposals with an analysis of an excerpt taken from a focus–group discussion. In conclusion, we argue that the dialogism of discourse provides us with some clues about the dialogicality of the mind, whereas the latter invites us to develop a theory showing the importance of interactions in the construction of the self, to pay more attention to the transpersonal dimension of the social, and to consider that the material world contributes to the construction of the self.",
           47,
           "culture_&_psychology"
          ],
          [
           "Buffer zones in Wayanad: A social constructivist exploration into farmers’ mental health",
           "10.1177/1354067x241242417",
           2024,
           " Buffer zones are regions set aside to border protected areas to preserve biodiversity, control interactions between people and wildlife, and foster sustainable development. The majority of research on buffer zones focuses on ecological issues, and little is known about how they affect local communities’ mental health. This study explores buffer zones’ potential consequences on farmers’ mental health in Wayanad. Through purposive sampling, eleven participants residing in Wayanad were recruited for the study. The socio-demographics of participants were collected through printed translated questionnaires. The qualitative exploration of their lived experiences, perceptions, and coping strategies was conducted using semi-structured, in-depth interviews. Thematic analysis by Braun and Clarke was used to gain a clearer understanding of the data collected. Through in-depth analysis of the data, it was identified that Mental Health Factors, Communication Factors, Financial Impact, Operational Stress, Interference of Judiciary and Legislature, and Seclusion of the Tribal Community were the issues the farmers faced in Wayanad. The results will contribute to the expanding mental health field and give policymakers, conservationists, and mental health professionals information about the potential psychological effects of buffer zones and guide them in creating suitable interventions and support systems to improve mental health. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Aesthetic social representations and concrete dialogues across boundaries: Toward intergenerational CHARACTERization",
           "10.1177/1354067x19888198",
           2019,
           " In this paper, I present Bertoldo and Castro’s (2019) epistemological limits in relation to Moscovici’s and propose to develop some of Moscovici’s dynamic aspects. Because Bertoldo and Castro (2019) refer to Boulanger and Christensen’s (2018) work—which aims to schematize the representation processes at different levels of abstraction and develop an aesthetic theory of social representations with respect to Simmel—as a dialogical response, I use this same framework to criticize and push further their effort of extending SRT with regard to the subjective dimension. Bakhtin’s work will be partially used to support my arguments and establish the basis for a dialogical model of aesthetic representation as CHARACTERization. I will quickly illustrate the theoretical propositions regarding the analysis of intergenerational practices in Quebec (Canada), thereby introducing the concept of intergenerational CHARACTERization. ",
           3,
           "culture_&_psychology"
          ],
          [
           "Moving global horizons: Imagining selfhood, mobility and futurities through creative practice in ethnographic research",
           "10.1177/1354067x20922141",
           2020,
           "This article explores imagined selfhood, mobility and futurities through creative practice in ethnography. Globalisation allows people with varying socio-economic and geographical backgrounds to imagine themselves with more possibilities. How can creative practice such as improvisation in ethnofictions, storytelling and participatory animation be applied in ethnographic research to explore the imaginary realm of selfhood and expectations on being elsewhere? Drawing on fieldwork on migration from Africa to Europe, Brazilian transgender mobility and British youth in environmental transformation, the article will show how existential immobility inspires production of global horizons through imagination.",
           5,
           "culture_&_psychology"
          ],
          [
           "Activity or Action: Two Different Roads Towards an Integration of Culture into Psychology?",
           "10.1177/1354067x9511005",
           2007,
           " Michael Cole's conception of a cultural psychology which is rooted in Russian activity theory is discussed from the perspective of action theory which also aims at an integration of culture into psychology but does so by slightly different concepts. Beyond the shared divergence from classical cross-cultural psychology there are many similarities between activity and action theory, but differences also exist. ",
           42,
           "culture_&_psychology"
          ],
          [
           "Commentary: Culturally Sensitive Treatments: Need for an Organizing Framework",
           "10.1177/1354067x08092638",
           2008,
           " To date, descriptions of culturally sensitive therapies have insufficiently acknowledged the heterogeneity of perspectives on the role of culture in therapy. The generally homogeneous manner in which advocates of culturally sensitive therapies have described this work has likely contributed to the mainstream's slow acceptance of the importance of culture. In this article, I propose an organizing framework that may help recognize the diversity of viewpoints regarding what constitutes culturally sensitive therapy. It is my hope that this framework, along with critical self-evaluation of the strengths and weaknesses of the various perspectives, will lead to more rapid incorporation of culture across treatments. ",
           15,
           "culture_&_psychology"
          ],
          [
           "Continuing Commentary: A Cyclical Model of Social Change",
           "10.1177/1354067x08099624",
           2009,
           "Castro and Batel's (2008) study points to some important strategies of resistance to social change in the transformation of transcendent to immanent representations. We contextualize this study within a broader cyclical model of social change, in which their focus is one of the four phases in the cycle. The expanded model is exemplified in the shifting representations of science communication in the UK from the `deficit model' of public understanding of science to the dialogic representation of `public engagement'. Within each of the four proposed phases, the dialectic of adoption/rejection is central, although it is modulated by strategies of resistance and the selective distribution of resources.",
           27,
           "culture_&_psychology"
          ],
          [
           "Contemporary Chinese communication made understandable: A cultural psychological perspective",
           "10.1177/1354067x12464985",
           2013,
           " Cultural psychology as a discipline is designed ultimately to help understand and to help guide cultural practice. In the present study, we focus on the case of present-day Chinese communication (or discourse) and argue that an adequate understanding must take into account its cultural ways of thinking and feeling—a discourse-dialectic collective consciousness connected with Chinese history on the one hand, and international cultures on the other hand. From this perspective, we propose in particular that the Chinese cultural psychological entity be seen as a network of values, rules and resources for thinking and feeling that are embodied and strategically utilized in contemporary Chinese discursive practice. To elucidate this cultural psychological perspective, we cite and examine a range of empirical discursive examples in diverse settings. In conclusion, the future research agenda is discussed. ",
           5,
           "culture_&_psychology"
          ],
          [
           "Applying a Sociocultural Approach to Vygotskian Academia: `Our Tsar Isn't Like Yours, and Yours Isn't Like Ours'",
           "10.1177/1354067x07085808",
           2008,
           "A Vygotskian approach to education and psychology involves attention to culture, history, society, and institutions that shape educational and psychological processes. Yet, Vygotskian academia itself seems to operate as if academic issues transcend local contexts. Often debates over Vygotsky's legacy in sociocultural international academic communities are carried out, around scholarly texts, without analysis of the (often very diverse) local historical and political situations that may promote such debates. This is especially true in national and international debates about the issues of multiculturalism in education. In my article, I consider cultural-historical and sociocultural paradigms to investigate their ontological projects and dialogical oppositions and consider their relationship between each other.",
           27,
           "culture_&_psychology"
          ],
          [
           "The Use of Symbolic Resources in Developmental Transitions",
           "10.1177/1354067x0394006",
           2004,
           " This paper introduces the idea of symbolic resources as the use of cultural elements to mediate the representational work occasioned by ruptures or discontinuities in the smooth experience of ordinary life, moments when the ‘taken-for-granted’ meanings cease to be taken for granted. In particular we are concerned with the use of symbolic resources in moments of developmental transitions, that is, the mobilization of symbolic elements ranging from shared bodies of knowledge or argumentative strategies to movies, magazines or art pieces. The paper begins with a brief theoretical sketch of these ideas, and then presents three case studies, each of which involves the use of a different type of symbolic resource within a particular age group. In the first, children are observed in interaction with a peer about a conservation problem. In the second, adolescents are observed negotiating the meaning of their art productions with their peers, teachers and parents. The third example looks at Western tourists searching for spirituality, adventure and freedom in Ladakh as an alternative to the materialism of modernity. In each case the analysis of the symbolic resources employed indicates the significance of the gaze of the other in the construction of meanings, and of the various constraints operating within specific situations. The analysis also reveals different modes of use of symbolic resources, linked to changing forms of reflectivity. ",
           129,
           "culture_&_psychology"
          ],
          [
           "Cultural psychological implications of Hermann Hesse’s Glasperlenspiel (glass bead game)",
           "10.1177/1354067x221132000",
           2022,
           " In the present article, I dissect key elements of Hermann Hesse’s famous novel, the Glass Bead Game (Glasperlenspiel) in order to make them fertile for Cultural Psychology. I originate from the idea that the Glass Bead Game can be understood as a universal language that relies on open ideographs, thus signs that can be combined and structured for multiple purposes. Yet, this universal language is not solely a play; it has an educational drive to educate the mind and to help the individual reaching inner harmony. This play comes into being only when listening to the play of other people interacting with me and me meditating upon the multiple meaning making opportunities of it. I argue that such a perspective is in close accordance with the actual task of Cultural Psychology helping to unravel how people do relate to their environments and the impact that results from this ecological interaction. However, I appeal interested readers in trying to better institutionalize such a cultural psychological purpose of serving the individual in order for Cultural Psychology to be a sustainable and long-lasting science unlike the Glass Bead Game that became an end in itself. ",
           4,
           "culture_&_psychology"
          ],
          [
           "The role of distancing in Werner and Kaplan’s account of symbol formation and beyond",
           "10.1177/1354067x13500323",
           2013,
           " The concept of distancing or polarization plays a central role in Werner and Kaplan’s account of symbol formation. It refers to the process of progressive differentiation and hierarchic integration of the four components constitutive of symbolic activity: addressor, addressee, symbolic vehicle and referent. Specifically, Werner and Kaplan suggest that distancing takes place between person and referent, between person and symbolic vehicle, between symbolic vehicle and referent and between addressor and addressee. We describe the theoretical context and different aspects of the distancing process. Furthermore, we argue that the distancing process identifies central prerequisites of symbolic activity that are largely ignored by contemporary developmental theories. We demonstrate the different aspects of the distancing process in several domains of symbolic development, including words, gestural development and pretend play. Finally, we compare Werner and Kaplan’s concept of distancing to ideas of distancing developed in recent developmental theories. ",
           10,
           "culture_&_psychology"
          ],
          [
           "An ecological model of experienced stigma during the COVID-19 pandemic: A qualitative study in Malaysia",
           "10.1177/1354067x241242409",
           2024,
           " In this paper, we adopted an ecological model and relational cognition framework to decolonize pandemic stigma in a non-WEIRD society. We reconstructed the concept of pandemic stigma in an ex-colonized and multicultural society of Southeast Asia region, by conducting a qualitative study in Malaysia to explore their lived experiences of differential treatment during the COVID-19 Pandemic from 2020 to 2022. We interviewed 30 Malaysians aged 18–64 of diverse ethnicities (Malays, Chinese, Indians, and other minorities) through online semi-structured sessions and coded the transcripts through consensus thematic analysis. Results showed that the interviewees’ lived experiences of stigma could be conceptualized as negative interactions with multiple systems: (1) Kinship, (2) Companionship, (3) Organizations, (4) Societal (5) Political, as well as (6) Internal systems. We found that interviewees attributed their experiences of stigma to (1) Individual (self) reasons, (2) Impact of close relationships, (3) Impact of casual social interactions, and (4) Impact of cultural-political context. Our findings could be translated into culturally responsive and context-specific interventions, which addressed systemic injustice that exacerbated the global polarization during the pandemic. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Rekindling individualism, consuming emotions: Constructing “psytizens” in the age of happiness",
           "10.1177/1354067x16655459",
           2016,
           "Happiness has become a new moral regime in neoliberal societies that defines what is right and wrong and stresses the insource of responsibility. More importantly, happiness stands out as a new model of selfhood that aligns with the neoliberal ideology of individualism and consumerism at the same time that legitimizes and rekindles this same ideology in seemingly nonideological terms through the discourse of science. The paper claims that this model of selfhood turns citizens into psytizens, that is, into psychological clients whose full functionality as individuals is largely tied to the pursuing, consuming, and development of their own happiness. The paper analyzes this notion of psytizen and its three main features, comments upon the happiness industry that simultaneously presupposes and targets this model of selfhood, and examines the role that happiness studies, in general, and positive psychology, in particular, play in shaping this emerging notion of citizenship.",
           32,
           "culture_&_psychology"
          ],
          [
           "Emics and Etics: A Symbiotic Conception",
           "10.1177/1354067x9952004",
           2007,
           " Cross-cultural psychology involves both the cultural understandings of behaviour and the comparative analysis of these understandings. The emic and etic approaches proposed by Pike were seen by him as complementary, rather than alternative, or even conflicting, ways of achieving these understandings. With Pike’s original conception as a basis, the cultural and the comparative aspects of the field are viewed as symbiotic, allowing for ecological and cultural explorations of the development of human behaviour, both within and across settings. ",
           103,
           "culture_&_psychology"
          ],
          [
           "The spiral: The concept of development after Werner and Kaplan",
           "10.1177/1354067x13500324",
           2013,
           "At the core of Heinz Werner’s concept of development is what he called “the genetic principle of spirality:” over the course of ontogenetic development, lower levels, processes, and functions do not disappear, and can even resurface again under specific conditions, normal and pathological. Werner’s work with Bernard Kaplan on symbol formation is a primer on this idea. This paper examines the idea of spirality and develops the notion of dynamic coexistence that can clarify the issue of directionality of development; that is, what is the general trajectory or ground plan that development assumes. Directionality is discussed in terms of the organism-in-environment unfolding over time as the unit of developmental analysis. Thinking on this issue has proceeded from the nature–nurture debates, to recognition of the interaction of external and internal processes, to transactions between the organism and the environment. The idea of dynamic coexistence is developed on this foundation. In the context of Werner and Kaplan’s work, dynamic coexistence represents the syncretic nature of processes and levels of organization: they are neither innately fused nor organized. Instead, the antithesis between fusion and differentiation is resolved only in concrete, context-bound conditions, even as development is generally oriented towards differentiation in maturity. Idiographic science, with its orientation towards generalizing from the unique and its attention to intra-individual variation over time, is discussed as the adequate methodological orientation for Wernerian developmental analysis.",
           8,
           "culture_&_psychology"
          ],
          [
           "Four problems for researchers using social categories",
           "10.1177/1354067x12446236",
           2012,
           " Research on lay categorization processes has revealed that it can lead to distortions. Yet researchers routinely categorize people into groups and cultures. We argue that researchers should be aware that social categories are (1) perspectival, (2) historical, (3) disrupted by the movement of people, and (4) re-constitutive of the phenomena they seek to describe. We illustrate these problems with reference to contemporary research on globalization and the “clash of cultures”. It is argued that problematizing cultural categories would do more to reduce inter-group conflict than reifying them. ",
           62,
           "culture_&_psychology"
          ],
          [
           "The External Brain: Eco-Cultural Roots of Distancing and Mediation",
           "10.1177/1354067x02008002440",
           2003,
           " First, this article attempts to approach the problem of distancing from the psychocultural perspective, relating it with the basic mechanism of mediation that was proposed by Vygotsky. Secondly, it is a reflection on the combined process of approaching and distancing in human biological and mental processes, and the limitations of contemplating the development as a process that is assumed to proceed only in the direction of ever greater cognitive distancing. Finally, it is proposed that instead of conceiving contact and distance as divergent developmental paths, models should articulate both processes of approaching and distancing, as well as of social mediation and instrumental mediation. I suggest the ecological and situated nature of psychological operators of distancing as a process in an extra-cortical mise-en-scËne. ",
           19,
           "culture_&_psychology"
          ],
          [
           "(Im)Mobile imagination. On trailing, feeling stuck and imagining work on-the-move",
           "10.1177/1354067x19899070",
           2020,
           " Emerging research focuses on the role of time in the context of mobility and explores the conditions of ‘wait’ and ‘stuckness’ as conceptual tools for understanding the tempos and socio-cultural implications of mobile experiences. This paper contributes to this research by exploring these conditions in the context of work and geographical mobility, with a special focus on people who migrate and follow their working partners in international professional migration and temporarily live in Switzerland. The increasingly mobile and changing conditions of some professional sectors have made transnational career trajectories imaginable also for many partners. Yet, at times, their working life is not easily reconstituted on the occasion of the move, and the timing for job-search and unemployment can extend indefinitely. I will discuss how mobile professionals’ partners, by transiting from a working situation to another one that is not yet in place, experience a condition of stuckness between identities, phases of life and destinations of migration. I will ask how the subjective experience of stuckness can trigger and at times block a person’s capacity to imagine work under conditions of geographical mobility. ",
           8,
           "culture_&_psychology"
          ],
          [
           "A glimpse inside: Examining <i>loob</i> from the life stories of center-based Filipino children in conflict with the law",
           "10.1177/1354067x241236740",
           2024,
           " This study is a reexamination of the life stories of 10 male, center-based, Filipino children in conflict with the law (CICL) focusing on the most prominent descriptions of their loob or inner self before entering the youth rehabilitation center, during their commitment at the center, and after they leave the center. Participants were 18–22 years old during the interviews but were charged with committing an offense as minors. An adapted life story interview guide was used to conduct in-depth, face-to-face, semi-structured interviews with the CICL which elicited stories of their past, present, and future. REC-approved protocols and research guidelines for juvenile justice populations were followed in gathering data. Thematic analysis showed that almost all the CICL had sama ng loob or resentments in the past, experienced pagbabagong-loob or a sense of renewal in the present, and expressed their desire to make up by giving back to others in the future because of their utang na loob or sense of gratitude to those who have helped them. The development of the inner self of the CICL from past to present to the future can be described as Nagibâ-Nabubuo-Babawi or Collapsed-Taking Shape-Giving Back. Findings of the study provide a glimpse of the inner self of the CICL from their perspective. It highlights the dynamic movement of the CICL’s inner self which has implications for prevention, intervention, and rehabilitation efforts in relation to youth offending. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Cultural spaces of popularized psychological knowledge: Attachment parenting in Turkey",
           "10.1177/1354067x19861055",
           2019,
           "The psychological concept of attachment is constantly evolving. Approximately 70 years after attachment theory was first introduced by John Bowlby in the late 1940s, the notion of attachment is still in flux with continually changing ideas of what it means to be a good parent. One path along which attachment as a concept is moving from academia to everyday life is the philosophy of attachment parenting which was first established in the US by William and Martha Sears. Ideas about attachment theory and attachment parenting are frequently accompanied by critical comments on “Western” cultures. This critical perspective on modernity, individualism, and autonomy is portrayed in the first part of this article. The second part traces attachment as a concept transferred to Turkey. Rather than studying academic work on attachment in Turkey, this article focuses on popularized versions of attachment theory which gain ground as part of the parenting philosophy of attachment parenting. This article analyzes parents’ blogs, websites, self-help books, fieldwork protocols, and interviews with parenting trainers and parents themselves. It focuses on how popular scientific use of attachment parenting in Turkey is accompanied by discussions of cultural identity, cultural values, and belonging. The article shows that attachment theory and parenting are used in quite diverse ways to comment on Turkish (parenting) culture, ranging from anglophile readings to more conservative appropriations of attachment theory as Anatolian education. These forms of popularizing attachment theory challenge the sociological concept of psychologization.",
           4,
           "culture_&_psychology"
          ],
          [
           "Problematizing Psychotherapy: The Discursive Production of a Bulimic",
           "10.1177/1354067x0172003",
           2007,
           "This paper explores the discursive production of a psychologized bulimic subject. Two processes are highlighted through a case study, both influencing the production of the bulimic: therapeutic operations of power; and the subjugation of non-psy accounts of bulimia. Power mechanisms in therapy encourage the client to construct a complex psychological subjectivity, enabling a psychological, self-contained account of her eating disorder, thereby facilitating ‘therapeutic’ change. However, the condition for therapy is the disguised subjugation of client, lay and erudite non-psy accounts. The concealment of power operations reinforces psy’s hegemony in defining the person—and the bulimic—in western culture. After problematizing psy discourses, a non-psychologized feminist discourse is hypothetically considered, and dialogue with this discourse suggested. A feminist discourse does not require ideals of self-containment, nor complex psy accounts, but nevertheless offers the bulimic a range of political subjectivities as a discursive priority, rather than psychological complexity.",
           29,
           "culture_&_psychology"
          ],
          [
           "Role Play and Language Development in the Preschool Years",
           "10.1177/1354067x05058577",
           2005,
           " The paper relies on Vygotsky's thesis that preschool children in role play are acting in the zone of proximal development (ZPD). One aim is to specify this thesis with respect to language development. The empirical investigations show that language is the central means of creating pretence. By explicit metacommunication, children collaboratively negotiate the plot, transform meanings and distinguish fiction from reality. Thus, metacommunication functions as a verbal frame, determining the meanings within play. Thereby children overcome sympraxic language use which is characteristic of toddlers. Another result is that role play changes during the preschool years. The paper argues that these changes can be subsumed under a general developmental phenomenon, namely the transition of interpsychic into intrapsychic processes. A point of special interest is why preschoolers, through role play, can act in the ZPD, although their ability to cooperate with other children is only at a nascent stage. To explain this, the paper discusses several aspects of psychosocial development. ",
           33,
           "culture_&_psychology"
          ],
          [
           "The grieving killjoy: Bereavement, alienation and cultural critique",
           "10.1177/1354067x20922138",
           2020,
           "In recent years, a range of scholars have put forth critical analyses of the consequences of the ideals of happiness, future-orientedness, and productivity which dominate contemporary Western cultures. The experience of grief—with its sadness, preoccupation with the past, and lack of initiative—is inherently at odds with such ideals. This conflict between grief and cultural ideals of happiness is reflected in the recent efforts within bereavement research to delineate pathological mourning from uncomplicated, normative mourning. While the latter is characterized by a gradual decline in emotional pain, sadness, lack of initiative, etc., complicated mourning is marked by a failure to meet normative standards for recovery. In this article, I will draw on loss experiences among bereaved parents in contemporary Danish society in order to shed light on how profound losses may catalyze estrangement from and opposition toward what has been termed the happiness imperative of contemporary Western societies. More specifically, I borrow the figure of the feminist killjoy, paraphrased as the grieving killjoy, as a lens through which bereavement experiences may be theorized and understood as a starting point for experientially driven cultural critique.",
           4,
           "culture_&_psychology"
          ],
          [
           "Ventriloquism: The Central Role of an Immigrant’s Own Group Members in Negotiating Ambiguity in Identity",
           "10.1177/1354067x0284003",
           2007,
           " Situated at the crossroads of cultures, an immigrant’s identity is filled with ambiguity. Humans frequently make use of intolerant strategies (e.g. prejudice) to construct clarity artificially out of an ambiguous identity. Although the locus of intolerance is often associated with the dominant group, complementing Verkuyten and de Wolf’s (2002) focus on minority group members, it is argued here that immigrants themselves can be sources of immigrant-oriented intolerance. In explanation of this in-group prejudice, the metaphor of ventriloquism is offered, showing how immigrants may assign the intolerance they feel for their own ambiguity to the ambiguity in fellow group members, in order to clarify (artificially) their own identity. ",
           12,
           "culture_&_psychology"
          ],
          [
           "“Recasting sorcery as critical psycho-social commentary, moral discourse, and local psychotherapy”",
           "10.1177/1354067x241246757",
           2024,
           " This article critically reflects on future directions in cross-cultural psychiatry and cultural psychology by engaging the challenges of interpreting psycho-social theories of causation and evidence in what is conventionally called “sorcery” in anthropology. This anthropologist argues that sorcery, notwithstanding its status as an older, classic topic in the history of anthropology and its seemingly “exotic” reputation, has continuing value in recent efforts to de-colonize the study of local ontology and moral personhood, in particular, in contexts of transcultural encounters. The focus here is on an incident in a Saharan Tuareg community that is locally-defined as “sorcery” (called ark echaghel in Tamajaq, their Amazigh language). Many Tuareg, predominantly Muslim, traditionally semi-nomadic, and socially-ranked, have experienced socio-economic and ecological upheavals, armed conflicts, and settled life in towns. This analysis examines a case of sorcery practice and its social context—of a transcultural encounter between a smith/artisan and a tourist and its aftermath—of diagnosis and commentary by an Islamic scholar—as moral discourse and local psycho-social treatment as critical commentary on and resistance to transcultural inequalities. The broader goal here is to suggest avenues to pursue by showing how sorcery reveals local ontology, moral discourse on evil, and culture theory. Thus, sorcery, rather than a “retrograde” or irrelevant topic, offers rich insights into local ontology’s psycho-social and political implications, thereby contributing to current concerns in transcultural psychiatry with social and political power asymmetries, critical epistemologies, and indigenous critiques that question universalizing absolutist psychological interpretations in cultural encounters. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Dialogical Relationship between Identity and Learning",
           "10.1177/1354067x09353206",
           2010,
           "This paper highlights some connections between cultural psychology, educational psychology, and identity psychology. This aim is pursued through the constructivist view of conceptualized learning as building knowledge. It is contended that identities should explicitly be considered as part of this process. Useful approaches to explore the relationship between learning and identity are the Dialogical Self Theory (DST) and the Communities of Learning model (CoL), both of which demonstrate a shared interest in dialogue and constructivism. DST defines the self as being composed of a set of I-positions, which are constantly in dialogue and in movement. The CoL model conceptualizes the classroom as a set of cultural contexts where dialogues permit the analysis of context and also shape it. Empirical examples of how relevant concepts related to learning, such as motivation and sense-making, can be viewed as innovation of the self are discussed.",
           52,
           "culture_&_psychology"
          ],
          [
           "The respect pyramid: A model of respect based on lay knowledge in two cultures",
           "10.1177/1354067x211066819",
           2022,
           " Respect is a common social concept, yet how lay people define it has not been thoroughly investigated. This study used a grounded theory approach, using in-depth interviews, to conceptualize respect according to lay knowledge. 40 participants from two cultures in the Middle East—20 Jewish Israelis and 20 Palestinians—reported how they define respect ( Kavod in Hebrew and Ihtiram in Arabic). The findings define respect as a complex, multidimensional concept. Based on the findings, a respect pyramid model was developed, which includes four dimensions: avoiding disrespect, deserved/normative respect, conditional respect, and considerate respect. Each dimension indicates an increase in aspects that make the respect less conditional and more intrinsic, while requiring higher sensitivity and greater effort. The implications of the respect pyramid for relationships and the cultural differences regarding definitions of respect are discussed. ",
           2,
           "culture_&_psychology"
          ],
          [
           "Classrooms and the Design of Pedagogic Discourse: A Multimodal Approach",
           "10.1177/1354067x05055519",
           2005,
           " This paper offers a social semiotic analysis of the school classroom, in this case the subject English classroom, as a material instantiation of pedagogic discourse. The classroom is looked at as a multimodal sign: the semiotic ‘residue’ or ‘sediment’ of discursive practices over time. In particular it discusses how visual displays and spatial design in the English classroom can be thought of as signs of school English. From this perspective a teacher’s classroom can be understood as a sign of how she or he mediates ‘official’ government and school discourse. Drawing on three illustrative examples of English classrooms from three different schools, the paper argues that the variation between these classrooms can be understood in part as a consequence of the complex web of social relations that mediate and institutionally frame pedagogy. ",
           16,
           "culture_&_psychology"
          ],
          [
           "Strategies for Dealing with Conflicts in Value Positions between Home and School: Influences on Ethnic Minority Students’ Development of Motives and Identity",
           "10.1177/1354067x05052351",
           2005,
           "A theoretical model is presented in which participation in the school community is viewed as a multifaceted activity. In this model, culture is conceptualized as traditions of practice and as a societal field. The school practice and the role of the family and their differences in value positions about school life are interpreted as a central factor for children’s involvement and participation in school practice and for the type of conflict they may face. The type of conflict and the individual’s strategy for dealing with it influence the children’s development of motives and identity. Discrepancies and conflicts between Turkish-Danish students’ motives and their parents’ value positions about school life are analysed to see how this influences young persons’ feelings of well-being and development of motives and competencies. The analyses draw on (a) interviews with Turkish-Danish youth about their school life, friends, subject matter learning, family and future plans, and (b) interviews with parents about their conception of their children’s school life and future.",
           49,
           "culture_&_psychology"
          ],
          [
           "Presenting Social Representations: A Conversation",
           "10.1177/1354067x9800400305",
           2007,
           " Serge Moscovici's theoretical system of social representations is by now nearly 40 years old; yet, today, various social psychological activities surrounding this field seem to flourish more than ever; much research into social representations is being carried out all over Europe and on other continents; there is a European PhD programme on social representations and communication; there is an association and a network on social representations; and a journal on social representations is in the pipeline. At the same time the theory has its critics; some of them argue that the theory is too loose; others, that it is too cognitive; that it is not clear how the concept of social representation differs from other concepts, say, from attitudes, social cognition, beliefs, stereotypes, and so on; still others would like to marry the theory either to discourse analysis or to social constructivism(s) and constructionism-or to both of them at the same time. Readers of French, in addition, are familiar with Moscovici's work in the history and philosophy of science, human invention and technology, the psychology of resistance and dissidence, and, most recently, with his magnificent autobiographical recit Chronique des annees egarees (Chronicle of Stray Years) (Moscovici, 1997). Although based permanently in Paris, Serge Moscovici has worked at a number of American Universities, has been invited to lecture all over the world, and has received a number of honorary doctorates at various European Universities. Since this Special Issue in Culture & Psychology is devoted to the concept of collective and social representation, we shall be concerned, in this dialogue, primarily with the origin of Moscovici's own ideas on the concept of social representations and how these ideas have developed into a broad programme of research. ",
           97,
           "culture_&_psychology"
          ],
          [
           "Seeing Historically: Goethe and Vygotsky’s ‘Enabling Theory-Method’",
           "10.1177/1354067x0062010",
           2007,
           " We can study dead forms from a distance, seeking to understand the pattern of past events that caused them to come into existence. We can, however, enter into a relationship with living forms and, in making ourselves open to their movements, find ourselves spontaneously responding to them, and in so doing, we can gain a sense of their character. In other words, from within our dialogically structured involvements with other living things, a kind of relationally responsive understanding, quite different from the referential-representational kind of understanding familiar to us in cognitive psychology, becomes directly available to us. Thus, rather than seeking to explain a child’s present activities in terms of their causes in the past, from the standpoint of an external observer, we can turn to a quite different aim: that of perceiving in a present behavior the possibilities and opportunities it offers for further developments. Orientation toward this aim is what I think is so special about both Vygotsky’s and Goethe’s historical methods of inquiry into the development of living forms. ",
           17,
           "culture_&_psychology"
          ],
          [
           "Meaning making in motion: Bodies and minds moving through institutional and semiotic structures",
           "10.1177/1354067x13500325",
           2013,
           "What is meaning? And how does it arise? Werner and Kaplan’s approach to symbol formation was prescient in understanding the importance of the body and activity. However, their embodied approach needs to be complemented by a broader conceptualization of social institutions and complex semiotic structures in the genesis and function of symbolic processes. Specifically, human bodies, which are the medium and locus of experience, are embedded in social situations and institutions. Thus embodied experience, the origin of meaning, must be understood as societally structured. Moreover, human experience is never unmediated; it is refracted through the complex semiotic artifacts that comprise human culture, such as discourses, social representations and symbolic resources. The present article focuses on the importance of bodies moving within institutions and minds moving within semiotic structures as a basis for meaning making. We argue that such movement has been neglected; yet, it has the potential to enhance our understanding of how experiences are differentiated and integrated within individuals to produce individuals who are products of society and who also have agency in relation to society.",
           37,
           "culture_&_psychology"
          ],
          [
           "School vs Child: In Search of Mitigating Circumstances",
           "10.1177/1354067x05052350",
           2005,
           " Langhout (2005) presents an account of a modern school, the degree of control over the students exerted by the teachers, and the ways the children resist this pressure. In my reaction I point out that the control mechanisms she describes form part of a long tradition in the history of education and that they may be inevitable. I also suggest that to make her stronger claims more convincing we would need rather more information. ",
           0,
           "culture_&_psychology"
          ],
          [
           "<i>The Brothers Karamazov</i>, affective neuroscience, and reconsolidation of memories",
           "10.1177/1354067x17738983",
           2017,
           "Why do Dostoevskian bodies throb, sob, and grimace in ways that seem so far from the civilized protocols of, for example, Henry James’ exhibitions of emotions? How precisely does the concept of unconscious motivation serve interpretation when complicated by neuroscientific ideas of “the body as ground reference,” of “the neural self” as a “repeatedly reconstructed biological state” that records memories. This essay explores the implications of affective neuroscience research (Panksepp, Damasio, Solms) for interpreting Dostoevsky’s The Brothers Karamazov, particularly those scenes in which the characters access memories and display physical symptoms which appear subcortical.",
           1,
           "culture_&_psychology"
          ],
          [
           "Why does Sally never Call Bobby `I'?",
           "10.1177/1354067x030093009",
           2003,
           " Coelho and Figueiredo (2003) raise the issue of intersubjectivity. I propose to consider the problem from an action-theoretical and constructivist perspective that in some ways agrees, in others contradicts, the theses of the authors. The view I present is based on various publications on the `I'-Other problem since 1975. The centrality of the person's `I', as the overarching locus of action control and regulation, is re-claimed. By the same token, the role of society is re-defined, society being too heterogeneous, too contradictory, to influence directly the formation of the `I'; social impacts have to be filtered, selected, evaluated and assimilated by individual `I's, and thus the `social other' is itself personally constructed. ",
           9,
           "culture_&_psychology"
          ],
          [
           "Personal life space: Learning from Martha Muchow’s classic study",
           "10.1177/1354067x15615813",
           2015,
           " In her study on the life space of the urban child, Martha Muchow extensively analyzed the personal life space of children growing up in Hamburg between two World Wars. Resorting to theoretical person<>environment conceptions as proposed by mentors and colleagues such as William Stern, Jakob von Uexkuell, and Heinz Werner, Muchow’s study represents a fine example of empirically investigating the emergence of the world not only as it is experienced by the child (subjectively) or in a purely physical and concrete relational manner (objectively), but also as the child lives his world (from a developmental and cultural psychological perspective). The aim of this paper is to briefly review Mey and Günther’s translation of Muchow’s original study and to expand on Muchow’s threefold differentiation of the personal life world. With the example of Gugging—a place for Art Brut—Muchow’s person<>environment conception is discussed in relation to the developmental aspect of time and socio-cultural processes. ",
           0,
           "culture_&_psychology"
          ],
          [
           "Reflections on accessing indigenous research settings: Encounters with traditional health practitioners and leaders in Vhembe district, South Africa",
           "10.1177/1354067x20971249",
           2020,
           " Conducting research in indigenous settings in rural villages, where traditional leaders are the custodians of communities remains a challenge. Traditional health practitioners have to adapt their protocols to the needs of the cultural setting. When gaining access to a setting, researchers have to follow a process that respects the autonomy of individuals, thus adhering to one of the ethical principles of research with human participants. In this paper, the researchers reflect on gaining access to conduct research with traditional health practitioners and traditional leaders in Vhembe district, South Africa. Researchers participated in sharing circles, and identified five reflective themes. The themes included initiating agreement and rapport, continuous negotiation and compromise, Them and Us, adhering to local dress code and ritual performance. Researchers planning to conduct research with traditional health practitioners and traditional leaders should consider these themes in the preparation phase. ",
           6,
           "culture_&_psychology"
          ],
          [
           "The construction of ethnic boundaries in classroom interaction through social space",
           "10.1177/1354067x11408136",
           2011,
           " This article adds a social-spatial dimension to ethnicity construction while acknowledging the production of ethnicity as constructed through a relation of the ‘‘here and now’’ and an imagined (common) past. Empirically, social-spatial analysis is elaborated by looking at how social difference is produced in multi-ethnic schools through classroom interaction both in the USA and in the Netherlands. In our analysis, we are concerned with how ‘‘school’’ becomes evoked or produced in student discourse while ethnic positions are established. At the same time we show how spaces such as migrant neighborhoods and homelands are evoked and related to school spaces. The results show that more general mechanisms can be distinguished of how students use these spaces in their constructions of otherness across the data sets, but that the quality and complexity of these mechanisms are specific and can be related to the more general (migration) histories of the ethnic groups. ",
           15,
           "culture_&_psychology"
          ],
          [
           "Culture as the Co-evolution of Psychic and Social Systems: New Perspectives on the Person—Environment Relationship",
           "10.1177/1354067x09353208",
           2010,
           "In this article we contribute a new theoretical perspective to the analysis of the relationship between individual and culture, and the person and the environment. Many hotly debated issues in cultural psychology, such as reification, the discourse of personality traits, and models of part—whole hierarchies are productively addressed. Taking a systems-theoretical approach following Niklas Luhmann and others, we distinguish three different types of system and their operational processes (biotic, psychic and social) and suggest that the person—environment relationship should be conceptualized as a process of co-evolution of psychic and social systems. We discuss the critical role of communication in this process and its implications for the concept of culture. Our own research on classroom disruptions and problem behavior in educational settings provides illustrative examples for the kinds of methodological considerations generally relevant to a systems-theoretical approach in empirical research.",
           6,
           "culture_&_psychology"
          ],
          [
           "The Legacy of Boesch's Intellectual Oeuvre",
           "10.1177/1354067x9733004",
           2007,
           " The article serves as an introduction to Boesch's theory from the personal point of view of an author who has interacted with Boesch for a long time. First, three roots of Boesch's enterprise are located (Boesch's clinical work, his interest in contexts, and his own scientific heritage), and their implications for his theoretical framework are drawn. In a second section the intrinsic relationship among some of Boesch's key concepts is illustrated (actor, action, cognitive and affective schemata, symbolism, fantasms and myths). In a third part some thoughts about the future of Boesch's theory are offered. Here it is claimed that in Boesch's theory the social world is not as adequately elaborated as is the world of objects, and that this is a task for the future. Additionally, some methodical and methodological implications are enumerated, which follow from an action theory that is built upon a potentially self-reflective subject who is to be respected also as a moral patient. ",
           16,
           "culture_&_psychology"
          ],
          [
           "The numinous experience in the context of psychopathology and traumatic stress studies",
           "10.1177/1354067x20922139",
           2020,
           " The psychological phenomenon of a suddenly appearing, extremely enigmatic, and at the same time fascinating state in which one feels influenced by higher powers was described as a “numinous experience” by R. Otto and C. G. Jung. This condition is one of those subjectively non-rational experiences that have so far received little attention in cultural clinical psychology and yet have great potency to explain psychopathological phenomena. In the first section of this paper, we work towards a contemporary psychological definition both by focusing on the roles of paradoxical cognitions and dissociation and by presenting various differentiations and possible explanatory mechanisms. In the second part of this paper, we describe the numinous state as it occurs in selected clinical phenomena such as the subjective experience of potentially traumatic events including near-death experiences, sexual abuse of children, post-traumatic stress disorder, severe states of mourning (diagnosed today as prolonged grief disorder), and sleep paralysis. This paper is intended as a theoretical proposal aimed at better understanding subjectively non-rational states in patients. ",
           0,
           "culture_&_psychology"
          ],
          [
           "The narrative construction of Lesbian identity: A study using Bruner's self-indicators",
           "10.1177/1354067x16650831",
           2016,
           " Starting from a narrative conception of identity, in this paper, we present a description of the process of construction of lesbian identity by applying Bruner's indicators of selfhood. Our main goal is to analyze the personal process of (re)construction of lesbian identity and its connection with socio-cultural context. The autobiographical narratives of eight (8) lesbian women were analyzed and categorized in accordance with a model that describes the construction of homosexual identity in three phases: before Self-definition, Self-definition, and after Self-definition. The analysis conducted allowed us to describe, in an integrated and coherent way, the process that led the participants to a dialogical and personal position in the flow of social discourses about homosexuality they are involved in. ",
           5,
           "culture_&_psychology"
          ],
          [
           "‘Why Sally Never Calls Bobby “I” ’                 Revisited: an Alternative Perspective on Language and Early Self Development",
           "10.1177/1354067x04044287",
           2004,
           " In this article, I consider the question posed by Boesch (2003) in his commentary that appeared in response to issues raised in Coehlo and Figueiredo’s (2003) discussion of intersubjectivity. I begin with an overview of an alternative view of language to the one adopted in Boesch’s question, one that starts from a usage-based approach. Next I move on to consider empirical findings from recent research that examines language and the construction of self. Agreeing with Boesch’s central claim, this article nevertheless offers a distinct view of the connection between language and human development suggesting that language not only provides a tool for the researcher, but also provides a powerful means for the child to come to interpret culturally sanctioned ways of being in the world. ",
           2,
           "culture_&_psychology"
          ],
          [
           "An Interview with K.J. Gergen (Part 11) Culture and Psychology in Postmodernism: A Necessary Dialog",
           "10.1177/1354067x9512010",
           2007,
           " Discussion of critical issues of postmodernism in psychology between Kenneth J. Gergen and Aydan Gulerce revealed a multitude of challenging questions that neither the intellectual tendency labeled 'postmodernism' nor contemporary psychology have managed to answer (see Culture & Psychology 1(1), 147-159). In this continuation of the invesfigation into ideas, lines for a possible new dialog are charted out. ",
           3,
           "culture_&_psychology"
          ],
          [
           "Doubly transient chaos in a decaying open flow",
           "10.1088/2632-072x/ac0326",
           2021,
           "\nDoubly transient chaos was recently characterized as the general form of chaos in undriven dissipative systems. Here we study this type of complex behavior in the advective dynamics of decaying incompressible open flows. Using a decaying version of the blinking vortex-sink map as a prototype, we show that the resulting dynamics is markedly distinct from the one of mechanical systems addressed in previous works. In particular, the asymptotic codimension of the set of initial conditions of non-escaping particles is zero rather than one and the time-dependent escape rates either undergo an exponential decay rather than growth (for moderate and fast energy dissipation) or display a complex, possibly nonmonotonic behavior (for slow energy dissipation).",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "On the coordination dynamics of (animate) moving bodies",
           "10.1088/2632-072x/ac7caf",
           2022,
           "\nCoordination comes in many guises and represents one of the most striking, but least understood features of living things. The different forms that coordination takes and how it emerges and changes are of great interest to many disciplines, particularly the social and behavioral sciences, neuroscience, psychology, biology and physics itself. Inspired originally by theories of self-organization in open, nonequilibrium systems, the science of coordination (coordination dynamics) seeks to understand coordinated patterns at many scales and for multiple functions in living things. Here we review some of the key concepts of coordination dynamics along with some recent developments and posit ten tenets of the theory that may guide further understanding.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "Focus on Monitoring and Control of Complex Supply Systems",
           "10.1088/2632-072x/acfadd",
           2023,
           "\nThe ongoing rapid transformation of our energy supply challenges the operation and stability of electric power grids and other supply networks. This focus issue comprises new ideas and concepts in the monitoring and control of complex networks to address these challenges.&#xD;",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Production process networks: a trophic analysis",
           "10.1088/2632-072x/acbd7c",
           2023,
           "\nIn this article, production process databases originating from environmental sciences, more specifically from life cycle inventory (LCI), are considered as bipartite directed random networks. To model the observed directed hierarchical connection patterns, we turn to recent development concerning trophic coherence. Extending the scope to include bipartite networks, we compare several LCI networks to networks from other fields, and show empirically that they have high coherence and belong to the loopless regime, or close to its boundary.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Targeted suppression of failure spreading in multistable oscillator networks",
           "10.1088/2632-072x/abf090",
           2021,
           "\nFluctuations and damages crucially determine the operation and stability of networked systems across disciplines, from electrical powergrids, to vascular networks or neuronal networks. Local changes in the underlying dynamics may affect the whole network and, in the worst case, cause a total collapse of the system through a cascading failure. It has been demonstrated that certain subgraphs can reduce failure spreading drastically, or even inhibit it completely. However, this shielding effect is poorly understood for non-linear dynamical models. Here, we study the effect of perturbations in networks of oscillators coupled via the Kuramoto model. We demonstrate how the network structure can be optimised for suppressing specific, targeted fluctuations at a desired operational state while letting others pass. We illustrate our approach by demonstrating that a significant reduction in time-dependent fluctuations may be achieved by optimising the edge weights. Finally, we demonstrate how to apply the developed method to real-world supply networks such as power grids. Our findings reveal that a targeted shielding of specific solutions in multistable systems is possible which may be applied to make supply networks more robust.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "A network approach to atomic spectra",
           "10.1088/2632-072x/ace1c3",
           2023,
           "\nNetwork science provides a universal framework for modeling complex systems, contrasting the reductionist approach generally adopted in physics. In a prototypical study, we utilize network models created from spectroscopic data of atoms to predict microscopic properties of the underlying physical system. For simple atoms such as helium, an a posteriori inspection of spectroscopic network communities reveals the emergence of quantum numbers and symmetries. For more complex atoms such as thorium, finer network hierarchies suggest additional microscopic symmetries or configurations. Furthermore, link prediction in spectroscopic networks yields a quantitative ranking of yet unknown atomic transitions, offering opportunities to discover new spectral lines in a well-controlled manner. Our work promotes a genuine bi-directional exchange of methodology between network science and physics, and presents new perspectives for the study of atomic spectra.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Social network heterogeneity benefits individuals at the expense of groups in the creation of innovation",
           "10.1088/2632-072x/ac9447",
           2022,
           "\nInnovation is fundamental for development and provides a competitive advantage for societies. It is the process of creating more complex technologies, ideas, or protocols from existing ones. While innovation may be created by single agents (i.e. individuals or organisations), it is often a result of social interactions between agents exchanging and combining complementary expertise and perspectives. The structure of social networks impacts this knowledge exchange process. To study the role of social network structures on the creation of new technologies, we design an evolutionary mechanistic model combining self-creation and social learning. We find that social heterogeneity allows agents to leverage the benefits of diversity and to develop technologies of higher complexity. Social heterogeneity, however, reduces the group ability to innovate. Not only the social structure but also the openness of agents to collaborate affect innovation. We find that interdisciplinary interactions lead to more complex technologies benefiting the entire group but also increase the inequality in the innovation output. Lower openness to interdisciplinary collaborations may be compensated by a higher ability to collaborate with multiple peers, but low openness also neutralises the intrinsic benefits of network heterogeneity. Our findings indicate that social network heterogeneity has contrasting effects on microscopic (local) and macroscopic (group) levels, suggesting that the emergence of innovation leaders may suppress the overall group performance.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Non-monotonic transients to synchrony in Kuramoto networks and electrochemical oscillators",
           "10.1088/2632-072x/abe109",
           2021,
           "\nWe performed numerical simulations with the Kuramoto model and experiments with oscillatory nickel electrodissolution to explore the dynamical features of the transients from random initial conditions to a fully synchronized (one-cluster) state. The numerical simulations revealed that certain networks (e.g., globally coupled or dense Erdős–Rényi random networks) showed relatively simple behavior with monotonic increase of the Kuramoto order parameter from the random initial condition to the fully synchronized state and that the transient times exhibited a unimodal distribution. However, some modular networks with bridge elements were identified which exhibited non-monotonic variation of the order parameter with local maximum and/or minimum. In these networks, the histogram of the transients times became bimodal and the mean transient time scaled well with inverse of the magnitude of the second largest eigenvalue of the network Laplacian matrix. The non-monotonic transients increase the relative standard deviations from about 0.3 to 0.5, i.e., the transient times became more diverse. The non-monotonic transients are related to generation of phase patterns where the modules are synchronized but approximately anti-phase to each other. The predictions of the numerical simulations were demonstrated in a population of coupled oscillatory electrochemical reactions in global, modular, and irregular tree networks. The findings clarify the role of network structure in generation of complex transients that can, for example, play a role in intermittent desynchronization of the circadian clock due to external cues or in deep brain stimulations where long transients are required after a desynchronization stimulus.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "A devil’s advocate view on ‘self-organized’ brain criticality",
           "10.1088/2632-072x/abfa0f",
           2021,
           "\nStationarity of the constituents of the body and of its functionalities is a basic requirement for life, being equivalent to survival in first place. Assuming that the resting state activity of the brain serves essential functionalities, stationarity entails that the dynamics of the brain needs to be regulated on a time-averaged basis. The combination of recurrent and driving external inputs must therefore lead to a non-trivial stationary neural activity, a condition which is fulfiled for afferent signals of varying strengths only close to criticality. In this view, the benefits of working in the vicinity of a second-order phase transition, such as signal enhancements, are not the underlying evolutionary drivers, but side effects of the requirement to keep the brain functional in first place. It is hence more appropriate to use the term ‘self-regulated’ in this context, instead of ‘self-organized’.",
           10,
           "journal_of_physics_complexity"
          ],
          [
           "A scientific portrait of Giorgio Parisi: complex systems and much more",
           "10.1088/2632-072x/acb8a1",
           2023,
           "\nThis article summarises the outstanding scientific career of Giorgio Parisi, who was awarded the 2021 Nobel Prize in Physics, with special emphasis on his contributions to the description of the equilibrium properties of disordered systems.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Preserved layout features embedded in road network development",
           "10.1088/2632-072x/ab7f4e",
           2020,
           "\nRoad networks are some of the oldest and most permanent man-made structures in space, serving as valuable records of the conditions of the society through long periods of time. Quantitatively analyzing these networks will therefore reveal rich insights into the socio-political conditions of the society through history, and can provide awareness for effectively managing the growth and evolution in the future. Here, we extracted the state of the road network of Manila, Philippines at various points in history through georeferencing and digitization of hand-drawn historical maps. Visual and metrical analyses revealed key well-planned periods punctuating the otherwise self-organized growth, particularly the more recent densification at reclamation areas coincident with the rapid economic growth. The road network of Manila shows statistical regularities that are also observed for other global road network data sets, although the recent reclamation significantly increase the statistics of the very short and peripheral nodes. Finally, the clusters of nodes with the highest closeness centralities mimic the historical shape of the network, allowing for an automatic identification of the core historical sections of the city. Studies such as this one extract useful information from these permanent spatial records, which may then be useful for developing sound policy measures for handling further urbanization.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Response of quantum spin networks to attacks",
           "10.1088/2632-072x/abf5c2",
           2021,
           "\nWe investigate the ground states of spin models defined on networks that we imprint (e.g., non-complex random networks like Erdos–Renyi, or complex networks like Watts–Strogatz, and Barabasi–Albert), and their response to decohering processes which we model with network attacks. We quantify the complexity of these ground states, and their response to the attacks, by calculating distributions of network measures of an emergent network whose link weights are the pairwise mutual information between spins. We focus on attacks which projectively measure spins. We find that the emergent networks in the ground state do not satisfy the usual criteria for complexity, and their average properties are captured well by a single dimensionless parameter in the Hamiltonian. While the response of classical networks to attacks is well-studied, where classical complex networks are known to be more robust to random attacks than random networks, we find counter-intuitive results for our quantum networks. We find that the ground states for Hamiltonians defined on different classes of imprinted networks respond similarly to all our attacks, and the attacks rescale the average properties of the emergent network by a constant factor. Mean field theory explains these results for relatively dense networks, but we also find the simple rescaling behavior away from the regime of validity of mean field theory. Our calculations indicate that complex spin networks are not more robust to projective measurement attacks, and presumably also other quantum attacks, than non-complex spin networks, in contrast to the classical case. Understanding the response of the spin networks to decoherence and attacks will have applications in understanding the physics of open quantum systems, and in designing robust complex quantum systems—possibly even a robust quantum internet in the long run—that is maximally resistant to decoherence.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "Predicting future links with new nodes in temporal academic networks",
           "10.1088/2632-072x/ac4bee",
           2022,
           "\nMost real-world systems evolve over time in which entities and the interactions between entities are added and removed—new entities or relationships appear and old entities or relationships vanish. While most network evolutionary models can provide an iterative process for constructing global properties, they cannot capture the evolutionary mechanisms of real systems. Link prediction is hence proposed to predict future links which also can help us understand the evolution law of real systems. The aim of link prediction is to uncover missing links from known parts of the network or quantify the likelihood of the emergence of future links from current structures of the network. However, almost all existing studies ignored that old nodes tend to disappear and new nodes appear over time in real networks, especially in social networks. It is more challenging for link prediction since the new nodes do not have pre-existing structure information. To solve the temporal link prediction problems with new nodes, here we take into account nodal attribute similarity and the shortest path length, namely, ASSPL, to predict future links with new nodes. The results tested on scholar social network and academic funding networks show that it is highly effective and applicable for ASSPL in funding networks with time-evolving. Meanwhile, we make full use of an efficient parameter to exploit how network structure or nodal attribute has an impact on the performance of temporal link prediction. Finally, we find that nodal attributes and network structure complement each other well for predicting future links with new nodes in funding networks.",
           10,
           "journal_of_physics_complexity"
          ],
          [
           "Reciprocity, community detection, and link prediction in dynamic networks",
           "10.1088/2632-072x/ac52e6",
           2022,
           "\nMany complex systems change their structure over time, in these cases dynamic networks can provide a richer representation of such phenomena. As a consequence, many inference methods have been generalized to the dynamic case with the aim to model dynamic interactions. Particular interest has been devoted to extend the stochastic block model and its variant, to capture community structure as the network changes in time. While these models assume that edge formation depends only on the community memberships, recent work for static networks show the importance to include additional parameters capturing structural properties, as reciprocity for instance. Remarkably, these models are capable of generating more realistic network representations than those that only consider community membership. To this aim, we present a probabilistic generative model with hidden variables that integrates reciprocity and communities as structural information of networks that evolve in time. The model assumes a fundamental order in observing reciprocal data, that is an edge is observed, conditional on its reciprocated edge in the past. We deploy a Markovian approach to construct the network’s transition matrix between time steps and parameters’ inference is performed with an expectation-maximization algorithm that leads to high computational efficiency because it exploits the sparsity of the dataset. We test the performance of the model on synthetic dynamical networks, as well as on real networks of citations and email datasets. We show that our model captures the reciprocity of real networks better than standard models with only community structure, while performing well at link prediction tasks.",
           15,
           "journal_of_physics_complexity"
          ],
          [
           "Outlier mining in high-dimensional data using the Jensen–Shannon divergence and graph structure analysis",
           "10.1088/2632-072x/aca94a",
           2022,
           "Reliable anomaly/outlier detection algorithms have practical applications in many fields. For instance, anomaly detection allows to filter and clean the data used to train machine learning algorithms, improving their performance. However, outlier mining is challenging when the data is high-dimensional, and different approaches have been proposed for different types of data (temporal, spatial, network, etc). Here we propose a methodology to mine outliers in generic datasets in which it is possible to define a meaningful distance between elements of the dataset. The methodology is based on defining a fully connected, undirected graph, where the nodes are the elements of the dataset and the links have weights that are the distances between the nodes. Outlier scores are defined by analyzing the structure of the graph, in particular, by using the Jensen–Shannon (JS) divergence to compare the distributions of weights of different nodes. We demonstrate the method using a publicly available database of credit-card transactions, where some of the transactions are labeled as frauds. We compare with the performance obtained when using Euclidean distances and graph percolation, and show that the JS divergence leads to performance improvement, but increases the computational cost.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "The changing notion of chimera states, a critical review",
           "10.1088/2632-072x/ac0810",
           2021,
           "\nChimera states, states of coexistence of synchronous and asynchronous motion, have been a subject of extensive research since they were first given a name in 2004. Increased interest has lead to their discovery in ever new settings, both theoretical and experimental. Less well-discussed is the fact that successive results have also broadened the notion of what actually constitutes a chimera state. In this article, we critically examine how the results for different model types and coupling schemes, as well as varying implicit interpretations of terms such as coexistence, synchrony and incoherence, have influenced the common understanding of what constitutes a chimera. We cover both theoretical and experimental systems, address various chimera-derived terms that have emerged over the years and finally reflect on the question of chimera states in real-world contexts.",
           27,
           "journal_of_physics_complexity"
          ],
          [
           "Deconstructing scale-free neuronal avalanches: behavioral transitions and neuronal response",
           "10.1088/2632-072x/ac35b4",
           2021,
           "\nObservations of neurons in a resting brain and neurons in cultures often display spontaneous scale-free (SF) collective dynamics in the form of information cascades, also called ‘neuronal avalanches’. This has motivated the so called critical brain hypothesis which posits that the brain is self-tuned to a critical point or regime, separating exponentially-growing dynamics from quiescent states, to achieve optimality. Yet, how such optimality of information transmission is related to behavior and whether it persists under behavioral transitions has remained a fundamental knowledge gap. Here, we aim to tackle this challenge by studying behavioral transitions in mice using two-photon calcium imaging of the retrosplenial cortex (RSC)—an area of the brain well positioned to integrate sensory, mnemonic, and cognitive information by virtue of its strong connectivity with the hippocampus, medial prefrontal cortex, and primary sensory cortices. Our work shows that the response of the underlying neural population to behavioral transitions can vary significantly between different sub-populations such that one needs to take the structural and functional network properties of these sub-populations into account to understand the properties at the total population level. Specifically, we show that the RSC contains at least one sub-population capable of switching between two different SF regimes, indicating an intricate relationship between behavior and the optimality of neuronal response at the subgroup level. This asks for a potential reinterpretation of the emergence of self-organized criticality in neuronal systems.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "Finite-time correlations boost large voltage angle fluctuations in electric power grids",
           "10.1088/2632-072x/acb62a",
           2023,
           "\nDecarbonization in the energy sector has been accompanied by an increased penetration of new renewable energy sources in electric power systems. Such sources differ from traditional productions in that, first, they induce larger, undispatchable fluctuations in power generation and second, they lack inertia. Recent measurements have indeed reported long, non-Gaussian tails in the distribution of local voltage frequency data. Large frequency deviations may induce grid instabilities, leading in worst-case scenarios to cascading failures and large-scale blackouts. In this article, we investigate how correlated noise disturbances, characterized by the cumulants of their distribution, propagate through meshed, high-voltage power grids. For a single source of fluctuations, we show that long noise correlation times boost non-Gaussian voltage angle fluctuations so that they propagate similarly to Gaussian fluctuations over the entire network. However, they vanish faster, over short distances if the noise fluctuates rapidly. We furthermore demonstrate that a Berry–Esseen theorem leads to the vanishing of non-Gaussianities as the number of uncorrelated noise sources increases. Our predictions are corroborated by numerical simulations on realistic models of power grids.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Digraphs are different: why directionality matters in complex systems",
           "10.1088/2632-072x/ab8e2f",
           2020,
           "\nMany networks describing complex systems are directed: the interactions between elements are not symmetric. Recent work has shown that these networks can display properties such as trophic coherence or non-normality, which in turn affect stability, percolation and other dynamical features. I show here that these topological properties have a common origin, in that the edges of directed networks can be aligned—or not—with a global direction. And I illustrate how this can lead to rich and unexpected dynamical behaviour even in the simplest of models.",
           15,
           "journal_of_physics_complexity"
          ],
          [
           "Simplicial complexes: higher-order spectral dimension and dynamics",
           "10.1088/2632-072x/ab82f5",
           2020,
           "\nSimplicial complexes constitute the underlying topology of interacting complex systems including among the others brain and social interaction networks. They are generalized network structures that allow to go beyond the framework of pairwise interactions and to capture the many-body interactions between two or more nodes strongly affecting dynamical processes. In fact, the simplicial complexes topology allows to assign a dynamical variable not only to the nodes of the interacting complex systems but also to links, triangles, and so on. Here we show evidence that the dynamics defined on simplices of different dimensions can be significantly different even if we compare dynamics of simplices belonging to the same simplicial complex. By investigating the spectral properties of the simplicial complex model called ‘network geometry with flavor’ (NGF) we provide evidence that the up and down higher-order Laplacians can have a finite spectral dimension whose value depends on the order of the Laplacian. Finally we discuss the implications of this result for higher-order diffusion defined on simplicial complexes showing that the n-order diffusion dynamics have a return type distribution that can depends on n as it is observed in NGFs.",
           49,
           "journal_of_physics_complexity"
          ],
          [
           "Probing the spectral dimension of quantum network geometries",
           "10.1088/2632-072x/abaf9b",
           2020,
           "\nWe consider an environment for an open quantum system described by a ‘quantum network geometry with flavor’ (QNGF) in which the nodes are coupled quantum oscillators. The geometrical nature of QNGF is reflected in the spectral properties of the Laplacian matrix of the network which display a finite spectral dimension, determining also the frequencies of the normal modes of QNGFs. We show that an a priori unknown spectral dimension can be indirectly estimated by coupling an auxiliary open quantum system to the network and probing the normal mode frequencies in the low frequency regime. We find that the network parameters do not affect the estimate; in this sense it is a property of the network geometry, rather than the values of, e.g., oscillator bare frequencies or the constant coupling strength. Numerical evidence suggests that the estimate is also robust both to small changes in the high frequency cutoff and noisy or missing normal mode frequencies. We propose to couple the auxiliary system to a subset of network nodes with random coupling strengths to reveal and resolve a sufficiently large subset of normal mode frequencies.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "Computational phase transition signature in Gibbs sampling",
           "10.1088/2632-072x/ad1410",
           2023,
           "\nGibbs sampling is fundamental to a wide range of computer algorithms. Such algorithms are set to be replaced by physics based processors—be it quantum or stochastic annealing devices—which embed problem instances and evolve a physical system into a low-energy ensemble to recover a probability distribution. At a critical constraint to variable ratio, satisfiability (SAT) problem instances exhibit a SAT-UNSAT transition (frustrated to frustration free). Algorithms require increasing computational resources from this critical point. This is a so called, algorithmic or computational phase transition and has extensively been studied. In this paper we consider the complexity in sampling and recovering ground states from resultant distributions of a physics based processor. In particular, we first consider the ideal Gibbs distributions at some fixed inverse temperature and observe that the success probability in sampling and recovering ground states decrease for instances starting at the critical density. Furthermore, simulating the Gibbs distribution, we employ Ising spin dynamics, which play a crucial role in understanding of non-equilibrium statistical physics, to find their steady states of 2-SAT Hamiltonians. We observe that beyond the critical density, the probability of sampling ground states decreases. Our results apply to several contemporary devices and provide a means to experimentally probe a signature of the computational phase transition.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "A perspective on complexity and networks science",
           "10.1088/2632-072x/ab9a24",
           2020,
           "\nComplexity and network science are nowadays used, or at least invoked, in a variety of scientific researchareas ranging from the analysis of financial systems to social structure and even to medicine. Here I explore some of the possible reasons for this success, the relationship between them and how they might be used in the future.",
           16,
           "journal_of_physics_complexity"
          ],
          [
           "Structure and stability of the Indian power transmission network",
           "10.1088/2632-072x/acd611",
           2023,
           "\nWe present the study on the Indian power transmission network using the framework of a complex network and quantify its structural properties. For this, we build the network structure underlying the Indian power grid, using two of its most prevalent power lines. We construct an equivalent model of an exponential network and study its structural changes with changes in two parameters related to redundancy and dead-ends. Then we analyze its stability against cascading failures by varying these two parameters using the link failure model. This helps to gain insight into the relation of network topology to its stability, and indicates how the optimum choice of these parameters can result in a power grid structure with minimum failed links. We apply the same model to study the robustness of the Indian power grid against such failures. In this case, we find that when a link connected to a generator fails, it results in a cascade that spreads in the grid until it is split into two separate stable clusters of generators and consumers, with over one-third of its nodes nonfunctional.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "On the information-theoretic formulation of network participation",
           "10.1088/2632-072x/ad32da",
           2024,
           "\nThe participation coefficient is a widely used metric of the diversity of a node’s connections with respect to a modular partition of a network. An information-theoretic formulation of this concept of connection diversity, referred to here as participation entropy, has been introduced as the Shannon entropy of the distribution of module labels across a node’s connected neighbors. While diversity metrics have been studied theoretically in other literatures, including to index species diversity in ecology, many of these results have not previously been applied to networks. Here we show that the participation coefficient is a first-order approximation to participation entropy and use the desirable additive properties of entropy to develop new metrics of connection diversity with respect to multiple labelings of nodes in a network, as joint and conditional participation entropies. The information-theoretic formalism developed here allows new and more subtle types of nodal connection patterns in complex networks to be studied.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Entropy, free energy, symmetry and dynamics in the brain",
           "10.1088/2632-072x/ac4bec",
           2022,
           "\nNeuroscience is home to concepts and theories with roots in a variety of domains including information theory, dynamical systems theory, and cognitive psychology. Not all of those can be coherently linked, some concepts are incommensurable, and domain-specific language poses an obstacle to integration. Still, conceptual integration is a form of understanding that provides intuition and consolidation, without which progress remains unguided. This paper is concerned with the integration of deterministic and stochastic processes within an information theoretic framework, linking information entropy and free energy to mechanisms of emergent dynamics and self-organization in brain networks. We identify basic properties of neuronal populations leading to an equivariant matrix in a network, in which complex behaviors can naturally be represented through structured flows on manifolds establishing the internal model relevant to theories of brain function. We propose a neural mechanism for the generation of internal models from symmetry breaking in the connectivity of brain networks. The emergent perspective illustrates how free energy can be linked to internal models and how they arise from the neural substrate.",
           15,
           "journal_of_physics_complexity"
          ],
          [
           "Nanoscale neuromorphic networks and criticality: a perspective",
           "10.1088/2632-072x/ac3ad3",
           2021,
           "\nNumerous studies suggest critical dynamics may play a role in information processing and task performance in biological systems. However, studying critical dynamics in these systems can be challenging due to many confounding biological variables that limit access to the physical processes underpinning critical dynamics. Here we offer a perspective on the use of abiotic, neuromorphic nanowire networks as a means to investigate critical dynamics in complex adaptive systems. Neuromorphic nanowire networks are composed of metallic nanowires and possess metal-insulator-metal junctions. These networks self-assemble into a highly interconnected, variable-density structure and exhibit nonlinear electrical switching properties and information processing capabilities. We highlight key dynamical characteristics observed in neuromorphic nanowire networks, including persistent fluctuations in conductivity with power law distributions, hysteresis, chaotic attractor dynamics, and avalanche criticality. We posit that neuromorphic nanowire networks can function effectively as tunable abiotic physical systems for studying critical dynamics and leveraging criticality for computation.",
           17,
           "journal_of_physics_complexity"
          ],
          [
           "Eco-evolutionary games for harvesting self-renewing common resource: effect of growing harvester population",
           "10.1088/2632-072x/acc5cb",
           2023,
           "\nThe tragedy of the commons (TOCs) is a ubiquitous social dilemma witnessed in interactions between a population of living entities and shared resources available to them: the individuals in the population tend to selfishly overexploit a common resource as it is arguably the rational choice, or in case of non-human beings, it may be an evolutionarily uninvadable action. How to avert the TOC is a significant problem related to the conservation of resources. It is not hard to envisage situations where the resource could be self-renewing and the size of the population may be dependent on the state of the resource through the fractions of the population employing different exploitation rates. If the self-renewal rate of the resource lies between the maximum and the minimum exploitation rates, it is not a priori obvious under what conditions the TOC can be averted. In this paper, we address this question analytically and numerically using the setup of an evolutionary game theoretical replicator equation that models the Darwinian tenet of natural selection. Through the replicator equation, while we investigate how a population of replicators exploit the shared resource, the latter’s dynamical feedback on the former is also not ignored. We also present a transparent bottom-up derivation of the game-resource feedback model to facilitate future studies on the stochastic effects on the findings presented herein.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Reward versus punishment: averting the tragedy of the commons in eco-evolutionary dynamics",
           "10.1088/2632-072x/ac6c6e",
           2022,
           "\nWe consider an unstructured population of individuals who are randomly matched in an underlying population game in which the payoffs depend on the evolving state of the common resource exploited by the population. There are many known mechanisms for averting the overexploitation (tragedy) of the (common) resource. Probably one of the most common mechanism is reinforcing cooperation through rewards and punishments. Additionally, the depleting resource can also provide feedback that reinforces cooperation. Thus, it is an interesting question that how reward and punishment comparatively fare in averting the tragedy of the common (TOC) in the game-resource feedback evolutionary dynamics. Our main finding is that, while averting the TOC completely, rewarding cooperators cannot get rid of all the defectors, unlike what happens when defectors are punished; and as a consequence, in the completely replete resource state, the outcome of the population game can be socially optimal in the presence of the punishment but not so in the presence of the reward.",
           5,
           "journal_of_physics_complexity"
          ],
          [
           "Extreme events in globally coupled chaotic maps",
           "10.1088/2632-072x/ac221f",
           2021,
           "\nUnderstanding and predicting uncertain things are the central themes of scientific evolution. Human beings revolve around these fears of uncertainties concerning various aspects like a global pandemic, health, finances, to name but a few. Dealing with this unavoidable part of life is far tougher due to the chaotic nature of these unpredictable activities. In the present article, we consider a global network of identical chaotic maps, which splits into two different clusters, despite the interaction between all nodes are uniform. The stability analysis of the spatially homogeneous chaotic solutions provides a critical coupling strength, before which we anticipate such partial synchronization. The distance between these two chaotic synchronized populations often deviates more than eight times of standard deviation from its long-term average. The probability density function of these highly deviated values fits well with the generalized extreme value distribution. Meanwhile, the distribution of recurrence time intervals between extreme events resembles the Weibull distribution. The existing literature helps us to characterize such events as extreme events using the significant height. These extremely high fluctuations are less frequent in terms of their occurrence. We determine numerically a range of coupling strength for these extremely large but recurrent events. On-off intermittency is the responsible mechanism underlying the formation of such extreme events. Besides understanding the generation of such extreme events and their statistical signature, we furnish forecasting these events using the powerful deep learning algorithms of an artificial recurrent neural network. This long short-term memory (LSTM) can offer handy one-step forecasting of these chaotic intermittent bursts. We also ensure the robustness of this forecasting model with two hundred hidden cells in each LSTM layer.",
           19,
           "journal_of_physics_complexity"
          ],
          [
           "Evolutionary behaviour of ‘inflating’ random real matrices for economy or biology: stasis statistics of vector iterations upon growth",
           "10.1088/2632-072x/ac718f",
           2022,
           "\nA scheme is proposed for describing stasis and transitions in evolutionary contexts defined by a growing number of interrelated items. These items could be genes/species in biology, or tools/products in economy. The target is a frame to describe the advent of stasis marked by dominant species or dominant objects (car, smartphone) between sharp transitions (quakes). The tool of random matrices is adapted to add an explicit varietal growth, through an ‘inflation’ of a real random matrix (Ginibre set), by regularly adding a line and a column, such a matrix operating at each unit time step on the evolving vector, U(t + 1) = M(t)U(t). In this view, U(t) ∝ log(C(t)) with C(t) the vector of abundances of genes in a gene pool, or of abundance of tools in a multi-sector production economy (as in Leontieff matrices of sector-wise productions). U(t) is trending toward the eigenvector with the largest-modulus eigenvalue (ev) U\n(N) for the current N(t). Most times, the next such eigenvector U\n(N+1) of the inflated matrix is close and mostly colinear to U\n(N). But, as time goes and N also grows, a wholly unrelated eigenvector may acquire a larger modulus ev and become the new attractor. Thus, there are slowly-moving stases punctuated by quakes. The leading-ev-modulus competition is elucidated, as well as the main features of the stasis duration distribution it entails, akin to a q-exponential law. This is done by means of a two-particles model of Brownian motion taking place with an N-dependent drift and diffusion. To minimally flesh the issue, a set of bibliographic data (yearly number of papers among all journals of a domain) is used, lending support to the vector-colinearity-based methods used for the detection of stases vs quakes. Hints are given for various developments tackling the appropriateness of the model to various growth contexts, e.g. with sparse network or with death and not only novelty/birth.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Meaningful local signalling in sinoatrial node identified by random matrix theory and PCA",
           "10.1088/2632-072x/acadc8",
           2022,
           "\nThe sinoatrial node (SAN) is the pacemaker of the heart. Recently calcium signals, believed to be crucially important in rhythm generation, have been imaged in intact SAN and shown to be heterogeneous in various regions of the SAN with a lot of analysis relying on visual inspection rather than mathematical tools. Here we apply methods of random matrix theory (RMT) developed for financial data and various biological data sets including β-cell collectives and electroencephalograms (EEG) to analyse correlations in SAN calcium signals using eigenvalues and eigenvectors of the correlation matrix. We use principal component analysis to locate signalling modules corresponding to localization properties the eigenvectors corresponding to high eigenvalues. We find that the top eigenvector captures the global behaviour of the SAN i.e. action potential (AP) induced calcium transient. In some cases, the eigenvector corresponding to the second highest eigenvalue yields a pacemaker region whose calcium signals predict the AP. Furthermore, using new analytic methods, we study the relationship between covariance coefficients and distance, and find that even inside the central zone, there are non-trivial long range correlations, indicating intercellular interactions in most cases. Lastly, we perform an analysis of nearest-neighbour eigenvalue distances and find that it coincides with universal Wigner surmise under all available experimental conditions, while the number variance, which captures eigenvalue correlations, is sensitive to experimental conditions. Thus RMT application to SAN allows to remove noise and the global effects of the AP-induced calcium transient and thereby isolate the local and meaningful correlations in calcium signalling.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Quantifying impact and response in markets using information filtering networks",
           "10.1088/2632-072x/ac6721",
           2022,
           "\nWe present a novel methodology to quantify the ‘impact’ of and ‘response’ to market shocks. We apply shocks to a group of stocks in a part of the market, and we quantify the effects in terms of average losses on another part of the market using a sparse probabilistic elliptical model for the multivariate return distribution of the whole market. Sparsity is introduced with an L\n0-norm regularization, which forces to zero some elements of the inverse covariance according to a dependency structure inferred from an information filtering network. Our study concerns the FTSE 100 and 250 markets and analyzes impact and response to shocks both applied to and received from individual stocks and group of stocks. We observe that the shock pattern is related to the structure of the network associated with the sparse structure of the inverse covariance of stock log-returns. Central sectors appear more likely to be affected by shocks, and stocks with a large level of underlying diversification have a larger impact on the rest of the market when experiencing shocks. By analyzing the system during times of crisis and comparative market calmness, we observe changes in the shock patterns with a convergent behavior in times of crisis.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Topological data analysis of task-based fMRI data from experiments on schizophrenia",
           "10.1088/2632-072x/abb4c6",
           2021,
           "\nWe use methods from computational algebraic topology to study functional brain networks in which nodes represent brain regions and weighted edges encode the similarity of functional magnetic resonance imaging (fMRI) time series from each region. With these tools, which allow one to characterize topological invariants such as loops in high-dimensional data, we are able to gain understanding of low-dimensional structures in networks in a way that complements traditional approaches that are based on pairwise interactions. In the present paper, we use persistent homology to analyze networks that we construct from task-based fMRI data from schizophrenia patients, healthy controls, and healthy siblings of schizophrenia patients. We thereby explore the persistence of topological structures such as loops at different scales in these networks. We use persistence landscapes and persistence images to represent the output of our persistent-homology calculations, and we study the persistence landscapes and persistence images using k-means clustering and community detection. Based on our analysis of persistence landscapes, we find that the members of the sibling cohort have topological features (specifically, their one-dimensional loops) that are distinct from the other two cohorts. From the persistence images, we are able to distinguish all three subject groups and to determine the brain regions in the loops (with four or more edges) that allow us to make these distinctions.",
           17,
           "journal_of_physics_complexity"
          ],
          [
           "Explicit construction of joint multipoint statistics in complex systems",
           "10.1088/2632-072x/ac2cda",
           2021,
           "\nComplex systems often involve random fluctuations for which self-similar properties in space and time play an important role. Fractional Brownian motions, characterized by a single scaling exponent, the Hurst exponent H, provide a convenient tool to construct synthetic signals that capture the statistical properties of many processes in the physical sciences and beyond. However, in certain strongly interacting systems, e.g., turbulent flows, stock market indices, or cardiac interbeats, multiscale interactions lead to significant deviations from self-similarity and may therefore require a more elaborate description. In the context of turbulence, the Kolmogorov–Oboukhov model (K62) describes anomalous scaling, albeit explicit constructions of a turbulent signal by this model are not available yet. Here, we derive an explicit formula for the joint multipoint probability density function of a multifractal field. To this end, we consider a scale mixture of fractional Ornstein–Uhlenbeck processes and introduce a fluctuating length scale in the corresponding covariance function. In deriving the complete statistical properties of the field, we are able to systematically model synthetic multifractal phenomena. We conclude by giving a brief outlook on potential applications which range from specific tailoring or stochastic interpolation of wind fields to the modeling of financial data or non-Gaussian features in geophysical or geospatial settings.",
           11,
           "journal_of_physics_complexity"
          ],
          [
           "Simplicial contagion in temporal higher-order networks",
           "10.1088/2632-072x/ac12bd",
           2021,
           "\nComplex networks represent the natural backbone to study epidemic processes in populations of interacting individuals. Such a modeling framework, however, is naturally limited to pairwise interactions, making it less suitable to properly describe social contagion, where individuals acquire new norms or ideas after simultaneous exposure to multiple sources of infections. Simplicial contagion has been proposed as an alternative framework where simplices are used to encode group interactions of any order. The presence of these higher-order interactions leads to explosive epidemic transitions and bistability. In particular, critical mass effects can emerge even for infectivity values below the standard pairwise epidemic threshold, where the size of the initial seed of infectious nodes determines whether the system would eventually fall in the endemic or the healthy state. Here we extend simplicial contagion to time-varying networks, where pairwise and higher-order simplices can be created or destroyed over time. By following a microscopic Markov chain approach, we find that the same seed of infectious nodes might or might not lead to an endemic stationary state, depending on the temporal properties of the underlying network structure, and show that persistent temporal interactions anticipate the onset of the endemic state in finite-size systems. We characterize this behavior on higher-order networks with a prescribed temporal correlation between consecutive interactions and on heterogeneous simplicial complexes, showing that temporality again limits the effect of higher-order spreading, but in a less pronounced way than for homogeneous structures. Our work suggests the importance of incorporating temporality, a realistic feature of many real-world systems, into the investigation of dynamical processes beyond pairwise interactions.",
           42,
           "journal_of_physics_complexity"
          ],
          [
           "Local multifractality in urban systems—the case study of housing prices in the greater Paris region",
           "10.1088/2632-072x/ac9772",
           2022,
           "\nEven though the study of fractal and multifractal properties has now become an established approach for statistical urban data analysis, the accurate multifractal characterisation of smaller, district-scale spatial units is still a somewhat challenging task. The latter issue is key for understanding complex spatial correlations within urban regions while the methodological challenge can be mainly attributed to inhomogeneous data availability over their territories. We demonstrate how the approach proposed here for the multifractal analysis of irregular marked point processes is able to estimate local self-similarity and intermittency exponents in a satisfactory manner via combining methods from classical multifractal and geographical analysis. With the aim of emphasizing general applicability, we first introduce the procedure on synthetic data using a multifractal random field as mark superposed on two distinct spatial distributions. We go on to illustrate the methodology on the example of home prices in the greater Paris region, France. In the context of complex urban systems, our findings proclaim the need for separately tackling processes on the geolocation (support) and any attached value (mark, e.g. home prices) of geospatial data points in an attempt to fully describe the phenomenon under observation. In particular, the results are indicators of the strength of global and local spatial dependency in the housing price structure and how these build distinct layered patterns within and outside of the municipal boundary. The derived properties are of potential urban policy and strategic planning relevance for the timely identification of local vulnerabilities while they are also intended to be combinable with existing price indices in the regional economics context.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Revisiting the coupling between accessibility and population growth",
           "10.1088/2632-072x/ab97a7",
           2020,
           "\nThe coupling between population growth and transport accessibility has been an elusive problem for more than 60 years now. Due to the lack of theoretical foundations, most of the studies that considered how the evolution of transportation networks impacts the population growth are based on regression analysis in order to identify relevant variables. The recent availability of large amounts of data allows us to envision the construction of new approaches for understanding this coupling between transport and population growth. Here, we use a detailed dataset for about 36 000 municipalities in France from 1968 until now. In the case of large urban areas such as Paris, we show that growth rate statistical variations decay in time and display a trend towards homogenization where local aspects are less relevant. We also show that growth rate differences due to accessibility are very small and can mostly be observed for cities that experienced very large accessibility variations. This suggests that the relevant variable for explaining growth rate variations is not the accessibility but its temporal variation. We propose a model that integrates the stochastic internal variation of the municipalities population and an inter-urban migration term that we show to be proportional to the accessibility variation and has a limited time duration. This model provides a simple theoretical framework that allows to go beyond econometric studies and sheds a new light on the impact of transportation modes on city growth.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Laplacian dynamics of convergent and divergent collective behaviors",
           "10.1088/2632-072x/acd6cb",
           2023,
           "\nCollective dynamics is ubiquitous in various physical, biological, and social systems, where simple local interactions between individual units lead to complex global patterns. A common feature of diverse collective behaviors is that the units exhibit either convergent or divergent evolution in their behaviors, i.e. becoming increasingly similar or distinct, respectively. The associated dynamics changes across time, leading to complex consequences on a global scale. In this study, we propose a generalized Laplacian dynamics model to describe both convergent and divergent collective behaviors, where the trends of convergence and divergence compete with each other and jointly determine the evolution of global patterns. We empirically observe non-trivial phase-transition-like phenomena between the convergent and divergent evolution phases, which are controlled by local interaction properties. We also propose a conjecture regarding the underlying phase transition mechanisms and outline the main theoretical difficulties for testing this conjecture. Overall, our framework may serve as a minimal model of collective behaviors and their intricate dynamics.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Collective behavior of coupled multiplicative processes with stochastic resetting",
           "10.1088/2632-072x/ac2070",
           2021,
           "\nA dynamical variable driven by the combination of a deterministic multiplicative process with stochastic reset events develops, at long times, a stationary power-law distribution. Here, we analyze how such distribution changes when several variables of the same kind interact with each other through diffusion-like coupling. While for weak coupling the variables are still distributed following power-law functions, their distributions are severely distorted as interactions become stronger, with sudden appearance of cutoffs and divergent singularities. We explore these effects both analytically and numerically, for coupled ensembles of identical and non-identical variables. The most relevant consequences of ensemble heterogeneity are assessed, and preliminary results for spatially distributed ensembles are presented.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Synthetic criticality in cellular brains",
           "10.1088/2632-072x/ac35b3",
           2021,
           "\nCognitive networks have evolved to cope with uncertain environments in order to make reliable decisions. Such decision making circuits need to respond to the external world in efficient and flexible ways, and one potentially general mechanism of achieving this is grounded in critical states. Mounting evidence has shown that brains operate close to such critical boundaries consistent with self-organized criticality (SOC). Is this also taking place in small-scale living systems, such as cells? Here, we explore a recent model of engineered gene networks that have been shown to exploit the feedback between order and control parameters (as defined by expression levels of two coupled genes) to achieve an SOC state. We suggest that such SOC motif could be exploited to generate adaptive behavioral patterns and might help design fast responses in synthetic cellular and multicellular organisms.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Opinion formation on social networks with algorithmic bias: dynamics and bias imbalance",
           "10.1088/2632-072x/ac340f",
           2021,
           "\nWe investigate opinion dynamics and information spreading on networks under the influence of content filtering technologies. The filtering mechanism, present in many online social platforms, reduces individuals’ exposure to disagreeing opinions, producing algorithmic bias. We derive evolution equations for global opinion variables in the presence of algorithmic bias, network community structure, noise (independent behavior of individuals), and pairwise or group interactions. We consider the case where the social platform shows a predilection for one opinion over its opposite, unbalancing the dynamics in favor of that opinion. We show that if the imbalance is strong enough, it may determine the final global opinion and the dynamical behavior of the population. We find a complex phase diagram including phases of coexistence, consensus, and polarization of opinions as possible final states of the model, with phase transitions of different order between them. The fixed point structure of the equations determines the dynamics to a large extent. We focus on the time needed for convergence and conclude that this quantity varies within a wide range, showing occasionally signatures of critical slowing down and meta-stability.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "Human mobility in interest space and interactive random walk",
           "10.1088/2632-072x/ab7f4f",
           2020,
           "\nCompared with the well-studied topic of human mobility in real geographic space, only a few studies focus on human mobility in virtual space, such as interests, knowledge, ideas, and so on. However, it relates to the issues like public opinion management, knowledge diffusion, and innovation. In this paper, we assume that the interests of a group of online users can span an Euclidean space which is called interest space, and the transfers of user interests can be modelled as Lévy Flight in the interest space. Considering the interaction between users, we assume that the random walkers are not independent but interacting with each other indirectly via the digital resources in the interest space. The proposed model in this paper successfully reproduced a set of scaling laws for describing the growth of attention flow networks of online communities, and obtaining similar ranges of users’ scaling exponents with empirical data. Further, we inferred parameters for describing the individual behaviours of the users according to the scaling laws of empirical attention flow network. Our model can not only provide theoretical understanding of human online behaviours but also has broad potential applications such as dissemination and public opinion management, online recommendation, etc.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Deep learning super-diffusion in multiplex networks",
           "10.1088/2632-072x/abe6e9",
           2021,
           "\nComplex network theory has shown success in understanding the emergent and collective behavior of complex systems Newman 2010 Networks: An Introduction (Oxford: Oxford University Press). Many real-world complex systems were recently discovered to be more accurately modeled as multiplex networks Bianconi 2018 Multilayer Networks: Structure and Function (Oxford: Oxford University Press); Boccaletti et al 2014 Phys. Rep.\n544 1–122; Lee et al 2015 Eur. Phys. J. B\n88 48; Kivelä et al 2014 J. Complex Netw.\n2 203–71; De Domenico et al 2013 Phys. Rev. X\n3 041022—in which each interaction type is mapped to its own network layer; e.g. multi-layer transportation networks, coupled social networks, metabolic and regulatory networks, etc. A salient physical phenomena emerging from multiplexity is super-diffusion: exhibited by an accelerated diffusion admitted by the multi-layer structure as compared to any single layer. Theoretically super-diffusion was only known to be predicted using the spectral gap of the full Laplacian of a multiplex network and its interacting layers. Here we turn to machine learning (ML) which has developed techniques to recognize, classify, and characterize complex sets of data. We show that modern ML architectures, such as fully connected and convolutional neural networks (CNN), can classify and predict the presence of super-diffusion in multiplex networks with 94.12% accuracy. Such predictions can be done in situ, without the need to determine spectral properties of a network.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Formation of trade networks by economies of scale and product differentiation",
           "10.1088/2632-072x/acc91f",
           2023,
           "\nUnderstanding the structure and formation of networks is a central topic in complexity science. Economic networks are formed by decisions of individual agents and thus not properly described by established random graph models. In this article, we establish a model for the emergence of trade networks that is based on rational decisions of individual agents. The model incorporates key drivers for the emergence of trade, comparative advantage and economic scale effects, but also the heterogeneity of agents and the transportation or transaction costs. Numerical simulations show three macroscopically different regimes of the emerging trade networks. Depending on the specific transportation costs and the heterogeneity of individual preferences, we find centralized production with a star-like trade network, distributed production with all-to-all trading or local production and no trade. Using methods from statistical mechanics, we provide an analytic theory of the transitions between these regimes and estimates for critical parameters values.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Probabilistic fair behaviors spark its boost in the Ultimatum game: the strength of good Samaritans",
           "10.1088/2632-072x/ac86b3",
           2022,
           "\nBehavioral experiments on the Ultimatum game have shown that we human beings have a remarkable preference in fair play, contradicting the predictions by the game theory. Most of the existing models seeking for explanations, however, strictly follow the assumption of Homo economicus in orthodox economics that people are self-interested and fully rational to maximize their earnings. Here we relax this assumption by allowing that people probabilistically choose to be ‘good Samaritans’, acting as fair players from time to time. For well-mixed and homogeneously structured populations, we numerically show that as this probability increases the level of fairness undergoes from the low scenario abruptly to the full fairness state, where occasional fair behaviors \n\n\n\n(\n\n∼\n5\n%\n\n)\n\n\n\n are sufficient to drive the whole population to behave in the half–half split manner. We also develop a mean-field theory, which correctly reproduces the first-order phase transition and points out the reason. Heterogeneously structured populations, however, display continuous fairness transition; surprisingly, very few hub nodes acting as fair players are able to entrain the whole population to the full fairness state. Our results thus reveal the unexpected strength of ‘good Samaritans’, which may constitute a new explanation for the emergence of fairness in our society.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "Neglecting complex network structures underestimates delays in a large-capital project",
           "10.1088/2632-072x/accef0",
           2023,
           "\nCompleting large-scale projects on time is a daunting challenge, partly due to the intricate network of dependencies between a project’s activities. To support this challenge, existing theory focuses on predicting whether a delay in completing a single activity is likely to spread and impact downstream activities. Using fine-grained information from 68 546 activities and 84 934 pairs, associated with the delivery of a $1.86Bn infrastructure project, we show that the core mechanism that underpins existing theory underestimates delay propagation. To elucidate the mechanisms that drive delay, we generated null models that destroyed the structural and temporal correlations of the original project activity network. By doing so, we argue that this underestimation is the result of neglecting endogenous structural features within the project’s activity network. Formulating a new mechanism that utilizes both temporal and structural features may help improve our capacity to predict how delays spread within projects.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Transitions in random graphs of fixed degrees with many short cycles",
           "10.1088/2632-072x/abf316",
           2021,
           "We analyze maximum entropy random graph ensembles with constrained degrees, drawn from arbitrary degree distributions, and a tuneable number of three-cycles (triangles). We find that such ensembles generally exhibit two transitions, a clustering and a shattering transition, separating three distinct regimes. At the clustering transition, the graphs change from typically having only isolated cycles to forming cycle clusters. At the shattering transition the graphs break up into many small cliques to achieve the desired three-cycle density. The locations of both transitions depend nontrivially on the system size. We derive a general formula for the three-cycle density in the regime of isolated cycles, for graphs with degree distributions that have finite first and second moments. For bounded degree distributions we present further analytical results on cycle densities and phase transition locations, which, while non-rigorous, are all validated via MCMC sampling simulations. We show that the shattering transition is of an entropic nature, occurring for all three-cycle density values, provided the system is large enough.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "Crossover phenomenon in adversarial attacks on voter model",
           "10.1088/2632-072x/acf90b",
           2023,
           "\nA recent study (Chiyomaru and Takemoto 2022 Phys. Rev. E 106 014301) considered adversarial attacks conducted to distort voter model dynamics in networks. This method intervenes in the interaction patterns of individuals and induces them to be in a target opinion state through a small perturbation ε. In this study, we investigate adversarial attacks on voter dynamics in random networks of finite size n. The exit probability P\n+1 to reach the target absorbing state and the mean time τ\n\nn\n to reach consensus are analyzed in the mean-field approximation. Given ε > 0, the exit probability P\n+1 converges asymptotically to unity as n increases. The mean time τ\n\nn\n to reach consensus scales as \n\n\n\n(\nln\nϵ\nn\n)\n/\nϵ\n\n\n\n for homogeneous networks with a large finite n. By contrast, it scales as \n\n\n(\nln\n(\nϵ\n\nμ\n1\n2\n\nn\n\n/\n\n\nμ\n2\n\n)\n)\n\n/\n\nϵ\n\n\n for heterogeneous networks with a large finite n, where µ\n1 and µ\n2 represent the first and second moments of the degree distribution, respectively. Moreover, we observe the crossover phenomenon of τ\n\nn\n from a linear scale to a logarithmic scale and find \n\n\n\nn\n\n\nc\no\n\n\n\n∼\n\nϵ\n\n−\n1\n\n/\n\nα\n\n\n\n\n above which the state of all nodes becomes the target state in logarithmic time. Here, α = 1 for homogeneous networks and \n\n\nα\n=\n(\nγ\n−\n1\n)\n\n/\n\n2\n\n\n for scale-free networks with a degree exponent \n\n\n2\n<\nγ\n<\n3\n\n\n.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Sparse block-structured random matrices: universality",
           "10.1088/2632-072x/acc71a",
           2023,
           "\nWe study ensembles of sparse block-structured random matrices generated from the adjacency matrix of a Erdös–Renyi random graph with N vertices of average degree Z, inserting a real symmetric d × d random block at each non-vanishing entry. We consider several ensembles of random block matrices with rank r < d and with maximal rank, r = d. The spectral moments of the sparse block-structured random matrix are evaluated for \n\n\nN\n→\n∞\n\n\n, d finite or infinite, and several probability distributions for the blocks (e.g. fixed trace, bounded trace and Gaussian). Because of the concentration of the probability measure in the \n\n\nd\n→\n∞\n\n\n limit, the spectral moments are independent of the probability measure of the blocks (with mild assumptions of isotropy, smoothness and sub-Gaussian tails). The effective medium approximation is the limiting spectral density of the sparse block-structured random ensembles with finite rank. Analogous classes of universality hold for the Laplacian sparse block-structured ensemble. The same limiting distributions are obtained using random regular graphs instead of Erdös–Renyi graphs.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Similarity matrix average for aggregating multiplex networks",
           "10.1088/2632-072x/acda09",
           2023,
           "\nWe introduce a methodology based on averaging similarity matrices with the aim of integrating the layers of a multiplex network into a single monoplex network. Multiplex networks are adopted for modelling a wide variety of real-world frameworks, such as multi-type relations in social, economic and biological structures. More specifically, multiplex networks are used when relations of different nature (layers) arise between a set of elements from a given population (nodes). A possible approach for analyzing multiplex similarity networks consists in aggregating the different layers in a single network (monoplex) which is a valid representation—in some sense—of all the layers. In order to obtain such an aggregated network, we propose a theoretical approach—along with its practical implementation—which stems on the concept of similarity matrix average. This methodology is finally applied to a multiplex similarity network of statistical journals, where the three considered layers express the similarity of the journals based on co-citations, common authors and common editors, respectively.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Evolution of cooperation driven by sampling reward",
           "10.1088/2632-072x/ad0208",
           2023,
           "\nA social dilemma implies that individuals will choose the defection strategy to maximize their individual gains. Reward is a powerful motivator to promote the evolution of cooperation, thus addressing the social dilemma. Nevertheless, it is costly since we need to monitor all participants in the game. Inspired by these observations, we here propose an inexpensive protocol, a so-called sampling reward mechanism, and apply it to social dilemmas, including public goods game and collective-risk social dilemma. More precisely, the actual usage of reward depends on the portion of cooperators in the sample. We show that the average cooperation level can be effectively improved under high reward threshold and high reward intensity, albeit at the expense of reward cost. It is intriguing to discover that for the latter aspect, there is a critical threshold at which further increases in reward intensity have no significant effect on improving the cooperation level. Moreover, we find that the small sample size favors the evolution of cooperation while an intermediate sample size always results in a lower reward cost. We also demonstrate that our findings are robust and remain valid for both types of social dilemmas.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Growing inequality in systems showing Zipf’s law",
           "10.1088/2632-072x/acc0c1",
           2023,
           "\nA central problem in economics and statistics is the assessment of income or wealth inequality starting from empirical data. Here we focus on the behavior of Gini index, one of the most used inequality measures, in presence of Zipf’s law, a situation which occurs in many complex financial and economical systems. First, we show that the application of asymptotic formulas to finite size systems always leads to an overestimation of inequality. We thus compute finite size corrections and we show that depending on Zipf’s exponent two distinct regimes can be observed: low inequality, where Gini index is less than one and maximal inequality, where Gini index asymptotically tends to its maximal value one. In both cases, the inequality of an expanding system slowly increases just as effect of growth, with a scaling never faster than the inverse of the size. We test our computations on two real systems, US cities and the cryptocurrency market, observing in both cases an increase of inequality that is completely explained by Zipf’s law and the systems expanding. This shows that in growing complex systems finite size effects must be considered in order to properly assess if inequality is increasing due to natural growth processes or if it is produced by a change in the economical structure of the systems. Finally we discuss how such effects must be carefully considered when analyzing survey data.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "Multitasking in RNN: an analysis exploring the combination of simple tasks",
           "10.1088/2632-072x/abdee3",
           2021,
           "\nThe brain and artificial neural networks are capable of performing multiple tasks. The mechanisms through which simultaneous tasks are performed by the same set of units in the brain are not yet entirely clear. Such systems can be modular or mixed selective through some variables such as sensory stimulus. Recurrent neural networks can help to a better understanding of those mechanisms. Based on simple tasks studied previously in Jarne 2020 arXiv Preprint 2005.13074, multitasking networks were trained and analyzed. In present work, a simple model that can perform multiple tasks using a contextual signal was studied, trying to illuminate mechanisms similar to those that could occur in biological brains. Backpropagation through time allows training networks with multitasking, but the realizations obtained are not unique. Different realizations for the same set of tasks are possible. Here the analysis of the dynamics and emergent behavior of their units is presented. The goal is to try to describe better the models used to describe different processes in the cortex.",
           5,
           "journal_of_physics_complexity"
          ],
          [
           "Reconstructing supply networks",
           "10.1088/2632-072x/ad30bf",
           2024,
           "\nNetwork reconstruction is a well-developed sub-field of network science, but it has only recently been applied to production networks, where nodes are firms and edges represent customer-supplier relationships. We review the literature that has flourished to infer the topology of these networks by partial, aggregate, or indirect observation of the data. We discuss why this is an important endeavour, what needs to be reconstructed, what makes it different from other network reconstruction problems, and how different researchers have approached the problem. We conclude with a research agenda.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Complex systems for the most vulnerable",
           "10.1088/2632-072x/ac60b1",
           2022,
           "\nIn a rapidly changing world, facing an increasing number of socioeconomic, health and environmental crises, complexity science can help us to assess and quantify vulnerabilities, and to monitor and achieve the UN sustainable development goals. In this perspective, we provide three exemplary use cases where complexity science has shown its potential: poverty and socioeconomic inequalities, collective action for representative democracy, and computational epidemic modeling. We then review the challenges and limitations related to data, methods, capacity building, and, as a result, research operationalization. We finally conclude with some suggestions for future directions, urging the complex systems community to engage in applied and methodological research addressing the needs of the most vulnerable.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Reconstructing irreducible links in temporal networks: which tool to choose depends on the network size",
           "10.1088/2632-072x/ab6727",
           2020,
           "\nFiltering information in complex networks entails the process of removing interactions explained by a proper null hypothesis and retaining the remaining interactions, which form the backbone network. The reconstructed backbone network depends upon the accuracy and reliability of the available tools, which, in turn, are affected by the specific features of the available dataset. Here, we examine the performance of three approaches for the discovery of backbone networks, in the presence of heterogeneous, time-varying node properties. In addition to the recently proposed evolving activity driven model, we extend two existing approaches (the disparity filter and the temporal fitness model) to tackle time-varying phenomena. Our analysis focuses on the influence of the network size, which was previously shown to be a determining factor for the performance of the evolving activity driven model. Through mathematical and numerical analysis, we propose general guidelines for the use of these three approaches based on the available dataset. For small networks, the evolving temporal fitness model offers a more reasonable trade-off between the number of links assigned to the backbone network and the accuracy of their inference. The main limitation of this methodology lies in its computational cost, which becomes excessively high for large networks. In this case, the evolving activity driven model could be a valid substitute to the evolving temporal fitness model. If one seeks to minimize the number of links inaccurately included in the backbone network at the risk of dismissing many links that could belong to it, then the temporal disparity filter would be the approach-of-choice. Overall, our contribution expands the toolbox of network discovery in the technical literature and should help users in choosing the right network discovery instrument, depending on the problem considered.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "Rewiring driven evolution of quenched frustrated signed network",
           "10.1088/2632-072x/ad1a1a",
           2024,
           "\nA framework for studying the behavior of a classically frustrated signed network in the process of random rewiring is developed. We describe jump probabilities for change in frustration and formulate a theoretical estimate in terms of the master equation. Stationary thermodynamic distribution and moments are derived from the master equation and compared to numerical simulations. Furthermore, an exact solution of the probability distribution is provided through suitable mapping of rewiring dynamic to birth and death processes with quadratic asymptotically symmetric transition rates.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Filtering higher-order datasets",
           "10.1088/2632-072x/ad253a",
           2024,
           "\nMany complex systems often contain interactions between more than two nodes, known as higher-order interactions, which can change the structure of these systems in significant ways. Researchers often assume that all interactions paint a consistent picture of a higher-order dataset’s structure. In contrast, the connection patterns of individuals or entities in empirical systems are often stratified by interaction size. Ignoring this fact can aggregate connection patterns that exist only at certain scales of interaction. To isolate these scale-dependent patterns, we present an approach for analyzing higher-order datasets by filtering interactions by their size. We apply this framework to several empirical datasets from three domains to demonstrate that data practitioners can gain valuable information from this approach.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "The complexity of climate change mitigation: an experiment with large groups",
           "10.1088/2632-072x/ad2372",
           2024,
           "\nWe have studied the problem of climate change mitigation in large groups by means of a series of experiments with 1785 people. Our participants included both young university students and people of relevance in different organizations, in particular, those attending the presentation of the annual report on innovation by Fundación COTEC (Spain). In the experiment, the participants, distributed in groups of more than 100 people, faced a dilemma: to avoid a global catastrophe that destroys any possibility of making profits, a certain collective sacrifice has to be made by contributing to reach a global threshold. When the threshold was low, the students reached the amount of overall contribution necessary to avoid it. But in the case of a high threshold, none of the populations reached the threshold. In fact, they were far from it. In this sense, the collective behavior of the students and of people of relevance was fundamentally the same. The majority of participants in the high-risk case fell into four categories: those who did not contribute (around 10%), those who contribute half of their means (15%) but less than the fair share required to reach the threshold, those who contributed the fair share (10%), and those who contributed everything they had, so that their personal benefit was zero. In the case of students this last percentage was 10%, but in the other sample it reached almost 30%. We also found that individuals could be classified as being optimistic or pessimistic, and in general they behaved accordingly with regard to their contributions. Our results highlight the complexity of mitigating climate change in large groups and specially the difficulty in communicating the issue to foster action in a general population.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Coexistence of coordination and anticoordination in nonlinear public goods game",
           "10.1088/2632-072x/ac9bc0",
           2022,
           "\nThere is a plethora of instances of interactions between players, in both biological and socio-economical context, that can be modeled as the paradigmatic PGG. However, in such interactions, arguably the PGG is often nonlinear in nature. This is because the increment in benefit generated, owing to additional cost contributed by the players, is realistically seldom linear. Furthermore, sometimes a social good is created due to interspecific interactions, e.g. in cooperative hunting by animals of two different species. In this paper, we study the evolutionary dynamics of a heterogenous population of cooperators and defectors playing nonlinear PGG; here we define heterogenous population as the one composed of distinct subpopulations with interactions among them. We employ the replicator equations for this investigation, and present the non-trivial effects of nonlinearity and size of the groups involved in the game. We report the possibility of discoordination, and coexistence of coordination and anti-coordination in such nonlinear PGG.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Emergence of transient chaos and intermittency in machine learning",
           "10.1088/2632-072x/ac0b00",
           2021,
           "\nAn emerging paradigm for predicting the state evolution of chaotic systems is machine learning with reservoir computing, the core of which is a dynamical network of artificial neurons. Through training with measured time series, a reservoir machine can be harnessed to replicate the evolution of the target chaotic system for some amount of time, typically about half dozen Lyapunov times. Recently, we developed a reservoir computing framework with an additional parameter channel for predicting system collapse and chaotic transients associated with crisis. It was found that the crisis point after which transient chaos emerges can be accurately predicted. The idea of adding a parameter channel to reservoir computing has also been used by others to predict bifurcation points and distinct asymptotic behaviors. In this paper, we address three issues associated with machine-generated transient chaos. First, we report the results from a detailed study of the statistical behaviors of transient chaos generated by our parameter-aware reservoir computing machine. When multiple time series from a small number of distinct values of the bifurcation parameter, all in the regime of attracting chaos, are deployed to train the reservoir machine, it can generate the correct dynamical behavior in the regime of transient chaos of the target system in the sense that the basic statistical features of the machine generated transient chaos agree with those of the real system. Second, we demonstrate that our machine learning framework can reproduce intermittency of the target system. Third, we consider a system for which the known methods of sparse optimization fail to predict crisis and demonstrate that our reservoir computing scheme can solve this problem. These findings have potential applications in anticipating system collapse as induced by, e.g., a parameter drift that places the system in a transient regime.",
           14,
           "journal_of_physics_complexity"
          ],
          [
           "Epidemic modelling requires knowledge of the social network",
           "10.1088/2632-072x/ad19e0",
           2024,
           "\n‘Compartmental models’ of epidemics are widely used to forecast the effects of communicable diseases such as COVID-19 and to guide policy. Although it has long been known that such processes take place on social networks, the assumption of ‘random mixing’ is usually made, which ignores network structure. However, ‘super-spreading events’ have been found to be power-law distributed, suggesting that the underlying networks may be scale free or at least highly heterogeneous. The random-mixing assumption would then produce an overestimation of the herd-immunity threshold for given R\n0; and a (more significant) overestimation of R\n0 itself. These two errors compound each other, and can lead to forecasts greatly overestimating the number of infections. Moreover, if networks are heterogeneous and change in time, multiple waves of infection can occur, which are not predicted by random mixing. A simple SIR model simulated on both Erdős–Rényi and scale-free networks shows that details of the network structure can be more important than the intrinsic transmissibility of a disease. It is therefore crucial to incorporate network information into standard models of epidemics.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Pathways to discontinuous transitions in interacting contagion dynamics",
           "10.1088/2632-072x/ad269b",
           2024,
           "\nYet often neglected, dynamical interdependencies between concomitant contagion processes can alter their intrinsic equilibria and bifurcations. A particular case of interest for disease control is the emergence of discontinuous transitions in epidemic dynamics coming from their interactions with other simultaneous processes. To address this problem, here we propose a framework coupling a standard epidemic dynamics with another contagion process, presenting a tunable parameter shaping the nature of its transitions. Our model retrieves well-known results in the literature, such as the existence of first-order transitions arising from the mutual cooperation of epidemics or the onset of abrupt transitions when social contagions unidirectionally drive epidemics. We also reveal that negative feedback loops between simultaneous dynamical processes might suppress abrupt phenomena, thus increasing systems robustness against external perturbations. Our results render a general perspective toward finding different pathways to abrupt phenomena from the interaction of contagion processes.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Nonuniformly twisted states and traveling chimeras in a system of nonlocally coupled identical phase oscillators",
           "10.1088/2632-072x/ad2ec2",
           2024,
           "\nWe explore the model of a population of nonlocally coupled identical phase oscillators on a ring (Abrams and Strogatz 2004 Phys. Rev. Lett.\n93 174102) and describe traveling patterns. In the continuous in space formulation, we find families of traveling wave solutions for left-right symmetric and asymmetric couplings. Only the simplest of these waves are stable, which is confirmed by numerical simulations for a finite population. We demonstrate that for asymmetric coupling, a weakly turbulent traveling chimera regime is established, both from an initial standing chimera or an unstable traveling wave profile. The weakly turbulent chimera is a macroscopically chaotic state, with a well-defined synchronous domain and partial coherence in the disordered domain. We characterize it through the correlation function and the Lyapunov spectrum.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Collective effects and synchronization of demand in real-time demand response",
           "10.1088/2632-072x/ac6477",
           2022,
           "\nFuture energy systems will be dominated by variable renewable power generation and interconnected sectors, leading to rapidly growing complexity. Flexible elements are required to balance the variability of renewable power sources, including backup generators and storage devices, but also flexible consumers. Demand response (DR) aims to adapt the demand to the variable generation, in particular by shifting the load in time. In this article, we provide a detailed statistic analysis of the collective operation of many DR units. We establish and simulate a model for load shifting in response to real-time electricity pricing using local storage systems. We show that DR drives load shifting as desired but also induces strong collective effects that may threaten system stability. The load of individual households synchronizes, leading to extreme demand peaks. We provide a detailed statistical analysis of the grid load and quantify both the likelihood and extent of extreme demand peaks.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "Phase separation and scaling in correlation structures of financial markets",
           "10.1088/2632-072x/abbed1",
           2020,
           "\nFinancial markets, being spectacular examples of complex systems, display rich correlation structures among price returns of different assets. The correlation structures change drastically, akin to critical phenomena in physics, as do the influential stocks (leaders) and sectors (communities), during market events like crashes. It is crucial to detect their signatures for timely intervention or prevention. Here we use eigenvalue decomposition and eigen-entropy, computed from eigenvector centralities of different stocks in the cross-correlation matrix, to extract information about the disorder in the market. We construct a ‘phase space’, where different market events (bubbles, crashes, etc) undergo phase separation and display order–disorder movements. An entropy functional exhibits scaling behavior. We propose a generic indicator that facilitates the continuous monitoring of the internal structure of the market—important for managing risk and stress-testing the financial system. Our methodology would help in understanding and foreseeing tipping points or fluctuation patterns in complex systems.",
           8,
           "journal_of_physics_complexity"
          ],
          [
           "The role of intervention mechanisms on a self-organized system: dynamics of a sandpile with site reinforcement",
           "10.1088/2632-072x/ad28ff",
           2024,
           "\nWe revisit the sandpile model and examine the effect of introducing site-dependent thresholds that increase over time based on the generated avalanche size. This is inspired by the simplest means of introducing stability into a self-organized system: the locations of collapse are repaired and reinforced. Statistically, for the case of finite driving times, we observe that the site-dependent reinforcements decrease the occurrence of very large avalanches, leading to an effective global stabilization. Interestingly, however, long simulation runs indicate that the system will persist in a state of self-organized criticality (SOC), recovering the power-law distributions with a different exponent as the original sandpile. These results suggest that tipping the heavy-tailed power-laws into more equitable and normal statistics may require unrealistic scales of intervention for real-world systems, and that, in the long run, SOC mechanisms still emerge. This may help explain the robustness of power-law statistics for many complex systems.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Local sign stability and its implications for spectra of sparse random graphs and stability of ecosystems",
           "10.1088/2632-072x/ad2698",
           2024,
           "\nWe study the spectral properties of sparse random graphs with different topologies and type of interactions, and their implications on the stability of complex systems, with particular attention to ecosystems. Specifically, we focus on the behaviour of the leading eigenvalue in different type of random matrices (including interaction matrices and Jacobian-like matrices), relevant for the assessment of different types of dynamical stability. By comparing numerical results on Erdős–Rényi and Husimi graphs with sign-antisymmetric interactions or mixed sign patterns, we propose a sufficient criterion, called strong local sign stability, for stability not to be affected by system size, as traditionally implied by the complexity-stability trade-off in conventional models of random matrices. The criterion requires sign-antisymmetric or unidirectional interactions and a local structure of the graph such that the number of cycles of finite length do not increase with the system size. Note that the last requirement is stronger than the classical local tree-like condition, which we associate to the less stringent definition of local sign stability, also defined in the paper. In addition, for strong local sign stable graphs which show stability to linear perturbations irrespectively of system size, we observe that the leading eigenvalue can undergo a transition from being real to acquiring a nonnull imaginary part, which implies a dynamical transition from nonoscillatory to oscillatory linear response to perturbations. Lastly, we ascertain the discontinuous nature of this transition.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Detection of limit cycle signatures of El Niño in models and observations using reservoir computing",
           "10.1088/2632-072x/ad2699",
           2024,
           "\nWhile the physics of the El Niño–Southern Oscillation (ENSO) phenomenon in the Tropical Pacific is quite well understood, there is still debate on several more fundamental aspects. The focus of this paper is on one of these issues that deals with whether ENSO variability, within the recharge-discharge oscillator theory arising from a stochastic Hopf bifurcation, is subcritical or supercritical. Using a Reservoir Computing method, we develop a criticality index as an indicator for the presence of a limit cycle in noisy time series. The utility of this index is shown in three members of a hierarchy of ENSO models: a conceptual box model, the classical Zebiak-Cane model and a state-of-the-art Global Climate Model. Finally, the criticality index is determined from observations, leading to the result that ENSO variability appears to be subcritical.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Exact time-dependent dynamics of discrete binary choice models",
           "10.1088/2632-072x/ac8c78",
           2022,
           "\nWe provide a generic method to find full dynamical solutions to binary decision models with interactions. In these models, agents follow a stochastic evolution where they must choose between two possible choices by taking into account the choices of their peers. We illustrate our method by solving Kirman and Föllmer’s ant recruitment model for any number N of discrete agents and for any choice of parameters, recovering past results found in the limit N → ∞. We then solve extensions of the ant recruitment model for increasing asymmetry between the two choices. Finally, we provide an analytical time-dependent solution to the standard voter model and a semi-analytical solution to the vacillating voter model. Our results show that exact analytical time-dependent solutions can be achieved for discrete choice models without invoking that the number of agents N are continuous or that both choices are symmetric, and additionally show how to practically use the analytics for fast evaluation of the resulting probability distributions.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "What is critical about criticality: in praise of the correlation function",
           "10.1088/2632-072x/ac24f2",
           2021,
           "\nWe present a brief review of power laws and correlation functions as measures of criticality and the relation between them. By comparing phenomenology from rain, brain and the forest fire model we discuss the relevant features of self-organisation to the vicinity about a critical state. We conclude that organisation to a region of extended correlations and approximate power laws may be behaviour of interest shared between the three considered systems.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "Higher-order models capture changes in controllability of temporal networks",
           "10.1088/2632-072x/abcc05",
           2020,
           "\nIn many complex systems, elements interact via time-varying network topologies. Recent research shows that temporal correlations in the chronological ordering of interactions crucially influence network properties and dynamical processes. How these correlations affect our ability to control systems with time-varying interactions remains unclear. In this work, we use higher-order network models to extend the framework of structural controllability to temporal networks, where the chronological ordering of interactions gives rise to time-respecting paths with non-Markovian characteristics. We study six empirical data sets and show that non-Markovian characteristics of real systems can both increase or decrease the minimum time needed to control the whole system. With both empirical data and synthetic models, we further show that spectral properties of generalisations of graph Laplacians to higher-order networks can be used to analytically capture the effect of temporal correlations on controllability. Our work highlights that (i) correlations in the chronological ordering of interactions are an important source of complexity that significantly influences the controllability of temporal networks, and (ii) higher-order network models are a powerful tool to understand the temporal-topological characteristics of empirical systems.",
           8,
           "journal_of_physics_complexity"
          ],
          [
           "Bio-inspired computing by nonlinear network dynamics—a brief introduction",
           "10.1088/2632-072x/ac3ad4",
           2021,
           "\nThe field of bio-inspired computing has established a new Frontier for conceptualizing information processing, aggregating knowledge from disciplines as different as neuroscience, physics, computer science and dynamical systems theory. The study of the animal brain has shown that no single neuron or neural circuit motif is responsible for intelligence or other higher-order capabilities. Instead, complex functions are created through a broad variety of circuits, each exhibiting an equally varied repertoire of emergent dynamics. How collective dynamics may contribute to computations still is not fully understood to date, even on the most elementary level. Here we provide a concise introduction to bio-inspired computing via nonlinear dynamical systems. We first provide a coarse overview of how the study of biological systems has catalyzed the development of artificial systems in several broad directions. Second, we discuss how understanding the collective dynamics of spiking neural circuits and model classes thereof, may contribute to and inspire new forms of ‘bio-inspired’ computational paradigms. Finally, as a specific set of examples, we analyze in more detail bio-inspired approaches to computing discrete decisions based on multi-dimensional analogue input signals, via k-winners-take-all functions. This article may thus serve as a brief introduction to the qualitative variety and richness of dynamical bio-inspired computing models, starting broadly and focusing on a general example of computation from current research. We believe that understanding basic aspects of the variety of bio-inspired approaches to computation on the coarse level of first principles (instead of details about specific simulation models) and how they relate to each other, may provide an important step toward catalyzing novel approaches to autonomous and computing machines in general.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Effects of uniform-allocation constraints in networked common-pool resource extraction games",
           "10.1088/2632-072x/ac42e0",
           2021,
           "\nCommunities that share common-pool resources (CPRs) often coordinate their actions to sustain resource quality more effectively than if they were regulated by some centralized authority. Networked models of CPR extraction suggest that the flexibility of individual agents to selectively allocate extraction effort among multiple resources plays an important role in maximizing their payoffs. However, empirical evidence suggests that real-world CPR appropriators may often de-emphasize issues of allocation, for example by responding to the degradation of a single resource by reducing extraction from multiple resources, rather than by reallocating extraction effort away from the degraded resource. Here, we study the population-level consequences that emerge when individuals are constrained to apply an equal amount of extraction effort to all CPRs that are available to them within an affiliation network linking agents to resources. In systems where all resources have the same capacity, this uniform-allocation constraint leads to reduced collective wealth compared to unconstrained best-response extraction, but it can produce more egalitarian wealth distributions. The differences are more pronounced in networks that have higher degree heterogeneity among resources. In the case that the capacity of each CPR is proportional to its number of appropriators, the uniform-allocation constraint can lead to more efficient collective extraction since it serves to distribute the burden of over-extraction more evenly among the network’s CPRs. Our results reinforce the importance of adaptive allocation in self-regulation for populations who share linearly degrading CPRs; although uniform-allocation extraction habits can help to sustain higher resource quality than does unconstrained extraction, in general this does not improve collective benefits for a population in the long term.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Information retrieval and structural complexity of legal trees",
           "10.1088/2632-072x/ac8e48",
           2022,
           "\nWe introduce a model for the retrieval of information hidden in legal texts. These are typically organised in a hierarchical (tree) structure, which a reader interested in a given provision needs to explore down to the ‘deepest’ level (articles, clauses, …). We assess the structural complexity of legal trees by computing the mean first-passage time a random reader takes to retrieve information planted in the leaves. The reader is assumed to skim through the content of a legal text based on their interests/keywords, and be drawn towards the sought information based on keywords affinity, i.e. how well the Chapters/Section headers of the hierarchy seem to match the informational content of the leaves. Using randomly generated keyword patterns, we investigate the effect of two main features of the text—the horizontal and vertical coherence—on the searching time, and consider ways to validate our results using real legal texts. We obtain numerical and analytical results, the latter based on a mean-field approximation on the level of patterns, which lead to an explicit expression for the complexity of legal trees as a function of the structural parameters of the model.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "Stochastic-like characteristics of arithmetic dynamical systems: the Collatz hailstone sequences",
           "10.1088/2632-072x/ad271f",
           2024,
           "\nThe numerical hailstone sequences, or orbits, generated by the Collatz map have been disclosed to present relevant features commonly associated with complex systems. It is so despite the extreme simplicity of the arithmetic dynamical system iteration rule. Indeed, for a positive integer n, the Collatz map f reads \n\n\nf\n(\nn\n)\n=\nn\n\n/\n\n2\n\n\n (\n\n\nf\n(\nn\n)\n=\n3\nn\n+\n1\n\n\n) for n even (odd). Seeking to elucidate this surprising fact, here we unveil distinct characteristics of stochastic-like behavior for collections of Collatz orbits by considering methods commonly employed to temporal series, as cryptography tests, power-spectrum, detrended fluctuation, auto-correlation and entropy measure. Besides confirming previous predictions that the Collatz orbits display some global properties of geometric Brownian motion, our results are likewise able to explain, at least heuristically, the reasons for so. In special, we show by means of comprehensive analysis that our findings cannot be ascribed to standard chaotic evolution. Moreover, we identify novel short- and mid-range correlations in the Collatz orbits. The Collatz map is hence a paradigmatic example of an arithmetic dynamical system which could also be regarded as displaying key characteristics of an arithmetic statistical physics system, explaining its dynamical richness.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Mobility restrictions in response to local epidemic outbreaks in rock-paper-scissors models",
           "10.1088/2632-072x/ad2d5b",
           2024,
           "\nWe study a three-species cyclic model whose organisms are vulnerable to contamination with an infectious disease which propagates person-to-person. We consider that individuals of one species perform a self-preservation strategy by reducing the mobility rate to minimise infection risk whenever an epidemic outbreak reaches the neighbourhood. Running stochastic simulations, we quantify the changes in spatial patterns induced by unevenness in the cyclic game introduced by the mobility restriction strategy of organisms of one out of the species. Our findings show that variations in disease virulence impact the benefits of dispersal limitation reaction, with the relative reduction of the organisms’ infection risk accentuating in surges of less contagious or deadlier diseases. The effectiveness of the mobility restriction tactic depends on the deceleration level and the fraction of infected neighbours which is considered too dangerous, thus triggering the defensive strategy. If each organism promptly reacts to the arrival of the first viral vectors in its surroundings with strict mobility reduction, contamination risk decreases significantly. Our conclusions may help biologists understand the impact of defensive strategies in ecosystems during an epidemic.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Demographic noise in complex ecological communities",
           "10.1088/2632-072x/acd21b",
           2023,
           "\nWe introduce an individual-based model of a complex ecological community with random interactions. The model contains a large number of species, each with a finite population of individuals, subject to discrete reproduction and death events. The interaction coefficients determining the rates of these events is chosen from an ensemble of random matrices, and is kept fixed in time. The set-up is such that the model reduces to the known generalised Lotka–Volterra equations with random interaction coefficients in the limit of an infinite population for each species. Demographic noise in the individual-based model means that species which would survive in the Lotka–Volterra model can become extinct. These noise-driven extinctions are the focus of the paper. We find that, for increasing complexity of interactions, ecological communities generally become less prone to extinctions induced by demographic noise. An exception are systems composed entirely of predator-prey pairs. These systems are known to be stable in deterministic Lotka–Volterra models with random interactions, but, as we show, they are nevertheless particularly vulnerable to fluctuations.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Stasis in heterogeneous networks of coupled oscillators: discontinuous transition with hysteresis",
           "10.1088/2632-072x/ace1c4",
           2023,
           "\nWe consider a heterogeneous ensemble of dynamical systems in \n\n\n\n\nR\n\n4\n\n\n\n that individually are either attracted to fixed points (and are termed inactive) or to limit cycles (in which case they are termed active). These distinct states are separated by bifurcations that are controlled by a single parameter. Upon coupling them globally, we find a discontinuous transition to global inactivity (or stasis) when the proportion of inactive components in the ensemble exceeds a threshold: there is a first–order phase transition from a globally oscillatory state to global oscillation death. There is hysteresis associated with these phase transitions. Numerical results for a representative system are supported by analysis using a system-reduction technique and different dynamical regimes can be rationalised through the corresponding bifurcation diagrams of the reduced set of equations.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Validating a data-driven framework for vehicular traffic modeling",
           "10.1088/2632-072x/ad3ed6",
           2024,
           "\nThis study presents a data-driven framework for modeling complex systems, with a specific emphasis on traffic modeling. &#xD;Traditional methods in traffic modeling often rely on assumptions regarding vehicle interactions. &#xD;Our approach comprises two steps: first, utilizing information-theoretic (IT) tools to identify interaction directions and candidate variables thus eliminating assumptions, and second, employing the Sparse Identification of Nonlinear Systems (SINDy) tool to establish functional relationships. &#xD;We validate the framework's efficacy using synthetic data from two distinct traffic models, while considering measurement noise. &#xD;Results show that IT tools can reliably detect directions of interaction as well as instances of no interaction.&#xD;SINDy proves instrumental in creating precise functional relationships and determining coefficients in tested models. &#xD;The innovation of our framework lies in its ability to use data-driven approach to model traffic dynamics without relying on assumptions, thus offering applications in various complex systems beyond traffic.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Queues with resetting: a perspective",
           "10.1088/2632-072x/ad3e5a",
           2024,
           "\nPerformance modeling is a key issue in queuing theory and operation research. It is well-known that the length of a queue that awaits service or the time spent by a job in a queue depends not only on the  service rate, but also crucially on the fluctuations in service time. The larger the fluctuations, the longer the delay becomes and hence, this is a major hindrance for the queue to operate efficiently. Various strategies have been adapted to prevent this drawback. In this perspective, we investigate the effects of one such novel strategy namely resetting or restart, an emerging concept in statistical physics and stochastic complex process, that was recently introduced to mitigate fluctuations-induced delays in queues. In particular, we show that a service resetting mechanism accompanied with an overhead time can remarkably shorten the average queue lengths and waiting times. We examine various resetting strategies and further shed light on the intricate role of the overhead times to the queuing performance. Our analysis opens up future avenues in operation research where resetting-based strategies can be universally promising.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "The training response law explains how deep neural networks learn",
           "10.1088/2632-072x/ac68bf",
           2022,
           "\nDeep neural network is the widely applied technology in this decade. In spite of the fruitful applications, the mechanism behind that is still to be elucidated. We study the learning process with a very simple supervised learning encoding problem. As a result, we found a simple law, in the training response, which describes neural tangent kernel. The response consists of a power law like decay multiplied by a simple response kernel. We can construct a simple mean-field dynamical model with the law, which explains how the network learns. In the learning, the input space is split into sub-spaces along competition between the kernels. With the iterated splits and the aging, the network gets more complexity, but finally loses its plasticity.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Boosted fluctuation responses in power grids with active voltage dynamics",
           "10.1088/2632-072x/acdb26",
           2023,
           "\nSecure electric energy supply and thus stable operation of power grids fundamentally relies on their capability to cope with fluctuations. Here, we study how active voltage dynamics impacts the collective response dynamics of networked power grids. We find that the systems driven by ongoing fluctuating inputs exhibit a bulk, a resonance, and a localized grid frequency response regime, as for static voltages. However, active voltage dynamics generically weakens the degree of localization in the grid, thereby intensifying and spatially extending the high-frequency responses. An analytic approximation scheme that takes into account shortest signal propagation paths among the voltage, phase angle and frequency variables result in an asymptotic lowest-order expansion that helps understanding the boosted high-frequency responses. These results moreover offer a generic tool to systematically investigate fluctuation response patterns in power grid models with and without active voltage dynamics.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Planted hitting set recovery in hypergraphs",
           "10.1088/2632-072x/abdb7d",
           2021,
           "\nIn various application areas, networked data is collected by measuring interactions involving some specific set of core nodes. This results in a network dataset containing the core nodes along with a potentially much larger set of fringe nodes that all have at least one interaction with a core node. In many settings, this type of data arises for structures that are richer than graphs, because they involve the interactions of larger sets; for example, the core nodes might be a set of individuals under surveillance, where we observe the attendees of meetings involving at least one of the core individuals. We model such scenarios using hypergraphs, and we study the problem of core recovery: if we observe the hypergraph but not the labels of core and fringe nodes, can we recover the ‘planted’ set of core nodes in the hypergraph? We provide a theoretical framework for analyzing the recovery of such a set of core nodes and use our theory to develop a practical and scalable algorithm for core recovery. The crux of our analysis and algorithm is that the core nodes are a hitting set of the hypergraph, meaning that every hyperedge has at least one node in the set of core nodes. We demonstrate the efficacy of our algorithm on a number of real-world datasets, outperforming competitive baselines derived from network centrality and core-periphery measures.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "Calibration of quantum decision theory: aversion to large losses and predictability of probabilistic choices",
           "10.1088/2632-072x/acbd7e",
           2023,
           "\nWe present the first calibration of quantum decision theory (QDT) to a dataset of binary risky choice. We quantitatively account for the fraction of choice reversals between two repetitions of the experiment, using a probabilistic choice formulation in the simplest form without model assumption or adjustable parameters. The prediction of choice reversal is then refined by introducing heterogeneity between decision makers through their differentiation into two groups: ‘majoritarian’ and ‘contrarian’ (in proportion 3:1). This supports the first fundamental tenet of QDT, which models choice as an inherent probabilistic process, where the probability of a prospect can be expressed as the sum of its utility and attraction factors. We propose to parameterize the utility factor with a stochastic version of cumulative prospect theory (logit-CPT), and the attraction factor with a constant absolute risk aversion function. For this dataset, and penalising the larger number of QDT parameters via the Wilks test of nested hypotheses, the QDT model is found to perform significantly better than logit-CPT at both the aggregate and individual levels, and for all considered fit criteria for the first experiment iteration and for predictions (second ‘out-of-sample’ iteration). The distinctive QDT effect captured by the attraction factor is mostly appreciable (i.e. most relevant and strongest in amplitude) for prospects with big losses. Our quantitative analysis of the experimental results supports the existence of an intrinsic limit of predictability, which is associated with the inherent probabilistic nature of choice. The results of the paper can find applications both in the prediction of choice of human decision makers as well as for organizing the operation of artificial intelligence.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Zoo guide to network embedding",
           "10.1088/2632-072x/ad0e23",
           2023,
           "\nNetworks have provided extremely successful models of data and complex systems. Yet, as combinatorial objects, networks do not have in general intrinsic coordinates and do not typically lie in an ambient space. The process of assigning an embedding space to a network has attracted great interest in the past few decades, and has been efficiently applied to fundamental problems in network inference, such as link prediction, node classification, and community detection. In this review, we provide a user-friendly guide to the network embedding literature and current trends in this field which will allow the reader to navigate through the complex landscape of methods and approaches emerging from the vibrant research activity on these subjects.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Atlas of urban scaling laws",
           "10.1088/2632-072x/ac718e",
           2022,
           "\nAccurate estimates of the urban fractal dimension D\nf are obtained by implementing the detrended moving average algorithm on high-resolution multi-spectral satellite images from the WorldView2 (WV2) database covering the largest European cities. Fractal dimension D\nf varies between 1.65 and 1.90 with high values for highly urbanised urban sectors and low ones for suburban and peripheral ones. Based on recently proposed models, the values of the fractal dimension D\nf are checked against the exponents β\ns and β\ni of the scaling law Y ∼ N\n\nβ\n, respectively for socio-economic and infrastructural variables Y, with N the population size. The exponents β\ns and β\ni are traditionally derived as if cities were zero-dimensional objects, with the relevant feature Y related to a single homogeneous population value N, thus neglecting the microscopic heterogeneity of the urban structure. Our findings go beyond this limit. High sensitive and repeatable satellite records yield robust local estimates of the urban scaling exponents. Furthermore, the work discusses how to discriminate among different scaling theories, shedding light on the debated issue of scaling phenomena contradictory perspectives and pave paths to a more systematic adoption of the complex system science methods to urban landscape analysis.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Multifractal analysis of glaciers in the Lombardy region of the Italian Alps",
           "10.1088/2632-072x/abd3ae",
           2020,
           "\nGlaciers are continuously monitored to detect their spatial extension and time evolution since they are the best witnesses of climate changes. There is a particular interest for Italian glaciers in the Alps as there is evidence that they are melting at a faster rate than those located in other regions of the globe. The determination of the perimeters of glaciers represents an effective method to evaluate the area covered by them. The availability of data for the perimeters encompassing several years suggests the opportunity of correlating the morphological variations in time with the properties of their shrinkage. In this work, we investigate the multifractal properties of the perimeters of the Lombardy glaciers in the Italian Alps. We characterize the area and perimeter distributions of the population of glaciers and we show that the distribution of perimeters exhibits a marked peak, not present in the distribution of areas. We analyze the area-perimeter relation, which is characterized by a power-law behavior that indicates a fractal structure of the perimeters with fractal dimension 1.2, independently from the size of the glaciers. We investigate the multifractal spectra of perimeters and we show that their features are strongly correlated with the area of the glaciers. Finally, we study the time evolution of the area and perimeter of glaciers and we detect the existence of a large class of glaciers whose perimeters increase while their areas decrease. We show that this behavior has a well definite counterpart in their multifractal spectra.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Heteroclinic units acting as pacemakers: entrained dynamics for cognitive processes",
           "10.1088/2632-072x/ac87e7",
           2022,
           "\nHeteroclinic dynamics is a suitable framework for describing transient and reproducible dynamics such as cognitive processes in the brain. We demonstrate how heteroclinic units can act as pacemakers to entrain larger sets of units from a resting state to hierarchical heteroclinic motion that is able to describe fast oscillations modulated by slow oscillations. Such features are observed in brain dynamics. The entrainment range depends on the type of coupling, the spatial location of the pacemaker and the individual bifurcation parameters of the pacemaker and the driven units. Noise as well as a small back-coupling to the pacemaker facilitate synchronization. Units can be synchronously entrained to different temporal patterns encoding transiently excited neural populations, depending on the selected path in the heteroclinic network. Via entrainment, these temporal patterns, locally generated by the pacemakers, can be communicated to the resting units in target waves over a spatial grid. For getting entrained there is no need of fine-tuning the parameters of the resting units. Thus, entrainment provides one way of processing information over the grid, when information is encoded in the generated spatiotemporal patterns.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "On the advances in machine learning and complex network measures to an EEG dataset from DMT experiments",
           "10.1088/2632-072x/ad1c68",
           2024,
           "\nThere is a growing interest in the medical use of psychedelic substances, as preliminary studies using them for psychiatric disorders have shown positive results. In particular, one of these substances is N, N-dimethyltryptamine (DMT), an agonist serotonergic psychedelic that can induce profound alterations in the state of consciousness. In this work, we use an exploratory tool to reveal DMT-induced changes in brain activity using EEG data and provide new insights into the mechanisms of action of this psychedelic substance. We used a two-class classification based on (A) the connectivity matrix or (B) complex network measures derived from it as input to a support vector machine (SVM). We found that both approaches could detect changes in the brain’s automatic activity, with case (B) showing the highest AUC (89%), indicating that complex network measurements best capture the brain changes that occur due to DMT use. In the second step, we ranked the features that contributed the most to this result. For case (A), we found that differences in the high alpha, low beta, and delta frequency bands were most important in distinguishing between the state before and after DMT inhalation, which is consistent with the results described in the literature. Further, the connection between the temporal (TP8) and central cortex (C3) and between the precentral gyrus (FC5) and the lateral occipital cortex (P8) contributed most to the classification result. The connection between regions TP8 and C3 has been found in the literature associated with finger movements that might have occurred during DMT consumption. However, the connection between cortical areas FC5 and P8 has not been found in the literature and is presumably related to the volunteers’ emotional, visual, sensory, perceptual, and mystical experiences during DMT consumption. For case (B), closeness centrality was the most crucial complex network measure. Furthermore, we discovered larger communities and longer average path lengths when DMT was used and the converse when not, showing that the balance between functional segregation and integration had been disrupted. These findings support the idea that cortical brain activity becomes more entropic under psychedelics. Overall, a robust computational workflow has been developed here with interpretability of how DMT (or other psychedelics) modify brain networks and insights into their mechanism of action. Finally, the same methodology applied here may help interpret EEG time series from patients who consumed other psychedelic drugs.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Spectral properties of the generalized diluted Wishart ensemble",
           "10.1088/2632-072x/ac956d",
           2022,
           "\nThe celebrated Marčenko–Pastur law, that considers the asymptotic spectral density of random covariance matrices, has found a great number of applications in physics, biology, economics, engineering, among others. Here, using techniques from statistical mechanics of spin glasses, we derive simple formulas concerning the spectral density of generalized diluted Wishart matrices. These are defined as \n\n\nF\n≡\n\n\n1\n\n\n2\nd\n\n\n\n\nX\n\n\nY\n\n\nT\n\n\n+\nY\n\n\nX\n\n\nT\n\n\n\n\n\n\n, where \nX\n and \nY\n are diluted N × P rectangular matrices, whose entries correspond to the links of doubly-weighted random bipartite Poissonian graphs following the distribution \n\n\nP\n\n(\n\n\n\nx\n\n\ni\n\n\nμ\n\n\n,\n\n\ny\n\n\ni\n\n\nμ\n\n\n\n)\n\n=\n\n\nd\n\n\nN\n\n\nϱ\n\n(\n\n\n\nx\n\n\ni\n\n\nμ\n\n\n,\n\n\ny\n\n\ni\n\n\nμ\n\n\n\n)\n\n+\n\n\n1\n−\n\n\nd\n\n\nN\n\n\n\n\n\n\nδ\n\n\n\n\nx\n\n\ni\n\n\nμ\n\n\n,\n0\n\n\n\n\nδ\n\n\n\n\ny\n\n\ni\n\n\nμ\n\n\n,\n0\n\n\n\n\n, with the probability density ϱ(x, y) controlling the correlation between the matrices entries of \nX\n and \nY\n. Our results cover several interesting cases by varying the parameters of the matrix ensemble, namely, the dilution of the graph d, the rectangularity of the matrices α = N/P, and the degree of correlation of the matrix entries via the density ϱ(x, y). Finally, we compare our findings to numerical diagonalisation showing excellent agreement.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Classical information theory of networks",
           "10.1088/2632-072x/ab9447",
           2020,
           "Existing information-theoretic frameworks based on maximum entropy network ensembles are not able to explain the emergence of heterogeneity in complex networks. Here, we fill this gap of knowledge by developing a classical framework for networks based on finding an optimal trade-off between the information content of a compressed representation of the ensemble and the information content of the actual network ensemble. We introduce a novel classical network ensemble satisfying a set of soft constraints and we find the optimal distribution of the constraints for this ensemble. We show that for the classical network ensemble in which the only constraints are the expected degrees a power-law degree distribution is optimal. Also, we study spatially embedded networks finding that the interactions between nodes naturally lead to non-uniform spread of nodes in the embedding space, leading in some cases to a fractal distribution of nodes. This result is consistent with the so called `blessing of non-uniformity' of data, i.e. the fact that real world data typically do not obey uniform distributions. The pertinent features of real-world air transportation networks are well described by the proposed framework.",
           12,
           "journal_of_physics_complexity"
          ],
          [
           "Generating directed networks with prescribed Laplacian spectra",
           "10.1088/2632-072x/abbd35",
           2020,
           "\nComplex real-world phenomena are often modeled as dynamical systems on networks. In many cases of interest, the spectrum of the underlying graph Laplacian sets the system stability and ultimately shapes the matter or information flow. This motivates devising suitable strategies, with rigorous mathematical foundation, to generate Laplacians that possess prescribed spectra. In this paper, we show that a weighted Laplacian can be constructed so as to exactly realize a desired complex spectrum. The method configures as a non trivial generalization of existing recipes which assume the spectra to be real. Applications of the proposed technique to (i) a network of Stuart–Landau oscillators and (ii) to the Kuramoto model are discussed. Synchronization can be enforced by assuming a properly engineered, signed and weighted, adjacency matrix to rule the pattern of pairing interactions.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Central limit theorem for the principal eigenvalue and eigenvector of Chung–Lu random graphs",
           "10.1088/2632-072x/acb8f7",
           2023,
           "\nA Chung–Lu random graph is an inhomogeneous Erdős–Rényi random graph in which vertices are assigned average degrees, and pairs of vertices are connected by an edge with a probability that is proportional to the product of their average degrees, independently for different edges. We derive a central limit theorem for the principal eigenvalue and the components of the principal eigenvector of the adjacency matrix of a Chung–Lu random graph. Our derivation requires certain assumptions on the average degrees that guarantee connectivity, sparsity and bounded inhomogeneity of the graph.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Higher-order connection Laplacians for directed simplicial complexes",
           "10.1088/2632-072x/ad353b",
           2024,
           "\nHigher-order networks encode the many-body interactions existing in complex systems, such as the brain, protein complexes, and social interactions. Simplicial complexes are higher-order networks that allow a comprehensive investigation of the interplay between topology and dynamics. However, simplicial complexes have the limitation that they only capture undirected higher-order interactions while in real-world scenarios, often there is a need to introduce the direction of simplices, extending the popular notion of direction of edges. On graphs and networks the Magnetic Laplacian, a special case of connection Laplacian, is becoming a popular operator to address edge directionality. Here we tackle the challenge of handling directionality in simplicial complexes by formulating higher-order connection Laplacians taking into account the configurations induced by the simplices’ directions. Specifically, we define all the connection Laplacians of directed simplicial complexes of dimension two and we discuss the induced higher-order diffusion dynamics by considering instructive synthetic examples of simplicial complexes. The proposed higher-order diffusion processes can be adopted in real scenarios when we want to consider higher-order diffusion displaying non-trivial frustration effects due to conflicting directionalities of the incident simplices.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Computational phase transitions: benchmarking Ising machines and quantum optimisers",
           "10.1088/2632-072x/abdadc",
           2021,
           "\nWhile there are various approaches to benchmark physical processors, recent findings have focused on computational phase transitions. This is due to several factors. Importantly, the hardest instances appear to be well-concentrated in a narrow region, with a control parameter allowing uniform random distributions of problem instances with similar computational challenge. It has been established that one could observe a computational phase transition in a distribution produced from coherent Ising machine(s). In terms of quantum approximate optimisation, the ability for the quantum algorithm to function depends critically on the ratio of a problems constraint to variable ratio (called density). The critical density dependence on performance resulted in what was called, reachability deficits. In this perspective we recall the background needed to understand how to apply computational phase transitions in various bench-marking tasks and we survey several such contemporary findings.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Hierarchical team structure and multidimensional localization (or siloing) on networks",
           "10.1088/2632-072x/ace602",
           2023,
           "\nKnowledge silos emerge when structural properties of organizational interaction networks limit the diffusion of information. These structural barriers are known to take many forms at different scales—hubs in otherwise sparse organizations, large dense teams, or global core-periphery structure—but we lack an understanding of how these different structures interact and shape dynamics. Here we take a first theoretical step in bridging the gap between the mathematical literature on localization of spreading dynamics and the more applied literature on knowledge silos in organizational interaction networks. To do so, we introduce a new model that considers a layered structure of teams to unveil a new form of hierarchical localization (i.e. the localization of information at the top or center of an organization) and study its interplay with known phenomena of mesoscopic localization (i.e. the localization of information in large groups), k-core localization (i.e. around denser subgraphs) and hub localization (i.e. around high degree stars). We also include a complex contagion mechanism by considering a general infection kernel which can depend on hierarchical level (influence), degree (popularity), infectious neighbors (social reinforcement) or team size (importance). This very general model allows us to explore the multifaceted phenomenon of information siloing in complex organizational interaction networks and opens the door to new optimization problems to promote or hinder the emergence of different localization regimes.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Complex systems of Kuramoto–sine-Gordon solitons",
           "10.1088/2632-072x/abf90d",
           2021,
           "\nThe 1 + 1 dimensional Kuramoto–sine-Gordon system consists of a set of N nonlinear coupled equations for N scalar fields θ\n\ni\n, which constitute the nodes of a complex system. These scalar fields interact by means of Kuramoto nonlinearities over a network of connections determined by N(N − 1)/2 symmetric coupling coefficients a\n\nij\n. This system, regarded as a chirally invariant quantum field theory, describes a single decoupled massless field together with N − 1 scalar boson excitations of nonzero mass depending on a\n\nij\n, which propagate and interact over the network. For N = 2 the equations decouple into separate sine-Gordon and wave equations. The system allows an extensive array of soliton configurations which interpolate between the various minima of the 2π-periodic potential, including sine-Gordon solitons in both static and time-dependent form, as well as double sine-Gordon solitons which can be imbedded into the system for any N. The precise form of the stable soliton depends critically on the coupling coefficients a\n\nij\n. We investigate specific configurations for N = 3 by classifying all possible potentials, and use the symmetries of the system to construct static solitons in both exact and numerical form.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Schrödinger’s ants: a continuous description of Kirman’s recruitment model",
           "10.1088/2632-072x/aba115",
           2020,
           "\nWe show how the approach to equilibrium in Kirman’s ants model can be fully characterized in terms of the spectrum of a Schrödinger equation with a Pöschl–Teller (tan2) potential. Among other interesting properties, we have found that in the bimodal phase where ants visit mostly one food site at a time, the switch time between the two sources only depends on the ‘spontaneous conversion’ rate and not on the recruitment rate. More complicated correlation functions can be computed exactly, and involve higher and higher eigenvalues and eigenfunctions of the Schrödinger operator, which can be expressed in terms of hypergeometric functions.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "Network processes on clique-networks with high average degree: the limited effect of higher-order structure",
           "10.1088/2632-072x/ac35b7",
           2021,
           "\nIn this paper, we investigate the effect of local structures on network processes. We investigate a random graph model that incorporates local clique structures, and thus deviates from the locally tree-like behavior of most standard random graph models. For the process of bond percolation, we derive analytical approximations for large percolation probabilities and the critical percolation value. Interestingly, these derivations show that when the average degree of a vertex is large, the influence of the deviations from the locally tree-like structure is small. In our simulations, this insensitivity to local clique structures often already kicks in for networks with average degrees as low as 6. Furthermore, we show that the different behavior of bond percolation on clustered networks compared to tree-like networks that was found in previous works can be almost completely attributed to differences in degree sequences rather than differences in clustering structures. We finally show that these results also extend to completely different types of dynamics, by deriving similar conclusions and simulations for the Kuramoto model on the same types of clustered and non-clustered networks.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "Anomalous diffusion in the citation time series of scientific publications",
           "10.1088/2632-072x/ac24f1",
           2021,
           "\nWe analyze the citation time-series of manuscripts in three different fields of science; physics, social science and technology. The evolution of the time-series of the yearly number of citations, namely the citation trajectories, diffuse anomalously, their variance scales with time ∝t\n2H\n, where H ≠ 1/2. We provide detailed analysis of the various factors that lead to the anomalous behavior: non-stationarity, long-ranged correlations and a fat-tailed increment distribution. The papers exhibit a high degree of heterogeneity across the various fields, as the statistics of the highest cited papers is fundamentally different from that of the lower ones. The citation data is shown to be highly correlated and non-stationary; as all the papers except the small percentage of them with high number of citations, die out in time.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Permutation entropy of indexed ensembles: quantifying thermalization dynamics",
           "10.1088/2632-072x/acd742",
           2023,
           "\nWe introduce ‘PI-Entropy’ \n\n\nΠ\n(\n\nρ\n˜\n\n)\n\n\n (the Permutation entropy of an Indexed ensemble) to quantify mixing due to complex dynamics for an ensemble ρ of different initial states evolving under identical dynamics. We find that \n\n\nΠ\n(\n\nρ\n˜\n\n)\n\n\n acts as an excellent proxy for the thermodynamic entropy \n\n\nS\n(\nρ\n)\n\n\n but is much more computationally efficient. We study 1-D and 2D iterative maps and find that \n\n\nΠ\n(\n\nρ\n˜\n\n)\n\n\n dynamics distinguish a variety of system time scales and track global loss of information as the ensemble relaxes to equilibrium. There is a universal S-shaped relaxation to equilibrium for generally chaotic systems, and this relaxation is characterized by a shuffling timescale that correlates with the system’s Lyapunov exponent. For the Chirikov Standard Map, a system with a mixed phase space where the chaos grows with nonlinear kick strength K, we find that for high K, \n\n\nΠ\n(\n\nρ\n˜\n\n)\n\n\n behaves like the uniformly hyperbolic 2D Cat Map. For low K we see periodic behavior with a relaxation envelope resembling those of the chaotic regime, but with frequencies that depend on the size and location of the initial ensemble in the mixed phase space as well as K. We discuss how \n\n\nΠ\n(\n\nρ\n˜\n\n)\n\n\n adapts to experimental work and its general utility in quantifying how complex systems change from a low entropy to a high entropy state.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Time-dependent relaxation of observables in complex quantum systems",
           "10.1088/2632-072x/ab79bc",
           2020,
           "\nWe consider time-dependent relaxation of observables in quantum systems of chaotic and regular type. Using statistical arguments and exact numerical solutions we show that the spread of the initial wave function in the Hilbert space and the main characteristics of evolution of observables have certain generic features. The study compares examples of regular dynamics, a completely chaotic case of the Gaussian orthogonal ensemble, a bosonic system with random interactions, and a fully realistic case of the time evolution of various initial non-stationary states in the nuclear shell model. In the case of the Gaussian orthogonal ensemble we show that the survival probability obtained analytically also fully defines the relaxation timescale of observables. This is not the case in general. Using the realistic nuclear shell model and the quadrupole moment as an observable we demonstrate that the relaxation time is significantly longer than defined by the survival probability of the initial state. The full analysis does not show the presence of an analog of the Lyapunov exponent characteristic for examples of classical chaos.",
           7,
           "journal_of_physics_complexity"
          ],
          [
           "Statistical physics of network structure and information dynamics",
           "10.1088/2632-072x/ac457a",
           2021,
           "\nIn the last two decades, network science has proven to be an invaluable tool for the analysis of empirical systems across a wide spectrum of disciplines, with applications to data structures admitting a representation in terms of complex networks. On the one hand, especially in the last decade, an increasing number of applications based on geometric deep learning have been developed to exploit, at the same time, the rich information content of a complex network and the learning power of deep architectures, highlighting the potential of techniques at the edge between applied math and computer science. On the other hand, studies at the edge of network science and quantum physics are gaining increasing attention, e.g., because of the potential applications to quantum networks for communications, such as the quantum Internet. In this work, we briefly review a novel framework grounded on statistical physics and techniques inspired by quantum statistical mechanics which have been successfully used for the analysis of a variety of complex systems. The advantage of this framework is that it allows one to define a set of information-theoretic tools which find widely used counterparts in machine learning and quantum information science, while providing a grounded physical interpretation in terms of a statistical field theory of information dynamics. We discuss the most salient theoretical features of this framework and selected applications to protein–protein interaction networks, neuronal systems, social and transportation networks, as well as potential novel applications for quantum network science and machine learning.",
           6,
           "journal_of_physics_complexity"
          ],
          [
           "Analytical evidence of nonlinearity in qubits and continuous-variable quantum reservoir computing",
           "10.1088/2632-072x/ac340e",
           2021,
           "\nThe natural dynamics of complex networks can be harnessed for information processing purposes. A paradigmatic example are artificial neural networks used for machine learning. In this context, quantum reservoir computing (QRC) constitutes a natural extension of the use of classical recurrent neural networks using quantum resources for temporal information processing. Here, we explore the fundamental properties of QRC systems based on qubits and continuous variables. We provide analytical results that illustrate how nonlinearity enters the input–output map in these QRC implementations. We find that the input encoding through state initialization can serve to control the type of nonlinearity as well as the dependence on the history of the input sequences to be processed.",
           7,
           "journal_of_physics_complexity"
          ],
          [
           "Effects of adaptive acceleration response of birds on collective behaviors",
           "10.1088/2632-072x/ac5b14",
           2022,
           "\nCollective dynamics of many interacting particles have been widely studied because of a wealth of their behavioral patterns quite different from the individual traits. A selective way of birds that reacts to their neighbors is one of the main factors characterizing the collective behaviors. Individual birds can react differently depending on their local environment during the collective decision-making process, and these variable reactions can be a source of complex spatiotemporal flocking dynamics. Here, we extend the deterministic Cucker–Smale model by including the individual’s reaction to neighbors’ acceleration where the reaction time depends on the local state of polarity. Simulation results show that the adaptive reaction of individuals induces the collective response of the flock. Birds are not frozen in a complete synchronization but remain sensitive to perturbations coming from environments. We confirm that the adaptivity of the reaction also generates natural fluctuations of orientation and speed, both of which are indeed scale-free as experimentally reported. This work may provide essential insight in designing resilient systems of many active agents working in complex, unpredictable environments.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Correlation functions as a tool to study collective behaviour phenomena in biological systems",
           "10.1088/2632-072x/ac2b06",
           2021,
           "\nMuch of interesting complex biological behaviour arises from collective properties. Important information about collective behaviour lies in the time and space structure of fluctuations around average properties, and two-point correlation functions are a fundamental tool to study these fluctuations. We give a self-contained presentation of definitions and techniques for computation of correlation functions aimed at providing students and researchers outside the field of statistical physics a practical guide to calculating correlation functions from experimental and simulation data. We discuss some properties of correlations in critical systems, and the effect of finite system size, which is particularly relevant for most biological experimental systems. Finally we apply these to the case of the dynamical transition in a simple neuronal model.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "Contrarian effects and echo chamber formation in opinion dynamics",
           "10.1088/2632-072x/abe561",
           2021,
           "The relationship between the topology of a network and specific types of dynamics unfolding in networks constitutes a subject of substantial interest. One type of dynamics that has attracted increasing attention because of its several potential implications is opinion formation. A phenomenon of particular importance, known to take place in opinion formation, is echo chambers’ appearance. In the present work, we approach this phenomenon, while emphasizing the influence of contrarian opinions in a multi-opinion scenario. To define the contrarian opinion, we considered theunderdogeffect, which is the eventual tendency of people to support the less popular option. We also considered an adaptation of the Sznajd dynamics with the possibility of friendship rewiring, performed on several network models. We analyze the relationship between topology and opinion dynamics by considering two measurements: opinion diversity and network modularity. Two specific situations have been addressed: (i) the agents can reconnect only with others sharing the same opinion; and (ii) same as in the previous case, but with the agents reconnecting only within a limited neighborhood. This choice can be justified because, in general, friendship is a transitive property along with subsequent neighborhoods (e.g., two friends of a person tend to know each other). As the main results, we found that the underdog effect, if strong enough, can balance the agents’ opinions. On the other hand, this effect decreases the possibilities of echo chamber formation. We also found that the restricted reconnection case reduced the chances of echo chamber formation and led to smaller echo chambers.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Exploitation by asymmetry of information reference in coevolutionary learning in prisoner’s dilemma game",
           "10.1088/2632-072x/ac301a",
           2021,
           "\nMutual relationships, such as cooperation and exploitation, are the basis of human and other biological societies. The foundations of these relationships are rooted in the decision making of individuals, and whether they choose to be selfish or altruistic. How individuals choose their behaviors can be analyzed using a strategy optimization process in the framework of game theory. Previous studies have shown that reference to individuals’ previous actions plays an important role in their choice of strategies and establishment of social relationships. A fundamental question remains as to whether an individual with more information can exploit another who has less information when learning the choice of strategies. Here we demonstrate that a player using a memory-one strategy, who can refer to their own previous action and that of their opponent, can be exploited by a reactive player, who only has the information of the other player, based on mutual adaptive learning. This is counterintuitive because the former has more choice in strategies and can potentially obtain a higher payoff. We demonstrated this by formulating the learning process of strategy choices to optimize the payoffs in terms of coupled replicator dynamics and applying it to the prisoner’s dilemma game. Further, we show that the player using a memory-one strategy, by referring to their previous experience, can sometimes act more generous toward the opponent’s defection, thereby accepting the opponent’s exploitation. Mainly, we found that through adaptive learning, a player with limited information usually exploits the player with more information, leading to asymmetric exploitation.",
           6,
           "journal_of_physics_complexity"
          ],
          [
           "The high-frequency and rare events barriers to neural closures of atmospheric dynamics",
           "10.1088/2632-072x/ad3e59",
           2024,
           "\nRecent years have seen a surge in interest for leveraging neural networks to parameterize small-scale or fast processes in climate and turbulence models. In this short paper, we point out two fundamental issues in this endeavor. The first concerns the difficulties neural networks may experience in capturing rare events due to limitations in how data is sampled. The second arises from the inherent multiscale nature of these systems. They combine high-frequency components (like inertia-gravity waves) with slower, evolving processes (geostrophic motion). This multiscale nature creates a significant hurdle for neural network closures. To illustrate these challenges, we focus on the atmospheric 1980 Lorenz model, a simplified version of the Primitive Equations that drive climate models. This model serves as a compelling example because it captures the essence of these difficulties.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Model-free control of dynamical systems with deep reservoir computing",
           "10.1088/2632-072x/ac24f3",
           2021,
           "\nWe propose and demonstrate a nonlinear control method that can be applied to unknown, complex systems where the controller is based on a type of artificial neural network known as a reservoir computer. In contrast to many modern neural-network-based control techniques, which are robust to system uncertainties but require a model nonetheless, our technique requires no prior knowledge of the system and is thus model-free. Further, our approach does not require an initial system identification step, resulting in a relatively simple and efficient learning process. Reservoir computers are well-suited to the control problem because they require small training data sets and remarkably low training times. By iteratively training and adding layers of reservoir computers to the controller, a precise and efficient control law is identified quickly. With examples on both numerical and high-speed experimental systems, we demonstrate that our approach is capable of controlling highly complex dynamical systems that display deterministic chaos to nontrivial target trajectories.",
           21,
           "journal_of_physics_complexity"
          ],
          [
           "Amplitude chimeras and bump states with and without frequency entanglement: a toy model",
           "10.1088/2632-072x/ad4228",
           2024,
           "\nWhen chaotic oscillators are coupled in complex networks a number of interesting synchronization phenomena emerge. Notable examples are the frequency and amplitude chimeras, chimera death states, solitary states as well as combinations of these. In a previous study [Journal of Physics: Complexity, 2020, 1(2), 025006], a toy model was introduced addressing possible mechanisms behind the formation of frequency chimera states. In the present study a variation of the toy model is proposed to address the formation of amplitude chimeras. The proposed oscillatory model is now equipped with an additional 3rd order equation modulating the amplitude of the network oscillators. This way, the single oscillators are constructed as bistable in amplitude and depending on the initial conditions their amplitude may result in one of the two stable ﬁxed points. Numerical simulations demonstrate that when these oscillators are nonlocally coupled in networks, they organize in domains with alternating amplitudes (related to the two ﬁxed points), naturally forming amplitude chimeras. A second extension of this model incorporates nonlinear terms merging amplitude together with frequency, and this extension allows for the spontaneous production of composite amplitude-and-frequency chimeras occurring simultaneously in the network. Moreover the extended model allows to understand the emergence of bump states via the continuous passage from chimera states, when both ﬁxed point amplitudes are positive, to bump states when one of the two ﬁxed points vanishes. The synchronization properties of the network are studied as a function of the system parameters for the case of amplitude chimeras, bump states and composite amplitude-and-frequency chimeras. The proposed mechanisms of creating domains with variable amplitudes and/or frequencies provide a generic scenario for understanding the formation of the complex synchronization phenomena observed in networks of coupled nonlinear and chaotic oscillators.&#xD;",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Both eyes open: Vigilant Incentives help Auditors improve AI Safety",
           "10.1088/2632-072x/ad424c",
           2024,
           "\nAuditors can play a vital role in ensuring that tech companies develop and deploy AI systems safely, taking into account not just immediate, but also systemic harms that may arise from the use of future AI capabilities. However, to support auditors in evaluating the capabilities and consequences of cutting-edge AI systems, governments may need to encourage a range of potential auditors to invest in new auditing tools and approaches. We use evolutionary game theory to model scenarios where the government wishes to incentivise auditing, but cannot discriminate between high and low-quality auditing. We warn that it is alarmingly easy to stumble on 'Adversarial incentives', which prevent a sustainable market for auditing AI systems from forming. Adversarial Incentives mainly reward auditors for catching unsafe behaviour. If AI companies learn to tailor their behaviour to the quality of audits, the lack of opportunities to catch unsafe behaviour will discourage auditors from innovating. Instead, we recommend that governments always reward auditors, except when they find evidence that those auditors failed to detect unsafe behaviour they should have. These 'Vigilant Incentives' could encourage auditors to find innovative ways to evaluate cutting-edge AI systems.&#xD;Overall, our analysis provides useful insights for the design and implementation of efficient incentive strategies for encouraging a robust auditing ecosystem.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Impact of tropical teleconnections on the long-range predictability of the atmosphere at midlatitudes: a reduced-order multi-scale model perspective",
           "10.1088/2632-072x/ad04e8",
           2023,
           "\nTeleconnections between the tropical and the extratropical climates are often considered as a potential source of long-term predictability at seasonal to decadal time scales in the extratropics. This claim is taken up in the present work by investigating the predictability of a coupled ocean–atmosphere extratropical model under a one-way forcing generated by a tropical model. Both models display a chaotic dynamics, and the dominant variable of the extratropical model displays a high correlation with the tropical forcing in the reference simulation, inducing a low-frequency variability signal in the extratropics. Numerical experiments emulating the presence of initial condition errors in the tropical model are conducted to clarify their impact on the predictability in the extratropics. It is shown that: (i) the correlation skill of the dominant observable affected by the forcing is considerably degraded at interannual time scales due to the presence of initial condition errors in the tropics, limiting the potential of teleconnections; (ii) averaging of an ensemble of forecasts–with a small number of members–may substantially improve the quality of the forecasts; and (iii) temporal averaging may also improve the quality of the forecasts (at the expense of being able to forecast extreme events), in particular when the forcing affects weakly the observable under interest.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Spatial patterns and biodiversity in rock-paper-scissors models with regional unevenness",
           "10.1088/2632-072x/acd610",
           2023,
           "\nClimate changes may affect ecosystems destabilising relationships among species. We investigate the spatial rock-paper-scissors models with a regional unevenness that reduces the selection capacity of organisms of one species. Our results show that the regionally weak species predominates in the local ecosystem, while spiral patterns appear far from the region, where individuals of every species play the rock-paper-scissors game with the same strength. Because the weak species controls all local territory, it is attractive for the other species to enter the local ecosystem to conquer the territory. However, our stochastic simulations show that the transitory waves formed when organisms of the strong species reach the region are quickly destroyed because of local strength unbalance in the selection game rules. Computing the effect of the topology on population dynamics, we find that the prevalence of the weak species becomes more significant if the transition of the selection capacity to the area of uneven rock-paper-scissors rules is smooth. Finally, our findings show that the biodiversity loss due to the arising of regional unevenness is minimised if the transition to the region where the cyclic game is unbalanced is abrupt. Our results may be helpful to biologists in comprehending the consequences of changes in the environmental conditions on species coexistence and spatial patterns in complex systems.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Explosive transitions in epidemic dynamics",
           "10.1088/2632-072x/ac99cd",
           2022,
           "\nStandard epidemic models exhibit one continuous, second order phase transition to macroscopic outbreaks. However, interventions to control outbreaks may fundamentally alter epidemic dynamics. Here we reveal how such interventions modify the type of phase transition. In particular, we uncover three distinct types of explosive phase transitions for epidemic dynamics with capacity-limited interventions. Depending on the capacity limit, interventions may (i) leave the standard second order phase transition unchanged but exponentially suppress the probability of large outbreaks, (ii) induce a first-order discontinuous transition to macroscopic outbreaks, or (iii) cause a secondary explosive yet continuous third-order transition. These insights highlight inherent limitations in predicting and containing epidemic outbreaks. More generally our study offers a cornerstone example of a third-order explosive phase transition in complex systems.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "Identifying key products to trigger new exports: an explainable machine learning approach",
           "10.1088/2632-072x/ad3604",
           2024,
           "\nTree-based machine learning algorithms provide the most precise assessment of the feasibility for a country to export a target product given its export basket. However, the high number of parameters involved prevents a straightforward interpretation of the results and, in turn, the explainability of policy indications. In this paper, we propose a procedure to statistically validate the importance of the products used in the feasibility assessment. In this way, we are able to identify which products, called explainers, significantly increase the probability to export a target product in the near future. The explainers naturally identify a low dimensional representation, the Feature Importance Product Space, that enhances the interpretability of the recommendations and provides out-of-sample forecasts of the export baskets of countries. Interestingly, we detect a positive correlation between the complexity of a product and the complexity of its explainers.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Assessing the impact of Byzantine attacks on coupled phase oscillators",
           "10.1088/2632-072x/ad0390",
           2023,
           "\nFor many coupled dynamical systems, the interaction is the outcome of the measurement that each unit has of the others as e.g. in modern inverter-based power grids, autonomous vehicular platoons or swarms of drones, or it is the result of physical flows. Synchronization among all the components of these systems is of primal importance to avoid failures. The overall operational state of these systems therefore crucially depends on the correct and reliable functioning of the individual elements as well as the information they transmit through the network. Here, we investigate the effect of Byzantine attacks where one unit does not behave as expected, but is controlled by an external attacker. For such attacks, we assess the impact on the global collective behavior of nonlinearly coupled phase oscillators. We relate the synchronization error induced by the input signal to the properties of the attacked node. This allows to anticipate the potential of an attacker and identify which network components to secure.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Identification of city motifs: a method based on modularity and similarity between hierarchical features of urban networks",
           "10.1088/2632-072x/ac9446",
           2022,
           "\nSeveral natural and theoretical networks can be broken down into smaller portions, henceforth called neighborhoods. The more frequent of these can then be understood as motifs of the network, being therefore important for better characterizing and understanding of its overall structure. Several developments in network science have relied on this interesting concept, with ample applications in areas including systems biology, computational neuroscience, economy and ecology. The present work aims at reporting a methodology capable of automatically identifying motifs respective to streets networks, i.e. graphs obtained from city plans by considering street junctions and terminations as nodes while the links are defined by the streets. Interesting results are described, including the identification of nine characteristic motifs, which have been obtained by three important considerations: (i) adoption of five hierarchical measurements to locally characterize the neighborhoods of nodes in the streets networks; (ii) adoption of an effective coincidence similarity methodology for translating datasets into networks; and (iii) definition of the motifs in statistical terms by using community finding methodology. The nine identified motifs are characterized and discussed from several perspectives, including their mutual similarity, visualization, histograms of measurements, and geographical adjacency in the original cities. Also presented is the analysis of the effect of the adopted features on the obtained networks as well as a simple supervised learning method capable of assigning reference motifs to cities.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Inferring the drivers of language change using spatial models",
           "10.1088/2632-072x/abfa82",
           2021,
           "\nDiscovering and quantifying the drivers of language change is a major challenge. Hypotheses about causal factors proliferate, but are difficult to rigorously test. Here we ask a simple question: can 20th century changes in English be explained as a consequence of spatial diffusion, or have other processes created bias in favour of certain linguistic forms? Using two of the most comprehensive spatial datasets available, which measure the state of English at the beginning and end of the 20th century, we calibrate a simple spatial model so that, initialised with the early state, it evolves into the later. Our calibrations reveal that while some changes can be explained by diffusion alone, others are clearly the result of substantial asymmetries between variants. We discuss the origins of these asymmetries and, as a by-product, we generate a full spatio–temporal prediction for the spatial evolution of English features over the 20th century, and a prediction of the future.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "The likelihood-ratio test for multi-edge network models",
           "10.1088/2632-072x/ac0493",
           2021,
           "The complexity underlying real-world systems implies that standard statistical hypothesis testing methods may not be adequate for these peculiar applications. Specifically, we show that the likelihood-ratio (LR) test’s null-distribution needs to be modified to accommodate the complexity found in multi-edge network data. When working with independent observations, thep-values of LR tests are approximated using aχ2distribution. However, such an approximation should not be used when dealing with multi-edge network data. This type of data is characterized by multiple correlations and competitions that make the standard approximation unsuitable. We provide a solution to the problem by providing a better approximation of the LR test null-distribution through a beta distribution. Finally, we empirically show that even for a small multi-edge network, the standardχ2approximation provides erroneous results, while the proposed beta approximation yields the correctp-value estimation.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Transient chaos enforces uncertainty in the British power grid",
           "10.1088/2632-072x/ac080f",
           2021,
           "\nMultistability is a common phenomenon which naturally occurs in complex networks. If coexisting attractors are numerous and their basins of attraction are complexly interwoven, the long-term response to a perturbation can be highly uncertain. We examine the uncertainty in the outcome of perturbations to the synchronous state in a Kuramoto-like representation of the British power grid. Based on local basin landscapes which correspond to single-node perturbations, we demonstrate that the uncertainty shows strong spatial variability. While perturbations at many nodes only allow for a few outcomes, other local landscapes show extreme complexity with more than a hundred basins. Particularly complex domains in the latter can be related to unstable invariant chaotic sets of saddle type. Most importantly, we show that the characteristic dynamics on these chaotic saddles can be associated with certain topological structures of the network. We find that one particular tree-like substructure allows for the chaotic response to perturbations at nodes in the north of Great Britain. The interplay with other peripheral motifs increases the uncertainty in the system response even further.",
           10,
           "journal_of_physics_complexity"
          ],
          [
           "Strength of minority ties: the role of homophily and group composition in a weighted social network",
           "10.1088/2632-072x/ad2720",
           2024,
           "\nHomophily describes a fundamental tie-formation mechanism in social networks in which connections between similar nodes occur at a higher rate than among dissimilar ones. In this article, we present an extension of the weighted social network (WSN) model that, under an explicit homophily principle, quantifies the emergence of attribute-dependent properties of a social system. To test our model, we make use of empirical association data of a group of free-ranging spider monkeys in Yucatan, Mexico. Our homophilic WSN model reproduces many of the properties of the empirical association network with statistical significance, specifically, the average weight of sex-dependent interactions (female-female, female-male, male-male), the weight distribution function, as well as many weighted macro properties (node strength, weighted clustering, and weighted number of modules), even for different age group combinations (adults, subadults, and juveniles). Furthermore, by performing simulations with fitted parameters, we show that one of the main features of a spider monkey social system, namely, stronger male-male interactions over female-female or female-male ones, can be accounted for by an asymmetry in the node-type composition of a bipartisan network, independently of group size. The reinforcement of connections among members of minority groups could be a general structuring mechanism in homophilic social networks.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Topological analysis of traffic pace via persistent homology*",
           "10.1088/2632-072x/abc96a",
           2020,
           "\nWe develop a topological analysis of robust traffic pace patterns using persistent homology. We develop Rips filtrations, parametrized by pace, for a symmetrization of traffic pace along the (naturally) directed edges in a road network. Our symmetrization is inspired by recent work of Turner (2019 Algebr. Geom. Topol.\n19 1135–1170). Our goal is to construct barcodes which help identify meaningful pace structures, namely connected components or ‘rings’. We develop a case study of our methods using datasets of Manhattan and Chengdu traffic speeds. In order to cope with the computational complexity of these large datasets, we develop an auxiliary application of the directed Louvain neighborhood-finding algorithm. We implement this as a preprocessing step prior to our main persistent homology analysis in order to coarse-grain small topological structures. We finally compute persistence barcodes on these neighborhoods. The persistence barcodes have a metric structure which allows us to both qualitatively and quantitatively compare traffic networks. As an example of the results, we find robust connected pace structures near Midtown bridges connecting Manhattan to the mainland.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "Disorder unleashes panic in bitcoin dynamics",
           "10.1088/2632-072x/ad00f7",
           2023,
           "\nThe behaviour of Bitcoin owners is reflected in the structure and the number of bitcoin transactions encoded in the Blockchain. Likewise, the behaviour of Bitcoin traders is reflected in the formation of bullish and bearish trends in the crypto market. In light of these observations, we wonder if human behaviour underlies some relationship between the Blockchain and the crypto market. To address this question, we map the Blockchain to a spin-lattice problem, whose configurations form ordered and disordered patterns, representing the behaviour of Bitcoin owners. This novel approach allows us to obtain time series suitable to detect a causal relationship between the dynamics of the Blockchain and market trends of the Bitcoin and to find that disordered patterns in the Blockchain precede Bitcoin panic selling. Our results suggest that human behaviour underlying Blockchain evolution and the crypto market brings out a fascinating connection between disorder and panic in Bitcoin dynamics.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Identifying robust functional modules using three-body correlations in Escherichia coli",
           "10.1088/2632-072x/ac5567",
           2022,
           "\nUnderstanding the underlying structure of a gene regulatory network is crucial to understand the biological functions of genes or groups of genes. A common strategy to investigate it is to find community structure of these networks. However, methods of finding these communities are often sensitive to noise in the gene expression data and the inherent stochasticity of the community detection algorithms. Here we introduce an approach for identifying functional groups and their hierarchical organization in gene co-expression networks from expression data. A network describing the relatedness in the expression profiles of genes is first inferred using an information theoretic approach. Community structure within the inferred network is found by using modularity maximization. This community structure is further refined using three-body structural correlations to robustly identify important functional gene communities. We apply this approach to the expression data of E. coli genes and identify 25 robust groups, many of which show key associations with important biological functions as demonstrated by gene ontology term enrichment analysis. Thus, our approach makes specific and novel predictions about the function of these genes.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Socio-economic disparities and COVID-19 in the USA",
           "10.1088/2632-072x/ac0fc7",
           2021,
           "\nCOVID-19 is not a universal killer. We study the spread of COVID-19 at the county level for the United States up until the 15th of August, 2020. We show that the prevalence of the disease and the death rate are correlated with the local socio-economic conditions often going beyond local population density distributions, especially in rural areas. We correlate the COVID-19 prevalence and death rate with data from the US Census Bureau and point out how the spreading patterns of the disease show asymmetries in urban and rural areas separately and are preferentially affecting the counties where a large fraction of the population is non-white. Our findings can be used for more targeted policy building and deployment of resources for future occurrence of a pandemic due to SARS-CoV-2. Our methodology, based on interpretable machine learning and game theory, can be extended to study the spread of other diseases.",
           23,
           "journal_of_physics_complexity"
          ],
          [
           "Brain criticality beyond avalanches: open problems and how to approach them",
           "10.1088/2632-072x/ac2071",
           2021,
           "\nA homeostatic mechanism that keeps the brain highly susceptible to stimuli and optimizes many of its functions—although this is a compelling theoretical argument in favor of the brain criticality hypothesis, the experimental evidence accumulated during the last two decades is still not entirely convincing, causing the idea to be seemingly unknown in the more clinically-oriented neuroscience community. In this perspective review, we will briefly review the theoretical framework underlying such bold hypothesis, and point to where theory and experiments agree and disagree, highlighting potential ways to try and bridge the gap between them. Finally, we will discuss how the stand point of statistical physics could yield practical applications in neuroscience and help with the interpretation of what is a healthy or unhealthy brain, regardless of being able to validate the critical brain hypothesis.",
           11,
           "journal_of_physics_complexity"
          ],
          [
           "Coincidence complex networks",
           "10.1088/2632-072x/ac54c3",
           2022,
           "\nComplex networks, which constitute the main subject of network science, have been wide and extensively adopted for representing, characterizing, and modeling an ample range of structures and phenomena from both theoretical and applied perspectives. The present work describes the application of the real-valued Jaccard and real-valued coincidence similarity indices for translating generic datasets into networks. More specifically, two data elements are linked whenever the similarity between their respective features, gauged by some similarity index, is greater than a given threshold. Weighted networks can also be obtained by taking these indices as weights. It is shown that the two proposed real-valued approaches can lead to enhanced performance when compared to cosine and Pearson correlation approaches, yielding a detailed description of the specific patterns of connectivity between the nodes, with enhanced modularity. In addition, a parameter α is introduced that can be used to control the contribution of positive and negative joint variations between the considered features, catering for enhanced flexibility while obtaining networks. The ability of the proposed methodology to capture detailed interconnections and emphasize the modular structure of networks is illustrated and quantified respectively to real-world networks, including handwritten letters and raisin datasets, as well as the Caenorhabditis elegans neuronal network. The reported methodology and results pave the way to a significant number of theoretical and applied developments.",
           12,
           "journal_of_physics_complexity"
          ],
          [
           "Higher-order synchronization on the sphere",
           "10.1088/2632-072x/ac42e1",
           2021,
           "\nWe construct a system of N interacting particles on the unit sphere \n\n\n\n\nS\n\n\nd\n−\n1\n\n\n\n\n in d-dimensional space, which has d-body interactions only. The equations have a gradient formulation derived from a rotationally-invariant potential of a determinantal form summed over all nodes, with antisymmetric coefficients. For d = 3, for example, all trajectories lie on the two-sphere and the potential is constructed from the triple scalar product summed over all oriented two-simplices. We investigate the cases d = 3, 4, 5 in detail, and find that the system synchronizes from generic initial values for both positive and negative coupling coefficients, to a static final configuration in which the particles lie equally spaced on \n\n\n\n\nS\n\n\nd\n−\n1\n\n\n\n\n. Completely synchronized configurations also exist, but are unstable under the d-body interactions. We compare the relative effect of two-body and d-body forces by adding the well-studied two-body interactions to the potential, and find that higher-order interactions enhance the synchronization of the system, specifically, synchronization to a final configuration consisting of equally spaced particles occurs for all d-body and two-body coupling constants of any sign, unless the attractive two-body forces are sufficiently strong relative to the d-body forces. In this case the system completely synchronizes as the two-body coupling constant increases through a positive critical value, with either a continuous transition for d = 3, or discontinuously for d = 5. Synchronization also occurs if the nodes have distributed natural frequencies of oscillation, provided that the frequencies are not too large in amplitude, even in the presence of repulsive two-body interactions which by themselves would result in asynchronous behaviour.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "Criticality and network structure drive emergent oscillations in a stochastic whole-brain model",
           "10.1088/2632-072x/ac7a83",
           2022,
           "\nUnderstanding the relation between the structure of brain networks and their functions is a fundamental open question. Simple models of neural activity based on real anatomical networks have proven to be effective in describing features of whole-brain spontaneous activity when tuned at their critical point. In this work, we show that structural networks are indeed a crucial ingredient in the emergence of collective oscillations in a whole-brain stochastic model at criticality. We study analytically a stochastic Greenberg–Hastings cellular automaton in the mean-field limit, showing that it undergoes an abrupt phase transition with a bistable region. In particular, no global oscillations emerge in this limit. Then, we show that by introducing a network structure in the homeostatic normalization regime, the bistability may be disrupted, and the transition may become smooth. Concomitantly, through an interplay between network topology and weights, a large peak in the power spectrum appears around the transition point, signaling the emergence of collective oscillations. Hence, both the structure of brain networks and criticality are fundamental in driving the collective responses of whole-brain stochastic models.",
           6,
           "journal_of_physics_complexity"
          ],
          [
           "Modelling non-linear consensus dynamics on hypergraphs",
           "10.1088/2632-072x/abcea3",
           2020,
           "\nThe basic interaction unit of many dynamical systems involves more than two nodes. In such situations where networks are not an appropriate modelling framework, it has recently become increasingly popular to turn to higher-order models, including hypergraphs. In this paper, we explore the non-linear dynamics of consensus on hypergraphs, allowing for interactions within hyperedges of any cardinality. After discussing the different ways in which nonlinearities can be incorporated in the dynamical model, building on different sociological theories, we explore its mathematical properties and perform simulations to investigate them numerically. After focussing on synthetic hypergraphs, namely on block hypergraphs, we investigate the dynamics on real-world structures, and explore in detail the role of involvement and stubbornness on polarisation.",
           21,
           "journal_of_physics_complexity"
          ],
          [
           "Complex systems approaches for Earth system data analysis",
           "10.1088/2632-072x/abd8db",
           2021,
           "\nComplex systems can, to a first approximation, be characterized by the fact that their dynamics emerging at the macroscopic level cannot be easily explained from the microscopic dynamics of the individual constituents of the system. This property of complex systems can be identified in virtually all natural systems surrounding us, but also in many social, economic, and technological systems. The defining characteristics of complex systems imply that their dynamics can often only be captured from the analysis of simulated or observed data. Here, we summarize recent advances in nonlinear data analysis of both simulated and real-world complex systems, with a focus on recurrence analysis for the investigation of individual or small sets of time series, and complex networks for the analysis of possibly very large, spatiotemporal datasets. We review and explain the recent success of these two key concepts of complexity science with an emphasis on applications for the analysis of geoscientific and in particular (palaeo-) climate data. In particular, we present several prominent examples where challenging problems in Earth system and climate science have been successfully addressed using recurrence analysis and complex networks. We outline several open questions for future lines of research in the direction of data-based complex system analysis, again with a focus on applications in the Earth sciences, and suggest possible combinations with suitable machine learning approaches. Beyond Earth system analysis, these methods have proven valuable also in many other scientific disciplines, such as neuroscience, physiology, epidemics, or engineering.",
           10,
           "journal_of_physics_complexity"
          ],
          [
           "Multiplicative noise induced bistability and stochastic resonance",
           "10.1088/2632-072x/ad399d",
           2024,
           "\nStochastic resonance is a well established phenomenon, which proves relevant for a wide range of applications, of broad trans-disciplinary breath. Consider a one dimensional bistable stochastic system, characterized by a deterministic double well potential and shaken by an additive noise source. When subject to an external periodic drive, and for a proper choice of the noise strength, the system swings regularly between the two existing deterministic fixed points, with just one switch for each oscillation of the imposed forcing term. This resonant condition can be exploited to unravel weak periodic signals, otherwise inaccessible to conventional detectors. Here, we will set to revisit the stochastic resonance concept by operating in a modified framework where bistability is induced by the nonlinear nature of the multiplicative noise. A candidate model is in particular introduced which fulfils the above requirements while allowing for analytical progress to be made.  Working with reference to this case study, we elaborate on the conditions for the onset of the generalized stochastic resonance mechanism. As a byproduct of the analysis, a novel resonant regime is also identified which displays no lower bound for the frequencies that can be resolved, at variance with the traditional setting.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Influence maximization under limited network information: seeding high-degree neighbors",
           "10.1088/2632-072x/ac9444",
           2022,
           "\nThe diffusion of information, norms, and practices across a social network can be initiated by compelling a small number of seed individuals to adopt first. Strategies proposed in previous work either assume full network information or a large degree of control over what information is collected. However, privacy settings on the Internet and high non-response in surveys often severely limit available connectivity information. Here we propose a seeding strategy for scenarios with limited network information: Only the degrees and connections of some random nodes are known. This new strategy is a modification of ‘random neighbor sampling’ (or ‘one-hop’) and seeds the highest-degree neighbors of randomly selected nodes. Simulating a fractional threshold model, we find that this new strategy excels in networks with heavy tailed degree distributions such as scale-free networks and large online social networks. It outperforms the conventional one-hop strategy even though the latter can seed 50% more nodes, and other seeding possibilities including pure high-degree seeding and clustered seeding.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "The degree of economic development pattern of economy",
           "10.1088/2632-072x/ad3261",
           2024,
           "\nIn this article, we explore the concept and measurement of the degree of economic development pattern (DEDP) of economy, which refers to the extent to which the development of an economy can serve as a reference for other economies. Utilizing 76 macroeconomic indicators across 217 economies, the economic development paths in a standardized space of economy is compared to identify variations in DEDP through the regression analysis on the relationship between the similarity of development paths and the growth rate on gross domestic product (GDP) per capita. To measure DEDP of economy from different perspective, two types of metrics are constructed. One is the determination coefficient of regression analysis, which exhibits significant positive correlations with population size of economy, uncovering differences of development paths among economies of varying population sizes. The other type of metrics is based on the consistency on regression coefficients and effectively explains disparities among economies in the growth rate on GDP per capita, economic complexity index and economic fitness. These findings reveal the differences in development paths among different countries from the perspective of referentiality for development patterns, suggesting the potential existence of the paths with more universal meaning to economic development.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Irregular collective dynamics in a Kuramoto–Daido system",
           "10.1088/2632-072x/abd3af",
           2020,
           "\nWe analyze the collective behavior of a mean-field model of phase-oscillators of Kuramoto–Daido type coupled through pairwise interactions which depend on phase differences: the coupling function is composed of three harmonics. We provide convincing evidence of a transient but long-lasting chaotic collective chaos, which persists in the thermodynamic limit. The regime is analyzed with the help of clever direct numerical simulations, by determining the maximum Lyapunov exponent and assessing the transversal stability to the self-consistent mean field. The structure of the invariant measure is finally described in terms of a resolution-dependent entropy.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "Anomaly detection in multidimensional time series—a graph-based approach",
           "10.1088/2632-072x/ac392c",
           2021,
           "\nAs the digital transformation is taking place, more and more data is being generated and collected. To generate meaningful information and knowledge researchers use various data mining techniques. In addition to classification, clustering, and forecasting, outlier or anomaly detection is one of the most important research areas in time series analysis. In this paper we present a method for detecting anomalies in multidimensional time series using a graph-based algorithm. We transform time series data to graphs prior to calculating the outlier since it offers a wide range of graph-based methods for anomaly detection. Furthermore the dynamic of the data is taken into consideration by implementing a window of a certain size that leads to multiple graphs in different time frames. We use feature extraction and aggregation to finally compare distance measures of two time-dependent graphs. The effectiveness of our algorithm is demonstrated on the numenta anomaly benchmark with various anomaly types as well as the KPI-anomaly-detection data set of 2018 AIOps competition.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "Fixation and fluctuations in two-species cooperation",
           "10.1088/2632-072x/ac52e7",
           2022,
           "\nCooperative interactions pervade in a broad range of many-body populations, such as ecological communities, social organizations, and economic webs. We investigate the dynamics of a population of two equivalent species A and B that are driven by cooperative and symmetric interactions between these species. For an isolated population, we determine the probability to reach fixation, where only one species remains, as a function of the initial concentrations of the two species, as well as the time to reach fixation. The latter scales exponentially with the population size. When members of each species migrate into the population at rate λ and replace a randomly selected individual, surprisingly rich dynamics ensues. Ostensibly, the population reaches a steady state, but the steady-state population distribution undergoes a unimodal to trimodal transition as the migration rate decreases below a critical value λ\nc. In the low-migration regime, λ < λ\nc, the steady state is not truly steady, but instead strongly fluctuates between near-fixation states, where the population consists of mostly A’s or of mostly B’s. The characteristic time scale of these fluctuations diverges as λ\n−1. Thus in spite of the cooperative interaction, a typical snapshot of the population will contain almost all A’s or almost all B’s.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "Which will be your firm’s next technology? Comparison between machine learning and network-based algorithms",
           "10.1088/2632-072x/ac768d",
           2022,
           "\nWe reconstruct the innovation dynamics of about two hundred thousand companies by following their patenting activity for about ten years. We define the technology portfolios of these companies as the set of the technological sectors present in the patents they submit. By assuming that companies move more frequently towards related sectors, we leverage their past activity to build network-based and machine learning algorithms to forecast the future submissions of patents in new sectors. We compare different prediction methodologies using suitable evaluation metrics, showing that tree-based machine learning algorithms outperform the standard methods based on networks of co-occurrences. This methodology can be applied by firms and policymakers to disentangle, given the present innovation activity, the feasible technological sectors from those that are out of reach.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "Information parity increases on functional brain networks under influence of a psychedelic substance",
           "10.1088/2632-072x/acc22b",
           2023,
           "\nThe physical basis of consciousness is one of the most intriguing open questions that contemporary science aims to solve. By approaching the brain as an interactive information system, complex network theory has greatly contributed to understand brain process in different states of mind. We study a non-ordinary state of mind by comparing resting-state functional brain networks of individuals in two different conditions: before and after the ingestion of the psychedelic brew Ayahuasca. In order to quantify the functional, statistical symmetries between brain region connectivity, we calculate the pairwise information parity of the functional brain networks. Unlike the usual approach to quantitative network analysis that considers only local or global scales, information parity instead quantifies pairwise statistical similarities over the entire network structure. We find an increase in the average information parity on brain networks of individuals under psychedelic influences. Notably, the information parity between regions from the limbic system and frontal cortex is consistently higher for all the individuals while under the psychedelic influence. These findings suggest that the resemblance of statistical influences between pair of brain regions activities tends to increase under Ayahuasca effects. This could be interpreted as a mechanism to maintain the network functional resilience.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Effects of active noise on transition-path dynamics",
           "10.1088/2632-072x/accc69",
           2023,
           "\nWe propose an extension of the existing model describing a biomolecular reaction such as protein folding or ligand binding which is usually visualised as the barrier crossing of a diffusing particle in a double-well potential. In addition to the thermal noise, an active noise modelled in terms of an Ornstein–Uhlenbeck process is introduced to the dynamics. Within this framework, we investigate the transition-path properties of an underdamped particle surmounting an energy barrier, and we show explicitly how these properties are affected by the activity and persistence of the particle. Our theoretical study suggests that an active particle can cross the barrier at comparatively shorter timescales by lowering the (effective) barrier height. In particular, we study how the persistence time of the active force alters the transition-path time (TPT) at different friction limits. Interestingly, in one of our models we find a nonmonotonic behaviour of the TPT which is absent in the overdamped limit. The framework presented here can be useful in designing a reaction in a non-equilibrium environment, particularly inside a living biological cell in which active fluctuations keep the system out of equilibrium.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "Transient chaos in time-delayed systems subjected to parameter drift",
           "10.1088/2632-072x/abd67b",
           2020,
           "\nExternal and internal factors may cause a system’s parameter to vary with time before it stabilizes. This drift induces a regime shift when the parameter crosses a bifurcation. Here, we study the case of an infinite dimensional system: a time-delayed oscillator whose time delay varies at a small but non-negligible rate. Our research shows that due to this parameter drift, trajectories from a chaotic attractor tip to other states with a certain probability. This causes the appearance of the phenomenon of transient chaos. By using an ensemble approach, we find a gamma distribution of transient lifetimes, unlike in other non-delayed systems where normal distributions have been found to govern the process. Furthermore, we analyze how the parameter change rate influences the tipping probability, and we derive a scaling law relating the parameter value for which the tipping takes place and the lifetime of the transient chaos with the parameter change rate.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "Hierarchical coarse-grained approach to the duration-dependent spreading dynamics on complex networks",
           "10.1088/2632-072x/abde9f",
           2021,
           "\nVarious coarse-grained models have been proposed to study the spreading dynamics on complex networks. A microscopic theory is needed to connect the spreading dynamics with individual behaviors. In this letter, we unify the description of different spreading dynamics by decomposing the microscopic dynamics into two basic processes, the aging process and the contact process. A hierarchical duration coarse-grained (DCG) approach is proposed to study the duration-dependent processes. Applied to the epidemic spreading, such formalism is feasible to reproduce different epidemic models, e.g., the SIS and the SIR models, and to associate the macroscopic spreading parameters with the microscopic mechanism. The DCG approach enables us to study the steady state of the duration-dependent SIS model. The current hierarchical formalism can also be used to describe the spreading of information and public opinions, or to model a reliability theory on networks.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Learning capacity and function of stochastic reaction networks",
           "10.1088/2632-072x/acf264",
           2023,
           "\nBiochemical reaction networks are expected to encode an efficient representation of the function of cells in a variable environment. It is thus important to see how these networks do learn and implement such representations. The first step in this direction is to characterize the function and learning capabilities of basic artificial reaction networks. In this study, we consider multilayer networks of reversible reactions that connect two layers of signal and response species through an intermediate layer of hidden species. We introduce a stochastic learning algorithm that updates the reaction rates based on the correlation values between reaction products and responses. Our findings indicate that the function of networks with random reaction rates, as well as their learning capacity for random signal-response activities, are critically determined by the number of reactants and reaction products. Moreover, the stored patterns exhibit different levels of robustness and qualities as the reaction rates deviate from their optimal values in a stochastic model of defect evolution. These findings can help suggest network modules that are better suited to specific functions, such as amplifiers or dampeners, or to the learning of biologically relevant signal-response activities.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Subduing always defecting mutants by multiplayer reactive strategies: non-reciprocity versus generosity",
           "10.1088/2632-072x/ac4d10",
           2022,
           "\nA completely non-generous and reciprocal population of players can create a robust cooperating state that cannot be invaded by always defecting free riders if the interactions among players are repeated for long enough. However, strict non-generosity and strict reciprocity are ideal concepts, and may not even be desirable sometimes. Therefore, to what extent generosity or non-reciprocity can be allowed while still not be swamped by the mutants, is a natural question. In this paper, we not only ask this question but furthermore ask how generosity comparatively fares against non-reciprocity in this context. For mathematical concreteness, we work within the framework of multiplayer repeated prisoner’s dilemma game with reactive strategies in a finite and an infinite population; and explore the aforementioned questions through the effects of the benefit to cost ratio, the interaction group size, and the population size.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Controlling extended criticality via modular connectivity",
           "10.1088/2632-072x/ac202e",
           2021,
           "\nCriticality has been conjectured as an integral part of neuronal network dynamics. Operating at a critical threshold requires precise parameter tuning and a corresponding mechanism remains an open question. Recent studies have suggested that topological features observed in brain networks give rise to a Griffiths phase, leading to power-law scaling in brain activity dynamics and the operational benefits of criticality in an extended parameter region. Motivated by growing evidence of neural correlates of different states of consciousness, we investigate how topological changes affect the expression of a Griffiths phase. We analyze the activity decay in modular networks using a susceptible-infected-susceptible propagation model and find that we can control the extension of the Griffiths phase by altering intra- and intermodular connectivity. We find that by adjusting system parameters, we can counteract changes in critical behavior and maintain a stable critical region despite changes in network topology. Our results give insight into how structural network properties affect the emergence of a Griffiths phase and how its features are linked to established topological network metrics. We discuss how those findings could contribute to an understanding of the changes in functional brain networks.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "A reasoning of economic complexity based on simulated general equilibrium international trade model\n                  <sup>*</sup>",
           "10.1088/2632-072x/ace39e",
           2023,
           "\nBy simulating a multi-country general equilibrium international trade model, we investigate how the economic complexity index (ECI) and fitness index (FI) are related directly to economic fundamentals with a clear basis in theory. The model is based on Eaton and Kortum (2002 Econometrica\n70 1741–79) and combines factor endowment (Heckscher-Ohlin) and technological (Ricardian) reasons for specialization, which further determines economic complexity across countries. First, we find that FI performs better than ECI in explaining the real-world specialization pattern, where successful countries not only produce complex products due to the comparative advantage but also tend to produce a wide range of possible products due to the absolute advantage. Second, we highlight that the predictive power of various economic complexity measures for income is crucially sensitive to other factors that shift marginal cost from its efficient level in manufacturing sectors. The essence of such an issue lies in the assumption that the revealed comparative advantage (RCA) correctly reflects a country’s real capability of specialization across different goods. However, there would exist a gap between the core idea of learning the national complexity from RCA and the fact that the revealed specialization pattern in data may not necessarily suggest a country’s actual capability in the presence of distortions, the latter of which is ubiquitous across developing countries.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Thoughts on complex systems: an interview with Giorgio Parisi",
           "10.1088/2632-072x/ac9171",
           2023,
           "\nThe Nobel Laureate Giorgio Parisi is interviewed by JPhys Complexity Editor-in-Chief, Ginestra Bianconi, on themes related to the 2021 Nobel Prize in Physics awarded to him for research on complex systems.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Probing criticality in quantum spin chains with neural networks",
           "10.1088/2632-072x/abaa2b",
           2020,
           "\nThe numerical emulation of quantum systems often requires an exponential number of degrees of freedom which translates to a computational bottleneck. Methods of machine learning have been used in adjacent fields for effective feature extraction and dimensionality reduction of high-dimensional datasets. Recent studies have revealed that neural networks are further suitable for the determination of macroscopic phases of matter and associated phase transitions as well as efficient quantum state representation. In this work, we address quantum phase transitions in quantum spin chains, namely the transverse field Ising chain and the anisotropic XY chain, and show that even neural networks with no hidden layers can be effectively trained to distinguish between magnetically ordered and disordered phases. Our neural network acts to predict the corresponding crossovers finite-size systems undergo. Our results extend to a wide class of interacting quantum many-body systems and illustrate the wide applicability of neural networks to many-body quantum physics.",
           5,
           "journal_of_physics_complexity"
          ],
          [
           "Poisson-distributed noise induces cortical γ-activity: explanation of γ-enhancement by anaesthetics ketamine and propofol",
           "10.1088/2632-072x/ac4004",
           2021,
           "\nAdditive noise is known to affect the stability of nonlinear systems. To understand better the role of additive noise in neural systems, we investigate the impact of additive noise on a random neural network of excitatory and inhibitory neurons. Here we hypothesize that the noise originates from the ascending reticular activating system. Coherence resonance in the γ-frequency range emerges for intermediate noise levels while the network exhibits non-coherent activity at low and high noise levels. The analytical study of a corresponding mean-field model system explains the resonance effect by a noise-induced phase transition via a saddle-node bifurcation. An analytical study of the linear mean-field systems response to additive noise reveals that the coherent state exhibits a quasi-cycle in the γ-frequency range whose spectral properties are tuned by the additive noise. To illustrate the importance of the work, we show that the quasi-cycle explains γ-enhancement under impact of the anaesthetics ketamine and propofol as a destabilizing effect of the coherent state.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Complex systems are always correlated but rarely information processing",
           "10.1088/2632-072x/ac371c",
           2021,
           "\n‘Complex systems are information processors’ is a statement that is frequently made. Here we argue for the distinction between information processing—in the sense of encoding and transmitting a symbolic representation—and the formation of correlations (pattern formation/self-organisation). The study of both uses tools from information theory, but the purpose is very different in each case: explaining the mechanisms and understanding the purpose or function in the first case, versus data analysis and correlation extraction in the latter. We give examples of both and discuss some open questions. The distinction helps focus research efforts on the relevant questions in each case.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Klaus Hasselmann and Economics*",
           "10.1088/2632-072x/ac956e",
           2022,
           "\nKlaus Hasselmann has earned the 2021 Nobel Prize in physics for his breakthroughs in analysing the climate system as a complex physical system. Since decades, as a leading climate scientist he is aware of the need for creative cooperation between climate scientists and researchers from other fields, especially economics. To facilitate such cooperation, he has designed a productive research program for economic analysis in view of climate change. Without blurring the differences between economics and physics, the Hasselmann program stresses the complexities of today’s economy. This includes the importance of heterogeneous actors and different time scales, of making major uncertainties explicit and bringing researchers and practitioners in close interaction. The program has triggered decades of collaborative research, especially in the network of the Global Climate Forum, that he has founded for this purpose. Research inspired by Hasselmann’s innovative ideas has led to a farewell to outdated economic approaches: single-equilibrium models, a single constant discount rate, framing the climate challenge as a kind of prisoner’s dilemma and framing it as a problem of scarcity requiring sacrifices from the majority of today’s population. Instead of presenting the climate problem as the ultimate apocalyptic narrative, he sees it as a challenge to be mastered. To meet this challenge requires careful research in order to identify underutilisation of human, technical and social capacities that offer the keys to a climate friendly world economy. Climate neutrality may then be achieved by activating these capacities through investment-oriented climate strategies, designed and implemented by different actors both in industrialised and developing countries. The difficulties to bring global greenhouse gas emissions down to net zero are enormous; the Hasselmann program holds promise of significant advances in this endeavour.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Minor extensions of the logistic equation for growth curves of word counts on online media: parametric observation of diversity of growth in society",
           "10.1088/2632-072x/acda72",
           2023,
           "\nTo understand the growth phenomena in collective human systems, we analyzed monthly word count time series of new vocabularies extracted from approximately 1 billion Japanese blog articles from 2007 to 2019. In particular, we first introduced the extended logistic equation by adding one parameter to the original equation and showed that the model can consistently reproduce various patterns of actual growth curves, such as the logistic function, linear growth, and finite-time divergence. Second, by analyzing the model parameters, we found that the typical growth pattern is not only a logistic function, which often appears in various complex systems, but also a non-trivial growth curve that starts with an exponential function and asymptotically approaches a power function without a steady state. We also observed a connection between the functional form of growth and the peak-out behavior. Finally, we showed that the proposed model and statistical properties are also valid for Google Trends data (English, French, Spanish, and Japanese), which is a time series of the nationwide popularity of search queries.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Multiplex mobility network and metapopulation epidemic simulations of Italy based on open data",
           "10.1088/2632-072x/ac9a29",
           2022,
           "\nThe patterns of human mobility play a key role in the spreading of infectious diseases and thus represent a key ingredient of epidemic modeling and forecasting. Unfortunately, as the Covid-19 pandemic has dramatically highlighted, for the vast majority of countries there is no availability of granular mobility data. This hinders the possibility of developing computational frameworks to monitor the evolution of the disease and to adopt timely and adequate prevention policies. Here we show how this problem can be addressed in the case study of Italy. We build a multiplex mobility network based solely on open data, and implement an susceptible-infected-recovered (SIR) metapopulation model that allows scenario analysis through data-driven stochastic simulations. The mobility flows that we estimate are in agreement with real-time proprietary data from smartphones. Our modeling approach can thus be useful in contexts where high-resolution mobility data is not available.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Transient effects in the decay of a normally hyperbolic invariant manifold",
           "10.1088/2632-072x/abc78f",
           2020,
           "\nThis article presents a new version of transient behaviour occurring around the remnants of normally hyperbolic invariant manifolds (NHIMs) when they are already in the process of decay. If in such a situation a chaotic region of the NHIM is in the process of decay, then typical trajectories starting in this chaotic region remain in this region for a finite time only and will leave the neighbourhood of the NHIM in the long run in tangential direction. Therefore this chaotic region has a transient existence only as remainder of the NHIM. Numerical examples of this phenomenon are presented for a three degrees of freedom (3-dof) model for the motion of a test particle in the gravitational field of a rotating barred galaxy.",
           3,
           "journal_of_physics_complexity"
          ],
          [
           "From single layer to multilayer networks in mild cognitive impairment and Alzheimer’s disease",
           "10.1088/2632-072x/ac3ddd",
           2021,
           "\nWe investigate the alterations of functional networks of patients suffering from mild cognitive impairment and Alzheimer’s disease (AD) when compared to healthy individuals. Departing from the magnetoencephalographic recordings of these three groups, we construct and analyse the corresponding single layer functional networks at different frequency bands, both at the sensors and the regions of interest (ROI) levels. Different network parameters show statistically significant differences, with global efficiency being the one having the most pronounced differences between groups. Next, we extend the analyses to the frequency-band multilayer networks (MN) of the same dataset. Using the mutual information as a metric to evaluate the coordination between brain regions, we construct the αβ MN and analyse their algebraic connectivity at baseline λ\n2−BSL\n (i.e., the second smallest eigenvalue of the corresponding Laplacian matrices). We report statistically significant differences at the sensor level, despite the fact that these differences are not clearly observed when networks are obtained at the ROIs level (i.e., after a source reconstruction procedure). Next, we modify the weights of the inter-links of the multilayer network to identify the value of the algebraic connectivity λ\n2−T\n leading to a transition where layers can be considered to be fully merged. However, differences between the values of λ\n2−T\n of the three groups are not statistically significant. Finally, we developed nested multinomial logistic regression models (MNR models), with the aim of predicting group labels with the parameters extracted from the MN (λ\n2−BSL\n and λ\n2−T\n). Using these models, we are able to quantify how age influences the risk of suffering AD and how the algebraic connectivity of frequency-based multilayer functional networks could be used as a biomarker of AD in clinical contexts.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "New features of doubly transient chaos: complexity of decay",
           "10.1088/2632-072x/abedc3",
           2021,
           "In dissipative systems without any driving or positive feedback all motion stops ultimately since the initial kinetic energy is dissipated away during time evolution. If chaos is present, it can only be of transient type. Traditional transient chaos is, however, supported by an infinity of unstable orbits. In the lack of these, chaos in undriven dissipative systems is of another type: it is termed doubly transient chaos as the strength of transient chaos is diminishing in time, and ceases asymptotically. Here we show that a clear view of such dynamics is provided by identifying KAM tori or chaotic regions of the dissipation-free case, and following their time evolution in the dissipative dynamics. The tori often smoothly deform first, but later they become disintegrated and dissolve in a kind of shrinking chaos. We identify different dynamical measures for the characterization of this process which illustrate that the strength of chaos is first diminishing, and after a while disappears, the motion enters the phase of ultimate stopping.",
           5,
           "journal_of_physics_complexity"
          ],
          [
           "Emergence of long-range correlations in random networks",
           "10.1088/2632-072x/abb4c5",
           2020,
           "\nWe perform an analysis of the long-range degree correlation of the giant component (GC) in an uncorrelated random network by employing generating functions. By introducing a characteristic length, we find that a pair of nodes in the GC is negatively degree-correlated within the characteristic length and uncorrelated otherwise. At the critical point, where the GC becomes fractal, the characteristic length diverges and the negative long-range degree correlation emerges. We further propose a correlation function for degrees of two nodes separated by the shortest path length l, which behaves as an exponentially decreasing function of distance in the off-critical region. The correlation function obeys a power-law with an exponential cutoff near the critical point. The Erdős-Rényi random graph is employed to confirm this critical behavior.",
           5,
           "journal_of_physics_complexity"
          ],
          [
           "No-boarding buses: agents allowed to cooperate or defect",
           "10.1088/2632-072x/ab4af5",
           2020,
           "\nWe study a bus system with a no-boarding policy, where a ‘slow’ bus may disallow passengers from boarding if it meets some criteria. When the no-boarding policy is activated, people waiting to board at the bus stop are given the choices of cooperating or defecting. The people’s heterogeneous behaviours are modelled by inductive reasoning and bounded rationality, inspired by the El Farol problem and the minority game. In defecting the no-boarding policy, instead of the minority group being the winning group, we investigate several scenarios where defectors win if the number of defectors does not exceed the maximum number of allowed defectors but lose otherwise. Contrary to the classical minority game which has N agents repeatedly playing amongst themselves, many real-world situations like boarding a bus involves only a subset of agents who ‘play each round’, with different subsets playing at different rounds. We find for such realistic situations, there is no phase transition with no herding behaviour when the usual control paramater 2\nm\n/N is small. The absence of the herding behaviour assures feasible and sustainable implementation of the no-boarding policy with allowance for defections, without leading to bus bunching.",
           8,
           "journal_of_physics_complexity"
          ],
          [
           "Computational behavioral models in public goods games with migration between groups",
           "10.1088/2632-072x/ac371b",
           2021,
           "\nIn this study we have simulated numerically two models of linear public goods games where players are equally distributed among a given number of groups. Agents play in their group by using two simple sets of rules, called ‘blind’ and ‘rational’ model, respectively, that are inspired by the observed behavior of human participants in laboratory experiments. In addition, unsatisfied agents have the option of leaving their group and migrating to a new random one through probabilistic choices. Stochasticity, and the introduction of two types of players in the blind model, help simulate the heterogeneous behavior that is often observed in experimental work. Our numerical simulations of the corresponding dynamical systems show that being able to leave a group when unsatisfied favors contribution and avoids free-riding to a good extent in a range of the enhancement factor where defection would prevail without migration. Our numerical simulation presents results that are qualitatively in line with known experimental data when human agents are given the same kind of information about themselves and the other players in the group. This is usually not the case with customary mathematical models based on replicator dynamics or stochastic approaches. As a consequence, models like the ones described here may be useful for understanding experimental results and also for designing new experiments by first running cheap computational simulations instead of doing costly preliminary laboratory work. The downside is that models and their simulation tend to be less general than standard mathematical approaches.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Smallworldness in hypergraphs",
           "10.1088/2632-072x/acf430",
           2023,
           "\nMost real-world networks are endowed with the small-world property, by means of which the maximal distance between any two of their nodes scales logarithmically rather than linearly with their size. The evidence sparkled a wealth of studies trying to reveal possible mechanisms through which the pairwise interactions amongst the units of a network are structured in a way to determine such observed regularity. Here we show that smallworldness occurs also when interactions are of higher order. Namely, by considering Q-uniform hypergraphs and a process through which connections can be randomly rewired with given probability p, we find that such systems may exhibit prominent clustering properties in connection with small average path lengths for a wide range of p values, in analogy to the case of dyadic interactions. The nature of small-world transition remains the same at different orders Q (\n\n\n\n=\n\n2\n,\n3\n,\n4\n,\n5\n,\n\n\n and 6) of the interactions, however, the increase in the hyperedge order reduces the range of rewiring probability for which smallworldness emerge.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "A controlled transfer entropy approach to detect asymmetric interactions in heterogeneous systems",
           "10.1088/2632-072x/acde2d",
           2023,
           "\nTransfer entropy is emerging as the statistical approach of choice to support the inference of causal interactions in complex systems from time-series of their individual units. With reference to a simple dyadic system composed of two coupled units, the successful application of net transfer entropy-based inference relies on unidirectional coupling between the units and their homogeneous dynamics. What happens when the units are bidirectionally coupled and have different dynamics? Through analytical and numerical insights, we show that net transfer entropy may lead to erroneous inference of the dominant direction of influence that stems from its dependence on the units’ individual dynamics. To control for these confounding effects, one should incorporate further knowledge about the units’ time-histories through the recent framework offered by momentary information transfer. In this realm, we demonstrate the use of two measures: controlled and fully controlled transfer entropies, which consistently yield the correct direction of dominant coupling irrespective of the sources and targets individual dynamics. Through the study of two real-world examples, we identify critical limitations with respect to the use of net transfer entropy in the inference of causal mechanisms that warrant prudence by the community.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Analysis of the structural complexity of Crab Nebula observed at radio frequency using a multifractal approach",
           "10.1088/2632-072x/ad1e83",
           2024,
           "\nThe Crab Nebula is an astrophysical system that exhibits complex morphological patterns at different observing frequencies. We carry out a systematic investigation of the structural complexity of the nebula using publicly available imaging data at radio frequency. For the analysis, we use the well-known multifractal detrended fluctuation analysis in two dimensions. We find that radio data exhibit long-range correlations, as expected from the underlying physics of the supernova explosion and evolution. The correlations follow a power-law scaling with length scales. The structural complexity is found to be multifractal in nature, as evidenced by the dependence of the generalized Hurst exponent on the order of the moments of the detrended fluctuation function. By repeating the analysis on shuffled data, we further probe the origin of the multifractality in the radio imaging data. For the radio data, we find that the probability density function is close to a Gaussian form. Hence, the multifractal behavior is due to the differing nature of long-range correlations of the large and small detrended fluctuation field values. We investigate the multifractal parameters across different partitions of the radio image and find that the structures across the image are highly heterogeneous, making the Crab Nebula a structurally complex astrophysical system. Our analysis thus provides a fresh perspective on the morphology of the Crab Nebula from a complexity science viewpoint.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Quantifying the hierarchical adherence of modular documents",
           "10.1088/2632-072x/ad0a9b",
           2023,
           "\nSeveral natural and artificial structures are characterized by an intrinsic hierarchical organization. The present work describes a methodology for quantifying the degree of adherence between a given hierarchical template and a respective modular document (e.g. books or homepages with content organized into modules) organized as a respective content network. The original document, which in the case of the present work concerns Wikipedia pages, is transformed into a respective content network by first dividing the document into parts or modules. Then, the contents (words) of each pair of modules are compared in terms of the coincidence similarity index, yielding a respective weight. The adherence between the hierarchical template and the content network can then be measured by considering the coincidence similarity between the respective adjacency matrices, leading to the respective hierarchical adherence index. In order to provide additional information about this adherence, four specific indices are also proposed, quantifying the number of links between non-adjacent levels, links between nodes in the same level, converging links between adjacent levels, and missing links. The potential of the approach is illustrated respectively to model-theoretical networks as well as to real-world data obtained from Wikipedia. In addition to confirming the effectiveness of the suggested concepts and methods, the results suggest that real-world documents do not tend to substantially adhere to respective hierarchical templates.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "The stochastic nature of power-grid frequency in South Africa",
           "10.1088/2632-072x/acb629",
           2023,
           "In this work, we explore two mechanisms that explain non-Gaussian behaviour of power-grid frequency recordings in the South African grid. We make use of a Fokker–Planck approach to power-grid frequency that yields a direct relation between common model parameters such as inertia, damping, and noise amplitude and non-parametric estimations of the same directly from power-grid frequency recordings. We propose two explanations for the non-Gaussian leptokurtic distributions in South Africa: the first based on multiplicative noise in power-grid frequency recordings, which we observe in South Africa; the second based on the well-known scheduled and unscheduled load shedding and rolling blackouts that beset South Africa. For the first we derive an analytic expression of the effects of multiplicative noise that permits the estimation of all statistical moments—and discuss drawbacks in comparison with the data; for the second we employ a simple numerical analysis with a modular power grid of South Africa. Both options help understand the statistics of power-grid frequency in South Africa—particularly the presence of heavy tails.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "From statistical physics to social sciences: the pitfalls of multi-disciplinarity",
           "10.1088/2632-072x/ad104a",
           2023,
           "\nThis is the English version of my inaugural lecture at Collège de France in 2021. I reflect on the difficulty of multi-disciplinary research, which often hinges on unexpected epistemological and methodological differences, for example about the scientific status of models. What is the purpose of a model? What are we ultimately trying to establish: rigorous theorems or ad-hoc calculation recipes; absolute truth, or heuristic representations of the world? I argue that the main contribution of statistical physics to social and economic sciences is to make us realise that unexpected behaviour can emerge at the aggregate level, that isolated individuals would never experience. Crises, panics, opinion reversals, the spread of rumours or beliefs, fashion effects and the zeitgeist, but also the existence of money, lasting institutions, social norms and stable societies, must be understood in terms of collective belief and/or trust, self-sustained by interactions, or on the contrary, the rapid collapse of this belief or trust. The appendix contains my opening remarks to the workshop ‘More is Different’, as a tribute to Phil Anderson.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "First passage dynamics of stochastic motion in heterogeneous media driven by correlated white Gaussian and coloured non-Gaussian noises",
           "10.1088/2632-072x/ac35b5",
           2021,
           "\nWe study the first passage dynamics for a diffusing particle experiencing a spatially varying diffusion coefficient while driven by correlated additive Gaussian white noise and multiplicative coloured non-Gaussian noise. We consider three functional forms for position dependence of the diffusion coefficient: power-law, exponential, and logarithmic. The coloured non-Gaussian noise is distributed according to Tsallis’ q-distribution. Tracks of the non-Markovian systems are numerically simulated by using the fourth-order Runge–Kutta algorithm and the first passage times (FPTs) are recorded. The FPT density is determined along with the mean FPT (MFPT). Effects of the noise intensity and self-correlation of the multiplicative noise, the intensity of the additive noise, the cross-correlation strength, and the non-extensivity parameter on the MFPT are discussed.",
           6,
           "journal_of_physics_complexity"
          ],
          [
           "Mitigation of adversarial attacks on voter model dynamics by network heterogeneity",
           "10.1088/2632-072x/acd296",
           2023,
           "\nVoter model dynamics in complex networks are vulnerable to adversarial attacks. In particular, the voting outcome can be inverted by adding extremely small perturbations that are strategically generated in social networks, even when one opinion is dominant over the other. However, the mitigation of adversarial attacks on the voter model dynamics in complex networks has not been thoroughly investigated. Thus, we examined network structures that could mitigate adversarial attacks using model networks and real-world networks, considering that the network structure affects the voter model dynamics. Numerical simulations demonstrated that the heterogeneity of node degrees in the networks (degree heterogeneity) significantly mitigates adversarial attacks. In particular, for complex networks with a power-law degree distribution \n\n\nP\n(\nk\n)\n∼\n\nk\n\n−\nγ\n\n\n\n\n, the mitigation effect is significant for \n\n\n\nγ\n⩽\n3\n\n\n\n. However, the mitigation effect of the degree heterogeneity was relatively weak for large and dense networks. The degree correlation and clustering in the networks exhibited almost no mitigation effect. The results enhance our understanding of how opinion dynamics and collective decision-making are distorted in social networks and may be useful for considering defense strategies against adversarial attacks.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Tree decompositions of real-world networks from simulated annealing",
           "10.1088/2632-072x/ab9d2f",
           2020,
           "\nDecompositions of networks are useful not only for structural exploration. They also have implications and use in analysis and computational solution of processes (such as the Ising model, percolation, SIR model) running on a given network. Tree and branch decompositions considered here directly represent network structure as trees for recursive computation of network properties. Unlike coarse-graining approximations in terms of community structure or metapopulations, tree decompositions of sufficiently small width allow for exact results on equilibrium processes. Here we use simulated annealing to find tree decompositions of narrow width for a set of medium-size empirical networks. Rather than optimizing tree decompositions directly, we employ a search space constituted by so-called elimination orders being permutations on the network’s node set. For each in a database of empirical networks with up to 1000 edges, we find a tree decomposition of low width.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Representative methods of computational socioeconomics",
           "10.1088/2632-072x/ac2072",
           2021,
           "\nThe increasing availability of data sources and analysis tools borrowed from computer science and physical science have sharply changed traditional methodologies of social sciences, leading to a new branch named computational socioeconomics, which studies various phenomena in socioeconomic development by using quantitative methods based on large-scale real-world data. Sited on recent publications, this perspective will introduce three representative methods: (i) natural data analyses, (ii) large-scale online experiments, and (iii) integration of big data and surveys. This perspective ends up with in-depth discussion on the limitations and challenges of the above-mentioned emerging methods.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Taming travel time fluctuations through adaptive stop pooling",
           "10.1088/2632-072x/ad370a",
           2024,
           "\nRide sharing services combine trips of multiple users in the same vehicle and may provide more sustainable transport than private cars. As mobility demand varies during the day, the travel times experienced by passengers may substantially vary as well, making the service quality unreliable. We show through model simulations that such travel time fluctuations may be drastically reduced by stop pooling. Having users walk to meet at joint locations for pick-up or drop-off allows buses to travel more direct routes by avoiding frequent door-to-door detours, especially during high demand. We in particular propose adaptive stop pooling by adjusting the maximum walking distance to the temporally and spatially varying demand. The results highlight that adaptive stop pooling may substantially reduce travel time fluctuations while even improving the average travel time of ride sharing services, especially for high demand. Such quality improvements may in turn increase the acceptance and adoption of ride sharing services.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Encapsulation structure and dynamics in hypergraphs",
           "10.1088/2632-072x/ad0b39",
           2023,
           "\nHypergraphs have emerged as a powerful modeling framework to represent systems with multiway interactions, that is systems where interactions may involve an arbitrary number of agents. Here we explore the properties of real-world hypergraphs, focusing on the encapsulation of their hyperedges, which is the extent that smaller hyperedges are subsets of larger hyperedges. Building on the concept of line graphs, our measures quantify the relations existing between hyperedges of different sizes and, as a byproduct, the compatibility of the data with a simplicial complex representation–whose encapsulation would be maximum. We then turn to the impact of the observed structural patterns on diffusive dynamics, focusing on a variant of threshold models, called encapsulation dynamics, and demonstrate that non-random patterns can accelerate the spreading in the system.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "The impact of chaotic saddles on the synchronization of complex networks of discrete-time units",
           "10.1088/2632-072x/abedc2",
           2021,
           "\nA chaotic saddle is a common nonattracting chaotic set well known for generating finite-time chaotic behavior in low and high-dimensional systems. In general, dynamical systems possessing chaotic saddles in their state-space exhibit irregular behavior with duration lengths following an exponential distribution. However, when these systems are coupled into networks the chaotic saddle plays a role in the long-term dynamics by trapping network trajectories for times that are indefinitely long. This process transforms the network’s high-dimensional state-space by creating an alternative persistent desynchronized state coexisting with the completely synchronized one. Such coexistence threatens the synchronized state with vulnerability to external perturbations. We demonstrate the onset of this phenomenon in complex networks of discrete-time units in which the synchronization manifold is perturbed either in the initial instant of time or in arbitrary states of its asymptotic dynamics. The role of topological asymmetries of Erdös–Rényi and Barabási–Albert graphs are investigated. Besides, the required coupling strength for the occurrence of trapping in the chaotic saddle is unveiled.",
           8,
           "journal_of_physics_complexity"
          ],
          [
           "Effects of topological structure and destination selection strategies on agent dynamics in complex networks",
           "10.1088/2632-072x/ad2971",
           2024,
           "\nWe analyzed agent behavior in complex networks: Barabási–Albert, Erdos–Rényi, and Watts–Strogatz models under the following rules: agents (a) randomly select a destination among adjacent nodes; (b) exclude the most congested adjacent node as a potential destination and randomly select a destination among the remaining nodes; or (c) select the sparsest adjacent node as a destination. We focused on small complex networks with node degrees ranging from zero to a maximum of approximately 20 to study agent behavior in traffic and transportation networks. We measured the hunting rate, that is, the rate of change of agent amounts in each node per unit of time, and the imbalance of agent distribution among nodes. Our simulation study reveals that the topological structure of a network precisely determines agent distribution when agents perform full random walks; however, their destination selections alter the agent distribution. Notably, rule (c) makes hunting and imbalance rates significantly high compared with random walk cases (a) and (b), irrespective of network types, when the network has a high degree and high activity rate. Compared with the full random walk in (a) and (b) increases the hunting rate while decreasing the imbalance rate when activity is low; however, both increase when activity is high. These characteristics exhibit slight periodic undulations over time. Furthermore, our analysis shows that in the BA, ER, and WS network models, the hunting rate decreases and the imbalance rate increases when the system disconnects randomly selected nodes in simulations where agents follow rules (a)–(c) and the network has the ability to disconnect nodes within a certain time of all time steps. Our findings can be applied to various applications related to agent dynamics in complex networks.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Bounded rationality and animal spirits: a fluctuation-response approach to Slutsky matrices",
           "10.1088/2632-072x/acb0a7",
           2023,
           "\nThe Slutsky equation, central in consumer choice theory, is derived from the usual hypotheses underlying most standard models in Economics, such as full rationality, homogeneity, and absence of interactions. We present a statistical physics framework that allows us to relax such assumptions. We first derive a general fluctuation-response formula that relates the Slutsky matrix to spontaneous fluctuations of consumption rather than to response to changing prices and budget. We then show that, within our hypotheses, the symmetry of the Slutsky matrix remains valid even when agents are only boundedly rational but non-interacting. We finally propose an ‘animal spirit’ model where agents are influenced by the choice of others, leading to a phase transition beyond which consumption is dominated by herding (or ‘fashion’) effects. In this case, the individual Slutsky matrix is no longer symmetric, even for fully rational agents. The vicinity of the transition features a peak in asymmetry.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Group polarization, influence, and domination in online interaction networks: a case study of the 2022 Brazilian elections",
           "10.1088/2632-072x/acf6a4",
           2023,
           "\nThe erosion of social cohesion and polarization is one of the topmost societal risks. In this work, we investigated the evolution of polarization, influence, and domination in online interaction networks using a large Twitter dataset collected before and during the 2022 Brazilian elections. From a theoretical perspective, we develop a methodology called d-modularity that allows discovering the contribution of specific groups to network polarization using the well-known modularity measure. While the overall network modularity (somewhat unexpectedly) decreased, the proposed group-oriented approach reveals that the contribution of the right-leaning community to this modularity increased, remaining very high during the analyzed period. Our methodology is general enough to be used in any situation when the contribution of specific groups to overall network modularity and polarization is needed to investigate. Moreover, using the concept of partial domination, we are able to compare the reach of sets of influential profiles from different groups and their ability to accomplish coordinated communication inside their groups and across segments of the entire network. We show that in the whole network, the left-leaning high-influential information spreaders dominated, reaching a substantial fraction of users with fewer spreaders. However, when comparing domination inside the groups, the results are inverse. Right-leaning spreaders dominate their communities using few nodes, showing as the most capable of accomplishing coordinated communication. The results bring evidence of extreme isolation and the ease of accomplishing coordinated communication that characterized right-leaning communities during the 2022 Brazilian elections, which likely influenced the subsequent coup events in Brasilia.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Mean-field theory of vector spin models on networks with arbitrary degree distributions",
           "10.1088/2632-072x/ac4bed",
           2022,
           "\nUnderstanding the relationship between the heterogeneous structure of complex networks and cooperative phenomena occurring on them remains a key problem in network science. Mean-field theories of spin models on networks constitute a fundamental tool to tackle this problem and a cornerstone of statistical physics, with an impressive number of applications in condensed matter, biology, and computer science. In this work we derive the mean-field equations for the equilibrium behavior of vector spin models on high-connectivity random networks with an arbitrary degree distribution and with randomly weighted links. We demonstrate that the high-connectivity limit of spin models on networks is not universal in that it depends on the full degree distribution. Such nonuniversal behavior is akin to a remarkable mechanism that leads to the breakdown of the central limit theorem when applied to the distribution of effective local fields. Traditional mean-field theories on fully-connected models, such as the Curie–Weiss, the Kuramoto, and the Sherrington–Kirkpatrick model, are only valid if the network degree distribution is highly concentrated around its mean degree. We obtain a series of results that highlight the importance of degree fluctuations to the phase diagram of mean-field spin models by focusing on the Kuramoto model of synchronization and on the Sherrington–Kirkpatrick model of spin-glasses. Numerical simulations corroborate our theoretical findings and provide compelling evidence that the present mean-field theory describes an intermediate regime of connectivity, in which the average degree c scales as a power c ∝ N\n\nb\n (b < 1) of the total number N ≫ 1 of spins. Our findings put forward a novel class of spin models that incorporate the effects of degree fluctuations and, at the same time, are amenable to exact analytic solutions.",
           5,
           "journal_of_physics_complexity"
          ],
          [
           "Hyperharmonic analysis for the study of high-order information-theoretic signals",
           "10.1088/2632-072x/abf231",
           2021,
           "\nNetwork representations often cannot fully account for the structural richness of complex systems spanning multiple levels of organisation. Recently proposed high-order information-theoretic signals are well-suited to capture synergistic phenomena that transcend pairwise interactions; however, the exponential-growth of their cardinality severely hinders their applicability. In this work, we combine methods from harmonic analysis and combinatorial topology to construct efficient representations of high-order information-theoretic signals. The core of our method is the diagonalisation of a discrete version of the Laplace–de Rham operator, that geometrically encodes structural properties of the system. We capitalise on these ideas by developing a complete workflow for the construction of hyperharmonic representations of high-order signals, which is applicable to a wide range of scenarios.",
           5,
           "journal_of_physics_complexity"
          ],
          [
           "Dynamical systems on hypergraphs",
           "10.1088/2632-072x/aba8e1",
           2020,
           "\nNetworks are a widely used and efficient paradigm to model real-world systems where basic units interact pairwise. Many body interactions are often at play, and cannot be modelled by resorting to binary exchanges. In this work, we consider a general class of dynamical systems anchored on hypergraphs. Hyperedges of arbitrary size ideally encircle individual units so as to account for multiple, simultaneous interactions. These latter are mediated by a combinatorial Laplacian, that is here introduced and characterised. The formalism of the master stability function is adapted to the present setting. Turing patterns and the synchronisation of non linear (regular and chaotic) oscillators are studied, for a general class of systems evolving on hypergraphs. The response to externally imposed perturbations bears the imprint of the higher order nature of the interactions.",
           42,
           "journal_of_physics_complexity"
          ],
          [
           "Equivalence between the Fitness-Complexity and the Sinkhorn-Knopp algorithms",
           "10.1088/2632-072x/ad2697",
           2024,
           "\nWe uncover the connection between the Fitness-Complexity algorithm, developed in the economic complexity field, and the Sinkhorn–Knopp algorithm, widely used in diverse domains ranging from computer science and mathematics to economics. Despite minor formal differences between the two methods, both converge to the same fixed-point solution up to normalization. The discovered connection allows us to derive a rigorous interpretation of the Fitness and the Complexity metrics as the potentials of a suitable energy function. Under this interpretation, high-energy products are unfeasible for low-fitness countries, which explains why the algorithm is effective at displaying nested patterns in bipartite networks. We also show that the proposed interpretation reveals the scale invariance of the Fitness-Complexity algorithm, which has practical implications for the algorithm’s implementation in different datasets. Further, analysis of empirical trade data under the new perspective reveals three categories of countries that might benefit from different development strategies.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Global synchronization on time-varying higher-order structures",
           "10.1088/2632-072x/ad3262",
           2024,
           "\nSynchronization has received a lot of attention from the scientific community for systems evolving on static networks or higher-order structures, such as hypergraphs and simplicial complexes. In many relevant real-world applications, the latter are not static but do evolve in time, in this work we thus discuss the impact of the time-varying nature of higher-order structures in the emergence of global synchronization. To achieve this goal, we extend the master stability formalism to account, in a general way, for the additional contributions arising from the time evolution of the higher-order structure supporting the dynamical systems. The theory is successfully challenged against two illustrative examples, the Stuart–Landau nonlinear oscillator and the Lorenz chaotic oscillator.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "The Euler characteristic and topological phase transitions in complex systems",
           "10.1088/2632-072x/ac664c",
           2022,
           "In this work, we use methods and concepts of applied algebraic topology to comprehensively explore the recent idea of topological phase transitions (TPTs) in complex systems. TPTs are characterized by the emergence of nontrivial homology groups as a function of a threshold parameter. Under certain conditions, one can identify TPTs via the zeros of the Euler characteristic or by singularities of the Euler entropy. Recent works provide strong evidence that TPTs can be interpreted as the intrinsic fingerprint of a complex network. This work illustrates this possibility by investigating various networks from a topological perspective. We first review the concept of TPTs in brain networks and discuss it in the context of high-order interactions in complex systems. We then investigate TPTs in protein–protein interaction networks using methods of topological data analysis for two variants of the duplication–divergence model. We compare our theoretical and computational results to experimental data freely available for gene co-expression networks ofS. cerevisiae, also known as baker’s yeast, as well as of the nematodeC. elegans. Supporting our theoretical expectations, we can detect TPTs in both networks obtained according to different similarity measures. We then perform numerical simulations of TPTs in four classical network models: the Erdős–Rényi, the Watts–Strogatz, the random geometric, and the Barabasi–Albert models. Finally, we discuss the relevance of these insights for network science. Given the universality and wide use of those network models across disciplines, our work indicates that TPTs permeate a wide range of theoretical and empirical networks, offering promising avenues for further research.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "Can x2vec save lives? Integrating graph and language embeddings for automatic mental health classification",
           "10.1088/2632-072x/aba83d",
           2020,
           "\nGraph and language embedding models are becoming commonplace in large scale analyses given their ability to represent complex sparse data densely in low-dimensional space. Integrating these models’ complementary relational and communicative data may be especially helpful if predicting rare events or classifying members of hidden populations—tasks requiring huge and sparse datasets for generalizable analyses. For example, due to social stigma and comorbidities, mental health support groups often form in amorphous online groups. Predicting suicidality among individuals in these settings using standard network analyses is prohibitive due to resource limits (e.g., memory), and adding auxiliary data like text to such models exacerbates complexity- and sparsity-related issues. Here, I show how merging graph and language embedding models (metapath2vec and doc2vec) avoids these limits and extracts unsupervised clustering data without domain expertise or feature engineering. Graph and language distances to a suicide support group have little correlation (ρ < 0.23), implying the two models are not embedding redundant information. When used separately to predict suicidality among individuals, graph and language data generate relatively accurate results (69% and 76%, respectively) but have moderately large false-positive (25% and 21%, respectively) and false-negative (38% and 27%, respectively) rates; however, when integrated, both data produce highly accurate predictions (90%, with 10% false-positives and 12% false-negatives). Visualizing graph embeddings annotated with predictions of potentially suicidal individuals shows the integrated model could classify such individuals even if they are positioned far from the support group. These results extend research on the importance of simultaneously analyzing behavior and language in massive networks and efforts to integrate embedding models for different kinds of data when predicting and classifying, particularly when they involve rare events.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Spiral wave chimera states in regular and fractal neuronal networks",
           "10.1088/2632-072x/abcd14",
           2020,
           "\nChimera states are spatial patterns in which coherent and incoherent patterns coexist. It was reported that small populations of coupled oscillators can exhibit chimera with transient nature. This spatial coexistence has been observed in various network topologies of coupled systems, such as coupled pendula, coupled chemical oscillators, and neuronal networks. In this work, we build two-dimensional neuronal networks with regular and fractal topologies to study chimera states. In the regular network, we consider a coupling between the nearest neighbours neurons, while the fractal network is constructed according to the square Cantor set. Our networks are composed of coupled adaptive exponential integrate-and-fire neurons, that can exhibit spike or burst activities. Depending on the parameters, we find spiral wave chimeras in both regular and fractal networks. The spiral wave chimeras arise for different values of the intensity of the excitatory synaptic conductance. In our simulations, we verify the existence of multicore chimera states. The cores are made up of neurons with desynchronous behaviour and the spiral waves rotates around them. The cores can be related to bumps or spatially localised pulses of neuronal activities. We also show that the initial value of the adaptation current plays an important role in the existence of spiral wave chimera states.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "Syndication network associates with specialisation and performance of venture capital firms",
           "10.1088/2632-072x/acd6cc",
           2023,
           "\nThe Chinese venture capital (VC) market is a young and rapidly expanding financial subsector. Gaining a deeper understanding of the investment behaviours of VC firms is crucial for the development of a more sustainable and healthier market and economy. Contrasting evidence supports that either specialisation or diversification helps to achieve a better investment performance. However, the impact of the syndication network is overlooked. Syndication network has a great influence on the propagation of information and trust. By exploiting an authoritative VC dataset of thirty-five-year investment information in China, we construct a joint-investment network of VC firms and analyse the effects of syndication and diversification on specialisation and investment performance. There is a clear correlation between the syndication network degree and specialisation level of VC firms, which implies that the well-connected VC firms are diversified. More connections generally bring about more information or other resources, and VC firms are more likely to enter a new stage or industry with some new co-investing VC firms when compared to a randomised null model.&#xD;Moreover, autocorrelation analysis of both specialisation and success rate on the syndication network indicates that clustering of similar VC firms is roughly limited to the secondary neighbourhood. When analysing local clustering patterns, we discover that, contrary to popular beliefs, there is no apparent successful club of investors. In contrast, investors with low success rates are more likely to cluster. Our discoveries enrich the understanding of VC investment behaviours and can assist policymakers in designing better strategies to promote the development of the VC industry.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Contact tracing in configuration models",
           "10.1088/2632-072x/abd3ad",
           2020,
           "\nQuarantining and contact tracing are popular ad hoc practices for mitigating epidemic outbreaks. However, few mathematical theories are currently available to asses the role of a network in the effectiveness of these practices. In this paper, we study how the final size of an epidemic is influenced by the procedure that combines contact tracing and quarantining on a network null model: the configuration model. Namely, we suppose that infected vertices may self-quarantine and trace their infector with a given success probability. A traced infector is, in turn, less likely to infect others. We show that the effectiveness of such tracing process strongly depends on the network structure. In contrast to previous findings, the tracing procedure is not necessarily more effective on networks with heterogeneous degrees. We also show that network clustering influences the effectiveness of the tracing process in a non-trivial way: depending on the infectiousness parameter, contact tracing on clustered networks may either be more, or less efficient than on networks without clustering.",
           6,
           "journal_of_physics_complexity"
          ],
          [
           "Evolutionary dynamics of Bertrand duopoly",
           "10.1088/2632-072x/abed37",
           2021,
           "\nDuopolies are one of the simplest economic situations where interactions between firms determine market behavior. The standard model of a price-setting duopoly is the Bertrand model, which has the unique solution that both firms set their prices equal to their costs—a paradoxical result where both firms obtain zero profit, which is generally not observed in real market duopolies. Here we propose a new game theory model for a price-setting duopoly, which we show resolves the paradoxical behavior of the Bertrand model and provides a consistent general model for duopolies.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Network-based ranking in social systems: three challenges",
           "10.1088/2632-072x/ab8a61",
           2020,
           "\nRanking algorithms are pervasive in our increasingly digitized societies, with important real-world applications including recommender systems, search engines, and influencer marketing practices. From a network science perspective, network-based ranking algorithms solve fundamental problems related to the identification of vital nodes for the stability and dynamics of a complex system. Despite the ubiquitous and successful applications of these algorithms, we argue that our understanding of their performance and their applications to real-world problems face three fundamental challenges: (1) rankings might be biased by various factors; (2) their effectiveness might be limited to specific problems; and (3) agents’ decisions driven by rankings might result in potentially vicious feedback mechanisms and unhealthy systemic consequences. Methods rooted in network science and agent-based modeling can help us to understand and overcome these challenges.",
           4,
           "journal_of_physics_complexity"
          ],
          [
           "Visibility graphs of animal foraging trajectories",
           "10.1088/2632-072x/aca949",
           2022,
           "\nThe study of self-propelled particles is a fast growing research topic where biological inspired movement is increasingly becoming of much interest. A relevant example is the collective motion of social insects, whose variety and complexity offer fertile grounds for theoretical abstractions. It has been demonstrated that the collective motion involved in the searching behaviour of termites is consistent with self-similarity, anomalous diffusion and Lévy walks. In this work we use visibility graphs—a method that maps time series into graphs and quantifies the signal complexity via graph topological metrics—in the context of social insects foraging trajectories extracted from experiments. Our analysis indicates that the patterns observed for isolated termites change qualitatively when the termite density is increased, and such change cannot be explained by jamming effects only, pointing to collective effects emerging due to non-trivial foraging interactions between insects as the cause. Moreover, we find that such onset of complexity is maximised for intermediate termite densities.",
           0,
           "journal_of_physics_complexity"
          ],
          [
           "Memory selection and information switching in oscillator networks with higher-order interactions",
           "10.1088/2632-072x/abbd4c",
           2020,
           "\nWe study the dynamics of coupled oscillator networks with higher-order interactions and their ability to store information. In particular, the fixed points of these oscillator systems consist of two clusters of oscillators that become entrained at opposite phases, mapping easily to information more commonly represented by sequences of 0’s and 1’s. While 2\nN\n such fixed point states exist in a system of N oscillators, we find that a relatively small fraction of these are stable, as chosen by the network topology. To understand the memory selection of such oscillator networks, we derive a stability criterion to identify precisely which states are stable, i.e., which pieces of information are supported by the network. We also investigate the process by which the system can switch between different stable states when a random perturbation is applied that may force the system into the basin of attraction of another stable state.",
           14,
           "journal_of_physics_complexity"
          ],
          [
           "Analyzing mass media influence using natural language processing and time series analysis",
           "10.1088/2632-072x/ab8784",
           2020,
           "\nA key question of collective social behavior is related to the influence of mass media on public opinion. Different approaches have been developed to address quantitatively this issue, ranging from field experiments to mathematical models. In this work we propose a combination of tools involving natural language processing and time series analysis. We compare selected features of mass media news articles with measurable manifestation of public opinion. We apply our analysis to news articles belonging to the 2016 US presidential campaign. We compare variations in polls (as a proxy of public opinion) with changes in the connotation of the news (sentiment) or in the agenda (topics) of a selected group of media outlets. Our results suggest that the sentiment content by itself is not enough to understand the differences in polls, but the combination of topics coverage and sentiment content provides an useful insight of the context in which public opinion varies. The methodology employed in this work is far general and can be easily extended to other topics of interest.",
           6,
           "journal_of_physics_complexity"
          ],
          [
           "Inferring directional interactions in collective dynamics: a critique to intrinsic mutual information",
           "10.1088/2632-072x/acace0",
           2022,
           "\nPairwise interactions are critical to collective dynamics of natural and technological systems. Information theory is the gold standard to study these interactions, but recent work has identified pitfalls in the way information flow is appraised through classical metrics—time-delayed mutual information and transfer entropy. These pitfalls have prompted the introduction of intrinsic mutual information to precisely measure information flow. However, little is known regarding the potential use of intrinsic mutual information in the inference of directional influences to diagnose interactions from time-series of individual units. We explore this possibility within a minimalistic, mathematically tractable leader–follower model, for which we document an excess of false inferences of intrinsic mutual information compared to transfer entropy. This unexpected finding is linked to a fundamental limitation of intrinsic mutual information, which suffers from the same sins of time-delayed mutual information: a thin tail of the null distribution that favors the rejection of the null-hypothesis of independence.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Avoidance, adjacency, and association in distributed systems design",
           "10.1088/2632-072x/abe27f",
           2021,
           "\nPatterns of avoidance, adjacency, and association in complex systems design emerge from the system’s underlying logical architecture (functional relationships among components) and physical architecture (component physical properties and spatial location). Understanding the physical–logical architecture interplay that gives rise to patterns of arrangement requires a quantitative approach that bridges both descriptions. Here, we show that statistical physics reveals patterns of avoidance, adjacency, and association across sets of complex, distributed system design solutions. Using an example arrangement problem and tensor network methods, we identify several phenomena in complex systems design, including placement symmetry breaking, propagating correlation, and emergent localization. Our approach generalizes straightforwardly to a broad range of complex systems design settings where it can provide a platform for investigating basic design phenomena.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "EEG functional connectivity and deep learning for automatic diagnosis of brain disorders: Alzheimer’s disease and schizophrenia",
           "10.1088/2632-072x/ac5f8d",
           2022,
           "\nMental disorders are among the leading causes of disability worldwide. The first step in treating these conditions is to obtain an accurate diagnosis. Machine learning algorithms can provide a possible solution to this problem, as we describe in this work. We present a method for the automatic diagnosis of mental disorders based on the matrix of connections obtained from EEG time series and deep learning. We show that our approach can classify patients with Alzheimer’s disease and schizophrenia with a high level of accuracy. The comparison with the traditional cases, that use raw EEG time series, shows that our method provides the highest precision. Therefore, the application of deep neural networks on data from brain connections is a very promising method for the diagnosis of neurological disorders.",
           19,
           "journal_of_physics_complexity"
          ],
          [
           "Analytic solution of the resolvent equations for heterogeneous random graphs: spectral and localization properties",
           "10.1088/2632-072x/aca9b1",
           2022,
           "\nThe spectral and localization properties of heterogeneous random graphs are determined by the resolvent distributional equations, which have so far resisted an analytic treatment. We solve analytically the resolvent equations of random graphs with an arbitrary degree distribution in the high-connectivity limit, from which we perform a thorough analysis of the impact of degree fluctuations on the spectral density, the inverse participation ratio, and the distribution of the local density of states (LDOSs). For random graphs with a negative binomial degree distribution, we show that all eigenvectors are extended and that the spectral density exhibits a logarithmic or a power-law divergence when the variance of the degree distribution is large enough. We elucidate this singular behaviour by showing that the distribution of the LDOSs at the centre of the spectrum displays a power-law tail controlled by the variance of the degree distribution. In the regime of weak degree fluctuations the spectral density has a finite support, which promotes the stability of large complex systems on random graphs.",
           2,
           "journal_of_physics_complexity"
          ],
          [
           "Predicting the power grid frequency of European islands",
           "10.1088/2632-072x/acbd7f",
           2023,
           "\nModelling, forecasting and overall understanding of the dynamics of the power grid and its frequency are essential for the safe operation of existing and future power grids. Much previous research was focused on large continental areas, while small systems, such as islands are less well-studied. These natural island systems are ideal testing environments for microgrid proposals and artificially islanded grid operation. In the present paper, we utilise measurements of the power grid frequency obtained in European islands: the Faroe Islands, Ireland, the Balearic Islands and Iceland and investigate how their frequency can be predicted, compared to the Nordic power system, acting as a reference. The Balearic Islands are found to be particularly deterministic and easy to predict in contrast to hard-to-predict Iceland. Furthermore, we show that typically 2–4 weeks of data are needed to improve prediction performance beyond simple benchmarks.",
           1,
           "journal_of_physics_complexity"
          ],
          [
           "Chimera states formed via a two-level synchronization mechanism",
           "10.1088/2632-072x/ab79bd",
           2020,
           "\nWe introduce an oscillatory toy-model with variable frequency governed by a 3rd order equation to shed light on the formation of chimera states in systems of coupled oscillators. The toy-oscillators are constructed as bistable units and depending on the initial conditions their frequency may result in one of the two attracting fixed points, \n\n and \n\n (two-level synchronization). Numerical simulations demonstrate that when these oscillators are nonlocally coupled in networks, they organize in domains with alternating frequencies. In each domain the oscillators synchronize, while sequential domains follow different modes of synchronization. The border elements between two consecutive domains form the asynchronous domains as they are influenced by both frequencies. This way chimera states are formed via a two-level synchronization scenario. We investigate the influence of the frequency coupling constant and of the coupling range on the chimera morphology and we show that the chimera multiplicity decreases as the coupling range increases.\nThe frequency spectrum is calculated in the coherent and incoherent domains of this model. In the coherent domains single frequencies (\n\n or \n\n) are observed, while in the incoherent domains both \n\n and \n\n as well as their superpositions appear. This mechanism of creating domains of alternating frequencies offers a reasonable generic scenario for chimera state formation.",
           5,
           "journal_of_physics_complexity"
          ],
          [
           "Towards automating structural discovery in scanning transmission electron microscopy\n                  <sup>*</sup>",
           "10.1088/2632-2153/ac3844",
           2021,
           "\nScanning transmission electron microscopy is now the primary tool for exploring functional materials on the atomic level. Often, features of interest are highly localized in specific regions in the material, such as ferroelectric domain walls, extended defects, or second phase inclusions. Selecting regions to image for structural and chemical discovery via atomically resolved imaging has traditionally proceeded via human operators making semi-informed judgements on sampling locations and parameters. Recent efforts at automation for structural and physical discovery have pointed towards the use of ‘active learning’ methods that utilize Bayesian optimization with surrogate models to quickly find relevant regions of interest. Yet despite the potential importance of this direction, there is a general lack of certainty in selecting relevant control algorithms and how to balance a priori knowledge of the material system with knowledge derived during experimentation. Here we address this gap by developing the automated experiment workflows with several combinations to both illustrate the effects of these choices and demonstrate the tradeoffs associated with each in terms of accuracy, robustness, and susceptibility to hyperparameters for structural discovery. We discuss possible methods to build descriptors using the raw image data and deep learning based semantic segmentation, as well as the implementation of variational autoencoder based representation. Furthermore, each workflow is applied to a range of feature sizes including NiO pillars within a La:SrMnO3 matrix, ferroelectric domains in BiFeO3, and topological defects in graphene. The code developed in this manuscript is open sourced and will be released at github.com/nccreang/AE_Workflows.",
           11,
           "machine_learning_science_and_technology"
          ],
          [
           "SMILES-X: autonomous molecular compounds characterization for small datasets without descriptors",
           "10.1088/2632-2153/ab57f3",
           2020,
           "\nThere is more and more evidence that machine learning can be successfully applied in materials science and related fields. However, datasets in these fields are often quite small (from tens to several thousands of samples). This means the most advanced machine learning techniques remain neglected, as they are considered to be applicable to big data only. Moreover, materials informatics methods often rely on human-engineered descriptors, that should be carefully chosen, or even created, to fit the physicochemical property that one intends to predict. In this article, we propose a new method that tackles both the issue of small datasets and the difficulty of developing task-specific descriptors. The SMILES-X is an autonomous pipeline for molecular compounds characterisation based on a {Embed-Encode-Attend-Predict} neural architecture with a data-specific Bayesian hyper-parameters optimisation. The only input to the architecture—the SMILES strings—are de-canonicalised in order to efficiently augment the data. One of the key features of the architecture is the attention mechanism, which enables the interpretation of output predictions without extra computational cost. The SMILES-X achieves state-of-the-art results in the inference of aqueous solubility (\n\n\n\n\n\n\n\n\nRMSE\n\n\n¯\n\n\n\n\ntest\n\n\n≃\n0.57\n±\n0.07\n\n\n mols/L), hydration free energy (\n\n\n\n\n\n\n\n\nRMSE\n\n\n¯\n\n\n\n\ntest\n\n\n≃\n0.81\n±\n0.22\n\n\n kcal/mol, which is ∼24.5% better than molecular dynamics simulations), and octanol/water distribution coefficient (\n\n\n\n\n\n\n\n\nRMSE\n\n\n¯\n\n\n\n\ntest\n\n\n≃\n0.59\n±\n0.02\n\n\n for LogD at pH 7.4) of molecular compounds. The SMILES-X is intended to become an important asset in the toolkit of materials scientists and chemists. The source code for the SMILES-X is available at github.com/GLambard/SMILES-X.",
           10,
           "machine_learning_science_and_technology"
          ],
          [
           "Confined hydrogen atom: endohedrals H@C<sub>36</sub> and H@C<sub>60</sub>",
           "10.1088/2632-2153/acb901",
           2023,
           "\nIn this work, for the lowest states with angular momentum, \n\n\nl\n=\n0\n,\n1\n,\n2\n\n\n the energies and eigenfunctions of the endohedrals H@C36 and H@C60 are presented. The confining spherically-symmetric barrier was modeled by an inverted Gaussian function of depth ω\n0, width σ and centered at r\n\nc\n, \n\n\nw\n(\nr\n)\n=\n−\n\nω\n0\n\n\nexp\n\n[\n−\n(\nr\n−\n\nr\nc\n\n\n\n)\n2\n\n\n\n/\n\n\nσ\n2\n\n]\n\n\n. The spectra of the system as a function of the parameters (\n\n\n\nω\n0\n\n,\nσ\n,\n\nr\nc\n\n\n\n) is calculated using three distinct numerical methods: (i) Lagrange-mesh method, (ii) fourth order finite differences and (iii) the finite element method. Concrete results with not less than 11 significant figures are displayed. Also, within the Lagrange-mesh approach the corresponding eigenfunctions and the expectation value of r for the first six states of \n\n\ns\n,\np\n\n\n, and d symmetries, respectively, are presented as well. Our accurate energies are taken as initial data to train an artificial neural network that generates faster and efficient numerical interpolation. The present numerical results improve and extend those reported in the literature.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "A filter-based feature selection approach in multilabel classification",
           "10.1088/2632-2153/ad035d",
           2023,
           "\nMulti-label classification is a fast-growing field of machine learning. Recent developments have shown several applications, including social media, healthcare, bio-molecular analysis, scene, and music classification associated with the multilabel classification. In classification problems, multiple labels (multilabel or more than one class label) are assigned to an unseen record instead of a single-label class assignment. Feature selection is a preprocessing phase used to identify the most relevant features that could improve the accuracy of the multilabel classifiers. The focus of this study is the feature selection method in multilabel classification. The study used a feature selection filter method involving the Fisher score, analysis of variance test, mutual information, Chi-Square, and ensembles of these statistical methods. An extensive range of machine learning algorithms is applied in the modelling phase of a multilabel classification model that includes binary relevance, classifier chain, label powerset, binary relevance KNN, multi-label twin support vector machine, multi-label KNN. Besides, label space partitioning and majority voting of ensemble methods are used and Random Forest is the base learner. The experiments are carried out over five different multilabel benchmarking datasets. The evaluation of the classification model is measured using accuracy, precision, recall, F1 score, and hamming loss. The study demonstrated that the filter methods (i.e. mutual information) having top weighted \n\n\n80\n%\n\n\n to \n\n\n20\n%\n\n\n features provided significant outcomes.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "Improving parametric neural networks for high-energy physics (and beyond)",
           "10.1088/2632-2153/ac917c",
           2022,
           "\nSignal-background classification is a central problem in high-energy physics, that plays a major role for the discovery of new fundamental particles. A recent method—the parametric neural network (pNN)—leverages multiple signal mass hypotheses as an additional input feature to effectively replace a whole set of individual classifiers, each providing (in principle) the best response for the corresponding mass hypothesis. In this work we aim at deepening the understanding of pNNs in light of real-world usage. We discovered several peculiarities of parametric networks, providing intuition, metrics, and guidelines to them. We further propose an alternative parametrization scheme, resulting in a new parametrized neural network architecture: the AffinePNN; along with many other generally applicable improvements, like the balanced training procedure. Finally, we extensively and empirically evaluate our models on the HEPMASS dataset, along its imbalanced version (called HEPMASS-IMB) we provide here for the first time, to further validate our approach. Provided results are in terms of the impact of the proposed design decisions, classification performance, and interpolation capability, as well.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Learning to discover: expressive Gaussian mixture models for multi-dimensional simulation and parameter inference in the physical sciences",
           "10.1088/2632-2153/ac4a3b",
           2022,
           "\nWe show that density models describing multiple observables with (1) hard boundaries and (2) dependence on external parameters may be created using an auto-regressive Gaussian mixture model. The model is designed to capture how observable spectra are deformed by hypothesis variations, and is made more expressive by projecting data onto a configurable latent space. It may be used as a statistical model for scientific discovery in interpreting experimental observations, for example when constraining the parameters of a physical model or tuning simulation parameters according to calibration data. The model may also be sampled for use within a Monte Carlo simulation chain, or used to estimate likelihood ratios for event classification. The method is demonstrated on simulated high-energy particle physics data considering the anomalous electroweak production of a Z boson in association with a dijet system at the Large Hadron Collider, and the accuracy of inference is tested using a realistic toy example. The developed methods are domain agnostic; they may be used within any field to perform simulation or inference where a dataset consisting of many real-valued observables has conditional dependence on external parameters.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "Towards a variational Jordan–Lee–Preskill quantum algorithm",
           "10.1088/2632-2153/aca06b",
           2022,
           "\nRapid developments of quantum information technology show promising opportunities for simulating quantum field theory in near-term quantum devices. In this work, we formulate the theory of (time-dependent) variational quantum simulation of the \n\n\n1\n+\n1\n\n\n dimensional \n\n\nλ\n\nϕ\n4\n\n\n\n quantum field theory including encoding, state preparation, and time evolution, with several numerical simulation results. These algorithms could be understood as near-term variational quantum circuit (quantum neural network) analogs of the Jordan–Lee–Preskill algorithm, the basic algorithm for simulating quantum field theory using universal quantum devices. Besides, we highlight the advantages of encoding with harmonic oscillator basis based on the Lehmann—Symanzik—Zimmermann reduction formula and several computational efficiency such as when implementing a bosonic version of the unitary coupled cluster ansatz to prepare initial states. We also discuss how to circumvent the ‘spectral crowding’ problem in the quantum field theory simulation and appraise our algorithm by both state and subspace fidelities.",
           6,
           "machine_learning_science_and_technology"
          ],
          [
           "A multi-stage machine learning algorithm for estimating personal dose equivalent using thermoluminescent dosimeter",
           "10.1088/2632-2153/ad1c31",
           2024,
           "\nIn the present age, marked by data-driven advancements in various fields, the importance of machine learning (ML) holds a prominent position. The ability of ML algorithms to resolve complex patterns and extract insights from large datasets has solidified its transformative potential in various scientific domains. This paper introduces an innovative application of ML techniques in the domain of radiation dosimetry. Specifically, it shows the applicability of ML in estimating the radiation dose received by occupational workers. This estimation is expressed in terms of personal dose equivalent, and it involves the utilization of thermoluminescence signals emitted by CaSO4:Dy-based personnel monitoring badges. To estimate personal dose equivalent, three-stage algorithm driven by ML models is proposed. This algorithm systematically identifies the photon energy ranges, calculates the average photon energy, and determines personal dose equivalent. By implementing this approach to the conventional three-element dosimeter, the study overcomes existing limitations and enhances accuracy in dose estimation. The algorithm demonstrates 97.8% classification accuracy in discerning photon energy ranges and achieves a coefficient of determination of 0.988 for estimating average photon energy. Importantly, it also reduces the coefficient of variation of relative deviations by up to 6% for estimated personal dose equivalent, compared to existing algorithms. The study improves accuracy and establishes a new methodology for evaluating radiation exposure to occupational workers using conventional thermoluminescent dosimeter badge.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Semi-equivariant conditional normalizing flows, with applications to target-aware molecule generation",
           "10.1088/2632-2153/ace58c",
           2023,
           "\nLearning over the domain of 3D graphs has applications in a number of scientific and engineering disciplines, including molecular chemistry, high energy physics, and computer vision. We consider a specific problem in this domain, namely: given one such 3D graph, dubbed the base graph, our goal is to learn a conditional distribution over another such graph, dubbed the complement graph. Due to the three-dimensional nature of the graphs in question, there are certain natural invariances such a distribution should satisfy: it should be invariant to rigid body transformations that act jointly on the base graph and the complement graph, and it should also be invariant to permutations of the vertices of either graph. We propose a general method for learning the conditional probabilistic model, the central part of which is a continuous normalizing flow. We establish semi-equivariance conditions on the flow which guarantee the aforementioned invariance conditions on the conditional distribution. Additionally, we propose a graph neural network architecture which implements this flow, and which is designed to learn effectively despite the typical differences in size between the base graph and the complement graph. We demonstrate the utility of our technique in the molecular setting by training a conditional generative model which, given a receptor, can generate ligands which may successfully bind to that receptor. The resulting model, which has potential applications in drug design, displays high quality performance in the key ΔBinding metric.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "ELUQuant: event-level uncertainty quantification in deep inelastic scattering",
           "10.1088/2632-2153/ad2098",
           2024,
           "\nWe introduce a physics-informed Bayesian neural network with flow-approximated posteriors using multiplicative normalizing flows for detailed uncertainty quantification (UQ) at the physics event-level. Our method is capable of identifying both heteroskedastic aleatoric and epistemic uncertainties, providing granular physical insights. Applied to deep inelastic scattering (DIS) events, our model effectively extracts the kinematic variables x, Q\n2, and y, matching the performance of recent deep learning regression techniques but with the critical enhancement of event-level UQ. This detailed description of the underlying uncertainty proves invaluable for decision-making, especially in tasks like event filtering. It also allows for the reduction of true inaccuracies without directly accessing the ground truth. A thorough DIS simulation using the H1 detector at HERA indicates possible applications for the future electron–ion collider. Additionally, this paves the way for related tasks such as data quality monitoring and anomaly detection. Remarkably, our approach effectively processes large samples at high rates.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Source-Agnostic Gravitational-Wave Detection with Recurrent Autoencoders",
           "10.1088/2632-2153/ac5385",
           2022,
           "\nWe present an application of anomaly detection techniques based on deep recurrent autoencoders to the problem of detecting gravitational wave signals in laser interferometers. Trained on noise data, this class of algorithms could detect signals using an unsupervised strategy, i.e., without targeting a speciﬁc kind of source. We develop a custom architecture to analyze the data from two interferometers. We compare the obtained performance to that obtained with other autoencoder architectures and with a convolutional classiﬁer. The unsupervised nature of the proposed strategy comes with a cost in terms of accuracy, when compared to more traditional supervised techniques. On the other hand, there is a qualitative gain in generalizing the experimental sensitivity beyond the ensemble of pre-computed signal templates. The recurrent autoencoder outperforms other autoencoders based on diﬀerent architectures. The class of recurrent autoencoders presented in this paper could complement the search strategy employed for gravitational wave detection and extend the reach of the ongoing detection campaigns. ",
           2,
           "machine_learning_science_and_technology"
          ],
          [
           "NeuralNEB—neural networks can find reaction paths fast",
           "10.1088/2632-2153/aca23e",
           2022,
           "Quantum mechanical methods like density functional theory (DFT) are used with great success alongside efficient search algorithms for studying kinetics of reactive systems. However, DFT is prohibitively expensive for large scale exploration. Machine learning (ML) models have turned out to be excellent emulators of small molecule DFT calculations and could possibly replace DFT in such tasks. For kinetics, success relies primarily on the models’ capability to accurately predict the potential energy surface around transition-states and minimal energy paths. Previously this has not been possible due to scarcity of relevant data in the literature. In this paper we train equivariant graph neural network-based models on data from 10 000 elementary reactions from the recently published Transition1x dataset. We apply the models as potentials for the nudged elastic band algorithm and achieve a mean average error of 0.23 eV and root mean squared error of 0.52 eV on barrier energies on unseen reactions. We compare the results against equivalent models trained on QM9x and ANI1x. We also compare with and outperform Density Functional based Tight Binding on both accuracy and required computational resources. The implication is that ML models are now at a level where they can be applied to studying chemical reaction kinetics given a sufficient amount of data relevant to this task.",
           10,
           "machine_learning_science_and_technology"
          ],
          [
           "Deep kernel methods learn better: from cards to process optimization",
           "10.1088/2632-2153/ad1a4f",
           2024,
           "\nThe ability of deep learning methods to perform classification and regression tasks relies heavily on their capacity to uncover manifolds in high-dimensional data spaces and project them into low-dimensional representation spaces. In this study, we investigate the structure and character of the manifolds generated by classical variational autoencoder (VAE) approaches and deep kernel learning (DKL). In the former case, the structure of the latent space is determined by the properties of the input data alone, while in the latter, the latent manifold forms as a result of an active learning process that balances the data distribution and target functionalities. We show that DKL with active learning can produce a more compact and smooth latent space which is more conducive to optimization compared to previously reported methods, such as the VAE. We demonstrate this behavior using a simple cards dataset and extend it to the optimization of domain-generated trajectories in physical systems. Our findings suggest that latent manifolds constructed through active learning have a more beneficial structure for optimization problems, especially in feature-rich target-poor scenarios that are common in domain sciences, such as materials synthesis, energy storage, and molecular discovery. The Jupyter Notebooks that encapsulate the complete analysis accompany the article.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Graph machine learning framework for depicting wavefunction on interface",
           "10.1088/2632-2153/ad0937",
           2023,
           "\nThe wavefunction, as the basic hypothesis of quantum mechanics, describes the motion of particles and plays a pivotal role in determining physical properties at the atomic scale. However, its conventional acquisition method, such as density functional theory, requires a considerable amount of calculation, which brings numerous problems to wide application. Here, we propose an algorithmic framework based on graph neural network to machine-learn the wavefunction of electrons. This framework primarily generates atomic features containing information about chemical environment and geometric structure and subsequently constructs a scalable distribution map. For the first time, the visualization of wavefunction of interface is realized by machine learning methods, bypassing complex calculation and obscure comprehension. In this way, we vividly illustrate quantum mechanics, which can inspire theoretical exploration. As an intriguing case to verify the ability of our method, a novel quantum confinement phenomenon on interfaces based on graphene nanoribbon is uncovered. We believe that the versatility of this framework paves the way for swiftly linking quantum physics and atom-level structures.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Stochastic gradient descent with random label noises: doubly stochastic models and inference stabilizer",
           "10.1088/2632-2153/ad13ba",
           2023,
           "\nRandom label noise (or observational noise) widely exists in practical machine learning settings. While previous studies primarily focused on the effects of label noise to the performance of learning, our work intends to investigate the implicit regularization effects of label noise, under mini-batch sampling settings of stochastic gradient descent (SGD), with the assumption that label noise is unbiased. Specifically, we analyze the learning dynamics of SGD over the quadratic loss with unbiased label noise (ULN), where we model the dynamics of SGD as a stochastic differentiable equation with two diffusion terms (namely a doubly stochastic model). While the first diffusion term is caused by mini-batch sampling over the (label-noiseless) loss gradients, as in many other works on SGD (Zhu et al 2019 ICML 7654–63; Wu et al 2020 Int. Conf. on Machine Learning (PMLR) pp 10367–76), our model investigates the second noise term of SGD dynamics, which is caused by mini-batch sampling over the label noise, as an implicit regularizer. Our theoretical analysis finds such an implicit regularizer would favor some convergence points that could stabilize model outputs against perturbations of parameters (namely inference stability). Though similar phenomenon have been investigated by Blanc et al (2020 Conf. on Learning Theory (PMLR) pp 483–513), our work does not assume SGD as an Ornstein–Uhlenbeck-like process and achieves a more generalizable result with convergence of the approximation proved. To validate our analysis, we design two sets of empirical studies to analyze the implicit regularizer of SGD with unbiased random label noise for deep neural network training and linear regression. Our first experiment studies the noisy self-distillation tricks for deep learning, where student networks are trained using the outputs from well-trained teachers with additive unbiased random label noise. Our experiment shows that the implicit regularizer caused by the label noise tends to select models with improved inference stability. We also carry out experiments on SGD-based linear regression with ULN, where we plot the trajectories of parameters learned in every step and visualize the effects of implicit regularization. The results back up our theoretical findings.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Efficient hyperparameter tuning for kernel ridge regression with Bayesian optimization",
           "10.1088/2632-2153/abee59",
           2021,
           "\nMachine learning methods usually depend on internal parameters—so called hyperparameters—that need to be optimized for best performance. Such optimization poses a burden on machine learning practitioners, requiring expert knowledge, intuition or computationally demanding brute-force parameter searches. We here assess three different hyperparameter selection methods: grid search, random search and an efficient automated optimization technique based on Bayesian optimization (BO). We apply these methods to a machine learning problem based on kernel ridge regression in computational chemistry. Two different descriptors are employed to represent the atomic structure of organic molecules, one of which introduces its own set of hyperparameters to the method. We identify optimal hyperparameter configurations and infer entire prediction error landscapes in hyperparameter space that serve as visual guides for the hyperparameter performance. We further demonstrate that for an increasing number of hyperparameters, BO and random search become significantly more efficient in computational time than an exhaustive grid search, while delivering an equivalent or even better accuracy.",
           28,
           "machine_learning_science_and_technology"
          ],
          [
           "Transfer learning application of self-supervised learning in ARPES",
           "10.1088/2632-2153/aced7d",
           2023,
           "\nThere is a growing recognition that electronic band structure is a local property of materials and devices, and there is steep growth in capabilities to collect the relevant data. New photon sources, from small-laboratory-based lasers to free electron lasers, together with focusing beam optics and advanced electron spectrometers, are beginning to enable angle-resolved photoemission spectroscopy (ARPES) in scanning mode with a spatial resolution of near to and below microns, two- to three orders of magnitude smaller than what has been typical for ARPES hitherto. The results are vast data sets inhabiting a five-dimensional subspace of the ten-dimensional space spanned by two scanning dimensions of real space, three of reciprocal space, three of spin-space, time, and energy. In this work, we demonstrate that recent developments in representational learning (self-supervised learning) combined with k-means clustering can help automate the labeling and spatial mapping of dispersion cuts, thus saving precious time relative to manual analysis, albeit with low performance. Finally, we introduce a few-shot learning (k-nearest neighbor) in representational space where we selectively choose one (k = 1) image reference for each known label and subsequently label the rest of the data with respect to the nearest reference image. This last approach demonstrates the strength of self-supervised learning to automate image analysis in ARPES in particular and can be generalized to any scientific image analysis.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Machine-learning Kohn–Sham potential from dynamics in time-dependent Kohn–Sham systems",
           "10.1088/2632-2153/ace8f0",
           2023,
           "\nThe construction of a better exchange-correlation potential in time-dependent density functional theory (TDDFT) can improve the accuracy of TDDFT calculations and provide more accurate predictions of the properties of many-electron systems. Here, we propose a machine learning method to develop the energy functional and the Kohn–Sham potential of a time-dependent Kohn–Sham (TDKS) system is proposed. The method is based on the dynamics of the Kohn–Sham system and does not require any data on the exact Kohn–Sham potential for training the model. We demonstrate the results of our method with a 1D harmonic oscillator example and a 1D two-electron example. We show that the machine-learned Kohn–Sham potential matches the exact Kohn–Sham potential in the absence of memory effect. Our method can still capture the dynamics of the Kohn–Sham system in the presence of memory effects. The machine learning method developed in this article provides insight into making better approximations of the energy functional and the Kohn–Sham potential in the TDKS system.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Defence against adversarial attacks using classical and quantum-enhanced Boltzmann machines\n                  <sup>†</sup>",
           "10.1088/2632-2153/abf834",
           2021,
           "\nWe provide a robust defence to adversarial attacks on discriminative algorithms. Neural networks are naturally vulnerable to small, tailored perturbations in the input data that lead to wrong predictions. On the contrary, generative models attempt to learn the distribution underlying a dataset, making them inherently more robust to small perturbations. We use Boltzmann machines for discrimination purposes as attack-resistant classifiers, and compare them against standard state-of-the-art adversarial defences. We find improvements ranging from 5% to 72% against attacks with Boltzmann machines on the MNIST dataset. We furthermore complement the training with quantum-enhanced sampling from the D-Wave 2000Q annealer, finding results comparable with classical techniques and with marginal improvements in some cases. These results underline the relevance of probabilistic methods in constructing neural networks and highlight a novel scenario of practical relevance where quantum computers, even with limited hardware capabilities, could provide advantages over classical computers.",
           3,
           "machine_learning_science_and_technology"
          ],
          [
           "How isotropic kernels perform on simple invariants",
           "10.1088/2632-2153/abd485",
           2020,
           "\nWe investigate how the training curve of isotropic kernel methods depends on the symmetry of the task to be learned, in several settings. (i) We consider a regression task, where the target function is a Gaussian random field that depends only on \n\n\n\nd\n∥\n\n\n\n variables, fewer than the input dimension d. We compute the expected test error ϵ that follows \n\n\nϵ\n∼\n\np\n\n−\nβ\n\n\n\n\n where p is the size of the training set. We find that β ∼ 1/d independently of \n\n\n\nd\n∥\n\n\n\n, supporting previous findings that the presence of invariants does not resolve the curse of dimensionality for kernel regression. (ii) Next we consider support-vector binary classification and introduce the stripe model, where the data label depends on a single coordinate \n\n\ny\n(\n\nx\n_\n\n)\n=\ny\n(\n\nx\n1\n\n)\n\n\n, corresponding to parallel decision boundaries separating labels of different signs, and consider that there is no margin at these interfaces. We argue and confirm numerically that, for large bandwidth, \n\n\nβ\n=\n\n\nd\n−\n1\n+\nξ\n\n\n3\nd\n−\n3\n+\nξ\n\n\n\n\n, where ξ ∈ (0, 2) is the exponent characterizing the singularity of the kernel at the origin. This estimation improves classical bounds obtainable from Rademacher complexity. In this setting there is no curse of dimensionality since \n\n\nβ\n→\n1\n\n/\n\n3\n\n\n as \n\n\nd\n→\n∞\n\n\n. (iii) We confirm these findings for the spherical model, for which \n\n\ny\n(\n\nx\n_\n\n)\n=\ny\n(\n\n|\n\n\n|\n\n\nx\n_\n\n\n|\n\n\n|\n\n)\n\n\n. (iv) In the stripe model, we show that, if the data are compressed along their invariants by some factor λ (an operation believed to take place in deep networks), the test error is reduced by a factor \n\n\n\nλ\n\n−\n\n\n2\n(\nd\n−\n1\n)\n\n\n3\nd\n−\n3\n+\nξ\n\n\n\n\n\n\n.",
           4,
           "machine_learning_science_and_technology"
          ],
          [
           "Machine learning for neutron scattering at ORNL<sup>*</sup>",
           "10.1088/2632-2153/abcf88",
           2020,
           "\nMachine learning (ML) offers exciting new opportunities to extract more information from scattering data. At neutron scattering user facilities, ML has the potential to help accelerate scientific productivity by empowering facility users with insight into their data which has traditionally been supplied by scattering experts. Such support can help in both speeding up common modeling problems for users, as well as help solve harder problems that are normally time consuming and difficult to address with standard methods. This article explores the recent ML work undertaken at Oak Ridge National Laboratory involving neutron scattering data. We cover materials structure modeling for diffuse scattering, powder diffraction, and small-angle scattering. We also discuss how ML can help to model the response of the instrument more precisely, as well as enable quick extraction of information from neutron data. The application of super-resolution techniques to small-angle scattering and peak extraction for diffraction will be discussed.",
           9,
           "machine_learning_science_and_technology"
          ],
          [
           "Deep learning neural network for approaching Schrödinger problems with arbitrary two-dimensional confinement",
           "10.1088/2632-2153/acf55b",
           2023,
           "\nThis article presents an approach to the two-dimensional Schrödinger equation based on automatic learning methods with neural networks. It is intended to determine the ground state of a particle confined in any two-dimensional potential, starting from the knowledge of the solutions to a large number of arbitrary sample problems. A network architecture with two hidden layers is proposed to predict the wave function and energy of the ground state. Several accuracy indicators are proposed for validating the estimates provided by the neural network. The testing of the trained network is done by applying it to a large set of confinement potentials different from those used in the learning process. Some particular cases with symmetrical potentials are solved as concrete examples, and a good network prediction accuracy is found.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "‘Flux+Mutability’: a conditional generative approach to one-class classification and anomaly detection",
           "10.1088/2632-2153/ac9bcb",
           2022,
           "\nAnomaly Detection is becoming increasingly popular within the experimental physics community. At experiments such as the Large Hadron Collider, anomaly detection is growing in interest for finding new physics beyond the Standard Model. This paper details the implementation of a novel Machine Learning architecture, called Flux+Mutability, which combines cutting-edge conditional generative models with clustering algorithms. In the ‘flux’ stage we learn the distribution of a reference class. The ‘mutability’ stage at inference addresses if data significantly deviates from the reference class. We demonstrate the validity of our approach and its connection to multiple problems spanning from one-class classification to anomaly detection. In particular, we apply our method to the isolation of neutral showers in an electromagnetic calorimeter and show its performance in detecting anomalous dijets events from standard QCD background. This approach limits assumptions on the reference sample and remains agnostic to the complementary class of objects of a given problem. We describe the possibility of dynamically generating a reference population and defining selection criteria via quantile cuts. Remarkably this flexible architecture can be deployed for a wide range of problems, and applications like multi-class classification or data quality control are left for further exploration.",
           7,
           "machine_learning_science_and_technology"
          ],
          [
           "GRINN: a physics-informed neural network for solving hydrodynamic systems in the presence of self-gravity",
           "10.1088/2632-2153/ad3a32",
           2024,
           "\nModeling self-gravitating gas flows is essential to answering many fundamental questions in astrophysics. This spans many topics including planet-forming disks, star-forming clouds, galaxy formation, and the development of large-scale structures in the Universe. However, the nonlinear interaction between gravity and fluid dynamics offers a formidable challenge to solving the resulting time-dependent partial differential equations (PDEs) in three dimensions (3D). By leveraging the universal approximation capabilities of a neural network within a mesh-free framework, physics informed neural networks (PINNs) offer a new way of addressing this challenge. We introduce the gravity-informed neural network (GRINN), a PINN-based code, to simulate 3D self-gravitating hydrodynamic systems. Here, we specifically study gravitational instability and wave propagation in an isothermal gas. Our results match a linear analytic solution to within 1% in the linear regime and a conventional grid code solution to within 5% as the disturbance grows into the nonlinear regime. We find that the computation time of the GRINN does not scale with the number of dimensions. This is in contrast to the scaling of the grid-based code for the hydrodynamic and self-gravity calculations as the number of dimensions is increased. Our results show that the GRINN computation time is longer than the grid code in one- and two- dimensional calculations but is an order of magnitude lesser than the grid code in 3D with similar accuracy. Physics-informed neural networks like GRINN thus show promise for advancing our ability to model 3D astrophysical flows.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Evaluation of synthetic and experimental training data in supervised machine learning applied to charge-state detection of quantum dots",
           "10.1088/2632-2153/ac104c",
           2021,
           "\nAutomated tuning of gate-defined quantum dots is a requirement for large-scale semiconductor-based qubit initialisation. An essential step of these tuning procedures is charge-state detection based on charge stability diagrams. Using supervised machine learning to perform this task requires a large dataset for models to train on. In order to avoid hand labelling experimental data, synthetic data has been explored as an alternative. While providing a significant increase in the size of the training dataset compared to using experimental data, using synthetic data means that classifiers are trained on data sourced from a different distribution than the experimental data that is part of the tuning process. Here we evaluate the prediction accuracy of a range of machine learning models trained on simulated and experimental data, and their ability to generalise to experimental charge stability diagrams in two-dimensional electron gas and nanowire devices. We find that classifiers perform best on either purely experimental or a combination of synthetic and experimental training data, and that adding common experimental noise signatures to the synthetic data does not dramatically improve the classification accuracy. These results suggest that experimental training data as well as realistic quantum dot simulations and noise models are essential in charge-state detection using supervised machine learning.",
           9,
           "machine_learning_science_and_technology"
          ],
          [
           "Reinforcement learning decoders for fault-tolerant quantum computation",
           "10.1088/2632-2153/abc609",
           2020,
           "\nTopological error correcting codes, and particularly the surface code, currently provide the most feasible road-map towards large-scale fault-tolerant quantum computation. As such, obtaining fast and flexible decoding algorithms for these codes, within the experimentally realistic and challenging context of faulty syndrome measurements, without requiring any final read-out of the physical qubits, is of critical importance. In this work, we show that the problem of decoding such codes can be naturally reformulated as a process of repeated interactions between a decoding agent and a code environment, to which the machinery of reinforcement learning can be applied to obtain decoding agents. While in principle this framework can be instantiated with environments modelling circuit level noise, we take a first step towards this goal by using deepQ learning to obtain decoding agents for a variety of simplified phenomenological noise models, which yield faulty syndrome measurements without including the propagation of errors which arise in full circuit level noise models.",
           30,
           "machine_learning_science_and_technology"
          ],
          [
           "Transferring predictions of formation energy across lattices of increasing size*",
           "10.1088/2632-2153/ad3d2c",
           2024,
           "\nIn this study, we show the transferability of graph convolutional neural network (GCNN) predictions of the formation energy of the nickel-platinum solid solution alloy across atomic structures of increasing sizes. The original dataset was generated with the large-scale atomic/molecular massively parallel simulator using the second nearest-neighbor modified embedded-atom method empirical interatomic potential. Geometry optimization was performed on the initially randomly generated face centered cubic crystal structures and the formation energy has been calculated at each step of the geometry optimization, with configurations spanning the whole compositional range. Using data from various steps of the geometry optimization, we first trained our open-source, scalable implementation of GCNN called HydraGNN on a lattice of 256 atoms, which accounts well for the short-range interactions. Using this data, we predicted the formation energy for lattices of 864 atoms and 2048 atoms, which resulted in lower-than-expected accuracy due to the long-range interactions present in these larger lattices. We accounted for the long-range interactions by including a small amount of training data representative for those two larger sizes, whereupon the predictions of HydraGNN scaled linearly with the size of the lattice. Therefore, our strategy ensured scalability while reducing significantly the computational cost of training on larger lattice sizes.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Quantum machine learning and quantum biomimetics: A perspective",
           "10.1088/2632-2153/ab9803",
           2020,
           "Quantum machine learning has emerged as an exciting and promising paradigm inside quantum technologies. It may permit, on the one hand, to carry out more efficient machine learning calculations by means of quantum devices, while, on the other hand, to employ machine learning techniques to better control quantum systems. Inside quantum machine learning, quantum reinforcement learning aims at developing ‘intelligent’ quantum agents that may interact with the outer world and adapt to it, with the strategy of achieving some final goal. Another paradigm inside quantum machine learning is that of quantum autoencoders, which may allow one for employing fewer resources in a quantum device via a training process. Moreover, the field of quantum biomimetics aims at establishing analogies between biological and quantum systems, to look for previously inadvertent connections that may enable useful applications. Two recent examples are the concepts of quantum artificial life, as well as of quantum memristors. In this Perspective, we give an overview of these topics, describing the related research carried out by the scientific community.",
           41,
           "machine_learning_science_and_technology"
          ],
          [
           "ML-based regionalization of climate variables to forecast seasonal precipitation for water resources management",
           "10.1088/2632-2153/ad1d04",
           2024,
           "\nNumerous dams and reservoirs have been constructed in South Korea, considering the distribution of seasonal precipitation which highly deviates from the actual one with high precipitation amount in summer and very low amount in other seasons. These water-related structures should be properly managed in order to meet seasonal demands of water resources wherein the forecasting of seasonal precipitation plays a critical role. However, owing to the impact of diverse complex weather systems, seasonal precipitation forecasting has been a challenging task. The current study proposes a novel procedure for forecasting seasonal precipitation by: (1) regionalizing the influential climate variables to the seasonal precipitation with k-means clustering; (2) extracting the features from the regionalized climate variables with machine learning-based algorithms such as principal component analysis (PCA), independent component analysis (ICA), and Autoencoder; and (3) finally regressing the extracted features with one linear model of generalized linear model (GLM) and another nonlinear model of support vector machine (SVM). Two globally gridded climate variables-mean sea level pressure (MSLP) and sea surface temperature (SST)-were teleconnected with the seasonal precipitation of South Korea, denoted as accumulated seasonal precipitation (ASP). Results indicated that k-means clustering successfully regionalized the highly correlated climate variables with the ASP, and all three extraction algorithms-PCA, ICA, and Autoencoder-combined with the GLM and SVM models presented their superiority in different seasons. In particular, the PCA combined with the linear GLM model performed better, and the Autoencoder combined with the nonlinear SVM model did better. It can be concluded that the proposed forecasting procedure of the seasonal precipitation, combined with several ML-based algorithms, can be a good alternative.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "The effects of topological features on convolutional neural networks—an explanatory analysis via Grad-CAM",
           "10.1088/2632-2153/ace6f3",
           2023,
           "\nTopological data analysis (TDA) characterizes the global structure of data based on topological invariants such as persistent homology, whereas convolutional neural networks (CNNs) are capable of characterizing local features in the global structure of the data. In contrast, a combined model of TDA and CNN, a family of multimodal networks, simultaneously takes the image and the corresponding topological features as the input to the network for classification, thereby significantly improving the performance of a single CNN. This innovative approach has been recently successful in various applications. However, there is a lack of explanation regarding how and why topological signatures, when combined with a CNN, improve discriminative power. In this paper, we use persistent homology to compute topological features and subsequently demonstrate both qualitatively and quantitatively the effects of topological signatures on a CNN model, for which the Grad-CAM analysis of multimodal networks and topological inverse image map are proposed and appropriately utilized. For experimental validation, we utilize two famous datasets: the transient versus bogus image dataset and the HAM10000 dataset. Using Grad-CAM analysis of multimodal networks, we demonstrate that topological features enforce the image network of a CNN to focus more on significant and meaningful regions across images rather than task-irrelevant artifacts such as background noise and texture.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Machine learning inference of molecular dipole moment in liquid water",
           "10.1088/2632-2153/ac0123",
           2021,
           "\nMolecular dipole moment in liquid water is an intriguing property, partly due to the fact that there is no unique way to partition the total electron density into individual molecular contributions. The prevailing method to circumvent this problem is to use maximally localized Wannier functions, which perform a unitary transformation of the occupied molecular orbitals by minimizing the spread function of Boys. Here we revisit this problem using a data-driven approach satisfying two physical constraints, namely: (a) The displacement of the atomic charges is proportional to the Berry phase polarization; (b) Each water molecule has a formal charge of zero. It turns out that the distribution of molecular dipole moments in liquid water inferred from latent variables is surprisingly similar to that obtained from maximally localized Wannier functions. Apart from putting a maximum-likelihood footnote to the established method, this work highlights the capability of graph convolution based charge models and the importance of physical constraints on improving the model interpretability.",
           4,
           "machine_learning_science_and_technology"
          ],
          [
           "Novel heuristic-based hybrid ResNeXt with recurrent neural network to handle multi class classification of sentiment analysis",
           "10.1088/2632-2153/acc0d5",
           2023,
           "\nPresent-day, interdisciplinary research is increasing in social network-related applications, and it is a daily routine activity in every human life. So, sentiment analysis (SA) based on opinion mining is the most sophisticated concept in the well-known social network environment. Different machine learning methods were implemented to extract different text label features in SA, and all of those methods can detect whether a given text is positive or negative based on the text features. Analysis of sentiment has been suffering from inaccuracies while using machine learning and sentiment-based lexical methods dependent on domain-specific problems. Multi-class SA is an expensive task where memory, label samples, and other parameters are insufficient. So, we propose and implement a novel hybrid model which is a combination of ResNeXt and recurrent neural framework (NH-ResNeXt-RNF) to explore multi-class sentiment from textual features. This framework investigates the polarity of words connected to a specific domain across the entire dataset and eliminates noisy data in an unsupervised manner using pre-processing. Optimization is required to perform efficient multi-class classification to reduce the effort associated with annotation for multi-class SA via unsupervised learning. The proposed model performance is evaluated on two data sets namely: Amazon and Twitter. We increase the accuracy of the sentiment of polarity on each sentence present in the data set. Experimental results of the proposed approach give better and more efficient multi-class (positive, negative, very positive, neutral and highly negative) domain-specific sentiment than traditional approaches related to supervised, semi-supervised, and unsupervised domains. The proposed hybrid model accuracy is 96.5% and 95.37% for Amazon and Twitter datasets respectively.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Online accelerator optimization with a machine learning-based stochastic algorithm",
           "10.1088/2632-2153/abc81e",
           2020,
           "\nOnline optimization is critical for realizing the design performance of accelerators. Highly efficient stochastic optimization algorithms are needed for many online accelerator optimization problems in order to find the global optimum in the non-linear, coupled parameter space. In this study, we propose to use the multi-generation Gaussian process optimizer for online accelerator optimization and demonstrate that the algorithm is significantly more efficient than other stochastic algorithms that are commonly used in the accelerator community.",
           4,
           "machine_learning_science_and_technology"
          ],
          [
           "Supplementing recurrent neural networks with annealing to solve combinatorial optimization problems",
           "10.1088/2632-2153/acb895",
           2023,
           "\nCombinatorial optimization problems can be solved by heuristic algorithms such as simulated annealing (SA) which aims to find the optimal solution within a large search space through thermal fluctuations. This algorithm generates new solutions through Markov-chain Monte Carlo techniques which can result in severe limitations, such as slow convergence and a tendency to stay within the same local search space at small temperatures. To overcome these shortcomings, we use the variational classical annealing (VCA) framework that combines autoregressive recurrent neural networks (RNNs) with traditional annealing to sample solutions that are uncorrelated. In this paper, we demonstrate the potential of using VCA as an approach to solving real-world optimization problems. We explore VCA’s performance in comparison with SA at solving three popular optimization problems: the maximum cut problem (Max-Cut), the nurse scheduling problem (NSP), and the traveling salesman problem (TSP). For all three problems, we find that VCA outperforms SA on average in the asymptotic limit by one or more orders of magnitude in terms of relative error. Interestingly, we reach large system sizes of up to 256 cities for the TSP. We also conclude that in the best case scenario, VCA can serve as a great alternative when SA fails to find the optimal solution.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "Using positional tracking to improve abdominal ultrasound machine learning classification",
           "10.1088/2632-2153/ad379d",
           2024,
           "\nDiagnostic abdominal ultrasound screening and monitoring protocols are based around gathering a set of standard cross sectional images that ensure the coverage of relevant anatomical structures during the collection procedure. This allows clinicians to make diagnostic decisions with the best picture available from that modality. Currently, there is very little assistance provided to sonographers to ensure adherence to collection protocols, with previous studies suggesting that traditional image only machine learning classification can provide only limited assistance in supporting this task, for example it can be difficult to differentiate between multiple liver cross sections or those of the left and right kidney from image post collection. In this proof of concept, positional tracking information was added to the image input of a neural network to provide the additional context required to recognize six otherwise difficult to identify edge cases. In this paper optical and sensor based infrared tracking (IR) was used to track the position of an ultrasound probe during the collection of clinical cross sections on an abdominal phantom. Convolutional neural networks were then trained using both image-only and image with positional data, the classification accuracy results were then compared. The addition of positional information significantly improved average classification results from ∼90% for image-only to 95% for optical IR position tracking and 93% for Sensor-based IR in common abdominal cross sections. While there is further work to be done, the addition of low-cost positional tracking to machine learning ultrasound classification will allow for significantly increased accuracy for identifying important diagnostic cross sections, with the potential to not only provide validation of adherence to protocol but also could provide navigation prompts to assist in user training and in ensuring adherence in capturing cross sections in future.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Machine learning-based signal quality assessment for cardiac volume monitoring in electrical impedance tomography",
           "10.1088/2632-2153/acc637",
           2023,
           "\nOwing to recent advances in thoracic electrical impedance tomography (EIT), a patient’s hemodynamic function can be noninvasively and continuously estimated in real-time by surveilling a cardiac volume signal (CVS) associated with stroke volume and cardiac output. In clinical applications, however, a CVS is often of low quality, mainly because of the patient’s deliberate movements or inevitable motions during clinical interventions. This study aims to develop a signal quality indexing method that assesses the influence of motion artifacts on transient CVSs. The assessment is performed on each cardiac cycle to take advantage of the periodicity and regularity in cardiac volume changes. Time intervals are identified using the synchronized electrocardiography system. We apply divergent machine-learning methods, which can be sorted into discriminative-model and manifold-learning approaches. The use of machine-learning could be suitable for our real-time monitoring application that requires fast inference and automation as well as high accuracy. In the clinical environment, the proposed method can be utilized to provide immediate warnings so that clinicians can minimize confusion regarding patients’ conditions, reduce clinical resource utilization, and improve the confidence level of the monitoring system. Numerous experiments using actual EIT data validate the capability of CVSs degraded by motion artifacts to be accurately and automatically assessed in real-time by machine learning. The best model achieved an accuracy of 0.95, positive and negative predictive values of 0.96 and 0.86, sensitivity of 0.98, specificity of 0.77, and AUC of 0.96.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "Near-optimal control of dynamical systems with neural ordinary differential equations",
           "10.1088/2632-2153/ac92c3",
           2022,
           "\nOptimal control problems naturally arise in many scientific applications where one wishes to steer a dynamical system from an initial state x\n0 to a desired target state \n\n\n\n\nx\n\n∗\n\n\n\n in finite time T. Recent advances in deep learning and neural network–based optimization have contributed to the development of numerical methods that can help solve control problems involving high-dimensional dynamical systems. In particular, the framework of neural ordinary differential equations (neural ODEs) provides an efficient means to iteratively approximate continuous-time control functions associated with analytically intractable and computationally demanding control tasks. Although neural ODE controllers have shown great potential in solving complex control problems, the understanding of the effects of hyperparameters such as network structure and optimizers on learning performance is still very limited. Our work aims at addressing some of these knowledge gaps to conduct efficient hyperparameter optimization. To this end, we first analyze how truncated and non-truncated backpropagation through time affect both runtime performance and the ability of neural networks to learn optimal control functions. Using analytical and numerical methods, we then study the role of parameter initializations, optimizers, and neural-network architecture. Finally, we connect our results to the ability of neural ODE controllers to implicitly regularize control energy.",
           3,
           "machine_learning_science_and_technology"
          ],
          [
           "Machine learning based quantification of synchrotron radiation-induced x-ray fluorescence measurements—a case study",
           "10.1088/2632-2153/abc9fb",
           2020,
           "\nIn this work, we describe the use of artificial neural networks (ANNs) for the quantification of x-ray fluorescence measurements. The training data were generated using Monte Carlo simulation, which avoided the use of adapted reference materials. The extension of the available dataset by means of an ANN to generate additional data was demonstrated. Particular emphasis was put on the comparability of simulated and experimental data and how the influence of deviations can be reduced. The search for the optimal hyperparameter, manual and automatic, is also described. For the presented case, we were able to train a network with a mean absolute error of 0.1 weight percent for the synthetic data and 0.7 weight percent for a set of experimental data obtained with certified reference materials.",
           5,
           "machine_learning_science_and_technology"
          ],
          [
           "Machine learning for analyzing and characterizing InAsSb-based nBn photodetectors",
           "10.1088/2632-2153/abcf89",
           2020,
           "\nThis paper discusses two cases of applying artificial neural networks to the capacitance–voltage characteristics of InAsSb-based barrier infrared detectors. In the first case, we discuss a methodology for training a fully-connected feedforward network to predict the capacitance of the device as a function of the absorber, barrier, and contact doping densities, the barrier thickness, and the applied voltage. We verify the model’s performance with physics-based justification of trends observed in single parameter sweeps, partial dependence plots, and two examples of gradient-based sensitivity analysis. The second case focuses on the development of a convolutional neural network that addresses the inverse problem, where a capacitance–voltage profile is used to predict the architectural properties of the device. The advantage of this approach is a more comprehensive characterization of a device by capacitance–voltage profiling than may be possible with other techniques. Finally, both approaches are material and device agnostic, and can be applied to other semiconductor device characteristics.",
           2,
           "machine_learning_science_and_technology"
          ],
          [
           "A recipe for cracking the quantum scaling limit with machine learned electron densities",
           "10.1088/2632-2153/acb314",
           2023,
           "A long-standing goal of science is to accurately simulate large molecular systems using quantum mechanics. The poor scaling of current quantum chemistry algorithms on classical computers, however, imposes an effective limit of about a few dozen atoms on traditional electronic structure calculations. We present a machine learning (ML) method to break through this scaling limit for electron densities. We show that Euclidean neural networks can be trained to predict molecular electron densities from limited data. By learning the electron density, the model can be trained on small systems and make accurate predictions on large ones. In the context of water clusters, we show that an ML model trained on clusters of just 12 molecules contains all the information needed to make accurate electron density predictions on cluster sizes of 50 or more, beyond the scaling limit of current quantum chemistry methods.",
           10,
           "machine_learning_science_and_technology"
          ],
          [
           "Enabling robust offline active learning for machine learning potentials using simple physics-based priors",
           "10.1088/2632-2153/abcc44",
           2020,
           "\nMachine learning surrogate models for quantum mechanical simulations have enabled the field to efficiently and accurately study material and molecular systems. Developed models typically rely on a substantial amount of data to make reliable predictions of the potential energy landscape or careful active learning (AL) and uncertainty estimates. When starting with small datasets, convergence of AL approaches is a major outstanding challenge which has limited most demonstrations to online AL. In this work we demonstrate a Δ-machine learning (ML) approach that enables stable convergence in offline AL strategies by avoiding unphysical configurations with initial datasets as little as a single data point. We demonstrate our framework’s capabilities on a structural relaxation, transition state calculation, and molecular dynamics simulation, with the number of first principle calculations being cut down anywhere from 70%–90%. The approach is incorporated and developed alongside AMPtorch, an open-source ML potential package, along with interactive Google Colab notebook examples.",
           19,
           "machine_learning_science_and_technology"
          ],
          [
           "Prediction of chemical reaction yields using deep learning",
           "10.1088/2632-2153/abc81d",
           2021,
           "\nArtificial intelligence is driving one of the most important revolutions in organic chemistry. Multiple platforms, including tools for reaction prediction and synthesis planning based on machine learning, have successfully become part of the organic chemists’ daily laboratory, assisting in domain-specific synthetic problems. Unlike reaction prediction and retrosynthetic models, the prediction of reaction yields has received less attention in spite of the enormous potential of accurately predicting reaction conversion rates. Reaction yields models, describing the percentage of the reactants converted to the desired products, could guide chemists and help them select high-yielding reactions and score synthesis routes, reducing the number of attempts. So far, yield predictions have been predominantly performed for high-throughput experiments using a categorical (one-hot) encoding of reactants, concatenated molecular fingerprints, or computed chemical descriptors. Here, we extend the application of natural language processing architectures to predict reaction properties given a text-based representation of the reaction, using an encoder transformer model combined with a regression layer. We demonstrate outstanding prediction performance on two high-throughput experiment reactions sets. An analysis of the yields reported in the open-source USPTO data set shows that their distribution differs depending on the mass scale, limiting the data set applicability in reaction yields predictions.",
           103,
           "machine_learning_science_and_technology"
          ],
          [
           "Vortex detection in atomic Bose–Einstein condensates using neural networks trained on synthetic images",
           "10.1088/2632-2153/ad03ad",
           2023,
           "\nQuantum vortices in atomic Bose–Einstein condensates (BECs) are topological defects characterized by quantized circulation of particles around them. In experimental studies, vortices are commonly detected by time-of-flight imaging, where their density-depleted cores are enlarged. In this work, we describe a machine learning-based method for detecting vortices in experimental BEC images, particularly focusing on turbulent condensates containing irregularly distributed vortices. Our approach employs a convolutional neural network (CNN) trained solely on synthetic simulated images, eliminating the need for manual labeling of the vortex positions as ground truth. We find that the CNN achieves accurate vortex detection in real experimental images, thereby facilitating analysis of large experimental datasets without being constrained by specific experimental conditions. This novel approach represents a significant advancement in studying quantum vortex dynamics and streamlines the analysis process in the investigation of turbulent BECs.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Feature space reduction method for ultrahigh-dimensional, multiclass data: random forest-based multiround screening (RFMS)",
           "10.1088/2632-2153/ad020e",
           2023,
           "\nIn recent years, several screening methods have been published for ultrahigh-dimensional data that contain hundreds of thousands of features, many of which are irrelevant or redundant. However, most of these methods cannot handle data with thousands of classes. Prediction models built to authenticate users based on multichannel biometric data result in this type of problem. In this study, we present a novel method known as random forest-based multiround screening (RFMS) that can be effectively applied under such circumstances. The proposed algorithm divides the feature space into small subsets and executes a series of partial model builds. These partial models are used to implement tournament-based sorting and the selection of features based on their importance. This algorithm successfully filters irrelevant features and also discovers binary and higher-order feature interactions. To benchmark RFMS, a synthetic biometric feature space generator known as BiometricBlender is employed. Based on the results, the RFMS is on par with industry-standard feature screening methods, while simultaneously possessing many advantages over them.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Finding simplicity: unsupervised discovery of features, patterns, and order parameters via shift-invariant variational autoencoders\n                  <sup>*</sup>",
           "10.1088/2632-2153/ad073b",
           2023,
           "\nRecent advances in scanning tunneling and transmission electron microscopies (STM and STEM) have allowed routine generation of large volumes of imaging data containing information on the structure and functionality of materials. The experimental data sets contain signatures of long-range phenomena such as physical order parameter fields, polarization, and strain gradients in STEM, or standing electronic waves and carrier-mediated exchange interactions in STM, all superimposed onto scanning system distortions and gradual changes of contrast due to drift and/or mis-tilt effects. Correspondingly, while the human eye can readily identify certain patterns in the images such as lattice periodicities, repeating structural elements, or microstructures, their automatic extraction and classification are highly non-trivial and universal pathways to accomplish such analyses are absent. We pose that the most distinctive elements of the patterns observed in STM and (S)TEM images are similarity and (almost-) periodicity, behaviors stemming directly from the parsimony of elementary atomic structures, superimposed on the gradual changes reflective of order parameter distributions. However, the discovery of these elements via global Fourier methods is non-trivial due to variability and lack of ideal discrete translation symmetry. To address this problem, we explore the shift-invariant variational autoencoders (shift-VAEs) that allow disentangling characteristic repeating features in the images, their variations, and shifts that inevitably occur when randomly sampling the image space. Shift-VAEs balance the uncertainty in the position of the object of interest with the uncertainty in shape reconstruction. This approach is illustrated for model 1D data, and further extended to synthetic and experimental STM and STEM 2D data. We further introduce an approach for training shift-VAEs that allows finding the latent variables that comport to known physical behavior. In this specific case, the condition is that the latent variable maps should be smooth on the length scale of the atomic lattice (as expected for physical order parameters), but other conditions can be imposed. The opportunities and limitations of the shift VAE analysis for pattern discovery are elucidated.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Bridging the gap between high-level quantum chemical methods and deep learning models",
           "10.1088/2632-2153/ad27e1",
           2024,
           "\nSupervised deep learning (DL) models are becoming ubiquitous in computational chemistry because they can efficiently learn complex input-output relationships and predict chemical properties at a cost significantly lower than methods based on quantum mechanics. The central challenge in many DL applications is the need to invest considerable computational resources in generating large (\n\n\nN\n>\n1\n×\n\n10\n5\n\n\n\n) training sets such that the resulting DL model can be generalized reliably to unseen systems. The lack of better alternatives has encouraged the use of low-cost and relatively inaccurate density-functional theory (DFT) methods to generate training data, leading to DL models that lack accuracy and reliability. In this article, we describe a robust and easily implemented approach based on property-specific atom-centered potentials (ACPs) that resolves this central challenge in DL model development. ACPs are one-electron potentials that are applied in combination with a computationally inexpensive but inaccurate quantum mechanical method (e.g. double-ζ DFT) and fitted against relatively few high-level data (\n\n\nN\n≈\n1\n×\n\n10\n\n3\n\n\n\n\n–\n\n\n1\n×\n\n10\n\n4\n\n\n\n\n), possibly obtained from the literature. The resulting ACP-corrected methods retain the low cost of the double-ζ DFT approach, while generating high-level-quality data in unseen systems for the specific property for which they were designed. With this approach, we demonstrate that ACPs can be used as an intermediate method between high-level approaches and DL model development, enabling the calculation of large and accurate DL training sets for the chemical property of interest. We demonstrate the effectiveness of the proposed approach by predicting bond dissociation enthalpies, reaction barrier heights, and reaction energies with chemical accuracy at a computational cost lower than the DFT methods routinely used for DL training data set generation.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Outlook for artificial intelligence and machine learning at the NSLS-II",
           "10.1088/2632-2153/abbd4e",
           2020,
           "We describe the current and future plans for using artificial intelligence and machine learning (AI/ML) methods at the National Synchrotron Light Source II (NSLS-II), a scientific user facility at the Brookhaven National Laboratory. We discuss the opportunity for using the AI/ML tools and techniques developed in the data and computational science areas to greatly improve the scientific output of large scale experimental user facilities. We describe our current and future plans in areas including from detecting and recovering from faults, optimizing the source and instrument configurations, streamlining the pipeline from measurement to insight, through data acquisition, processing, analysis. The overall strategy and direction of the NSLS-II facility in relation to AI/ML is presented.",
           12,
           "machine_learning_science_and_technology"
          ],
          [
           "Attention-based quantum tomography",
           "10.1088/2632-2153/ac362b",
           2021,
           "\nWith rapid progress across platforms for quantum systems, the problem of many-body quantum state reconstruction for noisy quantum states becomes an important challenge. There has been a growing interest in approaching the problem of quantum state reconstruction using generative neural network models. Here we propose the ‘attention-based quantum tomography’ (AQT), a quantum state reconstruction using an attention mechanism-based generative network that learns the mixed state density matrix of a noisy quantum state. AQT is based on the model proposed in ‘Attention is all you need’ by Vaswani et al (2017 NIPS) that is designed to learn long-range correlations in natural language sentences and thereby outperform previous natural language processing (NLP) models. We demonstrate not only that AQT outperforms earlier neural-network-based quantum state reconstruction on identical tasks but that AQT can accurately reconstruct the density matrix associated with a noisy quantum state experimentally realized in an IBMQ quantum computer. We speculate the success of the AQT stems from its ability to model quantum entanglement across the entire quantum system much as the attention model for NLP captures the correlations among words in a sentence.",
           22,
           "machine_learning_science_and_technology"
          ],
          [
           "Gaussian-process-regression-based method for the localization of exceptional points in complex resonance spectra",
           "10.1088/2632-2153/ad2e16",
           2024,
           "\nResonances in open quantum systems depending on at least two controllable parameters can show the phenomenon of exceptional points (EPs), where not only the eigenvalues but also the eigenvectors of two or more resonances coalesce. Their exact localization in the parameter space is challenging, in particular in systems, where the computation of the quantum spectra and resonances is numerically very expensive. We introduce an efficient machine learning algorithm to find EPs based on Gaussian process regression (GPR). The GPR-model is trained with an initial set of eigenvalue pairs belonging to an EP and used for a first estimation of the EP position via a numerically cheap root search. The estimate is then improved iteratively by adding selected exact eigenvalue pairs as training points to the GPR-model. The GPR-based method is developed and tested on a simple low-dimensional matrix model and then applied to a challenging real physical system, viz., the localization of EPs in the resonance spectra of excitons in cuprous oxide in external electric and magnetic fields. The precise computation of EPs, by taking into account the complete valence band structure and central-cell corrections of the crystal, can be the basis for the experimental observation of EPs in this system.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Optimal data generation for machine learned interatomic potentials",
           "10.1088/2632-2153/ac9ae7",
           2022,
           "\nMachine learning interatomic potentials (MLIPs) are routinely used atomic simulations, but generating databases of atomic configurations used in fitting these models is a laborious process, requiring significant computational and human effort. A computationally efficient method is presented to generate databases of atomic configurations that contain optimal information on the small-displacement regime of the potential energy surface of bulk crystalline matter. Utilising non-diagonal supercell (Lloyd-Williams and Monserrat 2015 Phys. Rev. B 92 184301), an automatic process is suggested for ab initio data generation. MLIPs were fitted for Al, W, Mg and Si, which very closely reproduce the ab initio phonon and elastic properties. The protocol can be easily adapted to other materials and can be inserted in the workflow of any flavour of MLIP generation.",
           3,
           "machine_learning_science_and_technology"
          ],
          [
           "Molecular machine learning with conformer ensembles",
           "10.1088/2632-2153/acefa7",
           2023,
           "\nVirtual screening can accelerate drug discovery by identifying promising candidates for experimental evaluation. Machine learning is a powerful method for screening, as it can learn complex structure–property relationships from experimental data and make rapid predictions over virtual libraries. Molecules inherently exist as a three-dimensional ensemble and their biological action typically occurs through supramolecular recognition. However, most deep learning approaches to molecular property prediction use a 2D graph representation as input, and in some cases a single 3D conformation. Here we investigate how the 3D information of multiple conformers, traditionally known as 4D information in the cheminformatics community, can improve molecular property prediction in deep learning models. We introduce multiple deep learning models that expand upon key architectures such as ChemProp and SchNet, adding elements such as multiple-conformer inputs and conformer attention. We then benchmark the performance trade-offs of these models on 2D, 3D and 4D representations in the prediction of drug activity using a large training set of geometrically resolved molecules. The new architectures perform significantly better than 2D models, but their performance is often just as strong with a single conformer as with many. We also find that 4D deep learning models learn interpretable attention weights for each conformer.",
           7,
           "machine_learning_science_and_technology"
          ],
          [
           "GWAK: Gravitational-Wave Anomalous Knowledge with Recurrent Autoencoders",
           "10.1088/2632-2153/ad3a31",
           2024,
           "\nMatched-filtering detection techniques for gravitational-wave (GW) signals in ground-based interferometers rely on having well-modeled templates of the GW emission. Such techniques have been traditionally used in searches for compact binary coalescences (CBCs), and have been employed in all known GW detections so far. However, interesting science cases aside from compact mergers do not yet have accurate enough modeling to make matched filtering possible, including core-collapse supernovae and sources where stochasticity may be involved. Therefore the development of techniques to identify sources of these types is of significant interest. In this paper, we present a method of anomaly detection based on deep recurrent autoencoders to enhance the search region to unmodeled transients. We use a semi-supervised strategy that we name “Gravitational Wave Anomalous Knowledge” (GWAK). While the semi-supervised nature of the problem comes with a cost in terms of accuracy as compared to supervised techniques, there is a qualitative advantage in generalizing experimental sensitivity beyond pre-computed signal templates. We construct a low-dimensional embedded space using the GWAK method, capturing the physical signatures of distinct signals on each axis of the space. By introducing signal priors that capture some of the salient features of GW signals, we allow for the recovery of sensitivity even when an unmodeled anomaly is encountered. We show that regions of the GWAK space can identify CBCs, detector glitches and also a variety of unmodeled astrophysical sources.&#xD;",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Noise enhanced neural networks for analytic continuation",
           "10.1088/2632-2153/ac6f44",
           2022,
           "\nAnalytic continuation maps imaginary-time Green’s functions obtained by various theoretical/numerical methods to real-time response functions that can be directly compared with experiments. Analytic continuation is an important bridge between many-body theories and experiments but is also a challenging problem because such mappings are ill-conditioned. In this work, we develop a neural network (NN)-based method for this problem. The training data is generated either using synthetic Gaussian-type spectral functions or from exactly solvable models where the analytic continuation can be obtained analytically. Then, we applied the trained NN to the testing data, either with synthetic noise or intrinsic noise in Monte Carlo simulations. We conclude that the best performance is always achieved when a proper amount of noise is added to the training data. Moreover, our method can successfully capture multi-peak structure in the resulting response function for the cases with the best performance. The method can be combined with Monte Carlo simulations to compare with experiments on real-time dynamics.",
           2,
           "machine_learning_science_and_technology"
          ],
          [
           "Role of multifidelity data in sequential active learning materials discovery campaigns: case study of electronic bandgap",
           "10.1088/2632-2153/ad1627",
           2023,
           "\nMaterials discovery and design typically proceeds through iterative evaluation (both experimental and computational) to obtain data, generally targeting improvement of one or more properties under one or more constraints (e.g. time or budget). However, there can be great variation in the quality and cost of different data, and when they are mixed together in what we here call multifidelity data, the optimal approaches to their utilization are not established. It is therefore important to develop strategies to acquire and use multifidelity data to realize the most efficient iterative materials exploration. In this work, we assess the impact of using multifidelity data through mock demonstration of designing solar cell materials, using the electronic bandgap as the target property. We propose a new approach of using multifidelity data through leveraging machine learning models of both low- and high-fidelity data, where using predicted low-fidelity data as an input feature in the high-fidelity model can improve the impact of a multifidelity data approach. We show how tradeoffs of low- versus high-fidelity measurement cost and acquisition can impact the materials discovery process. We find that the use of multifidelity data has maximal impact on the materials discovery campaign when approximately five low-fidelity measurements per high-fidelity measurement are performed, and when the cost of low-fidelity measurements is approximately 5% or less than that of high-fidelity measurements. This work provides practical guidance and useful qualitative measures for improving materials discovery campaigns that involve multifidelity data.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Mapping confinement potentials and charge densities of interacting quantum systems using conditional generative adversarial networks",
           "10.1088/2632-2153/acd6d8",
           2023,
           "\nAccurate and efficient tools for calculating the ground state properties of interacting quantum systems are essential in the design of nanoelectronic devices. The exact diagonalization method fully accounts for the Coulomb interaction beyond mean field approximations and it is regarded as the gold-standard for few electron systems. However, by increasing the number of instances to be solved, the computational costs become prohibitive and new approaches based on machine learning techniques can provide a significant reduction in computational time and resources, maintaining a reasonable accuracy. Here, we employ pix2pix, a general-purpose image-to-image translation method based on conditional generative adversarial network (cGAN), for predicting ground state densities from randomly generated confinement potentials. Other mappings were also investigated, like potentials to non-interacting densities and the translation from non-interacting to interacting densities. The architecture of the cGAN was optimized with respect to the internal parameters of the generator and discriminator. Moreover, the inverse problem of finding the confinement potential given the interacting density can also be approached by the pix2pix mapping, which is an important step in finding near-optimal solutions for confinement potentials.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "Miniaturizing neural networks for charge state autotuning in quantum dots",
           "10.1088/2632-2153/ac34db",
           2021,
           "\nA key challenge in scaling quantum computers is the calibration and control of multiple qubits. In solid-state quantum dots (QDs), the gate voltages required to stabilize quantized charges are unique for each individual qubit, resulting in a high-dimensional control parameter space that must be tuned automatically. Machine learning techniques are capable of processing high-dimensional data—provided that an appropriate training set is available—and have been successfully used for autotuning in the past. In this paper, we develop extremely small feed-forward neural networks that can be used to detect charge-state transitions in QD stability diagrams. We demonstrate that these neural networks can be trained on synthetic data produced by computer simulations, and robustly transferred to the task of tuning an experimental device into a desired charge state. The neural networks required for this task are sufficiently small as to enable an implementation in existing memristor crossbar arrays in the near future. This opens up the possibility of miniaturizing powerful control elements on low-power hardware, a significant step towards on-chip autotuning in future QD computers.",
           7,
           "machine_learning_science_and_technology"
          ],
          [
           "Efficient generation of stable linear machine-learning force fields with uncertainty-aware active learning",
           "10.1088/2632-2153/ace418",
           2023,
           "Machine-learning (ML) force fields (FFs) enable an accurate and universal description of the potential energy surface of molecules and materials on the basis of a training set ofab initiodata. However, large-scale applications of these methods rest on the possibility to train accurate ML models with a small number ofab initiodata. In this respect, active-learning (AL) strategies, where the training set is self-generated by the model itself, combined with linear ML models are particularly promising. In this work, we explore an AL strategy based on linear regression and able to predict the model’s uncertainty on predictions for molecular configurations not sampled by the training set, thus providing a straightforward recipe for the extension of the latter. We apply this strategy to the spectral neighbor analysis potential and show that only tens ofab initiosimulations of atomic forces are required to generate FFs for room-temperature molecular dynamics at or close to chemical accuracy and which stability can be systematically improved by the user at modest computational expenses. Moreover, the method does not necessitate any conformational pre-sampling, thus requiring minimal user intervention and parametrization.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "GA-based weighted ensemble learning for multi-label aerial image classification using convolutional neural networks and vision transformers",
           "10.1088/2632-2153/ad10cf",
           2023,
           "\nMulti-label classification (MLC) of aerial images is a crucial task in remote sensing image analysis. Traditional image classification methods have limitations in image feature extraction, leading to an increasing use of deep learning models, such as convolutional neural networks (CNN) and vision transformers (ViT). However, the standalone use of these models may have limitations when dealing with MLC. To enhance the generalization performance of MLC of aerial images, this paper combines two CNN and two ViT models, comparing four single deep learning models, a manually weighted ensemble learning method, and a GA-based weighted ensemble method. The experimental results using two public multi-label aerial image datasets show that the classification performance of ViT models is better than CNN models, the traditional weighted ensemble learning model performs better than a single deep learning model, and the GA-based weighted ensemble method performs better than the manually weighted ensemble learning method. The GA-based weighted ensemble method proposed in this study can achieve better MLC performance of aerial images than previous results.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Convolutional neural network based non-iterative reconstruction for accelerating neutron tomography\n                  <sup>*</sup>",
           "10.1088/2632-2153/abde8e",
           2021,
           "\nNeutron computed tomography (NCT), a 3D non-destructive characterization technique, is carried out at nuclear reactor or spallation neutron source-based user facilities. Because neutrons are not severely attenuated by heavy elements and are sensitive to light elements like hydrogen, neutron radiography and computed tomography offer a complementary contrast to x-ray CT conducted at a synchrotron user facility. However, compared to synchrotron x-ray CT, the acquisition time for an NCT scan can be orders of magnitude higher due to lower source flux, low detector efficiency and the need to collect a large number of projection images for a high-quality reconstruction when using conventional algorithms. As a result of the long scan times for NCT, the number and type of experiments that can be conducted at a user facility is severely restricted. Recently, several deep convolutional neural network (DCNN) based algorithms have been introduced in the context of accelerating CT scans that can enable high quality reconstructions from sparse-view data. In this paper, we introduce DCNN algorithms to obtain high-quality reconstructions from sparse-view and low signal-to-noise ratio NCT data-sets thereby enabling accelerated scans. Our method is based on the supervised learning strategy of training a DCNN to map a low-quality reconstruction from sparse-view data to a higher quality reconstruction. Specifically, we evaluate the performance of two popular DCNN architectures—one based on using patches for training and the other on using the full images for training. We observe that both the DCNN architectures offer improvements in performance over classical multi-layer perceptron as well as conventional CT reconstruction algorithms. Our results illustrate that the DCNN can be a powerful tool to obtain high-quality NCT reconstructions from sparse-view data thereby enabling accelerated NCT scans for increasing user-facility throughput or enabling high-resolution time-resolved NCT scans.",
           3,
           "machine_learning_science_and_technology"
          ],
          [
           "Atomic permutationally invariant polynomials for fitting molecular force fields",
           "10.1088/2632-2153/abd51e",
           2020,
           "\nWe introduce and explore an approach for constructing force fields for small molecules, which combines intuitive low body order empirical force field terms with the concepts of data driven statistical fits of recent machine learned potentials. We bring these two key ideas together to bridge the gap between established empirical force fields that have a high degree of transferability on the one hand, and the machine learned potentials that are systematically improvable and can converge to very high accuracy, on the other. Our framework extends the atomic permutationally invariant polynomials (aPIP) developed for elemental materials in (2019 Mach. Learn.: Sci. Technol.\n1 015004) to molecular systems. The body order decomposition allows us to keep the dimensionality of each term low, while the use of an iterative fitting scheme as well as regularisation procedures improve the extrapolation outside the training set. We investigate aPIP force fields with up to generalised 4-body terms, and examine the performance on a set of small organic molecules. We achieve a high level of accuracy when fitting individual molecules, comparable to those of the many-body machine learned force fields. Fitted to a combined training set of short linear alkanes, the accuracy of the aPIP force field still significantly exceeds what can be expected from classical empirical force fields, while retaining reasonable transferability to both configurations far from the training set and to new molecules.",
           25,
           "machine_learning_science_and_technology"
          ],
          [
           "Self-referencing embedded strings (SELFIES): A 100% robust molecular string representation",
           "10.1088/2632-2153/aba947",
           2020,
           "\nThe discovery of novel materials and functional molecules can help to solve some of society’s most urgent challenges, ranging from efficient energy harvesting and storage to uncovering novel pharmaceutical drug candidates. Traditionally matter engineering–generally denoted as inverse design–was based massively on human intuition and high-throughput virtual screening. The last few years have seen the emergence of significant interest in computer-inspired designs based on evolutionary or deep learning methods. The major challenge here is that the standard strings molecular representation SMILES shows substantial weaknesses in that task because large fractions of strings do not correspond to valid molecules. Here, we solve this problem at a fundamental level and introduce SELFIES (SELF-referencIng Embedded Strings), a string-based representation of molecules which is 100% robust. Every SELFIES string corresponds to a valid molecule, and SELFIES can represent every molecule. SELFIES can be directly applied in arbitrary machine learning models without the adaptation of the models; each of the generated molecule candidates is valid. In our experiments, the model’s internal memory stores two orders of magnitude more diverse molecules than a similar test with SMILES. Furthermore, as all molecules are valid, it allows for explanation and interpretation of the internal working of the generative models.",
           262,
           "machine_learning_science_and_technology"
          ],
          [
           "Deep-learning-based quantum vortex detection in atomic Bose–Einstein condensates",
           "10.1088/2632-2153/abea6a",
           2021,
           "\nQuantum vortices naturally emerge in rotating Bose–Einstein condensates (BECs) and, similarly to their classical counterparts, allow the study of a range of interesting out-of-equilibrium phenomena, such as turbulence and chaos. However, the study of such phenomena requires the determination of the precise location of each vortex within a BEC, which becomes challenging when either only the density of the condensate is available or sources of noise are present, as is typically the case in experimental settings. Here, we introduce a machine-learning-based vortex detector motivated by state-of-the-art object detection methods that can accurately locate vortices in simulated BEC density images. Our model allows for robust and real-time detection in noisy and non-equilibrium configurations. Furthermore, the network can distinguish between vortices and anti-vortices if the phase profile of the condensate is also available. We anticipate that our vortex detector will be advantageous for both experimental and theoretical studies of the static and dynamic properties of vortex configurations in BECs.",
           11,
           "machine_learning_science_and_technology"
          ],
          [
           "Ten years of generative adversarial nets (GANs): a survey of the state-of-the-art",
           "10.1088/2632-2153/ad1f77",
           2024,
           "\nGenerative adversarial networks (GANs) have rapidly emerged as powerful tools for generating realistic and diverse data across various domains, including computer vision and other applied areas, since their inception in 2014. Consisting of a discriminative network and a generative network engaged in a minimax game, GANs have revolutionized the field of generative modeling. In February 2018, GAN secured the leading spot on the ‘Top Ten Global Breakthrough Technologies List’ issued by the Massachusetts Science and Technology Review. Over the years, numerous advancements have been proposed, leading to a rich array of GAN variants, such as conditional GAN, Wasserstein GAN, cycle-consistent GAN, and StyleGAN, among many others. This survey aims to provide a general overview of GANs, summarizing the latent architecture, validation metrics, and application areas of the most widely recognized variants. We also delve into recent theoretical developments, exploring the profound connection between the adversarial principle underlying GAN and Jensen–Shannon divergence while discussing the optimality characteristics of the GAN framework. The efficiency of GAN variants and their model architectures will be evaluated along with training obstacles as well as training solutions. In addition, a detailed discussion will be provided, examining the integration of GANs with newly developed deep learning frameworks such as transformers, physics-informed neural networks, large language models, and diffusion models. Finally, we reveal several issues as well as future research outlines in this field.",
           2,
           "machine_learning_science_and_technology"
          ],
          [
           "Dynamics of supercooled liquids from static averaged quantities using machine learning",
           "10.1088/2632-2153/acc7e1",
           2023,
           "\nWe introduce a machine-learning approach to predict the complex non-Markovian dynamics of supercooled liquids from static averaged quantities. Compared to techniques based on particle propensity, our method is built upon a theoretical framework that uses as input and output system-averaged quantities, thus being easier to apply in an experimental context where particle resolved information is not available. In this work, we train a deep neural network to predict the self intermediate scattering function of binary mixtures using their static structure factor as input. While its performance is excellent for the temperature range of the training data, the model also retains some transferability in making decent predictions at temperatures lower than the ones it was trained for, or when we use it for similar systems. We also develop an evolutionary strategy that is able to construct a realistic memory function underlying the observed non-Markovian dynamics. This method lets us conclude that the memory function of supercooled liquids can be effectively parameterized as the sum of two stretched exponentials, which physically corresponds to two dominant relaxation modes.",
           4,
           "machine_learning_science_and_technology"
          ],
          [
           "Multi-task graph neural networks for simultaneous prediction of global and atomic properties in ferromagnetic systems\n                  <sup>*</sup>",
           "10.1088/2632-2153/ac6a51",
           2022,
           "\nWe introduce a multi-tasking graph convolutional neural network, HydraGNN, to simultaneously predict both global and atomic physical properties and demonstrate with ferromagnetic materials. We train HydraGNN on an open-source ab initio density functional theory (DFT) dataset for iron-platinum with a fixed body centered tetragonal lattice structure and fixed volume to simultaneously predict the mixing enthalpy (a global feature of the system), the atomic charge transfer, and the atomic magnetic moment across configurations that span the entire compositional range. By taking advantage of underlying physical correlations between material properties, multi-task learning (MTL) with HydraGNN provides effective training even with modest amounts of data. Moreover, this is achieved with just one architecture instead of three, as required by single-task learning (STL). The first convolutional layers of the HydraGNN architecture are shared by all learning tasks and extract features common to all material properties. The following layers discriminate the features of the different properties, the results of which are fed to the separate heads of the final layer to produce predictions. Numerical results show that HydraGNN effectively captures the relation between the configurational entropy and the material properties over the entire compositional range. Overall, the accuracy of simultaneous MTL predictions is comparable to the accuracy of the STL predictions. In addition, the computational cost of training HydraGNN for MTL is much lower than the original DFT calculations and also lower than training separate STL models for each property.",
           8,
           "machine_learning_science_and_technology"
          ],
          [
           "New angles on fast calorimeter shower simulation",
           "10.1088/2632-2153/acefa9",
           2023,
           "The demands placed on computational resources by the simulation requirements of high energy physics experiments motivate the development of novel simulation tools. Machine learning based generative models offer a solution that is both fast and accurate. In this work we extend the Bounded Information Bottleneck Autoencoder (BIB-AE) architecture, designed for the simulation of particle showers in highly granular calorimeters, in two key directions. First, we generalise the model to a multi-parameter conditioning scenario, while retaining a high degree of physics fidelity. In a second step, we perform a detailed study of the effect of applying a state-of-the-art particle flow-based reconstruction procedure to the generated showers. We demonstrate that the performance of the model remains high after reconstruction. These results are an important step towards creating a more general simulation tool, where maintaining physics performance after reconstruction is the ultimate target.",
           6,
           "machine_learning_science_and_technology"
          ],
          [
           "Generating stable molecules using imitation and reinforcement learning",
           "10.1088/2632-2153/ac3eb4",
           2021,
           "\nChemical space is routinely explored by machine learning methods to discover interesting molecules, before time-consuming experimental synthesizing is attempted. However, these methods often rely on a graph representation, ignoring 3D information necessary for determining the stability of the molecules. We propose a reinforcement learning (RL) approach for generating molecules in Cartesian coordinates allowing for quantum chemical prediction of the stability. To improve sample-efficiency we learn basic chemical rules from imitation learning (IL) on the GDB-11 database to create an initial model applicable for all stoichiometries. We then deploy multiple copies of the model conditioned on a specific stoichiometry in a RL setting. The models correctly identify low energy molecules in the database and produce novel isomers not found in the training set. Finally, we apply the model to larger molecules to show how RL further refines the IL model in domains far from the training data.",
           4,
           "machine_learning_science_and_technology"
          ],
          [
           "Hadrons, better, faster, stronger",
           "10.1088/2632-2153/ac7848",
           2022,
           "\nMotivated by the computational limitations of simulating interactions of particles in highly-granular detectors, there exists a concerted effort to build fast and exact machine-learning-based shower simulators. This work reports progress on two important fronts. First, the previously investigated Wasserstein generative adversarial network and bounded information bottleneck autoencoder generative models are improved and successful learning of hadronic showers initiated by charged pions in a segment of the hadronic calorimeter of the International Large Detector is demonstrated for the first time. Second, we consider how state-of-the-art reconstruction software applied to generated shower energies affects the obtainable energy response and resolution. While many challenges remain, these results constitute an important milestone in using generative models in a realistic setting.",
           20,
           "machine_learning_science_and_technology"
          ],
          [
           "A finite element-convolutional neural network model (FE-CNN) for stress field analysis around arbitrary inclusions",
           "10.1088/2632-2153/ad134a",
           2023,
           "\nThis study presents a data-driven finite element-machine learning surrogate model for predicting the end-to-end full-field stress distribution and stress concentration around an arbitrary-shaped inclusion. This is important because the model’s capacity to handle large datasets, consider variations in size and shape, and accurately replicate stress fields makes it a valuable tool for studying how inclusion characteristics affect material performance. An automatized dataset generation method using finite element simulation is proposed, validated, and used for attaining a dataset with one thousand inclusion shapes motivated by experimental observations and their corresponding spatially-varying stress distributions. A U-Net-based convolutional neural network (CNN) is trained using the dataset, and its performance is evaluated through quantitative and qualitative comparisons. The dataset, consisting of these stress data arrays, is directly fed into the CNN model for training and evaluation. This approach bypasses the need for converting the stress data into image format, allowing for a more direct and efficient input representation for the CNN. The model was evaluated through a series of sensitivity analyses, focusing on the impact of dataset size and model resolution on accuracy and performance. The results demonstrated that increasing the dataset size significantly improved the model’s prediction accuracy, as indicated by the correlation values. Additionally, the investigation into the effect of model resolution revealed that higher resolutions led to better stress field predictions and reduced error. Overall, the surrogate model proved effective in accurately predicting the effective stress concentration in inclusions, showcasing its potential in practical applications requiring stress analysis such as structural engineering, material design, failure analysis, and multi-scale modeling.",
           3,
           "machine_learning_science_and_technology"
          ],
          [
           "Prediction of 4D stress field evolution around additive manufacturing-induced porosity through progressive deep-learning frameworks",
           "10.1088/2632-2153/ad290c",
           2024,
           "\nThis study investigates the application of machine learning models to predict time-evolving stress fields in complex three-dimensional structures trained with full-scale finite element simulation data. Two novel architectures, the multi-decoder CNN (MUDE-CNN) and the multiple encoder–decoder model with transfer learning (MTED-TL), were introduced to address the challenge of predicting the progressive and spatial evolutional of stress distributions around defects. The MUDE-CNN leveraged a shared encoder for simultaneous feature extraction and employed multiple decoders for distinct time frame predictions, while MTED-TL progressively transferred knowledge from one encoder–decoder block to another, thereby enhancing prediction accuracy through transfer learning. These models were evaluated to assess their accuracy, with a particular focus on predicting temporal stress fields around an additive manufacturing (AM)-induced isolated pore, as understanding such defects is crucial for assessing mechanical properties and structural integrity in materials and components fabricated via AM. The temporal model evaluation demonstrated MTED-TL’s consistent superiority over MUDE-CNN, owing to transfer learning’s advantageous initialization of weights and smooth loss curves. Furthermore, an autoregressive training framework was introduced to improve temporal predictions, consistently outperforming both MUDE-CNN and MTED-TL. By accurately predicting temporal stress fields around AM-induced defects, these models can enable real-time monitoring and proactive defect mitigation during the fabrication process. This capability ensures enhanced component quality and enhances the overall reliability of additively manufactured parts.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "Categorical representation learning: morphism is all you need",
           "10.1088/2632-2153/ac2c5d",
           2021,
           "\nWe provide a construction for categorical representation learning and introduce the foundations of ‘categorifier’. The central theme in representation learning is the idea of everything to vector. Every object in a dataset \n\n\n\nS\n\n\n\n can be represented as a vector in \n\n\n\n\nR\n\nn\n\n\n\n by an encoding map\n\n\n\nE\n:\n\nO\n\nb\nj\n(\n\nS\n\n)\n→\n\n\nR\n\nn\n\n\n\n. More importantly, every morphism can be represented as a matrix \n\n\nE\n:\n\nH\n\no\nm\n(\n\nS\n\n)\n→\n\n\nR\n\n\nn\n\n\nn\n\n\n\n\n. The encoding map E is generally modeled by a deep neural network. The goal of representation learning is to design appropriate tasks on the dataset to train the encoding map (assuming that an encoding is optimal if it universally optimizes the performance on various tasks). However, the latter is still a set-theoretic approach. The goal of the current article is to promote the representation learning to a new level via a category-theoretic approach. As a proof of concept, we provide an example of a text translator equipped with our technology, showing that our categorical learning model outperforms the current deep learning models by 17 times. The content of the current article is part of a US provisional patent application filed by QGNai, Inc.",
           3,
           "machine_learning_science_and_technology"
          ],
          [
           "Machine learning spatio-temporal epidemiological model to evaluate Germany-county-level COVID-19 risk",
           "10.1088/2632-2153/ac0314",
           2021,
           "\nAs the COVID-19 pandemic continues to ravage the world, it is critical to assess the COVID-19 risk timely on multi-scale. To implement it and evaluate the public health policies, we develop a machine learning assisted framework to predict epidemic dynamics from the reported infection data. It contains a county-level spatio-temporal epidemiological model, which combines spatial cellular automata (CA) with time sensitive-undiagnosed-infected-removed (SUIR) model, and is compatible with the existing risk prediction models. The CA-SUIR model shows the multi-scale risk to the public and reveals the transmission modes of coronavirus in different scenarios. Through transfer learning, this new toolbox is used to predict the prevalence of multi-scale COVID-19 in all 412 counties in Germany. A t-day-ahead risk forecast as well as assessment of the non-pharmaceutical intervention policies is presented. We analyzed the situation at Christmas of 2020, and found that the most serious death toll could be 34.5. However, effective policy could control it below 21thousand, which provides a quantitative basis for evaluating the public policies implemented by the government. Such intervening evaluation process would help to improve public health policies and restart the economy appropriately in pandemics.",
           14,
           "machine_learning_science_and_technology"
          ],
          [
           "Tackling multimodal device distributions in inverse photonic design using invertible neural networks",
           "10.1088/2632-2153/acd619",
           2023,
           "\nWe show how conditional generative neural networks can be used to efficiently find nanophotonic devices with desired properties, also known as inverse photonic design. Machine learning has emerged as a promising approach to overcome limitations imposed by the dimensionality and topology of the parameter space. Importantly, traditional optimization routines assume an invertible mapping between the design parameters and response. However, different designs may have comparable or even identical performance confusing the optimization algorithm when performing inverse design. Our generative modeling approach provides the full distribution of possible solutions to the inverse design problem, including multiple solutions. We compare a commonly used conditional variational autoencoder (cVAE) and a conditional invertible neural network (cINN) on a proof-of-principle nanophotonic problem, consisting in tailoring the transmission spectrum trough a metallic film milled by subwavelength indentations. We show how cINNs have superior flexibility compared to cVAEs when dealing with multimodal device distributions.",
           2,
           "machine_learning_science_and_technology"
          ],
          [
           "On the expressivity of embedding quantum kernels",
           "10.1088/2632-2153/ad2f51",
           2024,
           "\nOne of the most natural connections between quantum and classical machine learning has been established in the context of kernel methods. Kernel methods rely on kernels, which are inner products of feature vectors living in large feature spaces. Quantum kernels are typically evaluated by explicitly constructing quantum feature states and then taking their inner product, here called embedding quantum kernels. Since classical kernels are usually evaluated without using the feature vectors explicitly, we wonder how expressive embedding quantum kernels are. In this work, we raise the fundamental question: can all quantum kernels be expressed as the inner product of quantum feature states? Our first result is positive: Invoking computational universality, we find that for any kernel function there always exists a corresponding quantum feature map and an embedding quantum kernel. The more operational reading of the question is concerned with efficient constructions, however. In a second part, we formalize the question of universality of efficient embedding quantum kernels. For shift-invariant kernels, we use the technique of random Fourier features to show that they are universal within the broad class of all kernels which allow a variant of efficient Fourier sampling. We then extend this result to a new class of so-called composition kernels, which we show also contains projected quantum kernels introduced in recent works. After proving the universality of embedding quantum kernels for both shift-invariant and composition kernels, we identify the directions towards new, more exotic, and unexplored quantum kernel families, for which it still remains open whether they correspond to efficient embedding quantum kernels.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Deep learning of interface structures from simulated 4D STEM data: cation intermixing vs. roughening\n                  <sup>\n                     <sup>∗</sup>\n                  </sup>",
           "10.1088/2632-2153/aba32d",
           2020,
           "\nInterface structures in complex oxides remain an active area of condensed matter physics research, largely enabled by recent advances in scanning transmission electron microscopy (STEM). Yet the nature of the STEM contrast in which the structure is projected along the given direction precludes separation of possible structural models. Here, we utilize deep convolutional neural networks (DCNN) trained on simulated 4D STEM datasets to predict structural descriptors of interfaces. We focus on the widely studied interface between LaAlO3 and SrTiO3, using dynamical diffraction theory and leveraging high performance computing to simulate thousands of possible 4D STEM datasets to train the DCNN to learn properties of the underlying structures on which the simulations are based. We test the DCNN on simulated data and show that it is possible (with >95% accuracy) to identify a physically rough from a chemically diffuse interface and create a DCNN regression model to predict step positions. We quantify the applicability of the model to different thicknesses and the transferability of the approach. The method shown here is general and can be applied for any inverse imaging problem where forward models are present.",
           5,
           "machine_learning_science_and_technology"
          ],
          [
           "Classification of diffraction patterns in single particle imaging experiments performed at x-ray free-electron lasers using a convolutional neural network",
           "10.1088/2632-2153/abd916",
           2021,
           "\nSingle particle imaging (SPI) is a promising method of native structure determination, which has undergone fast progress with the development of x-ray free-electron lasers. Large amounts of data are collected during SPI experiments, driving the need for automated data analysis. The necessary data analysis pipeline has a number of steps including binary object classification (single versus non-single hits). Classification and object detection are areas where deep neural networks currently outperform other approaches. In this work, we use the fast object detector networks YOLOv2 and YOLOv3. By exploiting transfer learning, a moderate amount of data is sufficient to train the neural network. We demonstrate here that a convolutional neural network can be successfully used to classify data from SPI experiments. We compare the results of classification for the two different networks, with different depth and architecture, by applying them to the same SPI data with different data representation. The best results are obtained for diffracted intensity represented by color images on a linear scale using YOLOv2 for classification. It shows an accuracy of about 95% with precision and recall of about 50% and 60%, respectively, in comparison to manual data classification.",
           13,
           "machine_learning_science_and_technology"
          ],
          [
           "Symmetric and antisymmetric kernels for machine learning problems in quantum physics and chemistry",
           "10.1088/2632-2153/ac14ad",
           2021,
           "\nWe derive symmetric and antisymmetric kernels by symmetrizing and antisymmetrizing conventional kernels and analyze their properties. In particular, we compute the feature space dimensions of the resulting polynomial kernels, prove that the reproducing kernel Hilbert spaces induced by symmetric and antisymmetric Gaussian kernels are dense in the space of symmetric and antisymmetric functions, and propose a Slater determinant representation of the antisymmetric Gaussian kernel, which allows for an efficient evaluation even if the state space is high-dimensional. Furthermore, we show that by exploiting symmetries or antisymmetries the size of the training data set can be significantly reduced. The results are illustrated with guiding examples and simple quantum physics and chemistry applications.",
           9,
           "machine_learning_science_and_technology"
          ],
          [
           "Laplace HypoPINN: physics-informed neural network for hypocenter localization and its predictive uncertainty",
           "10.1088/2632-2153/ac94b3",
           2022,
           "\nSeveral techniques have been proposed over the years for automatic hypocenter localization. While those techniques have pros and cons that trade-off computational efficiency and the susceptibility of getting trapped in local minima, an alternate approach is needed that allows robust localization performance and holds the potential to make the elusive goal of real-time microseismic monitoring possible. Physics-informed neural networks (PINNs) have appeared on the scene as a flexible and versatile framework for solving partial differential equations (PDEs) along with the associated initial or boundary conditions. We develop HypoPINN—a PINN-based inversion framework for hypocenter localization and introduce an approximate Bayesian framework for estimating its predictive uncertainties. This work focuses on predicting the hypocenter locations using HypoPINN and investigates the propagation of uncertainties from the random realizations of HypoPINN’s weights and biases using the Laplace approximation. We train HypoPINN to obtain the optimized weights for predicting hypocenter location. Next, we approximate the covariance matrix at the optimized HypoPINN’s weights for posterior sampling with the Laplace approximation. The posterior samples represent various realizations of HypoPINN’s weights. Finally, we predict the locations of the hypocenter associated with those weights’ realizations to investigate the uncertainty propagation that comes from those realizations. We demonstrate the features of this methodology through several numerical examples, including using the Otway velocity model based on the Otway project in Australia.",
           6,
           "machine_learning_science_and_technology"
          ],
          [
           "A machine learning based Bayesian optimization solution to non-linear responses in dusty plasmas",
           "10.1088/2632-2153/abe7b7",
           2021,
           "\nNonlinear frequency response analysis is a widely used method for determining system dynamics in the presence of nonlinearities. In dusty plasmas, the plasma–grain interaction (e.g. grain charging fluctuations) can be characterized by a single-particle non-linear response analysis, while grain–grain non-linear interactions can be determined by a multi-particle non-linear response analysis. Here a machine learning-based method to determine the equation of motion in the non-linear response analysis for dust particles in plasmas is presented. Searching the parameter space in a Bayesian manner allows an efficient optimization of the parameters needed to match simulated non-linear response curves to experimentally measured non-linear response curves.",
           6,
           "machine_learning_science_and_technology"
          ],
          [
           "An iterative deep learning procedure for determining electron scattering cross-sections from transport coefficients",
           "10.1088/2632-2153/ad2fed",
           2024,
           "\nWe propose improvements to the artificial neural network (ANN) method of determining electron scattering cross-sections from swarm data proposed by coauthors. A limitation inherent to this problem, known as the inverse swarm problem, is the non-unique nature of its solutions, particularly when there exists multiple cross-sections that each describe similar scattering processes. Considering this, prior methods leveraged existing knowledge of a particular cross-section set to reduce the solution space of the problem. To reduce the need for prior knowledge, we propose the following modifications to the ANN method. First, we propose a multi-branch ANN (MBANN) that assigns an independent branch of hidden layers to each cross-section output. We show that in comparison with an equivalent conventional ANN, the MBANN architecture enables an efficient and physics informed feature map of each cross-section. Additionally, we show that the MBANN solution can be improved upon by successive networks that are each trained using perturbations of the previous regression. Crucially, the method requires much less input data and fewer restrictive assumptions, and only assumes knowledge of energy loss thresholds and the number of cross-sections present.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Spectrally adapted physics-informed neural networks for solving unbounded domain problems",
           "10.1088/2632-2153/acd0a1",
           2023,
           "\nSolving analytically intractable partial differential equations (PDEs) that involve at least one variable defined on an unbounded domain arises in numerous physical applications. Accurately solving unbounded domain PDEs requires efficient numerical methods that can resolve the dependence of the PDE on the unbounded variable over at least several orders of magnitude. We propose a solution to such problems by combining two classes of numerical methods: (i) adaptive spectral methods and (ii) physics-informed neural networks (PINNs). The numerical approach that we develop takes advantage of the ability of PINNs to easily implement high-order numerical schemes to efficiently solve PDEs and extrapolate numerical solutions at any point in space and time. We then show how recently introduced adaptive techniques for spectral methods can be integrated into PINN-based PDE solvers to obtain numerical solutions of unbounded domain problems that cannot be efficiently approximated by standard PINNs. Through a number of examples, we demonstrate the advantages of the proposed spectrally adapted PINNs in solving PDEs and estimating model parameters from noisy observations in unbounded domains.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "Gradients should stay on path: better estimators of the reverse- and forward KL divergence for normalizing flows",
           "10.1088/2632-2153/ac9455",
           2022,
           "\nWe show how to use the path-wise derivative estimator for both the forward reverse Kullback–Leibler divergence for any practically invertible normalizing flow. The resulting path-gradient estimators are straightforward to implement, have lower variance, and lead not only to faster convergence of training but also to better overall approximation results compared to standard total gradient estimators. We also demonstrate that path-gradient training is less susceptible to mode-collapse. In light of our results, we expect that path-gradient estimators will become the new standard method to train normalizing flows for variational inference.",
           2,
           "machine_learning_science_and_technology"
          ],
          [
           "Machine learning phases in swarming systems",
           "10.1088/2632-2153/acc007",
           2023,
           "\nRecent years have witnessed a growing interest in using machine learning to predict and identify phase transitions (PTs) in various systems. Here we adopt convolutional neural networks (CNNs) to study the PTs of Vicsek model, solving the problem that traditional order parameters are insufficiently able to do. Within the large-scale simulations, there are four phases, and we confirm that all the PTs between two neighboring phases are first-order. We have successfully classified the phase by using CNNs with a high accuracy and identified the PT points, while traditional approaches using various order parameters fail to obtain. These results indicate the great potential of machine learning approach in understanding the complexities in collective behaviors, and in related complex systems in general.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "The reusability prior: comparing deep learning models without training",
           "10.1088/2632-2153/acc713",
           2023,
           "\nVarious choices can affect the performance of deep learning models. We conjecture that differences in the number of contexts for model components during training are critical. We generalize this notion by defining the reusability prior as follows: model components are forced to function in diverse contexts not only due to the training data, augmentation, and regularization choices, but also due to the model design itself. We focus on the design aspect and introduce a graph-based methodology to estimate the number of contexts for each learnable parameter. This allows a comparison of models without requiring any training. We provide supporting evidence with experiments using cross-layer parameter sharing on CIFAR-10, CIFAR-100, and Imagenet-1K benchmarks. We give examples of models that share parameters outperforming baselines that have at least 60% more parameters. The graph-analysis-based quantities we introduced for the reusability prior align well with the results, including at least two important edge cases. We conclude that the reusability prior provides a viable research direction for model analysis based on a very simple idea: counting the number of contexts for model parameters.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Generation model meets swin transformer for unsupervised low-dose CT reconstruction",
           "10.1088/2632-2153/ad370e",
           2024,
           "\nComputed tomography (CT) has evolved into an indispensable tool for clinical diagnosis. Reducing radiation dose crucially minimizes adverse effects but may introduce noise and artifacts in reconstructed images, affecting diagnostic processes for physicians. Scholars have tackled deep learning training instability by exploring diffusion models. Given the scarcity of clinical data, we propose the unsupervised image domain score generation model (UISG) for low-dose CT reconstruction. During training, normal-dose CT images are utilized as network inputs to train a score-based generative model that captures the prior distribution of CT images. In the iterative reconstruction, the initial CT image is obtained using a filtered back-projection algorithm. Subsequently, diffusion-based prior, high-frequency convolutional sparse coding prior, and data-consistency steps are employed to obtain the high-quality reconstructed image. Given the global characteristics of noise, the score network of the diffusion model utilizes a swin transformer structure to enhance the model’s ability to capture long-range dependencies. Furthermore, convolutional sparse coding is applied exclusively to the high-frequency components of the image, to prevent over-smoothing or the loss of crucial anatomical details during the denoising process. Quantitative and qualitative results indicate that UISG outperforms competing methods in terms of denoising and generalization performance.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Data-driven discovery of Koopman eigenfunctions for control",
           "10.1088/2632-2153/abf0f5",
           2021,
           "\nData-driven transformations that reformulate nonlinear systems in a linear framework have the potential to enable the prediction, estimation, and control of strongly nonlinear dynamics using linear systems theory. The Koopman operator has emerged as a principled linear embedding of nonlinear dynamics, and its eigenfunctions establish intrinsic coordinates along which the dynamics behave linearly. Previous studies have used finite-dimensional approximations of the Koopman operator for model-predictive control approaches. In this work, we illustrate a fundamental closure issue of this approach and argue that it is beneficial to first validate eigenfunctions and then construct reduced-order models in these validated eigenfunctions. These coordinates form a Koopman-invariant subspace by design and, thus, have improved predictive power. We show then how the control can be formulated directly in these intrinsic coordinates and discuss potential benefits and caveats of this perspective. The resulting control architecture is termed Koopman Reduced Order Nonlinear Identification and Control (KRONIC). It is further demonstrated that these eigenfunctions can be approximated with data-driven regression and power series expansions, based on the partial differential equation governing the infinitesimal generator of the Koopman operator. Validating discovered eigenfunctions is crucial and we show that lightly damped eigenfunctions may be faithfully extracted from EDMD or an implicit formulation. These lightly damped eigenfunctions are particularly relevant for control, as they correspond to nearly conserved quantities that are associated with persistent dynamics, such as the Hamiltonian. KRONIC is then demonstrated on a number of relevant examples, including (a) a nonlinear system with a known linear embedding, (b) a variety of Hamiltonian systems, and (c) a high-dimensional double-gyre model for ocean mixing.",
           81,
           "machine_learning_science_and_technology"
          ],
          [
           "COVID-19 detection from lung CT-scan images using transfer learning approach",
           "10.1088/2632-2153/abf22c",
           2021,
           "\nSince the onset of 2020, the spread of coronavirus disease (COVID-19) has rapidly accelerated worldwide into a state of severe pandemic. COVID-19 has infected more than 29 million people and caused more than 900 thousand deaths at the time of writing. Since it is highly contagious, it causes explosive community transmission. Thus, health care delivery has been disrupted and compromised by the lack of testing kits. COVID-19-infected patients show severe acute respiratory syndrome. Meanwhile, the scientific community has been involved in the implementation of deep learning (DL) techniques to diagnose COVID-19 using computed tomography (CT) lung scans, since CT is a pertinent screening tool due to its higher sensitivity in recognizing early pneumonic changes. However, large datasets of CT-scan images are not publicly available due to privacy concerns and obtaining very accurate models has become difficult. Thus, to overcome this drawback, transfer-learning pre-trained models are used in the proposed methodology to classify COVID-19 (positive) and COVID-19 (negative) patients. We describe the development of a DL framework that includes pre-trained models (DenseNet201, VGG16, ResNet50V2, and MobileNet) as its backbone, known as KarNet. To extensively test and analyze the framework, each model was trained on original (i.e. unaugmented) and manipulated (i.e. augmented) datasets. Among the four pre-trained models of KarNet, the one that used DenseNet201 demonstrated excellent diagnostic ability, with AUC scores of 1.00 and 0.99 for models trained on unaugmented and augmented data sets, respectively. Even after considerable distortion of the images (i.e. the augmented dataset) DenseNet201 achieved an accuracy of 97% for the test dataset, followed by ResNet50V2, MobileNet, and VGG16 (which achieved accuracies of 96%, 95%, and 94%, respectively).",
           30,
           "machine_learning_science_and_technology"
          ],
          [
           "Deep reinforcement learning for optical systems: A case study of mode-locked lasers",
           "10.1088/2632-2153/abb6d6",
           2020,
           "\nWe demonstrate that deep reinforcement learning (deep RL) provides a highly effective strategy for the control and self-tuning of optical systems. Deep RL integrates the two leading machine learning architectures of deep neural networks and reinforcement learning to produce robust and stable learning for control. Deep RL is ideally suited for optical systems as the tuning and control relies on interactions with its environment with a goal-oriented objective to achieve optimal immediate or delayed rewards. This allows the optical system to recognize bi-stable structures and navigate, via trajectory planning, to optimally performing solutions, the first such algorithm demonstrated to do so in optical systems. We specifically demonstrate the deep RL architecture on a mode-locked laser, where robust self-tuning and control can be established through access of the deep RL agent to its waveplates and polarizers. We further integrate transfer learning to help the deep RL agent rapidly learn new parameter regimes and generalize its control authority. Additionally, the deep RL learning can be easily integrated with other control paradigms to provide a broad framework to control any optical system.",
           16,
           "machine_learning_science_and_technology"
          ],
          [
           "Image mapping the temporal evolution of edge characteristics in tokamaks using neural networks",
           "10.1088/2632-2153/ab5639",
           2020,
           "\nWe propose a method for data-driven modelling of the temporal evolution of the plasma and neutral characteristics at the edge of a tokamak using neural networks. Our method proposes a novel fully convolutional network to serve as function approximators in modelling complex nonlinear phenomenon observed in the multi-physics representations of high energy physics. More specifically, we target the evolution of the temperatures, densities and parallel velocities of the electrons, ions and neutral particles at the edge. The central challenge in this context is in modelling together the different physics principles encapsulated in the evolution of plasma and the neutrals. We demonstrate that the inherent differences in nonlinear behaviour can be addressed by forking the network to process the plasma and neutral information individually before integrating as a holistic system. Our approach takes into account the spatial dependencies of the physics parameters across the grid while performing the temporal mappings, ensuring that the underlying physics is factored in and not lost to the black-box. Having used the conventional edge plasma-neutral solver code SOLPS to build the synthetic dataset, our method demonstrates a computational gain of over 5 orders of magnitude over it without a considerable compromise on accuracy.",
           3,
           "machine_learning_science_and_technology"
          ],
          [
           "Machine-learning accelerated identification of exfoliable two-dimensional materials",
           "10.1088/2632-2153/ac9bca",
           2022,
           "\nTwo-dimensional (2D) materials have been a central focus of recent research because they host a variety of properties, making them attractive both for fundamental science and for applications. It is thus crucial to be able to identify accurately and efficiently if bulk three-dimensional (3D) materials are formed by layers held together by a weak binding energy that, thus, can be potentially exfoliated into 2D materials. In this work, we develop a machine-learning (ML) approach that, combined with a fast preliminary geometrical screening, is able to efficiently identify potentially exfoliable materials. Starting from a combination of descriptors for crystal structures, we work out a subset of them that are crucial for accurate predictions. Our final ML model, based on a random forest classifier, has a very high recall of 98%. Using a SHapely Additive exPlanations analysis, we also provide an intuitive explanation of the five most important variables of the model. Finally, we compare the performance of our best ML model with a deep neural network architecture using the same descriptors. To make our algorithms and models easily accessible, we publish an online tool on the Materials Cloud portal that only requires a bulk 3D crystal structure as input. Our tool thus provides a practical yet straightforward approach to assess whether any 3D compound can be exfoliated into 2D layers.",
           7,
           "machine_learning_science_and_technology"
          ],
          [
           "Neural network field theories: non-Gaussianity, actions, and locality",
           "10.1088/2632-2153/ad17d3",
           2023,
           "\nBoth the path integral measure in field theory (FT) and ensembles of neural networks (NN) describe distributions over functions. When the central limit theorem can be applied in the infinite-width (infinite-N) limit, the ensemble of networks corresponds to a free FT. Although an expansion in \n\n\n1\n\n/\n\nN\n\n\n corresponds to interactions in the FT, others, such as in a small breaking of the statistical independence of network parameters, can also lead to interacting theories. These other expansions can be advantageous over the \n\n\n1\n\n/\n\nN\n\n\n-expansion, for example by improved behavior with respect to the universal approximation theorem. Given the connected correlators of a FT, one can systematically reconstruct the action order-by-order in the expansion parameter, using a new Feynman diagram prescription whose vertices are the connected correlators. This method is motivated by the Edgeworth expansion and allows one to derive actions for NN FT. Conversely, the correspondence allows one to engineer architectures realizing a given FT by representing action deformations as deformations of NN parameter densities. As an example, φ\n4 theory is realized as an infinite-N NN FT.",
           3,
           "machine_learning_science_and_technology"
          ],
          [
           "Probe microscopy is all you need\n                  <sup>*</sup>",
           "10.1088/2632-2153/acccd5",
           2023,
           "\nWe pose that microscopy offers an ideal real-world experimental environment for the development and deployment of active Bayesian and reinforcement learning methods. Indeed, the tremendous progress achieved by machine learning (ML) and artificial intelligence over the last decade has been largely achieved via the utilization of static data sets, from the paradigmatic MNIST to the bespoke corpora of text and image data used to train large models such as GPT3, DALL·E and others. However, it is now recognized that continuous, minute improvements to state-of-the-art do not necessarily translate to advances in real-world applications. We argue that a promising pathway for the development of ML methods is via the route of domain-specific deployable algorithms in areas such as electron and scanning probe microscopy and chemical imaging. This will benefit both fundamental physical studies and serve as a test bed for more complex autonomous systems such as robotics and manufacturing. Favorable environment characteristics of scanning and electron microscopy include low risk, extensive availability of domain-specific priors and rewards, relatively small effects of exogenous variables, and often the presence of both upstream first principles as well as downstream learnable physical models for both statics and dynamics. Recent developments in programmable interfaces, edge computing, and access to application programming interfaces (APIs) facilitating microscope control, all render the deployment of ML codes on operational microscopes straightforward. We discuss these considerations and hope that these arguments will lead to create novel set of development targets for the ML community by accelerating both real world ML applications and scientific progress.",
           5,
           "machine_learning_science_and_technology"
          ],
          [
           "Generation of conformational ensembles of small molecules via surrogate model-assisted molecular dynamics",
           "10.1088/2632-2153/ad3b64",
           2024,
           "\nThe accurate prediction of thermodynamic properties is crucial in various fields such as drug discovery and materials design. This task relies on sampling from the underlying Boltzmann distribution, which is challenging using conventional approaches such as simulations. In this work, we introduce surrogate model-assisted molecular dynamics (SMA-MD), a new procedure to sample the equilibrium ensemble of molecules. First, SMA-MD leverages deep generative models to enhance the sampling of slow degrees of freedom. Subsequently, the generated ensemble undergoes statistical reweighting, followed by short simulations. Our empirical results show that SMA-MD generates more diverse and lower energy ensembles than conventional MD simulations. Furthermore, we showcase the application of SMA-MD for the computation of thermodynamical properties by estimating implicit solvation free energies.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Deep Learning Based Event Reconstruction for Cyclotron Radiation Emission Spectroscopy",
           "10.1088/2632-2153/ad3ee3",
           2024,
           "\nThe general principle of Cyclotron Radiation Emission Spectroscopy (CRES) experiments is to build an energy spectrum by reconstructing the start frequencies of charged particle trajectories (called tracks) which leave quasilinear profiles in the time-frequency plane when exposed to a magnetic field. The Project 8 collaboration is developing the CRES technique in order to extract the unknown absolute neutrino mass value with a final sensitivity 0.04 eV/$c^2$ from the $\\beta$-decay energy spectrum of tritium. Due to the small number of events in the spectrum's endpoint region and the need for excellent instrumental energy resolution, efficient and highly accurate reconstruction methods are desired. Deep learning convolutional neural networks (CNNs) - particularly suited to deal with information-sparse data and which offer precise foreground localization - may be utilized to extract track properties from basic CRES signals with relative computational ease. In this work, we develop a novel machine learning based model which operates a CNN and a support vector machine in tandem to reconstruct simulated CRES tracks and events. As applied to simulated CRES data, we show comparable performance in accuracy of track parameter reconstruction and a relative gain of 24.1\\% in event reconstruction efficiency when compared to a traditional point-clustering based approach (baseline).",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Inception neural network for complete intersection Calabi–Yau 3-folds",
           "10.1088/2632-2153/abda61",
           2021,
           "We introduce a neural network inspired by Google’s Inception model to compute the Hodge numberh1,1of complete intersection Calabi–Yau (CICY) 3-folds. This architecture improves largely the accuracy of the predictions over existing results, giving already 97% of accuracy with just 30% of the data for training. Accuracy climbs to 99% when using 80% of the data for training. This proves that neural networks are a valuable resource to study geometric aspects in both pure mathematics and string theory.",
           9,
           "machine_learning_science_and_technology"
          ],
          [
           "Automated multi-layer optical design via deep reinforcement learning",
           "10.1088/2632-2153/abc327",
           2020,
           "\nOptical multi-layer thin films are widely used in optical and energy applications requiring photonic designs. Engineers often design such structures based on their physical intuition. However, solely relying on human experts can be time-consuming and may lead to sub-optimal designs, especially when the design space is large. In this work, we frame the multi-layer optical design task as a sequence generation problem. A deep sequence generation network is proposed for efficiently generating optical layer sequences. We train the deep sequence generation network with proximal policy optimization to generate multi-layer structures with desired properties. The proposed method is applied to two energy applications. Our algorithm successfully discovered high-performance designs, outperforming structures designed by human experts in task 1, and a state-of-the-art memetic algorithm in task 2.",
           40,
           "machine_learning_science_and_technology"
          ],
          [
           "Unsupervised machine learning of topological phase transitions from experimental data",
           "10.1088/2632-2153/abffe7",
           2021,
           "\nIdentifying phase transitions is one of the key challenges in quantum many-body physics. Recently, machine learning methods have been shown to be an alternative way of localising phase boundaries from noisy and imperfect data without the knowledge of the order parameter. Here, we apply different unsupervised machine learning techniques, including anomaly detection and influence functions, to experimental data from ultracold atoms. In this way, we obtain the topological phase diagram of the Haldane model in a completely unbiased fashion. We show that these methods can successfully be applied to experimental data at finite temperatures and to the data of Floquet systems when post-processing the data to a single micromotion phase. Our work provides a benchmark for the unsupervised detection of new exotic phases in complex many-body systems.",
           39,
           "machine_learning_science_and_technology"
          ],
          [
           "scGMM-VGAE: a Gaussian mixture model-based variational graph autoencoder algorithm for clustering single-cell RNA-seq data",
           "10.1088/2632-2153/acd7c3",
           2023,
           "\nCell type identification using single-cell RNA sequencing data is critical for understanding disease mechanisms and drug discovery. Cell clustering analysis has been widely studied in health research for rare tumor cell detection. In this study, we propose a Gaussian mixture model-based variational graph autoencoder on scRNA-seq data (scGMM-VGAE) that integrates a statistical clustering model to a deep learning algorithm to significantly improve the cell clustering performance. This model feeds a cell-cell graph adjacency matrix and a gene feature matrix into a graph variational autoencoder (VGAE) to generate latent data. These data are then used for cell clustering by the Gaussian mixture model (GMM) module. To optimize the algorithm, a designed loss function is derived by combining parameter estimates from the GMM and VGAE. We test the proposed method on four publicly available and three simulated datasets which contain many biological and technical zeros. The scGMM-VGAE outperforms four selected baseline methods on three evaluation metrics in cell clustering. By successfully incorporating GMM into deep learning VGAE on scRNA-seq data, the proposed method shows higher accuracy in cell clustering on scRNA-seq data. This improvement has a significant impact on detecting rare cell types in health research. All source codes used in this study can be found at https://github.com/ericlin1230/scGMM-VGAE.",
           3,
           "machine_learning_science_and_technology"
          ],
          [
           "Data augmentation with Mobius transformations",
           "10.1088/2632-2153/abd615",
           2020,
           "\nData augmentation has led to substantial improvements in the performance and generalization of deep models, and remains a highly adaptable method to evolving model architectures and varying amounts of data—in particular, extremely scarce amounts of available training data. In this paper, we present a novel method of applying Möbius transformations to augment input images during training. Möbius transformations are bijective conformal maps that generalize image translation to operate over complex inversion in pixel space. As a result, Möbius transformations can operate on the sample level and preserve data labels. We show that the inclusion of Möbius transformations during training enables improved generalization over prior sample-level data augmentation techniques such as cutout and standard crop-and-flip transformations, most notably in low data regimes.",
           8,
           "machine_learning_science_and_technology"
          ],
          [
           "Classifying rock types by geostatistics and random forests in tandem",
           "10.1088/2632-2153/ad3c0f",
           2024,
           "\nRock type classification is crucial for evaluating mineral resources in ore deposits and for rock mechanics. Mineral deposits are formed in a variety of rock bodies and rock types. However, the rock type identification in drill core samples is often complicated by overprinting and weathering processes. An approach to classifying rock types from drill core data relies on whole-rock geochemical assays as features. There are few studies on rock type classification from a limited number of metal grades and dry bulk density as features. The novelty in our approach is the introduction of two sets of feature variables (proxies) at sampled data points, generated by geostatistical leave-one-out cross-validation and by kriging for removing short-scale spatial variation of the measured features. We applied our proposal to a dataset from a porphyry Cu–Au deposit in Mongolia. The model performances on a testing data subset indicate that, when the training dataset is not large, the performance of the classifier (a random forest) substantially improves by incorporating the proxy features as a complement to the original measured features. At each training data point, these proxy features throw light based on the underlying spatial data correlation structure, scales of variations, sampling design, and values of features observed at neighboring points, and show the benefits of combining geostatistics with machine learning.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Reinforcement learning for semi-autonomous approximate quantum eigensolver",
           "10.1088/2632-2153/ab43b4",
           2020,
           "\nThe characterization of an operator by its eigenvectors and eigenvalues allows us to know its action over any quantum state. Here, we propose a protocol to obtain an approximation of the eigenvectors of an arbitrary Hermitian quantum operator. This protocol is based on measurement and feedback processes, which characterize a reinforcement learning protocol. Our proposal is composed of two systems, a black box named environment and a quantum state named agent. The role of the environment is to change any quantum state by a unitary matrix \n\n\n\n\n\n\n\n\nU\n\n\nˆ\n\n\n\n\nE\n\n\n=\n\n\ne\n\n\n−\ni\nτ\n\n\n\n\n\n\n\nˆ\n\n\n\n\nE\n\n\n\n\n\n\n where \n\n\n\n\n\n\n\n\n\n\n\nˆ\n\n\n\n\nE\n\n\n\n\n is a Hermitian operator, and τ is a real parameter. The agent is a quantum state which adapts to some eigenvector of \n\n\n\n\n\n\n\n\n\n\n\nˆ\n\n\n\n\nE\n\n\n\n\n by repeated interactions with the environment, feedback process, and semi-random rotations. With this proposal, we can obtain an approximation of the eigenvectors of a random qubit operator with average fidelity over 90% in less than 10 iterations, and surpass 98% in less than 300 iterations. Moreover, for the two-qubit cases, the four eigenvectors are obtained with fidelities above 89% in 8000 iterations for a random operator, and fidelities of 99% for an operator with the Bell states as eigenvectors. This protocol can be useful to implement semi-autonomous quantum devices which should be capable of extracting information and deciding with minimal resources and without human intervention.",
           13,
           "machine_learning_science_and_technology"
          ],
          [
           "Koopman-inspired approach for identification of exogenous anomalies in nonstationary time-series data",
           "10.1088/2632-2153/acdd50",
           2023,
           "\nIn many scenarios, it is necessary to monitor a complex system via a time-series of observations and determine when anomalous exogenous events have occurred so that relevant actions can be taken. Determining whether current observations are abnormal is challenging. It requires learning an extrapolative probabilistic model of the dynamics from historical data, and using a limited number of current observations to make a classification. We leverage recent advances in long-term probabilistic forecasting, namely Deep Probabilistic Koopman, to build a general method for classifying anomalies in multi-dimensional time-series data. We also show how to utilize models with domain knowledge of the dynamics to reduce type I and type II error. We demonstrate our proposed method on the important real-world task of global atmospheric pollution monitoring, integrating it with NASA’s Global Earth Observing System Model. The system successfully detects localized anomalies in air quality due to events such as COVID-19 lockdowns and wildfires.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Determination of latent dimensionality in international trade flow",
           "10.1088/2632-2153/aba9ee",
           2020,
           "\nCurrently, high-dimensional data is ubiquitous in data science, which necessitates the development of techniques to decompose and interpret such multidimensional (aka tensor) datasets. Finding a low dimensional representation of the data, that is, its inherent structure, is one of the approaches that can serve to understand the dynamics of low dimensional latent features hidden in the data. Moreover, decomposition methods with non-negative constraints are shown to extract more insightful factors. Nonnegative RESCAL is one such technique, particularly well suited to analyze self-relational data, such as dynamic networks found in international trade flows. Particularly, non-negative RESCAL computes a low dimensional tensor representation by finding the latent space containing multiple modalities. Furthermore, estimating the dimensionality of this latent space is crucial for extracting meaningful latent features. Here, to determine the dimensionality of the latent space with non-negative RESCAL, we propose a latent dimension determination method which is based on clustering of the solutions of multiple realizations of non-negative RESCAL decompositions. We demonstrate the performance of our model selection method on synthetic data. We then apply our method to decompose a network of international trade flows data from International Monetary Fund and shows that with a correct latent dimension determination, the resulting features are able to capture relevant empirical facts from economic literature.",
           3,
           "machine_learning_science_and_technology"
          ],
          [
           "Robust detection of marine life with label-free image feature learning and probability calibration",
           "10.1088/2632-2153/ace417",
           2023,
           "\nAdvances in in situ marine life imaging have significantly increased the size and quality of available datasets, but automatic image analysis has not kept pace. Machine learning has shown promise for image processing, but its effectiveness is limited by several open challenges: the requirement for large expert-labeled training datasets, disagreement among experts, under-representation of various species and unreliable or overconfident predictions. To overcome these obstacles for automated underwater imaging, we combine and test recent developments in deep classifier networks and self-supervised feature learning. We use unlabeled images for pretraining deep neural networks to extract task-relevant image features, allowing learning algorithms to cope with scarcity in expert labels, and carefully evaluate performance in subsequent label-based tasks. Performance on rare classes is improved by applying data rebalancing together with a Bayesian correction to avoid biasing inferred in situ class frequencies. A divergence-based loss allows training on multiple, conflicting labels for the same image, leading to better estimates of uncertainty which we quantify with a novel accuracy measure. Together, these techniques can reduce the required label counts ∼100-fold while maintaining the accuracy of standard supervised training, shorten training time, cope with expert disagreement and reduce overconfidence.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Achieving robustness to aleatoric uncertainty with heteroscedastic Bayesian optimisation",
           "10.1088/2632-2153/ac298c",
           2021,
           "\nBayesian optimisation is a sample-efficient search methodology that holds great promise for accelerating drug and materials discovery programs. A frequently-overlooked modelling consideration in Bayesian optimisation strategies however, is the representation of heteroscedastic aleatoric uncertainty. In many practical applications it is desirable to identify inputs with low aleatoric noise, an example of which might be a material composition which displays robust properties in response to a noisy fabrication process. In this paper, we propose a heteroscedastic Bayesian optimisation scheme capable of representing and minimising aleatoric noise across the input space. Our scheme employs a heteroscedastic Gaussian process surrogate model in conjunction with two straightforward adaptations of existing acquisition functions. First, we extend the augmented expected improvement heuristic to the heteroscedastic setting and second, we introduce the aleatoric noise-penalised expected improvement (ANPEI) heuristic. Both methodologies are capable of penalising aleatoric noise in the suggestions. In particular, the ANPEI acquisition yields improved performance relative to homoscedastic Bayesian optimisation and random sampling on toy problems as well as on two real-world scientific datasets. Code is available at: https://github.com/Ryan-Rhys/Heteroscedastic-BO\n",
           7,
           "machine_learning_science_and_technology"
          ],
          [
           "Realistic mask generation for matter-wave lithography via machine learning",
           "10.1088/2632-2153/acd988",
           2023,
           "\nFast production of large-area patterns is crucial for the established semiconductor industry and enables industrial-scale production of next-generation quantum devices. Metastable atom lithography with binary holography masks has been suggested as a higher resolution/low-cost alternative to the current state of the art: extreme ultraviolet lithography. However, it was recently shown that the interaction of the metastable atoms with the mask material (SiN) leads to a strong perturbation of the wavefront, not included in the existing mask generation theory, which is based on classical scalar waves. This means that the inverse problem (creating a mask based on the desired pattern) cannot be solved analytically, even in 1D. Here we present a machine-learning approach to mask generation targeted for metastable atoms. Our algorithm uses a combination of genetic optimisation and deep learning to obtain the mask. A novel deep neural architecture is trained to produce an initial approximation of the mask. This approximation is then used to generate the initial population of the genetic optimisation algorithm that can converge to arbitrary precision. We demonstrate the generation of arbitrary 1D patterns for system dimensions within the Fraunhofer approximation limit.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Standardizing chemical compounds with language models",
           "10.1088/2632-2153/ace878",
           2023,
           "\nWith the growing amount of chemical data stored digitally, it has become crucial to represent chemical compounds accurately and consistently. Harmonized representations facilitate the extraction of insightful information from datasets, and are advantageous for machine learning applications. To achieve consistent representations throughout datasets, one relies on molecule standardization, which is typically accomplished using rule-based algorithms that modify descriptions of functional groups. Here, we present the first deep-learning model for molecular standardization. We enable custom standardization schemes based solely on data, which, as additional benefit, support standardization options that are difficult to encode into rules. Our model achieves over \n\n\n98\n%\n\n\n accuracy in learning two popular rule-based standardization protocols. We then follow a transfer learning approach to standardize metal-organic compounds (for which there is currently no automated standardization practice), based on a human-curated dataset of 1512 compounds. This model predicts the expected standardized molecular format with a test accuracy of 80.7%. As standardization can be considered, more broadly, a transformation from undesired to desired representations of compounds, the same data-driven architecture can be applied to other tasks. For instance, we demonstrate the application to compound canonicalization and to the determination of major tautomers in solution, based on computed and experimental data.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "An automated approach for determining the number of components in non-negative matrix factorization with application to mutational signature learning",
           "10.1088/2632-2153/abc60a",
           2020,
           "\nNon-negative matrix factorization (NMF) is a popular method for finding a low rank approximation of a matrix, thereby revealing the latent components behind it. In genomics, NMF is widely used to interpret mutation data and derive the underlying mutational processes and their activities. A key challenge in the use of NMF is determining the number of components, or rank of the factorization. Here we propose a novel method, CV2K, to choose this number automatically from data that is based on a detailed cross validation procedure combined with a parsimony consideration. We apply our method for mutational signature analysis and demonstrate its utility on both simulated and real data sets. In comparison to previous approaches, some of which involve human assessment, CV2K leads to improved predictions across a wide range of data sets.",
           2,
           "machine_learning_science_and_technology"
          ],
          [
           "Rapid parameter estimation of discrete decaying signals using autoencoder networks",
           "10.1088/2632-2153/ac1eea",
           2021,
           "\nIn this work we demonstrate the use of neural networks for rapid extraction of signal parameters of discretely sampled signals. In particular, we use dense autoencoder networks to extract the parameters of interest from exponentially decaying signals and decaying oscillations. By using a three-stage training method and careful choice of the neural network size, we are able to retrieve the relevant signal parameters directly from the latent space of the autoencoder network at significantly improved rates compared to traditional algorithmic signal-analysis approaches. We show that the achievable precision and accuracy of this method of analysis is similar to conventional algorithm-based signal analysis methods, by demonstrating that the extracted signal parameters are approaching their fundamental parameter estimation limit as provided by the Cramér–Rao bound. Furthermore, we demonstrate that autoencoder networks are able to achieve signal analysis, and, hence, parameter extraction, at rates of 75 kHz, orders-of-magnitude faster than conventional techniques with similar precision. Finally, our exploration of the limitations of our approach in different computational systems suggests that analysis rates of \n\n\n>\n\n\n200 kHz are feasible using neural networks in systems where the transfer time between the data-acquisition system and data-analysis modules can be kept below ∼3 µs.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Extending the extended dynamic mode decomposition with latent observables: the latent EDMD framework",
           "10.1088/2632-2153/acccd6",
           2023,
           "\nBernard O Koopman proposed an alternative view of dynamical systems based on linear operator theory, in which the time evolution of a dynamical system is analogous to the linear propagation of an infinite-dimensional vector of observables. In the last few years, several works have shown that finite-dimensional approximations of this operator can be extremely useful for several applications, such as prediction, control, and data assimilation. In particular, a Koopman representation of a dynamical system with a finite number of dimensions will avoid all the problems caused by nonlinearity in classical state-space models. In this work, the identification of finite-dimensional approximations of the Koopman operator and its associated observables is expressed through the inversion of an unknown augmented linear dynamical system. The proposed framework can be regarded as an extended dynamical mode decomposition that uses a collection of latent observables. The use of a latent dictionary applies to a large class of dynamical regimes, and it provides new means for deriving appropriate finite-dimensional linear approximations to high-dimensional nonlinear systems.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Data efficiency and extrapolation trends in neural network interatomic potentials",
           "10.1088/2632-2153/acf115",
           2023,
           "\nRecently, key architectural advances have been proposed for neural network interatomic potentials (NNIPs), such as incorporating message-passing networks, equivariance, or many-body expansion terms. Although modern NNIP models exhibit small differences in test accuracy, this metric is still considered the main target when developing new NNIP architectures. In this work, we show how architectural and optimization choices influence the generalization of NNIPs, revealing trends in molecular dynamics (MD) stability, data efficiency, and loss landscapes. Using the 3BPA dataset, we uncover trends in NNIP errors and robustness to noise, showing these metrics are insufficient to predict MD stability in the high-accuracy regime. With a large-scale study on NequIP, MACE, and their optimizers, we show that our metric of loss entropy predicts out-of-distribution error and data efficiency despite being computed only on the training set. This work provides a deep learning justification for probing extrapolation and can inform the development of next-generation NNIPs.",
           4,
           "machine_learning_science_and_technology"
          ],
          [
           "Intramolecular proton transfer reaction dynamics using machine-learned ab initio potential energy surfaces",
           "10.1088/2632-2153/acdbbc",
           2023,
           "\nHydrogen bonding interactions, which are central to various physicochemical processes, are investigated in the present study using ab initio-based machine learning potential energy surfaces. Abnormally strong intramolecular O–H⋯O hydrogen bonds, occurring in β-diketone enols of malonaldehyde and its derivatives, with substituents ranging from various electron-withdrawing to electron-donating functional groups, are studied. Machine learning force fields were constructed using a kernel-based force learning model employing ab initio molecular dynamics reference data. These models were used for molecular dynamics simulations at finite temperature, and dynamical properties were determined by computing proton transfer free-energy surfaces. The chemical systems studied here show progression toward barrier-less proton transfer events at an accuracy of correlated electronic structure methods. Markov state models of the conformational states indicate shorter intramolecular hydrogen bonds exhibiting higher proton transfer rates. We demonstrate how functional group substitution can modulate the strength of intramolecular hydrogen bonds by studying the thermodynamic and kinetic properties.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Conditioning Boltzmann generators for rare event sampling",
           "10.1088/2632-2153/acf55c",
           2023,
           "Understanding the dynamics of complex molecular processes is often linked to the study of infrequent transitions between long-lived stable states. The standard approach to the sampling of such rare events is to generate an ensemble of transition paths using a random walk in trajectory space. This, however, comes with the drawback of strong correlations between subsequently sampled paths and with an intrinsic difficulty in parallelizing the sampling process. We propose a transition path sampling scheme based on neural-network generated configurations. These are obtained employing normalizing flows, a neural network class able to generate statistically independent samples from a given distribution. With this approach, not only are correlations between visited paths removed, but the sampling process becomes easily parallelizable. Moreover, by conditioning the normalizing flow, the sampling of configurations can be steered towards regions of interest. We show that this approach enables the resolution of both the thermodynamics and kinetics of the transition region for systems that can be sampled using exact-likelihood generative models.",
           4,
           "machine_learning_science_and_technology"
          ],
          [
           "K-means-driven Gaussian Process data collection for angle-resolved photoemission spectroscopy",
           "10.1088/2632-2153/abab61",
           2020,
           "\nWe propose the combination of k-means clustering with Gaussian Process (GP) regression in the analysis and exploration of 4D angle-resolved photoemission spectroscopy (ARPES) data. Using cluster labels as the driving metric on which the GP is trained, this method allows us to reconstruct the experimental phase diagram from as low as 12% of the original dataset size. In addition to the phase diagram, the GP is able to reconstruct spectra in energy-momentum space from this minimal set of data points. These findings suggest that this methodology can be used to improve the efficiency of ARPES data collection strategies for unknown samples. The practical feasibility of implementing this technology at a synchrotron beamline and the overall efficiency implications of this method are discussed with a view on enabling the collection of more samples or rapid identification of regions of interest.",
           7,
           "machine_learning_science_and_technology"
          ],
          [
           "Data-centric machine learning in quantum information science",
           "10.1088/2632-2153/ac9036",
           2022,
           "\nWe propose a series of data-centric heuristics for improving the performance of machine learning systems when applied to problems in quantum information science. In particular, we consider how systematic engineering of training sets can significantly enhance the accuracy of pre-trained neural networks used for quantum state reconstruction without altering the underlying architecture. We find that it is not always optimal to engineer training sets to exactly match the expected distribution of a target scenario, and instead, performance can be further improved by biasing the training set to be slightly more mixed than the target. This is due to the heterogeneity in the number of free variables required to describe states of different purity, and as a result, overall accuracy of the network improves when training sets of a fixed size focus on states with the least constrained free variables. For further clarity, we also include a ‘toy model’ demonstration of how spurious correlations can inadvertently enter synthetic data sets used for training, how the performance of systems trained with these correlations can degrade dramatically, and how the inclusion of even relatively few counterexamples can effectively remedy such problems.",
           5,
           "machine_learning_science_and_technology"
          ],
          [
           "Governing equation discovery based on causal graph for nonlinear dynamic systems",
           "10.1088/2632-2153/acffa4",
           2023,
           "\nThe governing equations of nonlinear dynamic systems is of great significance for understanding the internal physical characteristics. In order to learn the governing equations of nonlinear systems from noisy observed data, we propose a novel method named governing equation discovery based on causal graph that combines spatio-temporal graph convolution network with governing equation modeling. The essence of our method is to first devise the causal graph encoding based on transfer entropy to obtain the adjacency matrix with causal significance between variables. Then, the spatio-temporal graph convolutional network is used to obtain approximate solutions for the system variables. On this basis, automatic differentiation is applied to obtain basic derivatives and form a dictionary of candidate algebraic terms. Finally, sparse regression is used to obtain the coefficient matrix and determine the explicit formulation of the governing equations. We also design a novel cross-combinatorial optimization strategy to learn the heterogeneous parameters that include neural network parameters and control equation coefficients. We conduct extensive experiments on seven datasets from different physical fields. The experimental results demonstrate the proposed method can automatically discover the underlying governing equation of the systems, and has great robustness.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Simulation-based inference with approximately correct parameters via maximum entropy",
           "10.1088/2632-2153/ac6286",
           2022,
           "\nInferring the input parameters of simulators from observations is a crucial challenge with applications from epidemiology to molecular dynamics. Here we show a simple approach in the regime of sparse data and approximately correct models, which is common when trying to use an existing model to infer latent variables with observed data. This approach is based on the principle of maximum entropy (MaxEnt) and provably makes the smallest change in the latent joint distribution to fit new data. This method requires no likelihood or model derivatives and its fit is insensitive to prior strength, removing the need to balance observed data fit with prior belief. The method requires the ansatz that data is fit in expectation, which is true in some settings and may be reasonable in all settings with few data points. The method is based on sample reweighting, so its asymptotic run time is independent of prior distribution dimension. We demonstrate this MaxEnt approach and compare with other likelihood-free inference methods across three systems: a point particle moving in a gravitational field, a compartmental model of epidemic spread and molecular dynamics simulation of a protein.",
           2,
           "machine_learning_science_and_technology"
          ],
          [
           "Three-body renormalization group limit cycles based on unsupervised feature learning",
           "10.1088/2632-2153/ac579b",
           2022,
           "\nBoth the three-body system and the inverse square potential carry a special significance in the study of renormalization group limit cycles. In this work, we pursue an exploratory approach and address the question which two-body interactions lead to limit cycles in the three-body system at low energies, without imposing any restrictions upon the scattering length. For this, we train a boosted ensemble of variational autoencoders, that not only provide a severe dimensionality reduction, but also allow to generate further synthetic potentials, which is an important prerequisite in order to efficiently search for limit cycles in low-dimensional latent space. We do so by applying an elitist genetic algorithm to a population of synthetic potentials that minimizes a specially defined limit-cycle-loss. The resulting fittest individuals suggest that the inverse square potential is the only two-body potential that minimizes this limit cycle loss independent of the hyperangle.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "3D positioning and autofocus of the particle field based on the depth-from-defocus method and the deep networks",
           "10.1088/2632-2153/acdb2e",
           2023,
           "\nAccurate three-dimensional positioning of particles is a critical task in microscopic particle research, with one of the main challenges being the measurement of particle depths. In this paper, we propose a method for detecting particle depths from their blurred images using the depth-from-defocus technique and a deep neural network-based object detection framework called you-only-look-once. Our method provides simultaneous lateral position information for the particles and has been tested and evaluated on various samples, including synthetic particles, polystyrene particles, blood cells, and plankton, even in a noise-filled environment. We achieved autofocus for target particles in different depths using generative adversarial networks, obtaining clear-focused images. Our algorithm can process a single multi-target image in 0.008 s, allowing real-time application. Our proposed method provides new opportunities for particle field research.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Fast reconstruction of single-shot wide-angle diffraction images through deep learning",
           "10.1088/2632-2153/abb213",
           2020,
           "\nSingle-shot x-ray imaging of short-lived nanostructures such as clusters and nanoparticles near a phase transition or non-crystalizing objects such as large proteins and viruses is currently the most elegant method for characterizing their structure. Using hard x-ray radiation provides scattering images that encode two-dimensional projections, which can be combined to identify the full three-dimensional object structure from multiple identical samples. Wide-angle scattering using XUV or soft x-rays, despite yielding lower resolution, provides three-dimensional structural information in a single shot and has opened routes towards the characterization of non-reproducible objects in the gas phase. The retrieval of the structural information contained in wide-angle scattering images is highly non-trivial, and currently no efficient rigorous algorithm is known. Here we show that deep learning networks, trained with simulated scattering data, allow for fast and accurate reconstruction of shape and orientation of nanoparticles from experimental images. The gain in speed compared to conventional retrieval techniques opens the route for automated structure reconstruction algorithms capable of real-time discrimination and pre-identification of nanostructures in scattering experiments with high repetition rate—thus representing the enabling technology for fast femtosecond nanocrystallography.",
           4,
           "machine_learning_science_and_technology"
          ],
          [
           "Autonomous victim detection system based on deep learning and multispectral imagery",
           "10.1088/2632-2153/acb6cf",
           2023,
           "\nPost-disaster environments resulting from catastrophic events, leave sequels such as victims trapped in debris, which are difficult to detect by rescuers in a first inspection. Technological advances in electronics and perception have allowed the development of versatile and powerful optical sensors capable of capturing light in spectrums that humans cannot. new deep learning techniques, such as convolutional neural networks (CNNs), has allowed the generation of network models capable of autonomously detecting specific image patterns according to previous training. This work introduces an autonomous victim detection system to be deployed by using search and rescue robots. The proposed system defines new indexes based on combining the multispectral bands (Blue, Green, Red, Nir, Red Edge) to obtain new multispectral images where relevant characteristics of victims and the environment are highlighted. CNNs have been used as a second phase for automatically detecting victims in these new multispectral images. A qualitative and quantitative analysis of new indexes proposed by the authors has been carried out to evaluate their efficiency in contrast to the state-of-the-art ones. A data set has been generated to train different CNN models based on the best obtained index to analyze their effectiveness in detecting victims. The results show an efficiency of 92% in automatically detecting victims when applying the best multispectral index to new data. This method has also been contrasted with others based on thermal and RGB imagery to detect victims, where it has been proven that it generates better results in situations of outdoor environments and different weather conditions.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Learning from survey propagation: a neural network for MAX-E-3-SAT",
           "10.1088/2632-2153/ac0496",
           2021,
           "\nMany natural optimization problems are NP-hard, which implies that they are probably hard to solve exactly in the worst-case. However, it suffices to get reasonably good solutions for all (or even most) instances in practice. This paper presents a new algorithm for computing approximate solutions in Θ(N) for the maximum exact 3-satisfiability (MAX-E-3-SAT) problem by using supervised learning methodology. This methodology allows us to create a learning algorithm able to fix Boolean variables by using local information obtained by the Survey Propagation algorithm. By performing an accurate analysis, on random conjunctive normal form instances of the MAX-E-3-SAT with several Boolean variables, we show that this new algorithm, avoiding any decimation strategy, can build assignments better than a random one, even if the convergence of the messages is not found. Although this algorithm is not competitive with state-of-the-art maximum satisfiability solvers, it can solve substantially larger and more complicated problems than it ever saw during training.",
           4,
           "machine_learning_science_and_technology"
          ],
          [
           "Establishing an evaluation metric to quantify climate change image realism\n                  <sup>*</sup>",
           "10.1088/2632-2153/ab7657",
           2020,
           "\nWith success on controlled tasks, deep generative models are being increasingly applied to humanitarian applications (Nie et al 2017 Int. Conf. on Medical Image Computing and Computer-Assisted Intervention (Berlin: Springer) pp 417–25, Yanardag et al 2017 Deep Empathy). In this paper, we focus on the evaluation of a conditional generative model that illustrates the consequences of climate change-induced flooding to encourage public interest and awareness on the issue. Because metrics for comparing the realism of different modes in a conditional generative model do not exist, we propose several automated and human-based methods for evaluation. To do this, we adapt several existing metrics and assess the automated metrics against gold standard human evaluation. We find that using Fréchet Inception Distance with embeddings from an intermediary Inception-v3 layer that precedes the auxiliary classifier produces results most correlated with human realism. While insufficient alone to establish a human-correlated automatic evaluation metric, we believe this work begins to bridge the gap between human and automated generative evaluation procedures, and to generate more realistic images of the future consequences of climate change.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Massively parallel fitting of Gaussian approximation potentials",
           "10.1088/2632-2153/aca743",
           2023,
           "\nWe present a data-parallel software package for fitting Gaussian approximation potentials (GAPs) on multiple nodes using the ScaLAPACK library with MPI and OpenMP. Until now the maximum training set size for GAP models has been limited by the available memory on a single compute node. In our new implementation, descriptor evaluation is carried out in parallel with no communication requirement. The subsequent linear solve required to determine the model coefficients is parallelised with ScaLAPACK. Our approach scales to thousands of cores, lifting the memory limitation and also delivering substantial speedups. This development expands the applicability of the GAP approach to more complex systems as well as opening up opportunities for efficiently embedding GAP model fitting within higher-level workflows such as committee models or hyperparameter optimisation.",
           2,
           "machine_learning_science_and_technology"
          ],
          [
           "Automated real-space lattice extraction for atomic force microscopy images",
           "10.1088/2632-2153/acb5e0",
           2023,
           "\nAnalyzing atomically resolved images is a time-consuming process requiring solid experience and substantial human intervention. In addition, the acquired images contain a large amount of information such as crystal structure, presence and distribution of defects, and formation of domains, which need to be resolved to understand a material’s surface structure. Therefore, machine learning techniques have been applied in scanning probe and electron microscopies during the last years, aiming for automatized and efficient image analysis. This work introduces a free and open source tool (AiSurf: Automated Identification of Surface Images) developed to inspect atomically resolved images via scale-invariant feature transform and clustering algorithms. AiSurf extracts primitive lattice vectors, unit cells, and structural distortions from the original image, with no pre-assumption on the lattice and minimal user intervention. The method is applied to various atomically resolved non-contact atomic force microscopy images of selected surfaces with different levels of complexity: anatase TiO2(101), oxygen deficient rutile TiO2(110) with and without CO adsorbates, SrTiO3(001) with Sr vacancies and graphene with C vacancies. The code delivers excellent results and is tested against atom misclassification and artifacts, thereby facilitating the interpretation of scanning probe microscopy images.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "A bin and hash method for analyzing reference data and descriptors in machine learning potentials",
           "10.1088/2632-2153/abe663",
           2021,
           "\nIn recent years the development of machine learning potentials (MLPs) has become a very active field of research. Numerous approaches have been proposed, which allow one to perform extended simulations of large systems at a small fraction of the computational costs of electronic structure calculations. The key to the success of modern MLPs is the close-to first principles quality description of the atomic interactions. This accuracy is reached by using very flexible functional forms in combination with high-level reference data from electronic structure calculations. These data sets can include up to hundreds of thousands of structures covering millions of atomic environments to ensure that all relevant features of the potential energy surface are well represented. The handling of such large data sets is nowadays becoming one of the main challenges in the construction of MLPs. In this paper we present a method, the bin-and-hash (BAH) algorithm, to overcome this problem by enabling the efficient identification and comparison of large numbers of multidimensional vectors. Such vectors emerge in multiple contexts in the construction of MLPs. Examples are the comparison of local atomic environments to identify and avoid unnecessary redundant information in the reference data sets that is costly in terms of both the electronic structure calculations as well as the training process, the assessment of the quality of the descriptors used as structural fingerprints in many types of MLPs, and the detection of possibly unreliable data points. The BAH algorithm is illustrated for the example of high-dimensional neural network potentials using atom-centered symmetry functions for the geometrical description of the atomic environments, but the method is general and can be combined with any current type of MLP.",
           2,
           "machine_learning_science_and_technology"
          ],
          [
           "Physics-enhanced neural networks for equation-of-state calculations",
           "10.1088/2632-2153/ad13b9",
           2023,
           "\nRapid access to accurate equation-of-state (EOS) data is crucial in the warm-dense matter (WDM) regime, as it is employed in various applications, such as providing input for hydrodynamic codes to model inertial confinement fusion processes. In this study, we develop neural network models for predicting the EOS based on first-principles data. The first model utilises basic physical properties, while the second model incorporates more sophisticated physical information, using output from average-atom (AA) calculations as features. AA models are often noted for providing a reasonable balance of accuracy and speed; however, our comparison of AA models and higher-fidelity calculations shows that more accurate models are required in the WDM regime. Both the neural network models we propose, particularly the physics-enhanced one, demonstrate significant potential as accurate and efficient methods for computing EOS data in WDM.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Training-free hyperparameter optimization of neural networks for electronic structures in matter",
           "10.1088/2632-2153/ac9956",
           2022,
           "\nA myriad of phenomena in materials science and chemistry rely on quantum-level simulations of the electronic structure in matter. While moving to larger length and time scales has been a pressing issue for decades, such large-scale electronic structure calculations are still challenging despite modern software approaches and advances in high-performance computing. The silver lining in this regard is the use of machine learning to accelerate electronic structure calculations—this line of research has recently gained growing attention. The grand challenge therein is finding a suitable machine-learning model during a process called hyperparameter optimization. This, however, causes a massive computational overhead in addition to that of data generation. We accelerate the construction of neural network models by roughly two orders of magnitude by circumventing excessive training during the hyperparameter optimization phase. We demonstrate our workflow for Kohn–Sham density functional theory, the most popular computational method in materials science and chemistry.",
           5,
           "machine_learning_science_and_technology"
          ],
          [
           "BenchML: an extensible pipelining framework for benchmarking representations of materials and molecules at scale",
           "10.1088/2632-2153/ac4d11",
           2022,
           "\nWe introduce a machine-learning (ML) framework for high-throughput benchmarking of diverse representations of chemical systems against datasets of materials and molecules. The guiding principle underlying the benchmarking approach is to evaluate raw descriptor performance by limiting model complexity to simple regression schemes while enforcing best ML practices, allowing for unbiased hyperparameter optimization, and assessing learning progress through learning curves along series of synchronized train-test splits. The resulting models are intended as baselines that can inform future method development, in addition to indicating how easily a given dataset can be learnt. Through a comparative analysis of the training outcome across a diverse set of physicochemical, topological and geometric representations, we glean insight into the relative merits of these representations as well as their interrelatedness.",
           2,
           "machine_learning_science_and_technology"
          ],
          [
           "Graph convolutional networks applied to unstructured flow field data",
           "10.1088/2632-2153/ac1fc9",
           2021,
           "\nMany scientific and engineering processes produce spatially unstructured data. However, most data-driven models require a feature matrix that enforces both a set number and order of features for each sample. They thus cannot be easily constructed for an unstructured dataset. Therefore, a graph based data-driven model to perform inference on fields defined on an unstructured mesh, using a graph convolutional neural network (GCNN) is presented. The ability of the method to predict global properties from spatially irregular measurements with high accuracy is demonstrated by predicting the drag force associated with laminar flow around airfoils from scattered velocity measurements. The network can infer from field samples at different resolutions, and is invariant to the order in which the measurements within each sample are presented. The GCNN method, using inductive convolutional layers and adaptive pooling, is able to predict this quantity with a validation R\n2 above 0.98, and a Normalized Mean Squared Error below 0.01, without relying on spatial structure.",
           20,
           "machine_learning_science_and_technology"
          ],
          [
           "Artificial neural network potentials for mechanics and fracture dynamics of two-dimensional crystals\n                  <sup>**</sup>",
           "10.1088/2632-2153/accd45",
           2023,
           "\nUnderstanding the mechanics and failure of materials at the nanoscale is critical for their engineering and applications. The accurate atomistic modeling of brittle failure with crack propagation in covalent crystals requires a quantum mechanics-based description of individual bond-breaking events. Artificial neural network potentials (NNPs) have emerged to overcome the traditional, physics-based modeling tradeoff between accuracy and accessible time and length scales. Previous studies have shown successful applications of NNPs for describing the structure and dynamics of molecular systems and amorphous or liquid phases of materials. However, their application to deformation and failure processes in materials is still uncommon. In this study, we discuss the apparent limitations of NNPs for the description of deformation and fracture under loadings and propose a way to generate and select training data for their employment in simulations of deformation and fracture simulations of crystals. We applied the proposed approach to 2D crystalline graphene, utilizing the density-functional tight-binding method for more efficient and extensive data generation in place of density functional theory. Then, we explored how the data selection affects the accuracy of the developed artificial NNPs. It revealed that NNP’s reliability should not only be measured based on the total energy and atomic force comparisons for reference structures but also utilize comparisons for physical properties, e.g. stress–strain curves and geometric deformation. In sharp contrast to popular reactive bond order potentials, our optimized NNP predicts straight crack propagation in graphene along both armchair and zigzag (ZZ) lattice directions, as well as higher fracture toughness of ZZ edge direction. Our study provides significant insight into crack propagation mechanisms on atomic scales and highlights strategies for NNP developments of broader materials.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "A study of transfer learning in digital rock properties measurement",
           "10.1088/2632-2153/acf117",
           2023,
           "\nThe measurement of physical parameters of porous rock, which constitute reservoirs, is an essential part of hydrocarbon exploration. Typically, the measurement of these physical parameters is carried out through core analysis in a laboratory, which requires considerable time and high costs. Another approach involves using digital rock models, where the physical parameters are calculated through image processing and numerical simulations. However, this method also requires a significant amount of time for estimating the physical parameters of each rock sample. Machine learning, specifically convolutional neural network (CNN) algorithms, has been developed as an alternative method for estimating the physical parameters of porous rock in a shorter time frame. The advancement of CNN, particularly through transfer learning using pre-trained models, has contributed to rapid prediction capabilities. However, not all pre-trained models are suitable for estimating the physical parameters of porous rock. In this study, transfer learning was applied to estimate parameters of sandstones such as porosity, specific surface area, average grain size, average coordination number, and average throat radius. Six types of pre-trained models were utilized: ResNet152, DenseNet201, Xception, InceptionV3, InceptionResNetV2, and MobileNetV2. The results of this study indicate that the DenseNet201 model achieved the best performance with an error rate of 2.11%. Overall, this study highlights the potential of transfer learning to ultimately lead to more efficient and effective computation.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Theoretical characterization of uncertainty in high-dimensional linear classification",
           "10.1088/2632-2153/acd749",
           2023,
           "Being able to reliably assess not only theaccuracybut also theuncertaintyof models’ predictions is an important endeavor in modern machine learning. Even if the model generating the data and labels is known, computing the intrinsic uncertainty after learning the model from a limited number of samples amounts to sampling the corresponding posterior probability measure. Such sampling is computationally challenging in high-dimensional problems and theoretical results on heuristic uncertainty estimators in high-dimensions are thus scarce. In this manuscript, we characterize uncertainty for learning from a limited number of samples of high-dimensional Gaussian input data and labels generated by the probit model. In this setting, the Bayesian uncertainty (i.e. the posterior marginals) can be asymptotically obtained by the approximate message passing algorithm, bypassing the canonical but costly Monte Carlo sampling of the posterior. We then provide a closed-form formula for the joint statistics between the logistic classifier, the uncertainty of the statistically optimal Bayesian classifier and the ground-truth probit uncertainty. The formula allows us to investigate the calibration of the logistic classifier learning from a limited amount of samples. We discuss how over-confidence can be mitigated by appropriately regularizing.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "Polynomial differentiation decreases the training time complexity of physics-informed neural networks and strengthens their approximation power",
           "10.1088/2632-2153/acf97a",
           2023,
           "\nWe present novel approximates of variational losses, being applicable for the training of physics-informed neural networks (PINNs). The formulations reflect classic Sobolev space theory for partial differential equations (PDEs) and their weak formulations. The loss approximates rest on polynomial differentiation realised by an extension of classic Gauss–Legendre cubatures, we term Sobolev cubatures, and serve as a replacement of automatic differentiation. We prove the training time complexity of the resulting Sobolev -PINNs with polynomial differentiation to be less than required by PINNs relying on automatic differentiation. On top of one-to-two order of magnitude speed-up the Sobolev-PINNs are demonstrated to achieve closer solution approximations for prominent forward and inverse, linear and non-linear PDE problems compared to established PINNs.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Machine learning to predict the antimicrobial activity of cold atmospheric plasma-activated liquids",
           "10.1088/2632-2153/acc1c0",
           2023,
           "\nPlasma is defined as the fourth state of matter, and non-thermal plasma can be produced at atmospheric pressure under a high electrical field. The strong and broad-spectrum antimicrobial effect of plasma-activated liquids (PALs) is now well known. The antimicrobial effects of PALs depend on many different variables, which complicates the comparison of different studies and determining the most dominant parameters for the antimicrobial effect. The proven applicability of machine learning (ML) in the medical field is encouraging for its application in the field of plasma medicine as well. Thus, ML applications on PALs could present a new perspective to better understand the influences of various parameters on their antimicrobial effects. In this paper, comparative supervised ML models are presented by using previously obtained data to predict the in vitro antimicrobial activity of PALs. A comprehensive literature search was performed, and 12 distinct features related to PAL-microorganism interactions were collected from 33 relevant articles to automatically predict the antimicrobial activity of PALs. After the required normalization, feature encoding, and resampling steps, two supervised ML methods, namely classification and regression, are applied to the data to obtain microbial inactivation (MI) predictions. For classification, MI is labeled in four categories, and for regression, MI is used as a continuous variable. Sixteen different classifiers and 14 regressors are implemented to predict the MI value. Two different robust cross-validation strategies are conducted for classification and regression models to evaluate the proposed method: repeated stratified k-fold cross-validation and k-fold cross-validation, respectively. We also investigate the effect of different features on models. The results demonstrated that the hyperparameter-optimized Random Forest Classifier (oRFC) and Random Forest Regressor (oRFR) provided superior performance compared to other models for classification and regression. Finally, the best test accuracy of 82.68% for oRFC and R\n2 of 0.75 for the oRFR are obtained. Furthermore, the determined most important features of predictive models are in line with the outcomes of PALs reported in the literature. An ML framework can accurately predict the antimicrobial activity of PALs without the need for any experimental studies. To the best of our knowledge, this is the first study that investigates the antimicrobial efficacy of PALs with ML. Furthermore, ML techniques could contribute to a better understanding of plasma parameters that have a dominant role in the desired antimicrobial effect. Moreover, such findings may contribute to the definition of a plasma dose in the future.",
           5,
           "machine_learning_science_and_technology"
          ],
          [
           "Application of autoencoders artificial neural network and principal component analysis for pattern extraction and spatial regionalization of global temperature data",
           "10.1088/2632-2153/ad1c34",
           2024,
           "\nSpatial regionalization is instrumental in simplifying the spatial complexity of the climate system. To identify regions of significant climate variability, pattern extraction is often required prior to spatial regionalization with a clustering algorithm. In this study, the autoencoder (AE) artificial neural network was applied to extract the inherent patterns of global temperature data (from 1901 to 2021). Subsequently, Fuzzy C-means clustering was applied to the extracted patterns to classify the global temperature regions. Our analysis involved comparing AE-based and principal component analysis (PCA)-based clustering results to assess consistency. We determined the number of clusters by examining the average percentage decrease in Fuzzy Partition Coefficient (FPC) and its 95% confidence interval, seeking a balance between obtaining a high FPC and avoiding over-segmentation. This approach suggested that for a more general model, four clusters is reasonable. The Adjusted Rand Index between the AE-based and PCA-based clusters is 0.75, indicating that the AE-based and PCA-based clusters have considerable overlap. The observed difference between the AE-based clusters and PCA-based clusters is suggested to be associated with AE’s capability to learn and extract complex non-linear patterns, and this attribute, for example, enabled the clustering algorithm to accurately detect the Himalayas region as the ‘third pole’ with similar temperature characteristics as the polar regions. Finally, when the analysis period is divided into two (1901–1960 and 1961–2021), the Adjusted Rand Index between the two clusters is 0.96 which suggests that historical climate change has not significantly affected the defined temperature regions over the two periods. In essence, this study indicates both AE’s potential to enhance our understanding of climate variability and reveals the stability of the historical temperature regions.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Data-driven prediction of the performance of enhanced surfaces from an extensive CFD-generated parametric search space",
           "10.1088/2632-2153/acca60",
           2023,
           "\nMachine learning has rapidly been adopted in virtually all areas of engineering in recent years. This paper develops a machine learning model capable of predicting the performance of parametrically generated enhanced microsurface geometries for cooling electronic and power systems. Designing this type of geometry usually involves expensive computational fluid dynamics (CFD) simulations, limiting the number of candidate geometries that may be tested. For this reason, when searching for new geometries for a given application, designs are usually restricted to a simplified subset of basic shapes to reduce the complexity and dimension of the search space. In an effort to add geometrical diversity and explore singular morphologies, we have developed an algorithm capable of characterizing almost any geometry, based on an extensive CFD database with more than 15 800 geometries obtained from a Monte Carlo sampling of the space of possible geometries. With this framework, it is possible to estimate various quantities of interest, such as the heat flux in the enhanced zone and total drag, with relative errors below 10% and 2%, respectively. Thus, we establish the utility of machine learning to develop surrogate models for the rapid performance prediction of novel enhanced microsurfaces.",
           3,
           "machine_learning_science_and_technology"
          ],
          [
           "Spectral density classification for environment spectroscopy",
           "10.1088/2632-2153/ad2cf1",
           2024,
           "\nSpectral densities encode the relevant information characterizing the system–environment interaction in an open-quantum system problem. Such information is key to determining the system’s dynamics. In this work, we leverage the potential of machine learning techniques to reconstruct the features of the environment. Specifically, we show that the time evolution of a system observable can be used by an artificial neural network to infer the main features of the spectral density. In particular, for relevant examples of spin-boson models, we can classify with high accuracy the Ohmicity parameter of the environment as either Ohmic, sub-Ohmic or super-Ohmic, thereby distinguishing between different forms of dissipation.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Neural network training with highly incomplete medical datasets",
           "10.1088/2632-2153/ac7b69",
           2022,
           "\nNeural network training and validation rely on the availability of large high-quality datasets. However, in many cases only incomplete datasets are available, particularly in health care applications, where each patient typically undergoes different clinical procedures or can drop out of a study. Since the data to train the neural networks need to be complete, most studies discard the incomplete datapoints, which reduces the size of the training data, or impute the missing features, which can lead to artifacts. Alas, both approaches are inadequate when a large portion of the data is missing. Here, we introduce GapNet, an alternative deep-learning training approach that can use highly incomplete datasets without overfitting or introducing artefacts. First, the dataset is split into subsets of samples containing all values for a certain cluster of features. Then, these subsets are used to train individual neural networks. Finally, this ensemble of neural networks is combined into a single neural network whose training is fine-tuned using all complete datapoints. Using two highly incomplete real-world medical datasets, we show that GapNet improves the identification of patients with underlying Alzheimer’s disease pathology and of patients at risk of hospitalization due to Covid-19. Compared to commonly used imputation methods, this improvement suggests that GapNet can become a general tool to handle incomplete medical datasets.",
           3,
           "machine_learning_science_and_technology"
          ],
          [
           "A method for quantifying the generalization capabilities of generative models for solving Ising models",
           "10.1088/2632-2153/ad3710",
           2024,
           "\nFor Ising models with complex energy landscapes, whether the ground state can be found by neural networks depends heavily on the Hamming distance between the training datasets and the ground state. Despite the fact that various recently proposed generative models have shown good performance in solving Ising models, there is no adequate discussion on how to quantify their generalization capabilities. Here we design a Hamming distance regularizer in the framework of a class of generative models, variational autoregressive networks (VANs), to quantify the generalization capabilities of various network architectures combined with VAN. The regularizer can control the size of the overlaps between the ground state and the training datasets generated by networks, which, together with the success rates of finding the ground state, form a quantitative metric to quantify their generalization capabilities. We conduct numerical experiments on several prototypical network architectures combined with VAN, including feed-forward neural networks, recurrent neural networks, and graph neural networks, to quantify their generalization capabilities when solving Ising models. Moreover, considering the fact that the quantification of the generalization capabilities of networks on small-scale problems can be used to predict their relative performance on large-scale problems, our method is of great significance for assisting in the Neural Architecture Search field of searching for the optimal network architectures when solving large-scale Ising models.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Neural networks and quantum field theory",
           "10.1088/2632-2153/abeca3",
           2021,
           "\nWe propose a theoretical understanding of neural networks in terms of Wilsonian effective field theory. The correspondence relies on the fact that many asymptotic neural networks are drawn from Gaussian processes (GPs), the analog of non-interacting field theories. Moving away from the asymptotic limit yields a non-Gaussian process (NGP) and corresponds to turning on particle interactions, allowing for the computation of correlation functions of neural network outputs with Feynman diagrams. Minimal NGP likelihoods are determined by the most relevant non-Gaussian terms, according to the flow in their coefficients induced by the Wilsonian renormalization group. This yields a direct connection between overparameterization and simplicity of neural network likelihoods. Whether the coefficients are constants or functions may be understood in terms of GP limit symmetries, as expected from ’t Hooft’s technical naturalness. General theoretical calculations are matched to neural network experiments in the simplest class of models allowing the correspondence. Our formalism is valid for any of the many architectures that becomes a GP in an asymptotic limit, a property preserved under certain types of training.",
           34,
           "machine_learning_science_and_technology"
          ],
          [
           "Towards automated analysis for neutron reflectivity",
           "10.1088/2632-2153/abe7b5",
           2021,
           "\nWe describe a neural network-based tool for the automatic estimation of thin film thicknesses and scattering length densities from neutron reflectivity curves. The neural network sits within a data pipeline, that takes raw data from a neutron reflectometer, and outputs data and parameter estimates into a fitting program for end user analysis. Our tool deals with simple cases, predicting the number of layers and layer parameters up to three layers on a bulk substrate. This provides good accuracy in parameter estimation, while covering a large portion of the use case. By automating steps in data analysis that only require semi-expert knowledge, we lower the barrier to on-experiment data analysis, allowing better utility to be made from large scale facility experiments. Transfer learning showed that our tool works for x-ray reflectivity, and all code is freely available on GitHub (neutron-net 2020, available at: https://github.com/xmironov/neutron-net) (Accessed: 25 June 2020).",
           12,
           "machine_learning_science_and_technology"
          ],
          [
           "Estimating the probability of coincidental similarity between atomic displacement parameters with machine learning",
           "10.1088/2632-2153/ac022d",
           2021,
           "\nHigh-resolution diffraction studies of macromolecules incorporate the tensor form of the anisotropic displacement parameter (ADP) of atoms from their mean position. The comparison of these parameters requires a statistical framework that can handle the experimental and modeling errors linked to structure determination. Here, a Bayesian machine learning model is introduced that approximates ADPs with the random Wishart distribution. This model allows for the comparison of random samples from a distribution that is trained on experimental structures. The comparison revealed that the experimental similarity between atoms is larger than predicted by the random model for a substantial fraction of the comparisons. Different metrics between ADPs were evaluated and categorized based on how useful they are at detecting non-accidental similarity and whether they can be replaced by other metrics. The most complementary comparisons were provided by Euclidean, Riemann and Wasserstein metrics. The analysis of ADP similarity and the positional distance of atoms in bovine trypsin revealed a set of atoms with striking ADP similarity over a long physical distance, and generally the physical distance between atoms and their ADP similarity do not correlate strongly. A substantial fraction of long- and short-range ADP similarities does not form by coincidence and are reproducibly observed in different crystal structures of the same protein.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "The role of feature space in atomistic learning",
           "10.1088/2632-2153/abdaf7",
           2021,
           "\nEfficient, physically-inspired descriptors of the structure and composition of molecules and materials play a key role in the application of machine-learning techniques to atomistic simulations. The proliferation of approaches, as well as the fact that each choice of features can lead to very different behavior depending on how they are used, e.g. by introducing non-linear kernels and non-Euclidean metrics to manipulate them, makes it difficult to objectively compare different methods, and to address fundamental questions on how one feature space is related to another. In this work we introduce a framework to compare different sets of descriptors, and different ways of transforming them by means of metrics and kernels, in terms of the structure of the feature space that they induce. We define diagnostic tools to determine whether alternative feature spaces contain equivalent amounts of information, and whether the common information is substantially distorted when going from one feature space to another. We compare, in particular, representations that are built in terms of n-body correlations of the atom density, quantitatively assessing the information loss associated with the use of low-order features. We also investigate the impact of different choices of basis functions and hyperparameters of the widely used SOAP and Behler–Parrinello features, and investigate how the use of non-linear kernels, and of a Wasserstein-type metric, change the structure of the feature space in comparison to a simpler linear feature space.",
           25,
           "machine_learning_science_and_technology"
          ],
          [
           "An assessment of the structural resolution of various fingerprints commonly used in machine learning",
           "10.1088/2632-2153/abb212",
           2020,
           "\nAtomic environment fingerprints are widely used in computational materials science, from machine learning potentials to the quantification of similarities between atomic configurations. Many approaches to the construction of such fingerprints, also called structural descriptors, have been proposed. In this work, we compare the performance of fingerprints based on the overlap matrix, the smooth overlap of atomic positions, Behler–Parrinello atom-centered symmetry functions, modified Behler–Parrinello symmetry functions used in the ANI-1ccx potential and the Faber–Christensen–Huang–Lilienfeld fingerprint under various aspects. We study their ability to resolve differences in local environments and in particular examine whether there are certain atomic movements that leave the fingerprints exactly or nearly invariant. For this purpose, we introduce a sensitivity matrix whose eigenvalues quantify the effect of atomic displacement modes on the fingerprint. Further, we check whether these displacements correlate with the variation of localized physical quantities such as forces. Finally, we extend our examination to the correlation between molecular fingerprints obtained from the atomic fingerprints and global quantities of entire molecules.",
           36,
           "machine_learning_science_and_technology"
          ],
          [
           "Natural evolutionary strategies for variational quantum computation",
           "10.1088/2632-2153/abf3ac",
           2021,
           "\nNatural evolutionary strategies (NES) are a family of gradient-free black-box optimization algorithms. This study illustrates their use for the optimization of randomly initialized parameterized quantum circuits (PQCs) in the region of vanishing gradients. We show that using the NES gradient estimator the exponential decrease in variance can be alleviated. We implement two specific approaches, the exponential and separable NES, for parameter optimization of PQCs and compare them against standard gradient descent. We apply them to two different problems of ground state energy estimation using variational quantum eigensolver and state preparation with circuits of varying depth and length. We also introduce batch optimization for circuits with larger depth to extend the use of ES to a larger number of parameters. We achieve accuracy comparable to state-of-the-art optimization techniques in all the above cases with a lower number of circuit evaluations. Our empirical results indicate that one can use NES as a hybrid tool in tandem with other gradient-based methods for optimization of deep quantum circuits in regions with vanishing gradients.",
           15,
           "machine_learning_science_and_technology"
          ],
          [
           "Real-time semantic segmentation on FPGAs for autonomous vehicles with hls4ml",
           "10.1088/2632-2153/ac9cb5",
           2022,
           "In this paper, we investigate how field programmable gate arrays can serve as hardware accelerators for real-time semantic segmentation tasks relevant for autonomous driving. Considering compressed versions of the ENet convolutional neural network architecture, we demonstrate a fully-on-chip deployment with a latency of 4.9 ms per image, using less than 30% of the available resources on a Xilinx ZCU102 evaluation board. The latency is reduced to 3 ms per image when increasing the batch size to ten, corresponding to the use case where the autonomous vehicle receives inputs from multiple cameras simultaneously. We show, through aggressive filter reduction and heterogeneous quantization-aware training, and an optimized implementation of convolutional layers, that the power consumption and resource utilization can be significantly reduced while maintaining accuracy on the Cityscapes dataset.",
           5,
           "machine_learning_science_and_technology"
          ],
          [
           "Sparse optical flow outliers elimination method based on Borda stochastic neighborhood graph",
           "10.1088/2632-2153/ad1a50",
           2024,
           "\nDuring the tracking of moving targets in dynamic scenes, efficiently handling outliers in the optical flow and maintaining robustness across various motion amplitudes represents a critical challenge. So far, studies have used thresholding and local consistency based approaches to deal with optical outliers. However, there is subjectivity through expert-defined thresholds or delineated regions, and therefore these methods do not perform consistently enough under different target motion amplitudes. Other studies have focused on complex statistical-mathematical modeling which, although theoretically valid, requires significant computational resources. Aiming at the above problems this paper proposes a new method to calculate the optical outliers by using stochastic neighborhood graph combined with the Borda counting method, which reduces the computation amount on the basis of objectively eliminating the outliers. Sparse optical flow (SOF) values are used as the overall population and the outlier and inlier SOF values are used as samples. Analyze the dissimilarity between SOF data points, obtaining the dissimilarity matrix, introducing the Gaussian function to smooth and reduce the dimensionality of the dissimilarity matrix, and then normalizing the smoothing matrix to generate the binding matrix, where the probability sum of each node to other nodes in the matrix is equal to 1. Stochastic neighborhood graphs are then generated based on a binding matrix to obtain the outlier probabilities of data points in different neighborhood graphs, and outlier samples are obtained based on the probability. To avoid the subjectivity of the expert thresholds, the outlier probabilities are weighted and ranked to calculate the data point Borda scores to obtain accurate optical outliers. The experimental results show that the method in this paper is robust to different amplitude motions and real scenarios, and the accuracy, precision and recall of outliers elimination are better than the current mainstream algorithms.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Improving the background of gravitational-wave searches for core collapse supernovae: a machine learning approach",
           "10.1088/2632-2153/ab527d",
           2020,
           "\nBased on the prior O1–O2 observing runs, about 30% of the data collected by Advanced LIGO and Virgo in the next observing runs are expected to be single-interferometer data, i.e. they will be collected at times when only one detector in the network is operating in observing mode. Searches for gravitational-wave signals from supernova events do not rely on matched filtering techniques because of the stochastic nature of the signals. If a Galactic supernova occurs during single-interferometer times, separation of its unmodelled gravitational-wave signal from noise will be even more difficult due to lack of coherence between detectors. We present a novel machine learning method to perform single-interferometer supernova searches based on the standard LIGO-Virgo coherent WaveBurst pipeline. We show that the method may be used to discriminate Galactic gravitational-wave supernova signals from noise transients, decrease the false alarm rate of the search, and improve the supernova detection reach of the detectors.",
           24,
           "machine_learning_science_and_technology"
          ],
          [
           "The information of attribute uncertainties: what convolutional neural networks can learn about errors in input data",
           "10.1088/2632-2153/ad0285",
           2023,
           "\nErrors in measurements are key to weighting the value of data, but are often neglected in machine learning (ML). We show how convolutional neural networks (CNNs) are able to learn about the context and patterns of signal and noise, leading to improvements in the performance of classification methods. We construct a model whereby two classes of objects follow an underlying Gaussian distribution, and where the features (the input data) have varying, but known, levels of noise—in other words, each data point has a different error bar. This model mimics the nature of scientific data sets, such as those from astrophysical surveys, where noise arises as a realization of random processes with known underlying distributions. The classification of these objects can then be performed using standard statistical techniques (e.g. least squares minimization), as well as ML techniques. This allows us to take advantage of a maximum likelihood approach to object classification, and to measure the amount by which the ML methods are incorporating the information in the input data uncertainties. We show that, when each data point is subject to different levels of noise (i.e. noises with different distribution functions, which is typically the case in scientific data sets), that information can be learned by the CNNs, raising the ML performance to at least the same level of the least squares method—and sometimes even surpassing it. Furthermore, we show that, with varying noise levels, the confidence of the ML classifiers serves as a proxy for the underlying cumulative distribution function, but only if the information about specific input data uncertainties is provided to the CNNs.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Direct prediction of inelastic neutron scattering spectra from the crystal structure*",
           "10.1088/2632-2153/acb315",
           2023,
           "\nInelastic neutron scattering (INS) is a powerful technique to study vibrational dynamics of materials with several unique advantages. However, analysis and interpretation of INS spectra often require advanced modeling that needs specialized computing resources and relevant expertise. This difficulty is compounded by the limited experimental resources available to perform INS measurements. In this work, we develop a machine-learning based predictive framework which is capable of directly predicting both one-dimensional INS spectra and two-dimensional INS spectra with additional momentum resolution. By integrating symmetry-aware neural networks with autoencoders, and using a large scale synthetic INS database, high-dimensional spectral data are compressed into a latent-space representation, and a high-quality spectra prediction is achieved by using only atomic coordinates as input. Our work offers an efficient approach to predict complex multi-dimensional neutron spectra directly from simple input; it allows for improved efficiency in using the limited INS measurement resources, and sheds light on building structure-property relationships in a variety of on-the-fly experimental data analysis scenarios.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "A hybrid quantum regression model for the prediction of molecular atomization energies",
           "10.1088/2632-2153/abd486",
           2020,
           "\nQuantum machine learning is a relatively new research field that aims to combine the dramatic performance advantage offered by quantum computing and the ability of machine learning algorithms to learn complex distributions of high-dimensional data. The primary focus of this domain is the implementation of classical machine learning algorithms in the quantum mechanical domain and study of the speedup due to quantum parallelism, which could enable the development of novel techniques for solving problems such as quantum phase recognition and quantum error correction optimization. In this paper, we propose a hybrid quantum machine learning pipeline for predicting the atomization energies of various molecules using the nuclear charges and atomic positions of the constituent atoms. Firstly, we will be using a deep convolutional auto-encoder model for the feature extraction of data constructed from the eigenvalues and eigenvector centralities of the pairwise distance matrix calculated from atomic positions and the unrolled upper triangle of each Coulomb matrix calculated from nuclear charges, and we will then be using a quantum regression algorithm such as quantum linear regression, quantum radial basis function neural network and, a quantum neural network for estimating the atomization energy. The hybrid quantum neural network models do not seem to provide any speedup over their classical counterparts. Before implementing a quantum algorithm, we will also be using state-of-the-art classical machine learning and deep learning models such as XGBoost, multilayer perceptron, deep convolutional neural network, and a long short-term memory network to study the correlation between the extracted features and corresponding atomization energies of molecules.",
           6,
           "machine_learning_science_and_technology"
          ],
          [
           "Calibrated uncertainty for molecular property prediction using ensembles of message passing neural networks",
           "10.1088/2632-2153/ac3eb3",
           2021,
           "\nData-driven methods based on machine learning have the potential to accelerate computational analysis of atomic structures. In this context, reliable uncertainty estimates are important for assessing confidence in predictions and enabling decision making. However, machine learning models can produce badly calibrated uncertainty estimates and it is therefore crucial to detect and handle uncertainty carefully. In this work we extend a message passing neural network designed specifically for predicting properties of molecules and materials with a calibrated probabilistic predictive distribution. The method presented in this paper differs from previous work by considering both aleatoric and epistemic uncertainty in a unified framework, and by recalibrating the predictive distribution on unseen data. Through computer experiments, we show that our approach results in accurate models for predicting molecular formation energies with well calibrated uncertainty in and out of the training data distribution on two public molecular benchmark datasets, QM9 and PC9. The proposed method provides a general framework for training and evaluating neural network ensemble models that are able to produce accurate predictions of properties of molecules with well calibrated uncertainty estimates.",
           16,
           "machine_learning_science_and_technology"
          ],
          [
           "Development of use-specific high-performance cyber-nanomaterial optical detectors by effective choice of machine learning algorithms",
           "10.1088/2632-2153/ab8967",
           2020,
           "\nDue to their inherent variabilities, nanomaterials-based sensors are challenging to translate into real-world applications, where reliability and reproducibility are key. Machine learning can be a powerful approach for obtaining reliable inferences from data generated by such sensors. Here, we show that the best choice of ML algorithm in a cyber-nanomaterial detector is largely determined by the specific use-considerations, including accuracy, computational cost, speed, and resilience against drifts and long-term ageing effects. When sufficient data and computing resources are provided, the highest sensing accuracy can be achieved by the k-nearest neighbors (kNNs) and Bayesian inference algorithms, however, these algorithms can be computationally expensive for real-time applications. In contrast, artificial neural networks (ANNs) are computationally expensive to train (off-line), but they provide the fastest result under testing conditions (on-line) while remaining reasonably accurate. When access to data is limited, support vector machines (SVMs) can perform well even with small training sample sizes, while other algorithms show considerable reduction in accuracy if data is scarce, hence, setting a lower limit on the size of required training data. We also show by tracking and modeling the long-term drifts of the detector performance over a one year time-frame, it is possible to dramatically improve the predictive accuracy without any re-calibration. Our research shows for the first time that if the ML algorithm is chosen specific to the use-case, low-cost solution-processed cyber-nanomaterial detectors can be practically implemented under diverse operational requirements, despite their inherent variabilities.",
           9,
           "machine_learning_science_and_technology"
          ],
          [
           "Fast modeling and understanding fluid dynamics systems with encoder–decoder networks",
           "10.1088/2632-2153/abd1cf",
           2020,
           "\nIs a deep learning model capable of representing systems governed by certain first principle physics laws by only observing the system’s output? In an effort to simulate two-dimensional subsurface fluid dynamics in porous media, we found that an accurate deep-learning-based proxy model can be taught efficiently by a computationally expensive finite-volume-based simulator. We pose the problem as an image-to-image regression, running the simulator with different input parameters to furnish a synthetic training dataset upon which we fit the deep learning models. Since the data is spatiotemporal, we compare the performance of three alternative treatments of time; a convolutional LSTM, an autoencoder network that treats time as a direct input and an echo state network. Adversarial methods are adopted to address the sharp spatial gradient in the fluid dynamics problem. Compared to traditional simulation, the proposed deep learning approach enables much faster forward computation, which allows us to explore more scenarios with a much larger parameter space given the same time. It is shown that the improved forward computation efficiency is particularly valuable in solving inversion problems, where the physics model has unknown parameters to be determined by history matching. By computing the pixel-level attention of the trained model, we quantify the sensitivity of the deep learning model to key physical parameters and hence demonstrate that the inverse problem can be solved with great acceleration. We assess the efficacy of the machine learning surrogate in terms of its training speed and accuracy. The network can be trained within minutes using limited training data and achieve accuracy that scales desirably with the amount of training data supplied.",
           4,
           "machine_learning_science_and_technology"
          ],
          [
           "Spherical convolutions on molecular graphs for protein model quality assessment",
           "10.1088/2632-2153/abf856",
           2021,
           "\nProcessing information on three-dimensional (3D) objects requires methods stable to rigid-body transformations, in particular rotations, of the input data. In image processing tasks, convolutional neural networks achieve this property using rotation-equivariant operations. However, contrary to images, graphs generally have irregular topology. This makes it challenging to define a rotation-equivariant convolution operation on these structures. In this work, we propose spherical graph convolutional network that processes 3D models of proteins represented as molecular graphs. In a protein molecule, individual amino acids have common topological elements. This allows us to unambiguously associate each amino acid with a local coordinate system and construct rotation-equivariant spherical filters that operate on angular information between graph nodes. Within the framework of the protein model quality assessment problem, we demonstrate that the proposed spherical convolution method significantly improves the quality of model assessment compared to the standard message-passing approach. It is also comparable to state-of-the-art methods, as we demonstrate on critical assessment of structure prediction benchmarks. The proposed technique operates only on geometric features of protein 3D models. This makes it universal and applicable to any other geometric-learning task where the graph structure allows constructing local coordinate systems. The method is available at https://team.inria.fr/nano-d/software/s-gcn/.",
           9,
           "machine_learning_science_and_technology"
          ],
          [
           "Importance nested sampling with normalising flows",
           "10.1088/2632-2153/acd5aa",
           2023,
           "\nWe present an improved version of the nested sampling algorithm nessai in which the core algorithm is modified to use importance weights. In the modified algorithm, samples are drawn from a mixture of normalising flows and the requirement for samples to be independently and identically distributed (i.i.d.) according to the prior is relaxed. Furthermore, it allows for samples to be added in any order, independently of a likelihood constraint, and for the evidence to be updated with batches of samples. We call the modified algorithm i-nessai. We first validate i-nessai using analytic likelihoods with known Bayesian evidences and show that the evidence estimates are unbiased in up to 32 dimensions. We compare i-nessai to standard nessai for the analytic likelihoods and the Rosenbrock likelihood, the results show that i-nessai is consistent with nessai whilst producing more precise evidence estimates. We then test i-nessai on 64 simulated gravitational-wave signals from binary black hole coalescence and show that it produces unbiased estimates of the parameters. We compare our results to those obtained using standard nessai and dynesty and find that i-nessai requires 2.68 and 13.3 times fewer likelihood evaluations to converge, respectively. We also test i-nessai of an 80 s simulated binary neutron star signal using a reduced-order-quadrature basis and find that, on average, it converges in 24 min, whilst only requiring \n\n\n1.01\n×\n\n10\n\n6\n\n\n\n\n likelihood evaluations compared to \n\n\n1.42\n×\n\n10\n\n6\n\n\n\n\n for nessai and \n\n\n4.30\n×\n\n10\n\n7\n\n\n\n\n for dynesty. These results demonstrate that i-nessai is consistent with nessai and dynesty whilst also being more efficient.",
           5,
           "machine_learning_science_and_technology"
          ],
          [
           "Kernel charge equilibration: efficient and accurate prediction of molecular dipole moments with a machine-learning enhanced electron density model",
           "10.1088/2632-2153/ac568d",
           2022,
           "\nState-of-the-art machine learning (ML) interatomic potentials use local representations of atomic environments to ensure linear scaling and size-extensivity. This implies a neglect of long-range interactions, most prominently related to electrostatics. To overcome this limitation, we herein present a ML framework for predicting charge distributions and their interactions termed kernel charge equilibration (kQEq). This model is based on classical charge equilibration (QEq) models expanded with an environment-dependent electronegativity. In contrast to previously reported neural network models with a similar concept, kQEq takes advantage of the linearity of both QEq and Kernel Ridge Regression to obtain a closed-form linear algebra expression for training the models. Furthermore, we avoid the ambiguity of charge partitioning schemes by using dipole moments as reference data. As a first application, we show that kQEq can be used to generate accurate and highly data-efficient models for molecular dipole moments.",
           15,
           "machine_learning_science_and_technology"
          ],
          [
           "Deep learning of chaos classification",
           "10.1088/2632-2153/abb6d3",
           2020,
           "\nWe train an artificial neural network which distinguishes chaotic and regular dynamics of the two-dimensional Chirikov standard map. We use finite length trajectories and compare the performance with traditional numerical methods which need to evaluate the Lyapunov exponent (LE). The neural network has superior performance for short periods with length down to 10 Lyapunov times on which the traditional LE computation is far from converging. We show the robustness of the neural network to varying control parameters, in particular we train with one set of control parameters, and successfully test in a complementary set. Furthermore, we use the neural network to successfully test the dynamics of discrete maps in different dimensions, e.g. the one-dimensional logistic map and a three-dimensional discrete version of the Lorenz system. Our results demonstrate that a convolutional neural network can be used as an excellent chaos indicator.",
           11,
           "machine_learning_science_and_technology"
          ],
          [
           "Robust errant beam prognostics with conditional modeling for particle accelerators",
           "10.1088/2632-2153/ad2e18",
           2024,
           "\nParticle accelerators are complex and comprise thousands of components, with many pieces of equipment running at their peak power. Consequently, they can fault and abort operations for numerous reasons, lowering efficiency and science output. To avoid these faults, we apply anomaly detection techniques to predict unusual behavior and perform preemptive actions to improve the total availability. Supervised machine learning (ML) techniques such as siamese neural network models can outperform the often-used unsupervised or semi-supervised approaches for anomaly detection by leveraging the label information. One of the challenges specific to anomaly detection for particle accelerators is the data’s variability due to accelerator configuration changes within a production run of several months. ML models fail at providing accurate predictions when data changes due to changes in the configuration. To address this challenge, we include the configuration settings into our models and training to improve the results. Beam configurations are used as a conditional input for the model to learn any cross-correlation between the data from different conditions and retain its performance. We employ conditional siamese neural network (CSNN) models and conditional variational auto encoder (CVAE) models to predict errant beam pulses at the spallation neutron source under different system configurations and compare their performance. We demonstrate that CSNNs outperform CVAEs in our application.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Online meta-learned gradient norms for active learning in science and technology",
           "10.1088/2632-2153/ad2e17",
           2024,
           "\nAcquisition of scientific data can be expensive and time-consuming. Active learning is a solution to reduce costs and time by guiding the selection of scientific experiments. Autonomous and automatic identification of the most essential samples to annotate by active learning can also help to mitigate human bias. Previous research has demonstrated that unlabelled samples causing the largest gradient norms of neural network models can promote active learning in classification. However, gradient norm estimation in regression is non-trivial because the continuous one-dimensional output of regression significantly differs from classification. In this study, we propose a new active learning method that uses meta-learning to estimate the gradient norm of the unlabelled sample in regression. Specifically, we use a separate model to be a selector that learns knowledge from the previous active learning results and is used to predict the gradient norms of unlabelled samples. In each active learning iteration, we estimate and select unlabelled samples with the largest gradient norms to annotate. Our method is evaluated on six regression data sets in various domains, which include costly scientific data.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "WATUNet: a deep neural network for segmentation of volumetric sweep imaging ultrasound",
           "10.1088/2632-2153/ad2e15",
           2024,
           "\nLimited access to breast cancer diagnosis globally leads to delayed treatment. Ultrasound, an effective yet underutilized method, requires specialized training for sonographers, which hinders its widespread use. Volume sweep imaging (VSI) is an innovative approach that enables untrained operators to capture high-quality ultrasound images. Combined with deep learning, like convolutional neural networks, it can potentially transform breast cancer diagnosis, enhancing accuracy, saving time and costs, and improving patient outcomes. The widely used UNet architecture, known for medical image segmentation, has limitations, such as vanishing gradients and a lack of multi-scale feature extraction and selective region attention. In this study, we present a novel segmentation model known as Wavelet_Attention_UNet (WATUNet). In this model, we incorporate wavelet gates and attention gates between the encoder and decoder instead of a simple connection to overcome the limitations mentioned, thereby improving model performance. Two datasets are utilized for the analysis: the public ‘Breast Ultrasound Images’ dataset of 780 images and a private VSI dataset of 3818 images, captured at the University of Rochester by the authors. Both datasets contained segmented lesions categorized into three types: no mass, benign mass, and malignant mass. Our segmentation results show superior performance compared to other deep networks. The proposed algorithm attained a Dice coefficient of 0.94 and an F1 score of 0.94 on the VSI dataset and scored 0.93 and 0.94 on the public dataset, respectively. Moreover, our model significantly outperformed other models in McNemar’s test with false discovery rate correction on a 381-image VSI set. The experimental findings demonstrate that the proposed WATUNet model achieves precise segmentation of breast lesions in both standard-of-care and VSI images, surpassing state-of-the-art models. Hence, the model holds considerable promise for assisting in lesion identification, an essential step in the clinical diagnosis of breast lesions.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Coherent optical communications enhanced by machine intelligence",
           "10.1088/2632-2153/ab9c3d",
           2020,
           "\nAccuracy in discriminating between different received coherent signals is integral to the operation of many free-space communications protocols, and is often difficult when the receiver measures a weak signal. Here we design an optical communication scheme that uses balanced homodyne detection in combination with an unsupervised generative machine learning and convolutional neural network (CNN) system, and demonstrate its efficacy in a realistic simulated coherent quadrature phase shift keyed (QPSK) communications system. Additionally, we design the neural network system such that it autonomously learns to correct for the noise associated with a weak QPSK signal, which is distributed to the receiver prior to the implementation of the communications. We find that the scheme significantly reduces the overall error probability of the communications system, achieving the classical optimal limit. We anticipate that these results will allow for a significant enhancement of current classical and quantum coherent optical communications technologies.",
           5,
           "machine_learning_science_and_technology"
          ],
          [
           "End-to-end AI framework for interpretable prediction of molecular and crystal properties",
           "10.1088/2632-2153/acd434",
           2023,
           "\nWe introduce an end-to-end computational framework that allows for hyperparameter optimization using the DeepHyper library, accelerated model training, and interpretable AI inference. The framework is based on state-of-the-art AI models including CGCNN, PhysNet, SchNet, MPNN, MPNN-transformer, and TorchMD-NET. We employ these AI models along with the benchmark QM9, hMOF, and MD17 datasets to showcase how the models can predict user-specified material properties within modern computing environments. We demonstrate transferable applications in the modeling of small molecules, inorganic crystals and nanoporous metal organic frameworks with a unified, standalone framework. We have deployed and tested this framework in the ThetaGPU supercomputer at the Argonne Leadership Computing Facility, and in the Delta supercomputer at the National Center for Supercomputing Applications to provide researchers with modern tools to conduct accelerated AI-driven discovery in leadership-class computing environments. We release these digital assets as open source scientific software in GitLab, and ready-to-use Jupyter notebooks in Google Colab.",
           2,
           "machine_learning_science_and_technology"
          ],
          [
           "Evidence Networks: simple losses for fast, amortized, neural Bayesian model comparison",
           "10.1088/2632-2153/ad1a4d",
           2024,
           "\nEvidence Networks can enable Bayesian model comparison when state-of-the-art methods (e.g. nested sampling) fail and even when likelihoods or priors are intractable or unknown. Bayesian model comparison, i.e. the computation of Bayes factors or evidence ratios, can be cast as an optimization problem. Though the Bayesian interpretation of optimal classification is well-known, here we change perspective and present classes of loss functions that result in fast, amortized neural estimators that directly estimate convenient functions of the Bayes factor. This mitigates numerical inaccuracies associated with estimating individual model probabilities. We introduce the leaky parity-odd power (l-POP) transform, leading to the novel ‘l-POP-Exponential’ loss function. We explore neural density estimation for data probability in different models, showing it to be less accurate and scalable than Evidence Networks. Multiple real-world and synthetic examples illustrate that Evidence Networks are explicitly independent of dimensionality of the parameter space and scale mildly with the complexity of the posterior probability density function. This simple yet powerful approach has broad implications for model inference tasks. As an application of Evidence Networks to real-world data we compute the Bayes factor for two models with gravitational lensing data of the Dark Energy Survey. We briefly discuss applications of our methods to other, related problems of model comparison and evaluation in implicit inference settings.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "Developing novel machine-learning-based fire weather indices",
           "10.1088/2632-2153/acc008",
           2023,
           "\nAccurate wildfire risk estimation is an essential yet challenging task. As the frequency of extreme fire weather and wildfires is on the rise, forest managers and firefighters require accurate wildfire risk estimations to successfully implement forest management and firefighting strategies. Wildfire risk depends on non-linear interactions between multiple factors; therefore, the performance of linear models in its estimation is limited. To date, several traditional fire weather indices (FWIs) have been commonly used by weather services, such as the Canadian FWI.@Traditional FWIs are primarily based on empirical and statistical analyses. In this paper, we propose a novel FWI that was developed using machine learning—the machine learning based fire weather index (MLFWI). We present the performance of the MLFWI and compare it with various traditional FWIs. We find that the MLFWI significantly outperforms traditional indices in predicting wildfire occurrence, achieving an area under the curve score of 0.99 compared to 0.62–0.80. We recommend applying the MLFWI in wildfire warning systems.",
           3,
           "machine_learning_science_and_technology"
          ],
          [
           "Robust simulation-based inference in cosmology with Bayesian neural networks",
           "10.1088/2632-2153/acbb53",
           2023,
           "\nSimulation-based inference (SBI) is rapidly establishing itself as a standard machine learning technique for analyzing data in cosmological surveys. Despite continual improvements to the quality of density estimation by learned models, applications of such techniques to real data are entirely reliant on the generalization power of neural networks far outside the training distribution, which is mostly unconstrained. Due to the imperfections in scientist-created simulations, and the large computational expense of generating all possible parameter combinations, SBI methods in cosmology are vulnerable to such generalization issues. Here, we discuss the effects of both issues, and show how using a Bayesian neural network framework for training SBI can mitigate biases, and result in more reliable inference outside the training set. We introduce cosmoSWAG, the first application of stochastic weight averaging to cosmology, and apply it to SBI trained for inference on the cosmic microwave background.",
           5,
           "machine_learning_science_and_technology"
          ],
          [
           "Comparison of neural network architectures for feature extraction from binary black hole merger waveforms",
           "10.1088/2632-2153/ad2972",
           2024,
           "\nWe evaluate several neural-network architectures, both convolutional and recurrent, for gravitational-wave time-series feature extraction by performing point parameter estimation on noisy waveforms from binary-black-hole mergers. We build datasets of 100 000 elements for each of four different waveform models (or approximants) in order to test how approximant choice affects feature extraction. Our choices include SEOBNRv4P and IMRPhenomPv3, which contain only the dominant quadrupole emission mode, alongside IMRPhenomPv3HM and NRHybSur3dq8, which also account for high-order modes. Each dataset element is injected into detector noise corresponding to the third observing run of the LIGO-Virgo-KAGRA (LVK) collaboration. We identify the temporal convolutional network architecture as the overall best performer in terms of training and validation losses and absence of overfitting to data. Comparison of results between datasets shows that the choice of waveform approximant for the creation of a dataset conditions the feature extraction ability of a trained network. Hence, care should be taken when building a dataset for the training of neural networks, as certain approximants may result in better network convergence of evaluation metrics. However, this performance does not necessarily translate to data which is more faithful to numerical relativity simulations. We also apply this network on actual signals from LVK runs, finding that its feature-extracting performance can be effective on real data.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Extending the relative seriality formalism for interpretable deep learning of normal tissue complication probability models",
           "10.1088/2632-2153/ac6932",
           2022,
           "\nWe formally demonstrate that the relative seriality (RS) model of normal tissue complication probability (NTCP) can be recast as a simple neural network with one convolutional and one pooling layer. This approach enables us to systematically construct deep relative seriality networks (DRSNs), a new class of mechanistic generalizations of the RS model with radiobiologically interpretable parameters amenable to deep learning. To demonstrate the utility of this formulation, we analyze a simplified example of xerostomia due to irradiation of the parotid gland during alpha radiopharmaceutical therapy. Using a combination of analytical calculations and numerical simulations, we show for both the RS and DRSN cases that the ability of the neural network to generalize without overfitting is tied to ‘stiff’ and ‘sloppy’ directions in the parameter space of the mechanistic model. These results serve as proof-of-concept for radiobiologically interpretable deep learning of NTCP, while simultaneously yielding insight into how such techniques can robustly generalize beyond the training set despite uncertainty in individual parameters.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "FINETUNA: fine-tuning accelerated molecular simulations",
           "10.1088/2632-2153/ac8fe0",
           2022,
           "\nProgress towards the energy breakthroughs needed to combat climate change can be significantly accelerated through the efficient simulation of atomistic systems. However, simulation techniques based on first principles, such as density functional theory (DFT), are limited in their practical use due to their high computational expense. Machine learning approaches have the potential to approximate DFT in a computationally efficient manner, which could dramatically increase the impact of computational simulations on real-world problems. However, they are limited by their accuracy and the cost of generating labeled data. Here, we present an online active learning framework for accelerating the simulation of atomic systems efficiently and accurately by incorporating prior physical information learned by large-scale pre-trained graph neural network models from the Open Catalyst Project. Accelerating these simulations enables useful data to be generated more cheaply, allowing better models to be trained and more atomistic systems to be screened. We also present a method of comparing local optimization techniques on the basis of both their speed and accuracy. Experiments on 30 benchmark adsorbate-catalyst systems show that our method of transfer learning to incorporate prior information from pre-trained models accelerates simulations by reducing the number of DFT calculations by 91%, while meeting an accuracy threshold of 0.02 eV 93% of the time. Finally, we demonstrate a technique for leveraging the interactive functionality built in to Vienna ab initio Simulation Package (VASP) to efficiently compute single point calculations within our online active learning framework without the significant startup costs. This allows VASP to work in tandem with our framework while requiring 75% fewer self-consistent cycles than conventional single point calculations. The online active learning implementation, and examples using the VASP interactive code, are available in the open source FINETUNA package on Github.",
           13,
           "machine_learning_science_and_technology"
          ],
          [
           "Learning to unknot",
           "10.1088/2632-2153/abe91f",
           2021,
           "\nWe introduce natural language processing into the study of knot theory, as made natural by the braid word representation of knots. We study the UNKNOT problem of determining whether or not a given knot is the unknot. After describing an algorithm to randomly generate N-crossing braids and their knot closures and discussing the induced prior on the distribution of knots, we apply binary classification to the UNKNOT decision problem. We find that the Reformer and shared-QK Transformer network architectures outperform fully-connected networks, though all perform at \n\n\n≳\n\n\n95% accuracy. Perhaps surprisingly, we find that accuracy increases with the length of the braid word, and that the networks learn a direct correlation between the confidence of their predictions and the degree of the Jones polynomial. Finally, we utilize reinforcement learning (RL) to find sequences of Markov moves and braid relations that simplify knots and can identify unknots by explicitly giving the sequence of unknotting actions. Trust region policy optimization (TRPO) performs consistently well, reducing \n\n\n≳\n\n\n80% of the unknots with up to 96 crossings we tested to the empty braid word, and thoroughly outperformed other RL algorithms and random walkers. Studying these actions, we find that braid relations are more useful in simplifying to the unknot than one of the Markov moves.",
           19,
           "machine_learning_science_and_technology"
          ],
          [
           "Machine learning the computational cost of quantum chemistry",
           "10.1088/2632-2153/ab6ac4",
           2020,
           "\nComputational quantum mechanics based molecular and materials design campaigns consume increasingly more high-performance computer resources, making improved job scheduling efficiency desirable in order to reduce carbon footprint or wasteful spending. We introduce quantum machine learning (QML) models of the computational cost of common quantum chemistry tasks. For 2D nonlinear toy systems, single point, geometry optimization, and transition state calculations the out of sample prediction error of QML models of wall times decays systematically with training set size. We present numerical evidence for a toy system containing two functions and three commonly used optimizer and for thousands of organic molecular systems including closed and open shell equilibrium structures, as well as transition states. Levels of electronic structure theory considered include B3LYP/def2-TZVP, MP2/6-311G(d), local CCSD(T)/VTZ-F12, CASSCF/VDZ-F12, and MRCISD+Q-F12/VDZ-F12. In comparison to conventional indiscriminate job treatment, QML based wall time predictions significantly improve job scheduling efficiency for all tasks after training on just thousands of molecules. Resulting reductions in CPU time overhead range from 10% to 90%.",
           25,
           "machine_learning_science_and_technology"
          ],
          [
           "Fractional deep neural network via constrained optimization",
           "10.1088/2632-2153/aba8e7",
           2020,
           "\nThis paper introduces a novel algorithmic framework for a deep neural network (DNN), which in a mathematically rigorous manner, allows us to incorporate history (or memory) into the network—it ensures all layers are connected to one another. This DNN, called Fractional-DNN, can be viewed as a time-discretization of a fractional in time non-linear ordinary differential equation (ODE). The learning problem then is a minimization problem subject to that fractional ODE as constraints. We emphasize that an analogy between the existing DNN and ODEs, with standard time derivative, is well-known by now. The focus of our work is the Fractional-DNN. Using the Lagrangian approach, we provide a derivation of the backward propagation and the design equations. We test our network on several datasets for classification problems. Fractional-DNN offers various advantages over the existing DNN. The key benefits are a significant improvement to the vanishing gradient issue due to the memory effect, and better handling of nonsmooth data due to the network’s ability to approximate non-smooth functions.",
           5,
           "machine_learning_science_and_technology"
          ],
          [
           "Recipes for when physics fails: recovering robust learning of physics informed neural networks",
           "10.1088/2632-2153/acb416",
           2023,
           "\nPhysics-informed neural networks (PINNs) have been shown to be effective in solving partial differential equations by capturing the physics induced constraints as a part of the training loss function. This paper shows that a PINN can be sensitive to errors in training data and overfit itself in dynamically propagating these errors over the domain of the solution of the PDE. It also shows how physical regularizations based on continuity criteria and conservation laws fail to address this issue and rather introduce problems of their own causing the deep network to converge to a physics-obeying local minimum instead of the global minimum. We introduce Gaussian process (GP) based smoothing that recovers the performance of a PINN and promises a robust architecture against noise/errors in measurements. Additionally, we illustrate an inexpensive method of quantifying the evolution of uncertainty based on the variance estimation of GPs on boundary data. Robust PINN performance is also shown to be achievable by choice of sparse sets of inducing points based on sparsely induced GPs. We demonstrate the performance of our proposed methods and compare the results from existing benchmark models in literature for time-dependent Schrödinger and Burgers’ equations.",
           4,
           "machine_learning_science_and_technology"
          ],
          [
           "Noise-aware physics-informed machine learning for robust PDE discovery",
           "10.1088/2632-2153/acb1f0",
           2023,
           "\nThis work is concerned with discovering the governing partial differential equation (PDE) of a physical system. Existing methods have demonstrated the PDE identification from finite observations but failed to maintain satisfying results against noisy data, partly owing to suboptimal estimated derivatives and found PDE coefficients. We address the issues by introducing a noise-aware physics-informed machine learning framework to discover the governing PDE from data following arbitrary distributions. We propose training a couple of neural networks, namely solver and preselector, in a multi-task learning paradigm, which yields important scores of basis candidates that constitute the hidden physical constraint. After they are jointly trained, the solver network estimates potential candidates, e.g. partial derivatives, for the sparse regression to initially unveil the most likely parsimonious PDE, decided according to information criterion. Denoising physics-informed neural networks, based on discrete Fourier transform, is proposed to deliver the optimal PDE coefficients respecting the noise-reduced variables. Extensive experiments on five canonical PDEs affirm that the proposed framework presents a robust and interpretable approach for PDE discovery, leading to a new automatic PDE selection algorithm established on minimization of the information criterion decay rate.",
           4,
           "machine_learning_science_and_technology"
          ],
          [
           "PyXtal_FF: a python library for automated force field generation",
           "10.1088/2632-2153/abc940",
           2020,
           "\nWe present PyXtal_FF—a package based on Python programming language—for developing machine learning potentials (MLPs). The aim of PyXtal_FF is to promote the application of atomistic simulations through providing several choices of atom-centered descriptors and machine learning regressions in one platform. Based on the given choice of descriptors (including the atom-centered symmetry functions, embedded atom density, SO4 bispectrum, and smooth SO3 power spectrum), PyXtal_FF can train MLPs with either generalized linear regression or neural network models, by simultaneously minimizing the errors of energy/forces/stress tensors in comparison with the data from ab-initio simulations. The trained MLP model from PyXtal_FF is interfaced with the Atomic Simulation Environment (ASE) package, which allows different types of light-weight simulations such as geometry optimization, molecular dynamics simulation, and physical properties prediction. Finally, we will illustrate the performance of PyXtal_FF by applying it to investigate several material systems, including the bulk SiO2, high entropy alloy NbMoTaW, and elemental Pt for general purposes. Full documentation of PyXtal_FF is available at https://pyxtal-ff.readthedocs.io.",
           18,
           "machine_learning_science_and_technology"
          ],
          [
           "Solving quantum statistical mechanics with variational autoregressive networks and quantum circuits",
           "10.1088/2632-2153/aba19d",
           2020,
           "\nWe extend the ability of an unitary quantum circuit by interfacing it with a classical autoregressive neural network. The combined model parametrizes a variational density matrix as a classical mixture of quantum pure states, where the autoregressive network generates bitstring samples as input states to the quantum circuit. We devise an efficient variational algorithm to jointly optimize the classical neural network and the quantum circuit to solve quantum statistical mechanics problems. One can obtain thermal observables such as the variational free energy, entropy, and specific heat. As a byproduct, the algorithm also gives access to low energy excitation states. We demonstrate applications of the approach to thermal properties and excitation spectra of the quantum Ising model with resources that are feasible on near-term quantum computers.",
           25,
           "machine_learning_science_and_technology"
          ],
          [
           "Quantum machine learning of large datasets using randomized measurements",
           "10.1088/2632-2153/acb0b4",
           2023,
           "\nQuantum computers promise to enhance machine learning for practical applications. Quantum machine learning for real-world data has to handle extensive amounts of high-dimensional data. However, conventional methods for measuring quantum kernels are impractical for large datasets as they scale with the square of the dataset size. Here, we measure quantum kernels using randomized measurements. The quantum computation time scales linearly with dataset size and quadratic for classical post-processing. While our method scales in general exponentially in qubit number, we gain a substantial speed-up when running on intermediate-sized quantum computers. Further, we efficiently encode high-dimensional data into quantum computers with the number of features scaling linearly with the circuit depth. The encoding is characterized by the quantum Fisher information metric and is related to the radial basis function kernel. Our approach is robust to noise via a cost-free error mitigation scheme. We demonstrate the advantages of our methods for noisy quantum computers by classifying images with the IBM quantum computer. To achieve further speedups we distribute the quantum computational tasks between different quantum computers. Our method enables benchmarking of quantum machine learning algorithms with large datasets on currently available quantum computers.",
           12,
           "machine_learning_science_and_technology"
          ],
          [
           "Inverting the Kohn–Sham equations with physics-informed machine learning",
           "10.1088/2632-2153/ad3159",
           2024,
           "\nElectronic structure theory calculations offer an understanding of matter at the quantum level, complementing experimental studies in materials science and chemistry. One of the most widely used methods, density functional theory, maps a set of real interacting electrons to a set of fictitious non-interacting electrons that share the same probability density. Ensuring that the density remains the same depends on the exchange-correlation (XC) energy and, by a derivative, the XC potential. Inversions provide a method to obtain exact XC potentials from target electronic densities, in hopes of gaining insights into accuracy-boosting approximations. Neural networks provide a new avenue to perform inversions by learning the mapping from density to potential. In this work, we learn this mapping using physics-informed machine learning methods, namely physics informed neural networks and Fourier neural operators. We demonstrate the capabilities of these two methods on a dataset of one-dimensional atomic and molecular models. The capabilities of each approach are discussed in conjunction with this proof-of-concept presentation. The primary finding of our investigation is that the combination of both approaches has the greatest potential for inverting the Kohn–Sham equations at scale.",
           0,
           "machine_learning_science_and_technology"
          ],
          [
           "Physics-informed neural networks for solving forward and inverse Vlasov–Poisson equation via fully kinetic simulation",
           "10.1088/2632-2153/ad03d5",
           2023,
           "\nThe Vlasov–Poisson equation is one of the most fundamental models in plasma physics. It has been widely used in areas such as confined plasmas in thermonuclear research and space plasmas in planetary magnetospheres. In this study, we explore the feasibility of the physics-informed neural networks for solving forward and inverse Vlasov–Poisson equation (PINN-Vlasov). The PINN-Vlasov method employs a multilayer perceptron (MLP) to represent the solution of the Vlasov–Poisson equation. The training dataset comprises the randomly sampled time, space, and velocity coordinates and the corresponding distribution function. We generate training data using the fully kinetic PIC simulation rather than the analytical solution to the Vlasov–Poisson equation to eliminate the correlation between data and equations. The Vlasov equation and Poisson equation are concurrently integrated into the PINN-Vlasov framework using automatic differentiation and the trapezoidal rule, respectively. By minimizing the residuals between the reconstructed distribution function and labeled data, and the physically constrained residuals of the Vlasov–Poisson equation, the PINN-Vlasov method is capable of dealing with both forward and inverse problems. For forward problems, the PINN-Vlasov method can solve the Vlasov–Poisson equation with given initial and boundary conditions. For inverse problems, the completely unknown electric field and equation coefficients can be predicted with the PINN-Vlasov method using little particle distribution data.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "A differentiable programming method for quantum control",
           "10.1088/2632-2153/ab9802",
           2020,
           "\nOptimal control is highly desirable in many current quantum systems, especially to realize tasks in quantum information processing. We introduce a method based on differentiable programming to leverage explicit knowledge of the differential equations governing the dynamics of the system. In particular, a control agent is represented as a neural network that maps the state of the system at a given time to a control pulse. The parameters of this agent are optimized via gradient information obtained by direct differentiation through both the neural network and the differential equation of the system. This fully differentiable reinforcement learning approach ultimately yields time-dependent control parameters optimizing a desired figure of merit. We demonstrate the method’s viability and robustness to noise in eigenstate preparation tasks for three systems: a single qubit, a chain of qubits, and a quantum parametric oscillator.",
           31,
           "machine_learning_science_and_technology"
          ],
          [
           "RG-Flow: a hierarchical and explainable flow model based on renormalization group and sparse prior",
           "10.1088/2632-2153/ac8393",
           2022,
           "\nFlow-based generative models have become an important class of unsupervised learning approaches. In this work, we incorporate the key ideas of renormalization group (RG) and sparse prior distribution to design a hierarchical flow-based generative model, RG-Flow, which can separate information at different scales of images and extract disentangled representations at each scale. We demonstrate our method on synthetic multi-scale image datasets and the CelebA dataset, showing that the disentangled representations enable semantic manipulation and style mixing of the images at different scales. To visualize the latent representations, we introduce receptive fields for flow-based models and show that the receptive fields of RG-Flow are similar to those of convolutional neural networks. In addition, we replace the widely adopted isotropic Gaussian prior distribution by the sparse Laplacian distribution to further enhance the disentanglement of representations. From a theoretical perspective, our proposed method has \n\n\n\nO\n(\nlog\nL\n)\n\n\n\n complexity for inpainting of an image with edge length L, compared to previous generative models with \n\n\nO\n(\n\nL\n2\n\n)\n\n\n complexity.",
           5,
           "machine_learning_science_and_technology"
          ],
          [
           "An end-to-end trainable hybrid classical-quantum classifier",
           "10.1088/2632-2153/ac104d",
           2021,
           "\nWe introduce a hybrid model combining a quantum-inspired tensor network and a variational quantum circuit to perform supervised learning tasks. This architecture allows for the classical and quantum parts of the model to be trained simultaneously, providing an end-to-end training framework. We show that compared to the principal component analysis, a tensor network based on the matrix product state with low bond dimensions performs better as a feature extractor for the input data of the variational quantum circuit in the binary and ternary classification of MNIST and Fashion-MNIST datasets. The architecture is highly adaptable and the classical-quantum boundary can be adjusted according to the availability of the quantum resource by exploiting the correspondence between tensor networks and quantum circuits.",
           20,
           "machine_learning_science_and_technology"
          ],
          [
           "Introducing Machine Learning: Science and Technology",
           "10.1088/2632-2153/ab6d5d",
           2020,
           "\nDue to the remarkable progress of ever-growing digitalisation and computing capabilities, data has become increasingly abundant, and machine learning has emerged as a key ingredient in many enabling technologies within modern society. Its potential for pushing the frontiers of science is now also clear and has been demonstrated in various domains extending from novel materials design, quantum physics and the simulation of molecules and chemical systems, to particle physics, medical imaging, space science, climate science and drug discovery. Conceived in close consultation with the community, Machine Learning: Science and Technology has been launched as a unique multidisciplinary, open access journal that will bridge the application of machine learning across the natural sciences with new conceptual advances in machine learning methods as motivated by physical insights.",
           11,
           "machine_learning_science_and_technology"
          ],
          [
           "Neural network Gaussian processes as efficient models of potential energy surfaces for polyatomic molecules",
           "10.1088/2632-2153/ad0652",
           2023,
           "\nKernel models of potential energy surfaces (PESs) for polyatomic molecules are often restricted by a specific choice of the kernel function. This can be avoided by optimizing the complexity of the kernel function. For regression problems with very expensive data, the functional form of the model kernels can be optimized in the Gaussian process (GP) setting through compositional function search guided by the Bayesian information criterion. However, the compositional kernel search is computationally demanding and relies on greedy strategies, which may yield sub-optimal kernels. An alternative strategy of increasing complexity of GP kernels treats a GP as a Bayesian neural network (NN) with a variable number of hidden layers, which yields NNGP models. Here, we present a direct comparison of GP models with composite kernels and NNGP models for applications aiming at the construction of global PES for polyatomic molecules. We show that NNGP models of PES can be trained much more efficiently and yield better generalization accuracy without relying on any specific form of the kernel function. We illustrate that NNGP models trained by distributions of energy points at low energies produce accurate predictions of PES at high energies. We also illustrate that NNGP models can extrapolate in the input variable space by building the free energy surface of the Heisenberg model trained in the paramagnetic phase and validated in the ferromagnetic phase. By construction, composite kernels yield more accurate models than kernels with a fixed functional form. Therefore, by illustrating that NNGP models outperform GP models with composite kernels, our work suggests that NNGP models should be a preferred choice of kernel models for PES.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "Randomized CP tensor decomposition",
           "10.1088/2632-2153/ab8240",
           2020,
           "\nThe CANDECOMP/PARAFAC (CP) tensor decomposition is a popular dimensionality-reduction method for multiway data. Dimensionality reduction is often sought after since many high-dimensional tensors have low intrinsic rank relative to the dimension of the ambient measurement space. However, the emergence of ‘big data’ poses significant computational challenges for computing this fundamental tensor decomposition. By leveraging modern randomized algorithms, we demonstrate that coherent structures can be learned from a smaller representation of the tensor in a fraction of the time. Thus, this simple but powerful algorithm enables one to compute the approximate CP decomposition even for massive tensors. The approximation error can thereby be controlled via oversampling and the computation of power iterations. In addition to theoretical results, several empirical results demonstrate the performance of the proposed algorithm.",
           15,
           "machine_learning_science_and_technology"
          ],
          [
           "Constraints on parameter choices for successful time-series prediction with echo-state networks",
           "10.1088/2632-2153/aca1f6",
           2022,
           "\nEcho-state networks are simple models of discrete dynamical systems driven by a time series. By selecting network parameters such that the dynamics of the network is contractive, characterized by a negative maximal Lyapunov exponent, the network may synchronize with the driving signal. Exploiting this synchronization, the echo-state network may be trained to autonomously reproduce the input dynamics, enabling time-series prediction. However, while synchronization is a necessary condition for prediction, it is not sufficient. Here, we study what other conditions are necessary for successful time-series prediction. We identify two key parameters for prediction performance, and conduct a parameter sweep to find regions where prediction is successful. These regions differ significantly depending on whether full or partial phase space information about the input is provided to the network during training. We explain how these regions emerge.",
           2,
           "machine_learning_science_and_technology"
          ],
          [
           "Methods for comparing uncertainty quantifications for material property predictions",
           "10.1088/2632-2153/ab7e1a",
           2020,
           "\nData science and informatics tools have been proliferating recently within the computational materials science and catalysis fields. This proliferation has spurned the creation of various frameworks for automated materials screening, discovery, and design. Underpinning these frameworks are surrogate models with uncertainty estimates on their predictions. These uncertainty estimates are instrumental for determining which materials to screen next, but the computational catalysis field does not yet have a standard procedure for judging the quality of such uncertainty estimates. Here we present a suite of figures and performance metrics derived from the machine learning community that can be used to judge the quality of such uncertainty estimates. This suite probes the accuracy, calibration, and sharpness of a model quantitatively. We then show a case study where we judge various methods for predicting density-functional-theory-calculated adsorption energies. Of the methods studied here, we find that the best performer is a model where a convolutional neural network is used to supply features to a Gaussian process regressor, which then makes predictions of adsorption energies along with corresponding uncertainty estimates.",
           73,
           "machine_learning_science_and_technology"
          ],
          [
           "Neural network analysis of neutron and x-ray reflectivity data: pathological cases, performance and perspectives",
           "10.1088/2632-2153/abf9b1",
           2021,
           "\nNeutron and x-ray reflectometry (NR and XRR) are powerful techniques to investigate the structural, morphological and even magnetic properties of solid and liquid thin films. While neutrons and x-rays behave similarly in many ways and can be described by the same general theory, they fundamentally differ in certain specific aspects. These aspects can be exploited to investigate different properties of a system, depending on which particular questions need to be answered. Having demonstrated the general applicability of neural networks to analyze XRR and NR data before (Greco et al 2019 J. Appl. Cryst.\n52 1342), this study discusses challenges arising from certain pathological cases as well as performance issues and perspectives. These cases include a low signal-to-noise ratio, a high background signal (e.g. from incoherent scattering), as well as a potential lack of a total reflection edge (TRE). By dynamically modifying the training data after every mini batch, a fully-connected neural network was trained to determine thin film parameters from reflectivity curves. We show that noise and background intensity pose no significant problem as long as they do not affect the TRE. However, for curves without strong features the prediction accuracy is diminished. Furthermore, we compare the prediction accuracy for different scattering length density combinations. The results are demonstrated using simulated data of a single-layer system while also discussing challenges for multi-component systems.",
           13,
           "machine_learning_science_and_technology"
          ],
          [
           "A duality connecting neural network and cosmological dynamics",
           "10.1088/2632-2153/ac87e9",
           2022,
           "\nWe demonstrate that the dynamics of neural networks (NNs) trained with gradient descent and the dynamics of scalar fields in a flat, vacuum energy dominated Universe are structurally profoundly related. This duality provides the framework for synergies between these systems, to understand and explain NN dynamics and new ways of simulating and describing early Universe models. Working in the continuous-time limit of NNs, we analytically match the dynamics of the mean background and the dynamics of small perturbations around the mean field, highlighting potential differences in separate limits. We perform empirical tests of this analytic description and quantitatively show the dependence of the effective field theory parameters on hyperparameters of the NN. As a result of this duality, the cosmological constant is matched inversely to the learning rate in the gradient descent update.",
           2,
           "machine_learning_science_and_technology"
          ],
          [
           "Bayesian renormalization",
           "10.1088/2632-2153/ad0102",
           2023,
           "\nIn this note we present a fully information theoretic approach to renormalization inspired by Bayesian statistical inference, which we refer to as Bayesian renormalization. The main insight of Bayesian renormalization is that the Fisher metric defines a correlation length that plays the role of an emergent renormalization group (RG) scale quantifying the distinguishability between nearby points in the space of probability distributions. This RG scale can be interpreted as a proxy for the maximum number of unique observations that can be made about a given system during a statistical inference experiment. The role of the Bayesian renormalization scheme is subsequently to prepare an effective model for a given system up to a precision which is bounded by the aforementioned scale. In applications of Bayesian renormalization to physical systems, the emergent information theoretic scale is naturally identified with the maximum energy that can be probed by current experimental apparatus, and thus Bayesian renormalization coincides with ordinary renormalization. However, Bayesian renormalization is sufficiently general to apply even in circumstances in which an immediate physical scale is absent, and thus provides an ideal approach to renormalization in data science contexts. To this end, we provide insight into how the Bayesian renormalization scheme relates to existing methods for data compression and data generation such as the information bottleneck and the diffusion learning paradigm. We conclude by designing an explicit form of Bayesian renormalization inspired by Wilson’s momentum shell renormalization scheme in quantum field theory. We apply this Bayesian renormalization scheme to a simple neural network and verify the sense in which it organizes the parameters of the model according to a hierarchy of information theoretic importance.",
           2,
           "machine_learning_science_and_technology"
          ],
          [
           "Enhancing wildfire spread modelling by building a gridded fuel moisture content product with machine learning",
           "10.1088/2632-2153/aba480",
           2020,
           "\nWildland fire decision support systems require accurate predictions of wildland fire spread. Fuel moisture content (FMC) is one of the important parameters controlling the rate of spread of wildland fire. However, dead FMC measurements are provided by a relatively sparse network of remote automatic weather stations (RAWS), while live FMC is relatively infrequently measured manually. We developed a high resolution, gridded, real-time FMC data sets that did not previously exist for assimilation into operational wildland fire prediction systems based on ML. We used surface observations of live and dead FMC to train machine learning models to estimate FMC based on satellite observations. Moderate Resolution Imaging Spectrometer Terra and Aqua reflectances are used to predict the live and dead FMC measured by the Wildland Fire Assessment System and RAWS). We evaluate multiple machine learning methods including multiple linear regression, random forests (RFs), gradient boosted regression and artificial neural networks. The models are trained to learn the relationships between the satellite reflectances, surface weather and soil moisture observations and FMC. After training on data corresponding to the temporally and spatially nearest grid points to the irregularly spaced surface FMC observations, the machine learning models could be applied to all grid cells for a gridded product over the Conterminous United States (CONUS). The results show generally that the rule-based approaches have the lowest errors likely due to the sharp decision boundaries among the predictors, and the RF approach that utilizes bagging to avoid over-fitting has the lowest error on the test dataset. The errors are typically between 25%−33% the typical variability of the FMC data, which indicate the skill of the RF in estimating the FMC based on satellite data and surface characteristics. The FMC gridded product based on the RF runs operationally daily over CONUS and can be assimilated into WRF-Fire for more accurate wildland fire spread predictions.",
           13,
           "machine_learning_science_and_technology"
          ],
          [
           "Probability flow solution of the Fokker–Planck equation",
           "10.1088/2632-2153/ace2aa",
           2023,
           "\nThe method of choice for integrating the time-dependent Fokker–Planck equation (FPE) in high-dimension is to generate samples from the solution via integration of the associated stochastic differential equation (SDE). Here, we study an alternative scheme based on integrating an ordinary differential equation that describes the flow of probability. Acting as a transport map, this equation deterministically pushes samples from the initial density onto samples from the solution at any later time. Unlike integration of the stochastic dynamics, the method has the advantage of giving direct access to quantities that are challenging to estimate from trajectories alone, such as the probability current, the density itself, and its entropy. The probability flow equation depends on the gradient of the logarithm of the solution (its ‘score’), and so is a-priori unknown. To resolve this dependence, we model the score with a deep neural network that is learned on-the-fly by propagating a set of samples according to the instantaneous probability current. We show theoretically that the proposed approach controls the Kullback–Leibler (KL) divergence from the learned solution to the target, while learning on external samples from the SDE does not control either direction of the KL divergence. Empirically, we consider several high-dimensional FPEs from the physics of interacting particle systems. We find that the method accurately matches analytical solutions when they are available as well as moments computed via Monte-Carlo when they are not. Moreover, the method offers compelling predictions for the global entropy production rate that out-perform those obtained from learning on stochastic trajectories, and can effectively capture non-equilibrium steady-state probability currents over long time intervals.",
           1,
           "machine_learning_science_and_technology"
          ],
          [
           "3D reconstruction of a patient‐specific surface model of the proximal femur from calibrated x‐ray radiographs: A validation studya)",
           "10.1118/1.3089423",
           2009,
           "Twenty‐three femurs (one plastic bone and twenty‐two cadaver bones) with both nonpathologic and pathologic cases were considered to validate a statistical shape model based technique for three‐dimensional (3D) reconstruction of a patient‐specific surface model from calibrated x‐ray radiographs. The 3D reconstruction technique is based on an iterative nonrigid registration of the features extracted from a statistically instantiated 3D surface model to those interactively identified from the radiographs. The surface models reconstructed from the radiographs were compared to the associated ground truths derived either from a 3D CT‐scan reconstruction method or from a 3D laser‐scan reconstruction method and an average error distance of 0.95 mm were found. Compared to the existing works, our approach has the advantage of seamlessly handling both nonpathologic and pathologic cases even when the statistical shape model that we used was constructed from surface models of nonpathologic bones.",
           33,
           "medical_physics"
          ],
          [
           "Automatic quantitative analysis of in‐stent restenosis using FD‐OCT <i>in vivo</i> intra‐arterial imaging",
           "10.1118/1.4803461",
           2013,
           "Purpose:A new segmentation technique is implemented for automatic lumen area extraction and stent strut detection in intravascular optical coherence tomography (OCT) images for the purpose of quantitative analysis of in‐stent restenosis (ISR). In addition, a user‐friendly graphical user interface (GUI) is developed based on the employed algorithm toward clinical use.Methods:Four clinical datasets of frequency‐domain OCT scans of the human femoral artery were analyzed. First, a segmentation method based on fuzzy C means (FCM) clustering and wavelet transform (WT) was applied toward inner luminal contour extraction. Subsequently, stent strut positions were detected by utilizing metrics derived from the local maxima of the wavelet transform into the FCM membership function.Results:The inner lumen contour and the position of stent strut were extracted with high precision. Compared to manual segmentation by an expert physician, the automatic lumen contour delineation had an average overlap value of 0.917 ± 0.065 for all OCT images included in the study. The strut detection procedure achieved an overall accuracy of 93.80% and successfully identified 9.57 ± 0.5 struts for every OCT image. Processing time was confined to approximately 2.5 s per OCT frame.Conclusions:A new fast and robust automatic segmentation technique combining FCM and WT for lumen border extraction and strut detection in intravascular OCT images was designed and implemented. The proposed algorithm integrated in a GUI represents a step forward toward the employment of automated quantitative analysis of ISR in clinical practice.",
           20,
           "medical_physics"
          ],
          [
           "Photon scatter in portal images: Physical characteristics of pencil beam kernels generated using the <scp>EGS</scp> Monte Carlo code",
           "10.1118/1.598833",
           2002,
           "Pencil beam kernels describing scattered photon fluence behind homogeneous water slabs at various air gap distances were generated using the EGS Monte Carlo code. Photon scatter fluence was scored in separate bins based on the particle's history: singly scattered, multiply scattered, and bremsstrahlung and positron annihilation photons. Simultaneously, the mean energy and mean angle with respect to the incident photon pencil beam were tallied. Kernels were generated for incident photon pencil beams exhibiting monoenergetic spectra of 2.0 and 10.0 MeV, and polyenergetic spectra representative of 6 and 24 MV beams. Reciprocity was used to generate scatter fractions on the central axis for various field sizes, phantom thicknesses, and air gaps. The scatter kernels were further characterized by full width at half‐maximum estimates. Modulation transfer functions were calculated, providing theoretical estimates of the limit of performance of portal imaging systems due to the intrinsic scattering of photon radiation through the patient.",
           27,
           "medical_physics"
          ],
          [
           "Evaluation of the accuracy of fetal dose estimates using TG‐36 data",
           "10.1118/1.2710332",
           2007,
           "The American Association of Physicists in Medicine Radiation Therapy Committee Task Group 36 report (TG‐36) provides guidelines for managing radiation therapy of pregnant patients. Included in the report are data that can be used to estimate the dose to the fetus. The purpose of this study is to evaluate the accuracy of these fetal dose estimates as compared to clinically measured values. TG‐36 calculations were performed and compared with measurements of the fetal dose made in vivo or in appropriately‐designed phantoms. Calculation and measurement data was collected for eight pregnant patients who underwent radiation therapy at the MD Anderson Cancer Center as well as for several fetal dose studies in the literature. The maximum measured unshielded fetal dose was , which was 1.5% of the prescription dose. For all cases, TG‐36 calculations and measured fetal doses differed by up to a factor of 3—the ratio of the calculated to measured dose ranged from 0.34 to 2.93. On average, TG‐36 calculations underestimated the measured dose by 31%. No significant trends in the relationship between the calculated and measured fetal doses were found based on the distance from, or the size of, the treatment field.",
           17,
           "medical_physics"
          ],
          [
           "Commissioning of output factors for uniform scanning proton beams",
           "10.1118/1.3569581",
           2011,
           "Purpose:Current commercial treatment planning systems are not able to accurately predict output factors and calculate monitor units for proton fields. Patient‐specific field output factors are thus determined by either measurements or empirical modeling based on commissioning data. The objective of this study is to commission output factors for uniform scanning beams utilized at the ProCure proton therapy centers.Methods:Using water phantoms and a plane parallel ionization chamber, the authors first measured output factors with a fixed 10 cm diameter aperture as a function of proton range and modulation width for clinically available proton beams with ranges between 4 and 31.5 cm and modulation widths between 2 and 15 cm. The authors then measured the output factor as a function of collimated field size at various calibration depths for proton beams of various ranges and modulation widths. The authors further examined the dependence of the output factor on the scanning area (i.e., uncollimated proton field), snout position, and phantom material. An empirical model was developed to calculate the output factor for patient‐specific fields and the model‐predicted output factors were compared to measurements.Results:The output factor increased with proton range and field size, and decreased with modulation width. The scanning area and snout position have a small but non‐negligible effect on the output factors. The predicted output factors based on the empirical modeling agreed within 2% of measurements for all prostate treatment fields and within 3% for 98.5% of all treatment fields.Conclusions:Comprehensive measurements at a large subset of available beam conditions are needed to commission output factors for proton therapy beams. The empirical modeling agrees well with the measured output factor data. This investigation indicates that it is possible to accurately predict output factors and thus eliminate or reduce time‐consuming patient‐specific output measurements for proton treatments.",
           32,
           "medical_physics"
          ],
          [
           "Implementation of output prediction models for a passively double‐scattered proton therapy system",
           "10.1118/1.4965046",
           2016,
           "PurposeTwo output (cGy/MU) prediction models (one existing and one newly developed) for a passively double‐scattered proton therapy system are implemented and investigated for clinical use. Variations of each model are tested for accuracy in order to determine the most viable prediction model.MethodsThe first output prediction model [model (1)] is a semianalytical model proposed by Kooy et al. [Phys. Med. Biol. 50, 5847–5856 (2005)], which employs three main factors. The first factor (basic output prediction) uses a unique combined parameter [r = (R − M)/M] of range (R) and modulation [M; spread‐out Bragg peak (SOBP) width] along with option specific fitting parameters. The second factor takes into account minor source shifts using a linear fit due to varying beamline configurations for different options. The final factor accounts for a condition where the point of measurement is not at the isocenter or away from the middle of the SOBP based on an inverse‐square correction. The second model [model (2)] is a novel quartic polynomial fit of the basic output prediction whose idea was inspired by the first model. Different variations in the definition of R and M at distal (D) and proximal (P) ends resulted in the exploration of three variations of r for both models: r1 = (RD90 − MD90−P95)/MD90−P95, r2 = [(RD90 + ΔR1) − m × (MD90−P95 + ΔR1)]/[m × (MD90−P95 + ΔR1)], where ΔR1 is an offset between RD80 and RD90 and m is a ratio between MD90−P95 and theoretical , and r3 = [(RD90 − 0.305) − 0.801 × MD90−P95]/(0.801 × MD90−P95), where 0.305 (ΔR2) is an offset between RD90 and RD100 and 0.801 is a ratio between MD90−P95 and measured MD100−P100. Output measurements for 177 sets of R and M from all 24 options are compared to outputs predicted by both the models of three variations of r.ResultsThe mean differences between measurements and predictions ([predicted − measured]/measured × 100%) were −0.41% ± 1.78% (r1), 0.03% ± 1.53% (r2), and 0.05% ± 1.20% (r3) for model (1), and 0.27% ± 1.36% (r1), 0.71% ± 1.51% (r2), and −0.05% ± 1.20% (r3) for model (2). For a passing prediction rate with a difference threshold of ±3%, model (1) showed slightly worse results than model (2) using r1 (91.5% vs 94.4%). In general, small (M < 4 g/cm2) and close‐to‐full modulations produced larger discrepancies. However, 100% output predictions using r3 were confined within ±3% of measurements for both models and the difference between the models was not substantial (mean difference: 0.05% vs −0.05%).ConclusionsThe first existing model has proven to be a successful predictor of output for our compact double‐scattering proton therapy system. The new model performed comparably to the first model and showed better performance in some options due to a great degree of flexibility of a polynomial fit. Both models performed well using r3. Either model with r3 thus can serve well as an output prediction calculator.",
           5,
           "medical_physics"
          ],
          [
           "SU‐GG‐T‐558: OPTIS2 ‐ PSI's New Ocular Proton Therapy Facility",
           "10.1118/1.2962307",
           2008,
           "Since 1984 nearly 5000 patients with eye tumors, primarily ocular melanomas, were treated by a 72 MeV Phillips cyclotron within the OPTIS program (local tumor control 98%@10y). In the frame work of the PROSCAN project a dedicated superconducting cyclotron (COMET) is in clinical operation since February 2007. The aim of OPTIS2 project, an entirely new facility for the treatment ocular tumors with COMET, is to match the clinical success of OPTIS. Using the COMET/PROSCAN facility the beam intensity at the start of the OPTIS2 nozzle is 30 times lower than that currently used at the OPTIS facility. If we would keep using the OPTIS nozzle the treatment time would increase dramatically. Therefore, the new nozzle utilizes a double scattering technique with multiple‐ring second‐scattering foils which increases the nozzle efficiency by factor of 10, keeping the maximum treatment time under one minute. Due to the difference in scattering techniques the OPTIS2 and OPTIS beams are not identical. But the major characteristics, distal‐ and lateral‐ dose fall‐off are comparable. The flatness and symmetry have actually been improved. In OPTIS2 reliance on a single analog X‐ray film provider and extensive operator experience will be diminished by introducing digital imaging and computer aided semi‐automatic patient positioning. A new imaging and patient positioning concept has been developed, bringing together techniques and software already clinically tested at the Center de Protontherapie Orsay (France) and the Hahn Meitner Institut (Germany). OPTIS2 is designed and built from scratch, providing a continuation of the existing proton therapy program OPTIS, with comparable beam characteristics, whilst obtaining its protons from COMET. Beam commissioning and system testing is currently underway. A first patient treatment is scheduled for summer 2008.",
           3,
           "medical_physics"
          ],
          [
           "Dosimetry for ocular proton beam therapy at the Harvard Cyclotron Laboratory based on the ICRU Report 59",
           "10.1118/1.1487425",
           2002,
           "The Massachusetts General Hospital, the Harvard Cyclotron Laboratory (HCL), and the Massachusetts Eye and Ear Infirmary have treated almost 3000 patients with ocular disease using high‐energy external‐beam proton radiation therapy since 1975. The absorbed dose standard for ocular proton therapy beams at HCL was based on a fluence measurement with a Faraday cup (FC). A majority of proton therapy centers worldwide, however, use an absorbed dose standard that is based on an ionization chamber (IC) technique. The ion chamber calibration is deduced from a measurement in a reference  photon field together with a calculated correction factor that takes into account differences in a chamber's response in  and proton fields. In this work, we implemented an ionization chamber‐based absolute dosimetry system for the HCL ocular beamline based on the recommendations given in Report 59 by the International Commission on Radiation Units and Measurements. Comparative measurements revealed that the FC system yields an absorbed dose to water value that is 1.1% higher than was obtained with the IC system. That difference is small compared with the experimental uncertainties and is clinically insignificant. In June of 1998, we adopted the IC‐based method as our standard practice for the ocular beam.",
           30,
           "medical_physics"
          ],
          [
           "Field size dependence of the output factor in passively scattered proton therapy: Influence of range, modulation, air gap, and machine settings",
           "10.1118/1.3152111",
           2009,
           "At the Francis H. Burr Proton Therapy Center field specific output factors (i.e., dose per monitor unit) for patient treatments were modeled for all beamlines (two gantries, fixed stereotactic, and fixed eye beamline). The authors evaluated the accuracy of dose calculation and output model for small fields. Measurements in a water phantom were performed in three of our beamlines quantifying the dependency of the output factor on the field size for a variety of proton ranges. The influence of snout size, air gap, modulation, and second scatterer was investigated. The impact of field size on output depends strongly on the depth of interest. The air gap has a notable influence on small field outputs. A field size specific correction factor to the output is necessary if the latter was modeled or measured without the custom hardware in place. The output was shown to be field size dependent even for large fields, indicating an effect beyond charged particle disequilibrium caused by lateral scatter.",
           29,
           "medical_physics"
          ],
          [
           "Magnetic resonance imaging of microbubbles in a superheated emulsion chamber for brachytherapy dosimetry",
           "10.1118/1.598441",
           2002,
           "This paper describes development of magnetic resonance imaging (MRI) techniques for three‐dimensional (3D) imaging of a position‐sensitive detector for brachytherapy dosimetry. The detector is a 0.5 l chamber containing an emulsion of halocarbon‐115 droplets in a tissue‐equivalent glycerin‐based gel. The halocarbon droplets are highly superheated and expand into vapor microbubbles upon irradiation. Brachytherapy sources can be inserted into the superheated emulsion chamber to create distributions of bubbles. Three‐dimensional MRI of the chamber is then performed. A 3D gradient‐echo technique was optimized for spatial resolution and contrast between bubbles and gel. Susceptibility gradients at the interfaces between bubbles and gel are exploited to enhance contrast so microscopic bubbles can be imaged using relatively large voxel sizes. Three‐dimensional gradient‐echo images are obtained with an isotropic resolution of 300 μm over a  field‐of‐view in an imaging time of 14 min. A post‐processing technique was developed to semi‐automatically segment the bubbles from the images and to assess dose distributions based on the measured bubble densities. Relative dose distributions are computed from MR images for a  brachytherapy source and the results compare favorably to relative radial dose distributions calculated as recommended by Task Group 43 of the American Association of Physicists in Medicine.",
           8,
           "medical_physics"
          ],
          [
           "Radiation dose estimation using preclinical imaging with ‐metaiodobenzylguanidine (MIBG) PET",
           "10.1118/1.3480965",
           2010,
           "Purpose:A pretherapy‐metaiodobenzylguanidine (MIBG) positron emission tomography (PET)/computed tomography (CT) provides a potential method to estimate radiation dose to normal organs, as well as tumors prior to ‐MIBG treatment of neuroblastoma or pheochromocytoma. The aim of this work was to estimate human‐equivalent internal radiation dose of ‐MIBG using PET/CT data in a murine xenograft model.Methods:Athymic mice subcutaneously implanted with NB1691 cells that express high levels of human norepinephrine transporter were imaged using small animal microPET/CT over 96 h (approximate imaging time points: 0.5, 2, 24, 52, and 96 h) after intravenous administration of 3.07–4.84 MBq of ‐MIBG via tail vein. The tumors did not accumulate ‐MIBG to a detectable level. All four animals were considered as control and organ radiation dosimetry was performed. Volumes of interest were drawn on the coregistered CT images for thyroid, heart, lung, liver, kidney, and bladder, and transferred to PET images to obtain pharmacokinetic data. Based on tabulated organ mass distributions for both mice and adult male human, preclinical pharmacokinetic data were extrapolated to their human‐equivalent values. Radiation dose estimations for different age groups were performed using the OLINDA|EXM software with modified tissue weighting factors in the recent International Commission on Radiological Protection (ICRP) Publication 103.Results:The mean effective dose from‐MIBG using weighting factors from ICRP 103 to the adult male was estimated at 0.25 mSv/MBq. In different age groups, effective doses using values from ICRP 103 were estimated as follows: Adult female: 0.34, 15‐yr‐old: 0.39 mSv/MBq, 10‐yr‐old: 0.58 mSv/MBq, 5‐yr‐old: 1.03 mSv/MBq, 1‐yr‐old: 1.92 mSv/MBq, and newborn: 3.75 mSv/MBq. For comparison, the reported effective dose equivalent of ‐NaI for adult male (25% thyroid uptake, MIRD Dose Estimate Report No. 5) was 6.5 mSv/MBq.Conclusions:The authors estimated human‐equivalent internal radiation dose of‐MIBG using preclinical imaging data. As a reference, the effective dose estimation showed that ‐MIBG would deliver less radiation dose than ‐NaI, a radiotracer already being used in patients with thyroid cancer.",
           57,
           "medical_physics"
          ],
          [
           "A dosimetric comparison of  versus  for HDR prostate brachytherapy",
           "10.1118/1.2126821",
           2005,
           "For the purpose of evaluating the use of  for prostate High Dose Rate brachytherapy (HDR), a hypothetical  source is assumed with the exact same design of the new microSelectron source replacing the  active core by pure  metal. Monte Carlo simulation is employed for the full dosimetric characterization of both sources and results are compared following the AAPM TG‐43 dosimetric formalism. Monte Carlo calculated dosimetry results are incorporated in a commercially available treatment planning system , which features an inverse treatment planning option based on a multiobjective dose optimization engine. The quality of prostate HDR brachytherapy using the real  and hypothetical  source is compared in a comprehensive analysis of different prostate implants in terms of the multiobjective dose optimization solutions as well as treatment quality indices such as Dose Volume Histograms (DVH) and the Conformal Index (COIN). Given that scattering overcompensates for absorption in intermediate photon energies and distances in the range of interest to prostate HDR brachytherapy,  proves at least equivalent to  irrespective of prostate volume. This has to be evaluated in view of the shielding requirements for the  energies that are minimal relative to that for .",
           23,
           "medical_physics"
          ],
          [
           "Imaging characteristics of x‐ray capillary optics in digital mammography",
           "10.1118/1.597703",
           2003,
           "Computed radiography (CR) has shown promise in digital mammographic screening due to its good low spatial frequency MTF and its relatively wide exposure latitude. The CR image format has not gained acceptance clinically because of reduced high spatial frequency resolution as compared to film‐screen images. X‐ray capillary optics, aligned between the breast and CR phosphor imaging plate, will capture primary x‐ray photons almost exclusively. Due to the very small angle of acceptance, scattered photons angled more than about 1.6×10−3 radians from primary trajectory will not be accepted at the capillary optic entrance. The virtual elimination of detected scatter means almost 100% of the possible primary contrast should be visible in the image. In addition, the image can be magnified without focal spot blurring. Effective resolution of CR images can be increased by a factor equal to that magnification. Clinical implementation of future capillary optics are expected to be either in the form of a large, stationary, post‐patient optic that accepts primary from the entire breast or a fan‐shaped optic that is scanned across the breast. Measurements of a test capillary optic showed a reduction of scatter fraction to 0.018. Images of a lucite contrast detail phantom revealed a corresponding increase in image contrast when compared to anti‐scatter grid and no grid methods. Spectral transmission measurements using a high‐purity germanium detector showed good primary transmission (45%–50%) in the mammographic energy range. The MTF measurements of both stationary and scanned capillary optics showed improvement at the 5% MTF level to 8.4 mm−1 for scanned optics and 9.2 mm−1 for stationary optics representing a 68% and 84% respective increase over the CR MTF without magnification or capillary optics.",
           24,
           "medical_physics"
          ],
          [
           "Fluorometer for endoscopic diagnosis of tumors",
           "10.1118/1.595521",
           2003,
           "A filter fluorometer suitable for endoscopic applications has been developed for detection and characterization of superficial tumors by the fluorescence of a previously injected, tumor‐specific agent, hematoporphyrin derivative. Fluorescence is excited by violet light conducted through a fiberoptic lightguide in the endoscope, and the fluorescence emission together with reflected violet are collected by another fiberoptic lightguide. The red fluorescence and violet are separated by a dichroic mirror and filter and detected in photomultiplier tubes. The ratio of the fluorescence signal to the reflected violet signal is proportional to the ratio of the fluorescence yield to the violet reflectivity but is insensitive to variations in distance, angle, and violet power. The instrument may be useful for localizing small tumors, and for quantitative measurements of the amount of hematoporphyrin derivative in the tumor, a requirement for accurate dosimetry in photoradiation therapy.",
           40,
           "medical_physics"
          ],
          [
           "Accurate quantification of width and density of bone structures by computed tomography",
           "10.1118/1.2769102",
           2007,
           "In computed tomography (CT), the representation of edges between objects of different densities is influenced by the limited spatial resolution of the scanner. This results in the misrepresentation of density of narrow objects, leading to errors of up to  and more. Our interest is in the imaging and measurement of narrow bone structures, and the issues are the same for imaging with clinical CT scanners, peripheral quantitative CT scanners or micro CT scanners. Mathematical models, phantoms and tests with patient data led to the following procedures: (i) extract density profiles at one‐degree increments from the CT images at right angles to the bone boundary; (ii) consider the outer and inner edge of each profile separately due to different adjacent soft tissues; (iii) measure the width of each profile based on a threshold at fixed percentage of the difference between the soft‐tissue value and a first approximated bone value; (iv) correct the underlying material density of bone for each profile based on the measured width with the help of the density‐versus‐width curve obtained from computer simulations and phantom measurements. This latter curve is specific to a certain scanner and is not dependent on the densities of the tissues within the range seen in patients. This procedure allows the calculation of the material density of bone. Based on phantom measurements, we estimate the density error to be below  relative to the density of normal bone and the bone‐width error about one tenth of a pixel size.",
           29,
           "medical_physics"
          ],
          [
           "Radionuclide spatial distribution and dose deposition for <i>in vitro</i> assessments of <sup>212</sup>Pb‐αVCAM‐1 targeted alpha therapy",
           "10.1002/mp.13969",
           2019,
           "PurposeTargeted alpha therapy (TAT) takes advantage of the short‐range and high‐linear energy transfer of α‐particles and is increasingly used, especially for the treatment of metastatic lesions. Nevertheless, dosimetry of α‐emitters is challenging for the very same reasons, even for in vitro experiments. Assumptions, such as the uniformity of the distribution of radionuclides in the culture medium, are commonly made, which could have a profound impact on dose calculations. In this study we measured the spatial distribution of α‐emitting 212Pb coupled to an anti‐VCAM‐1 antibody (212Pb‐αVCAM‐1) and its evolution over time in the context of in vitro irradiations.MethodsTwo experimental setups were implemented without cells to measure α‐particle count rates and energy spectra in culture medium containing 15 kBq of 212Pb‐α‐VCAM‐1. Silicon detectors were placed above and below cell culture dishes for 20 h. One of the dishes had a 2.5‐µm‐thick mylar‐base allowing easy detection of the α‐particles. Monte Carlo simulations were performed to analyze experimental spectra. Experimental setups were modeled and α‐energy spectra were simulated in the silicon detectors for different decay positions in the culture medium. Simulated spectra were then used to deconvolute experimental spectra to determine the spatial distribution of 212Pb‐αVCAM‐1 in the medium. This distribution was finally used to calculate the dose deposition in cell culture experiments.ResultsExperimental count rates and energy spectra showed differences in measurements taken at the top and the bottom of dishes and temporal variations that did not follow 212Pb decay. The radionuclide spatial distribution was shown to be composed of a uniform distribution and concentration gradients at the top and the bottom, which were subjected to temporal variations that may be explained by gravity and electrostatic attraction. The absorbed dose in cells calculated from this distribution was compared with the dose expected for a uniform and static distribution and found to be 1.75 times higher, which is highly significant to interpret biological observations.ConclusionsThis study demonstrated that accurate dosimetry of α‐emitters requires the experimental determination of radionuclide spatial and temporal distribution and highlighted that in vitro assessment of dose for TAT cannot only rely on a uniform distribution of activity in the culture medium. The reliability and reproducibility of future experiments should benefit from specifically developed dosimetry tools and methods.",
           7,
           "medical_physics"
          ],
          [
           "Comprehensive Brachytherapy: Physical and Clinical Aspects.",
           "10.1118/1.4826194",
           2013,
           "Comprehensive Brachytherapy: Physical and Clinical Aspects. Venselaar J., Baltas D., Meigooni A., Hoskin P., Imaging in Medical Diagnosis and Therapy, William R. Hendee, Series Editor. CRC/Taylor & Francis Group, Boca Raton, FL, 2013. Hardback 535 pp. Price: $199.95. ISBN: 9781439844984.",
           3,
           "medical_physics"
          ],
          [
           "Assessment of variation in Elekta<sup>®</sup> plastic spherical‐calibration phantom and its impact on the Leksell Gamma Knife<sup>®</sup> calibration",
           "10.1118/1.3481508",
           2010,
           "Purpose:Traditionally, the dose‐rate calibration (output) of the Leksell Gamma Knife® (LGK) unit is performed using a 160 mm diameter plastic spherical phantom provided by the vendor of the LGK, Elekta Instrument AB. The purpose of this study was to evaluate variations in the Elekta spherical phantom and to assess its impact and use for the LGK calibration.Methods:Altogether, 13 phantoms from six different centers were acquired, 10 of these phantoms were manufactured within the past 10 years and the last 3 approximately 15–20 years ago. To assess variation in phantoms, the diameter and mass densities were measured. To assess the impact on LGK calibration, the output of two models of LGK (LGK Perfexion™ and LGK 4C) were measured under identical irradiation conditions using all 13 phantoms for each LGK model.Results:The mean measured deviation in diameter from expected nominal 160 mm for 13 phantoms was 0.51 mm (range of 0.09–1.51 mm). The mean measured phantom mass density for 13 phantoms was (range of ). The percentage deviation of output for individual phantom from mean of 13 phantom outputs ranged from −0.37% to 0.55% for LGK Perfexion™. Similarly, the percentage deviation of output for individual phantom from mean of 13 phantom outputs ranged from −0.72% to 0.47% for LGK 4C.Conclusions:This study demonstrated that small variations in terms of phantom size and mass density of the phantom material do not have a significant impact on dose‐rate measurements of the Leksell Gamma Knife®. Also, date of manufacture of the phantom did not show up to be a significant factor in this study.",
           18,
           "medical_physics"
          ],
          [
           "An improved analytical model for CT dose simulation with a new look at the theory of CT dose",
           "10.1118/1.2122507",
           2005,
           "Gagne [Med. Phys. 16, 29–37 (1989)] has previously described a model for predicting the sensitivity and dose profiles in the slice‐width  direction for CT scanners. The model, developed prior to the advent of multidetector CT scanners, is still widely used; however, it does not account for the effect of anode tilt on the penumbra or include the heel effect, both of which are increasingly important for the wider beams (up to ) of contemporary, multidetector scanners. Additionally, it applied only on (or near) the axis of rotation, and did not incorporate the photon energy spectrum. The improved model described herein transcends all of the aforementioned limitations of the Gagne model, including extension to the peripheral phantom axes. Comparison of simulated and measured dose data provides experimental validation of the model, including verification of the superior match to the penumbra provided by the tilted‐anode model, as well as the observable effects on the cumulative dose distribution. The initial motivation for the model was to simulate the quasiperiodic dose distribution on the peripheral, phantom axes resulting from a helical scan series in order to facilitate the implementation of an improved method of CT dose measurement utilizing a short ion chamber, as proposed by Dixon [Med. Phys. 30, 1272–1280 (2003)]. A more detailed set of guidelines for implementing such measurements is also presented in this paper. In addition, some fundamental principles governing CT dose which have not previously been clearly enunciated follow from the model, and a fundamental (energy‐based) quantity dubbed “CTDI‐aperture” is introduced.",
           35,
           "medical_physics"
          ],
          [
           "Metal–polysiloxane shields for radiation therapy of maxillo–facial tumors",
           "10.1118/1.596724",
           2003,
           "In the treatment of some head and neck lesions with high‐intensity radiation (teletherapy), an essential procedure is the application of an individually customized shielding appliance, which is designed, modeled, and formed into a working extra‐ or intraoral stent for the purpose of sparing healthy tissues. The present state of the art is slow and technique intensive, which can add to patient discomfort and inconvenience during molding and fabrication. A new formulation is described, which offers speed and ease of forming a moldable composite stent especially for intraoral use. Interleaved stacks of calibrated thin radiochromic film strips and soft‐tissue‐simulating plastic (polystyrene) layers gave a means of mapping one‐ or two‐dimensional profiles of dose distributions adjacent to the high‐density shielding materials using a spectrophotometer equipped with a gel scanner or a scanning laser‐beam microdensitometer. Tests using collimated gamma‐ray beams from a 60Co teletherapy unit were made in order to measure the dose distribution near interfaces of tissue‐simulating polymer and the composite stent material with and without mixtures of metals (Ag–Cu and Sn–Sb). These results show that quickly formed composites made of a flexible resin with high concentrations of powdered spherical metal alloys provide effective custom‐designed shielding, and, with a thin overlayer of the resin without metal, a diminished back‐scattered radiation dose to normal tissues. An example of a successful formulation is a mixture of 90% by weight Ag–Cu alloy powder in a vinyl polysiloxane resin. This material is a moldable putty which, upon polymerization, forms a rigid elastomeric material, providing a half‐value layer of ≊2.5 to 2.8 cm for a gamma‐ray beam from a 60Co source.",
           24,
           "medical_physics"
          ],
          [
           "Calculation of enhanced dynamic wedge factors for symmetric and asymmetric photon fields",
           "10.1118/1.598313",
           2002,
           "A method is introduced to calculate wedge factors for an enhanced dynamic wedge (EDW). An analytic formula has been derived that allows the determination of wedge factors at the center of symmetric and asymmetric photon fields. The formalism is an extension of the “MU fraction approximation,” which holds that the dynamic wedge factor is equal to the fraction of MU delivered to the point of calculation. Extensive data are presented, comparing measured enhanced dynamic wedge factors with the current method and the MU fraction model for both symmetric and asymmetric fields. For both 6 and 18 MV photons, the current method demonstrates improved results: Agreement to within 1% is obtained in all symmetric fields and within 2% for all asymmetric fields compared with discrepancies of up to 4% obtained with the MU fraction model.",
           40,
           "medical_physics"
          ],
          [
           "Methods to determine the fluorescence and Auger spectra due to decay of radionuclides or due to a single atomic‐subshell ionization and comparisons with experiments",
           "10.1118/1.599020",
           2002,
           "The aim of this work is to describe methods of determining the fluorescence and Auger spectra due to decay of radionuclides or a single atomic‐subshell ionization. First discussed is the electron vacancy generation in an atomic subshell by ionization, internal‐conversion decay, or electron‐capture decay. Later discussed is the status of electron vacancy following emission of fluorescence x rays and Auger electrons. Special attention is given to the relaxation probabilities and the procedures to calculate energies of released electrons. Also discussed are the Monte Carlo and deterministic methods to calculate vacancy cascades.",
           17,
           "medical_physics"
          ],
          [
           "New low‐contrast resolution phantoms for computed tomography",
           "10.1118/1.598516",
           2002,
           "Computed tomography (CT) has been established as a major imaging modality in diagnostic radiology. Accordingly, acceptance testing and quality control of CT scanners is of great importance. While most procedures and phantoms for testing are widely accepted, there is still discussion and uncertainty about low‐contrast (LC) sensitivity. In our opinion this unsatisfactory situation is caused at least in part by the lack of suitable phantoms for LC resolution measurements. We investigated the commonly used phantoms for LC detectability, the Catphan, and for LC resolution, the ATS phantom. While the Catphan showed stable object contrasts, the ATS phantom's measured contrast exhibited a strong dependence on temperature and x‐ray quality. Based on newly developed polyurethane resin materials, we designed and tested a LC resolution phantom with several different contrast steps. The object contrasts showed no dependence on temperature and beam quality. The new LC resolution phantom proved to be very suitable for measuring a scanner's low‐contrast sensitivity in the image plane, one of the most important image quality parameters. To assess LC resolution in three dimensions we designed an additional phantom with rows of spherical objects. A first prototype was evaluated in a multicenter study. The setup proved to be very helpful to quantify the in‐plane and axial LC sensitivity of spiral CT scan modes.",
           20,
           "medical_physics"
          ],
          [
           "The dosimetric properties of an intraoperative radiation therapy applicator system for a Mevatron‐80",
           "10.1118/1.596338",
           2003,
           "An applicator system for intraoperative radiation therapy has been fabricated which does not require physical docking with the accelerator. A dosimetric study has been completed which documents the properties of this system for a variety of electron beam energies, applicator sizes, collimator settings, both primary and secondary, and source–surface distance (SSD) settings. Sensitivity of the system to common misalignment errors was also determined. Results indicate (a) applicator leakage of less than 5%, (b) beam flatness to within plus or minus 5% at the dMAX with a single primary collimator setting, (c) smooth changes in output with cone size, beam energy and SSD, and (d) negligible changes in dose distributions within alignment errors permitted by the system.",
           10,
           "medical_physics"
          ],
          [
           "EchoSeed Model 6733 Iodine‐125 brachytherapy source: Improved dosimetric characterization using the MCNP5 Monte Carlo code",
           "10.1118/1.4736418",
           2012,
           "This study primarily aimed to obtain the dosimetric characteristics of the Model 6733 125I seed (EchoSeed) with improved precision and accuracy using a more up‐to‐date Monte‐Carlo code and data (MCNP5) compared to previously published results, including an uncertainty analysis. Its secondary aim was to compare the results obtained using the MCNP5, MCNP4c2, and PTRAN codes for simulation of this low‐energy photon‐emitting source. The EchoSeed geometry and chemical compositions together with a published 125I spectrum were used to perform dosimetric characterization of this source as per the updated AAPM TG‐43 protocol. These simulations were performed in liquid water material in order to obtain the clinically applicable dosimetric parameters for this source model. Dose rate constants in liquid water, derived from MCNP4c2 and MCNP5 simulations, were found to be 0.993 cGyh−1 U−1 (±1.73%) and 0.965 cGyh−1 U−1 (±1.68%), respectively. Overall, the MCNP5 derived radial dose and 2D anisotropy functions results were generally closer to the measured data (within ±4%) than MCNP4c and the published data for PTRAN code (Version 7.43), while the opposite was seen for dose rate constant. The generally improved MCNP5 Monte Carlo simulation may be attributed to a more recent and accurate cross‐section library. However, some of the data points in the results obtained from the above‐mentioned Monte Carlo codes showed no statistically significant differences. Derived dosimetric characteristics in liquid water are provided for clinical applications of this source model.",
           8,
           "medical_physics"
          ],
          [
           "Spatial response of synthetic microDiamond and diode detectors measured with kilovoltage synchrotron radiation",
           "10.1002/mp.12733",
           2017,
           "PurposeTo map the spatial response of four solid‐state radiation detectors of types commonly used for radiotherapy dosimetry.MethodsPTW model 60016 Diode P, 60017 Diode E, 60018 Diode SRS, and 60019 microDiamond detectors were radiographed using a high resolution conventional X‐ray system. Their spatial response was then investigated using a 0.1 mm diameter beam of 95 keV average energy photons generated by a synchrotron. The detectors were scanned through the beam while their signal was recorded as a function of position, to map the response. These 2D response maps were created in both the end‐on and side‐on orientations.ResultsThe results show the location and size of the active region. End‐on, the active area was determined to be centrally located and within 0.2 mm of the manufacturer's specified diameter. The active areas of the 60016 Diode P, 60017 Diode E, 60018 Diode SRS detectors are uniform to within approximately 5%. The 60019 microDiamond showed local variations up to 30%. The extra‐cameral signal in the microDiamond was calculated from the side‐on scan to be approximately 8% of the signal from the active element.ConclusionsThe spatial response of four solid‐state detectors has been measured. The technique yielded information about the location and uniformity of the active area, and the extra‐cameral signal, for the beam quality used.",
           25,
           "medical_physics"
          ],
          [
           "Fiber‐optic, real‐time dosimeter based on optically stimulated luminescence of  and KBr:Eu for potential use in the radiotherapy of cancer",
           "10.1118/1.1758349",
           2004,
           "This thesis describes a single‐fiber dosimetry system based on optically stimulated luminescence (OSL) of artificially grown single crystals of  and KBr:Eu, with potential application in the medical field, especially in radio oncology. Small fiber‐shaped dosimeters with dimensions (diameter/length) on the order of 500 μm/5 mm are attached to one end of an optical fiber, resulting in fiber probes with diameters of less than 1 mm and lengths of up to 15 m. The opposite end of the fiber is connected to an OSL reader that contains a stimulation light source (laser) and a photomultiplier tube that is used for luminescence detection. During irradiation, an optomechanical shutter periodically allows laser light to be transmitted down the optical fiber, to stimulate the luminescence response from the dosimeter being irradiated at a remote location. The luminescence measured during each interval of laser stimulation is indicative of the radiation dose absorbed in the dosimeter since the previous stimulation. The integral absorbed dose is obtained via a summation procedure from the measured dose fractions. Several operating procedures and data processing algorithms were developed in order to increase the speed and accuracy of the measurements, and integrated into the software that controls automated operation of the OSL readers. Periodic modulation of the stimulation also allows the OSL signal to be discriminated from background fluorescence, and thus yields measurements that are unaffected by Čerenkov light (the so‐called “stem effect”). Depending on the type of material used, the speed of the measurements, expressed as the time required to estimate an individual dose fraction, can be as short as 67 ms. Integral dose estimates from real‐time OSL of  and KBr:Eu were obtained for water‐phantom irradiations performed with medical teletherapy sources, and were found to agree within 3.7% and 2.8%, respectively, with reference measurements from ionization chambers. We also investigated the possibility of using the fiber OSL readers for other purposes, such as two‐dimensional mapping of dose distributions on compacted layers of  grains, and detection of low‐level doses, for possible application in Homeland Security projects.",
           2,
           "medical_physics"
          ],
          [
           "Comparison of organ doses for patients undergoing balloon brachytherapy of the breast with HDR  or electronic sources using Monte Carlo simulations in a heterogeneous human phantoma)",
           "10.1118/1.3292292",
           2010,
           "Purpose:Accelerated partial breast irradiation via interstitial balloon brachytherapy is a fast and effective treatment method for certain early stage breast cancers. The radiation can be delivered using a conventional high‐dose rate (HDR) gamma‐emitting source or a novel electronic brachytherapy (eBx) source which uses lower energy x rays that do not penetrate as far within the patient. A previous study [A. Dickler, M. C. Kirk, N. Seif, K. Griem, K. Dowlatshahi, D. Francescatti, and R. A. Abrams, “A dosimetric comparison of MammoSite high‐dose‐rate brachytherapy and Xoft Axxent electronic brachytherapy,” Brachytherapy 6, 164–168 (2007)] showed that the target dose is similar for HDR  and eBx. This study compares these sources based on the dose received by healthy organs and tissues away from the treatment site.Methods:A virtual patient with left breast cancer was represented by a whole‐body, tissue‐heterogeneous female voxel phantom. Monte Carlo methods were used to calculate the dose to healthy organs in a virtual patient undergoing balloon brachytherapy of the left breast with HDR or eBx sources. The dose‐volume histograms for a few organs which received large doses were also calculated. Additional simulations were performed with all tissues in the phantom defined as water to study the effect of tissue inhomogeneities.Results:For both HDR and eBx, the largest mean organ doses were received by the ribs, thymus gland, left lung, heart, and sternum which were close to the brachytherapy source in the left breast. eBx yielded mean healthy organ doses that were more than a factor of  smaller than for HDR  for all organs considered, except for the three closest ribs. Excluding these ribs, the average and median dose‐reduction factors were  and , respectively. The volume distribution of doses in nearby soft tissue organs that were outside the PTV were also improved with eBx. However, the maximum dose to the closest rib with the eBx source was 5.4 times greater than that of the HDR  source. The ratio of tissue‐to‐water maximum rib dose for the eBx source was .Conclusions:The results of this study indicate that eBx may offer lower toxicity to most healthy tissues, except nearby bone. TG‐43 methods have a tendency to underestimate dose to bone, especially the ribs. Clinical studies evaluating the negative health effects caused by irradiating healthy organs are needed so that physicians can better understand when HDR or eBx might best benefit a patient.",
           22,
           "medical_physics"
          ],
          [
           "Monte Carlo modeling of small photon fields: Quantifying the impact of focal spot size on source occlusion and output factors, and exploring miniphantom design for small‐field measurements",
           "10.1118/1.3152866",
           2009,
           "The accuracy with which Monte Carlo models of photon beams generated by linear accelerators (linacs) can describe small‐field dose distributions depends on the modeled width of the electron beam profile incident on the linac target. It is known that the electron focal spot width affects penumbra and cross‐field profiles; here, the authors explore the extent to which source occlusion reduces linac output for smaller fields and larger spot sizes. A BEAMnrc Monte Carlo linac model has been used to investigate the variation in penumbra widths and small‐field output factors with electron spot size. A formalism is developed separating head scatter factors into source occlusion and flattening filter factors. Differences between head scatter factors defined in terms of in‐air energy fluence, collision kerma, and terma are explored using Monte Carlo calculations. Estimates of changes in kerma‐based source occlusion and flattening filter factors with field size and focal spot width are obtained by calculating doses deposited in a narrow 2 mm wide virtual “milliphantom” geometry. The impact of focal spot size on phantom scatter is also explored. Modeled electron spot sizes of 0.4–0.7 mm FWHM generate acceptable matches to measured penumbra widths. However the 0.5 cm field output factor is quite sensitive to electron spot width, the measured output only being matched by calculations for a 0.7 mm spot width. Because the spectra of the unscattered primary  and head‐scattered  photon energy fluences differ, miniphantom‐based collision kerma measurements do not scale precisely with total in‐air energy fluence  but with . For most field sizes, on‐axis collision kerma is independent of the focal spot size; but for a 0.5 cm field size and 1.0 mm spot width, it is reduced by around 7% mostly due to source occlusion. The phantom scatter factor of the 0.5 cm field also shows some spot size dependence, decreasing by 6% (relative) as spot size is increased from 0.1 to 1.0 mm. The dependence of small‐field source occlusion and output factors on the focal spot size makes this a significant factor in Monte Carlo modeling of small  fields. Changes in penumbra width with spot size are not sufficiently large to accurately pinpoint spot widths. Consequently, while Monte Carlo models based exclusively on large‐field data can quite accurately predict small‐field profiles and PDDs, in the absence of experimental methods of determining incident electron beam profiles it will remain necessary to measure small‐field output factors, fine‐tuning modeled spot sizes to ensure good matching between the Monte Carlo and the measured output factors.",
           71,
           "medical_physics"
          ],
          [
           "Impact of interseed attenuation and tissue composition for permanent prostate implants",
           "10.1118/1.2168295",
           2006,
           "The purpose is to evaluate the impact of interseed attenuation and prostate composition for prostate treatment plans with  permanent seed implants using the Monte Carlo (MC) method. The effect of seed density (number of seeds per prostate unit volume) is specifically investigated. The study focuses on treatment plans that were generated for clinical cases. For each plan, four different dose calculation techniques are compared: TG‐43 based calculation, superposition MC, full MC with water prostate, and full MC with realistic prostate tissue. The prostate tissue description is from the ICRP report 23 (W. S. Snyer, M. J. Cook, E. S. Nasset, L. R. Karkhausen, G. P. Howells, and I. H. Tipton, “Report of the task group on reference man,” Technical Report 23, International Commission on Radiological Protection, 1974). According to the comparisons, the seed density has an influence on interseed attenuation. A plan with a typical low seed density ( seeds in a  prostate) suffers a 1.2% drop in the CTV  value due to interseed attenuation. A drop of 3.0% is calculated for a higher seed density (75 0.3  seeds, same prostate). The influence of the prostate composition is similar for all seed densities and prostate sizes. The difference between MC simulations in water and MC simulations in prostate tissue is between 4.4% and 4.8% for the  parameter. Overall, the effect on  is ranging from 5.8% to 12.8% when comparing clinically approved TG‐43 and MC simulations in prostate tissue. The impact varies from one patient to the other and depends on the prostate size and the number of seeds. This effect can reach a significant level when reporting correlations between clinical effect and deposited dose.",
           60,
           "medical_physics"
          ],
          [
           "Investigation of energy dependence of EBT and EBT‐2 Gafchromic film",
           "10.1118/1.3291622",
           2010,
           "Purpose:The purpose of this study was to quantify the extent of energy dependence of Gafchromic film to x‐ray energies ranging in quality from 105 kVp to 6 MV, and relate this dependency to the film's chemical composition and date of production.Methods:Lots of Gafchromic EBT film manufactured in 2004 and 2005 together with more recent batches produced in 2007 were evaluated for energy dependence. Multiple batches of EBT‐2 film were also evaluated. Energy dependence was quantified as—the ratio of net optical density (netOD) measured at a given energy  relative to the netOD measured at 6 MV, as measured on a linear accelerator.  was evaluated for beam qualities of 105 and 220 kVp on a clinical orthovoltage unit using two separate techniques—a flatbed scanner (Epson) and a real‐time fiber‐optic readout system. Neutron activation analysis for chlorine and bromine content was performed on all the films to determine whether the composition of the film had changed between batches of film exhibiting different energy dependence responses.Results:For batches of EBT manufactured in 2007, was 0.75 and  was 0.85, indicating an under‐response at orthovoltage energies. These results were confirmed using both the Epson flatbed scanner as well as the real‐time readout system. For batches of EBT film manufactured before 2006,  ranged from 0.9 to 1.0. The results from the neutron activation analysis confirmed a direct relationship between the concentration of chlorine and the magnitude of under‐response at orthovoltage energies. EBT‐2 film exhibited  values ranging from 0.79 (under‐response) to 1.20 (over‐response) among batches containing varying concentrations of bromine, chlorine, and potassium.Conclusions:The results of this study indicated that differences in energy response of EBT and EBT‐2 films were due to differences in the chemical composition and therefore the effective atomic number of the film, which have changed over time. To achieve an energy independent dosimeter over a range of kilovoltage energies, the effective atomic number of the dosimeter must be closely matched to that of water. Small deviations in chemical composition can lead to large deviations in response as a function of energy.",
           70,
           "medical_physics"
          ],
          [
           "Verification of the plan dosimetry for high dose rate brachytherapy using metal–oxide–semiconductor field effect transistor detectors",
           "10.1118/1.2736288",
           2007,
           "The feasibility of a recently designed metal–oxide–semiconductor field effect transistor (MOSFET) dosimetry system for dose verification of high dose rate (HDR) brachytherapy treatment planning was investigated. MOSFET detectors were calibrated with a  NE‐2571 Farmer‐type ionization chamber in water. Key characteristics of the MOSFET detectors, such as the energy dependence, that will affect phantom measurements with HDR  sources were measured. The MOSFET detector was then applied to verify the dosimetric accuracy of HDR brachytherapy treatments in a custom‐made water phantom. Three MOSFET detectors were calibrated independently, with the calibration factors ranging from . A distance dependent energy response was observed, significant within  from the source. The new MOSFET detector has a good reproducibility , small angular effect , and good dose linearity . It was observed that the MOSFET detectors had a linear response to dose until the threshold voltage reached approximately  for  source measurements. Further comparison of phantom measurements using MOSFET detectors with dose calculations by a commercial treatment planning system for computed tomography‐based brachytherapy treatment plans showed that the mean relative deviation was  for dose points  away from the source and  for dose points located  away. The percentage deviations between the measured doses and the planned doses were below 5% for all the measurements. The MOSFET detector, with its advantages of small physical size and ease of use, is a reliable tool for quality assurance of HDR brachytherapy. The phantom verification method described here is universal and can be applied to other HDR brachytherapy treatments.",
           47,
           "medical_physics"
          ],
          [
           "An unsupervised automatic segmentation algorithm for breast tissue classification of dedicated breast computed tomography images",
           "10.1002/mp.12920",
           2018,
           "PurposeTo develop and evaluate a new automatic classification algorithm to identify voxels containing skin, vasculature, adipose, and fibroglandular tissue in dedicated breast CT images.MethodsThe proposed algorithm combines intensity‐ and region‐based segmentation methods with energy minimizing splines and unsupervised data mining approaches for classifying and segmenting the different tissue types. Breast skin segmentation is achieved by a region‐growing method which uses constraints from the previously extracted skin centerline to add robustness to the model and to reduce the false positive rate. An energy minimizing active contour model is then used to classify adipose tissue voxels by including gradient flow and region‐based features. Finally, blood vessels are separated from fibroglandular tissue by a k‐means clustering algorithm based on automatically extracted shape‐based features. To evaluate the accuracy of the algorithm, two sets of 15 different patient breast CT scans, each acquired with different breast CT systems and acquisition settings were obtained. Three slices from each scan were manually segmented under the supervision of an experienced breast radiologist and considered the gold standard. Comparisons with manual segmentation were quantified using five similarity metrics: Dice similarity coefficient (DSC), sensitivity, conformity coefficient, and two Hausdorff distance measures. To evaluate the robustness to image noise, the segmentation was repeated after separately adding Gaussian noise with increasing standard deviation (in four steps, from 0.01 to 0.04) to an additional 15 slices from the first dataset. In addition, to evaluate vasculature classification, three different pre‐ and postcontrast injection patient breast CT images were classified and compared. Finally, DSC was also used for quantitative comparisons with previously proposed approaches for breast CT tissue classification using 10 images from the first dataset.ResultsThe algorithm showed a high accuracy in classifying the different tissue types for both breast CT systems, with an average DSC of 95% and 90% for the first and second image dataset, respectively. Furthermore, it demonstrated to be robust to image noise with a robustness to image noise of 85%, 83%, 79%, and 71% for the images corrupted with the four increasing noise levels. Previous methods for breast tissues classification resulted, for the tested dataset, in an average global DSC of 87%, while our approach resulted in a global average DSC of 94.5%.ConclusionsThe proposed algorithm resulted in accurate and robust breast tissue classification, with no prior training or threshold setting. Potential applications include breast density quantification and tissue pattern characterization (both biomarkers of cancer development), simulation‐based radiation dose analysis, and patient data‐based phantom design, which could be used for further breast imaging research.",
           25,
           "medical_physics"
          ],
          [
           "Pre‐discard estimation of radioactivated materials in positron emission tomography cyclotron systems and concrete walls of a cyclotron vault",
           "10.1002/mp.13492",
           2019,
           "PurposeThe concrete vault, cyclotron body, and peripheral equipment in a cyclotron room become radioactivated by neutrons generated by operating an unshielded cyclotron. Radionuclides and the amounts of radioactivated materials must be identified before discarding a cyclotron system. The present study aimed to reduce the amounts of concrete from cyclotron vaults, as well as cyclotron components and peripheral equipment, that will be disposed of as radioactivated waste by clarifying the nature and quantity of radioactivated materials remaining in facilities after cyclotron operations have ceased.MethodsCylindrical concrete cores were bored into all four walls, ceiling, and floor of a room where a Cypris 370 cyclotron had been operated for 22.8 yr and then cooled for 40 months. The accelerated particles comprised protons and deuterons with constant energy of 18 and 10 MeV, respectively. The types and amounts of radionuclides in these cores, in 38 components of the cyclotron including the yoke, and in 13 pieces of equipment in the room, were determined by γ‐ray spectrometry. Concentrations of radioactivity were also calculated using an updated version of Particle and Heavy Ion Transport System and DCHAIN‐SP. Amounts of materials with both measured and calculated total radioactivity concentration (ΣD) of <0.1 Bq/g were identified as being nonradioactivated.ResultsThe major radionuclides in the concrete were 60Co and 152Eu. The radioactivated concrete was distributed to a depth of <38 cm. Most cyclotron components and equipment were radioactivated by neutrons. The major radionuclides in cyclotron components and equipment were 54Mn, 60Co, and 65Zn. A 33% volume of the yoke was regarded as nonradioactivated.ConclusionsThe estimated amount of radioactivated waste in the concrete was about 70,000 kg (12.5% of the total concrete). Most components of the cyclotron except for the 33% volume of the yoke (20% of the cyclotron body), as well as most peripheral equipment in the room, were radioactivated. Part‐by‐part assessments of radioactive materials using measurements and calculations could distinguish nonradioactive from radioactive materials before they are discarded.",
           1,
           "medical_physics"
          ],
          [
           "Description and dosimetric verification of the <scp>PEREGRINE</scp> Monte Carlo dose calculation system for photon beams incident on a water phantom",
           "10.1118/1.1381551",
           2002,
           "PEREGRINE is a three‐dimensional Monte Carlo dose calculation system written specifically for radiotherapy. This paper describes the implementation and overall dosimetric accuracy of PEREGRINE physics algorithms, beam model, and beam commissioning procedure. Particle‐interaction data, tracking geometries, scoring, variance reduction, and statistical analysis are described. The BEAM code system is used to model the treatment‐independent accelerator head, resulting in the identification of primary and scattered photon sources and an electron contaminant source. The magnitude of the electron source is increased to improve agreement with measurements in the buildup region in the largest fields. Published measurements provide an estimate of backscatter on monitor chamber response. Commissioning consists of selecting the electron beam energy, determining the scale factor that defines dose per monitor unit, and describing treatment‐dependent beam modifiers. We compare calculations with measurements in a water phantom for open fields, wedges, blocks, and a multileaf collimator for 6 and 18 MV Varian Clinac 2100C photon beams. All calculations are reported as dose per monitor unit. Aside from backscatter estimates, no additional, field‐specific normalization is included in comparisons with measurements. Maximum discrepancies were less than either 2% of the maximum dose or 1.2 mm in isodose position for all field sizes and beam modifiers.",
           137,
           "medical_physics"
          ],
          [
           "Computed tomography dose measurements with radiochromic films and a flatbed scanner",
           "10.1118/1.3271584",
           2009,
           "Gafchromic® XR‐QA films were developed for patient dosimetry in diagnostic radiology. A possible application of these films is the measurement of doses in computed tomography. In this study a method to evaluate the CTDI using Gafchromic XR‐QA film and a flatbed scanner was developed and tested. Film samples were cut to dimensions of  in order to have an integration area similar to that of a pencil ionization chamber, with the possibility of changing the integration length. Prior to exposing these films to a computed tomography beam, the angular dependence of the film dose response was investigated by exposing film strips to a static x‐ray beam at different angles in the range 0°–180°. A difference of 49% was found between the response with the axis beam parallel to the film surface (90°) and with the axis beam perpendicular (0° and 180°). Integrating over a 360° exposure like the one in computed tomography, a difference of less than 2% was estimated, which is comparable with the measurement error obtainable with XR‐QA film. A calibration with a CT beam in the scout mode was performed and film strips were then exposed to single axial scans and to helical scans both in air and in phantoms. Two different types of flatbed scanners were used to read the film samples, a Microtek ScanMaker 9800XL scanner and an Epson Expression 10000 XL scanner, and the accuracy of the results were compared. For beam collimations above 10 mm differences between CTDI measured by film and CTDI measured by ionization chamber below 9% were found for the Epson scanner, with an average estimated error at  level of 5%. For the Microtek scanner and for the same film samples, differences below 11% with an average error at  level of 8% were founded. The  uncertainty of the measured CTDI was provided by the method for each measurement, and it was shown that about the 95% of the differences between the CTDI measurements with radiochromic films and with the ionization chamber were below the estimated  uncertainty, for both scanners. After an accurate calibration procedure and the consideration of the uncertainty associated with the measurement, Gafchromic® XR‐QA films can be used to evaluate the CTDI.",
           39,
           "medical_physics"
          ],
          [
           "The three parameter equivalent spectra as an index of beam quality",
           "10.1118/1.596223",
           2003,
           "A parametric spectral model based on the work of Birch and Marshall is used to characterize the x‐ray spectra of a specific x‐ray system. Using least‐squares comparison between measured and calculated attenuation data, an equivalent spectrum (EQSPEC) is iteratively found which very closely matches the measured attenuation characteristics of the x‐ray system. The resulting parametric spectrum is a function of the anode angle (θ), equivalent kilovoltage (kVeq), and the equivalent aluminum filtration (Aleq), and these three parameters can serve as very concise yet very accurate indices of beam quality. The utility of the EQSPEC for characterization and reporting of x‐ray spectra (and thus beam quality) may have numerous applications in diagnostic imaging procedures where spectral quality is an important consideration.",
           36,
           "medical_physics"
          ],
          [
           "Comparison of different computed radiography systems: Physical characterization and contrast detail analysis",
           "10.1118/1.3284539",
           2010,
           "Purpose:In this study, five different units based on three different technologies—traditional computed radiography (CR) units with granular phosphor and single‐side reading, granular phosphor and dual‐side reading, and columnar phosphor and line‐scanning reading—are compared in terms of physical characterization and contrast detail analysis.Methods:The physical characterization of the five systems was obtained with the standard beam condition RQA5. Three of the units have been developed by FUJIFILM (FCR ST‐VI, FCR ST‐BD, and FCR Velocity U), one by Kodak (Direct View CR 975), and one by Agfa (DX‐S). The quantitative comparison is based on the calculation of the modulation transfer function (MTF), noise power spectrum (NPS), and detective quantum efficiency (DQE). Noise investigation was also achieved by using a relative standard deviation analysis. Psychophysical characterization is assessed by performing a contrast detail analysis with an automatic reading of CDRAD images.Results:The most advanced units based on columnar phosphors provide MTF values in line or better than those from conventional CR systems. The greater thickness of the columnar phosphor improves the efficiency, allowing for enhanced noise properties. In fact, NPS values for standard CR systems are remarkably higher for all the investigated exposures and especially for frequencies up to 3.5 lp/mm. As a consequence, DQE values for the three units based on columnar phosphors and line‐scanning reading, or granular phosphor and dual‐side reading, are neatly better than those from conventional CR systems. Actually, DQE values of about 40% are easily achievable for all the investigated exposures.Conclusions:This study suggests that systems based on the dual‐side reading or line‐scanning reading with columnar phosphors provide a remarkable improvement when compared to conventional CR units and yield results in line with those obtained from most digital detectors for radiography.",
           23,
           "medical_physics"
          ],
          [
           "Electron beam therapy with transverse magnetic fields",
           "10.1118/1.598490",
           2002,
           "Detailed Monte Carlo electron transport simulations were carried out for the purpose of investigating the possibility of improving electron dose distribution for therapeutic applications, by using transverse magnetic fields. The case studied here is that of a 15 MeV electron beam of 6 cm diameter. The electrons pass through 4 cm of field‐free tissue and a transverse magnetic field is applied for depth greater than 4 cm. A field of 3 T was found to improve the skin sparing factor by a factor of 2, when compared to field‐free irradiation. A field of 2 T could also have a significant effect although less pronounced than 3 T while, for the case at hand, a magnetic field of only 1 T is not effective. The results here include detailed energy deposition contours in three dimensions.",
           21,
           "medical_physics"
          ],
          [
           "Vision 20/20: Mammographic breast density and its clinical applications",
           "10.1118/1.4935141",
           2015,
           "Breast density is a strong predictor of the failure of mammography screening to detect breast cancer and is a strong predictor of the risk of developing breast cancer. The many imaging options that are now available for imaging dense breasts show great promise, but there is still the question of determining which women are “dense” and what imaging modality is suitable for individual women. To date, mammographic breast density has been classified according to the Breast Imaging‐Reporting and Data System (BI‐RADS) categories from visual assessment, but this is known to be very subjective. Despite many research reports, the authors believe there has been a lack of physics‐led and evidence‐based arguments about what breast density actually is, how it should be measured, and how it should be used. In this paper, the authors attempt to start correcting this situation by reviewing the history of breast density research and the debates generated by the advocacy movement. The authors review the development of breast density estimation from pattern analysis to area‐based analysis, and the current automated volumetric breast density (VBD) analysis. This is followed by a discussion on seeking the ground truth of VBD and mapping volumetric methods to BI‐RADS density categories. The authors expect great improvement in VBD measurements that will satisfy the needs of radiologists, epidemiologists, surgeons, and physicists. The authors believe that they are now witnessing a paradigm shift toward personalized breast screening, which is going to see many more cancers being detected early, with the use of automated density measurement tools as an important component.",
           35,
           "medical_physics"
          ],
          [
           "A new radiation shielding block material for radiation therapy",
           "10.1118/1.1809767",
           2004,
           "In recent years, lead has been recognized as a source of environmental pollution; this includes lead use for radiation shielding in radiotherapy. We looked for a new material that could be a lead substitute. We chose a material composed of tungsten and resin. We compared the attenuation coefficient of the material with those of lead and Lipowitz's metal, and found the material has a higher attenuation coefficient than the other two. The material may be used as a substitute for lead because it is easy to fabricate and friendly to the environment.",
           15,
           "medical_physics"
          ],
          [
           "Electrons as the cause of the observed <i>d</i><sub>max</sub> shift with field size in high energy photon beams",
           "10.1118/1.594580",
           2003,
           "For megavoltage x‐ray beams, it is well known that the percent depth‐dose increases considerably with field size in the buildup region, resulting in a significant shift in the apparent position of maximum dose, dmax. The nature of this increase has been investigated using a sweeping magnet placed just below the treatment head of a 25‐MV linac. Measurements show that for increasing magnetic fields the dose in the buildup region is continually reduced, until a point is reached beyond which no additional reduction is observed. Here the buildup curve is essentially field size independent. These results clearly show that electrons are the primary cause of dose increase with field size in the buildup region, in contrast to a recent publication claiming that scattered photons are the cause. Further measurements were made by blocking out the primary beam at the level of the jaws and measuring the depth dose of the scattered electrons originating from the jaws. The results show that a thickness of approximately 1 g cm−2, of either polystyrene or lead, reduces the dose by a factor of two, providing further evidence that the scattered component of the beam consists of low energy electrons.",
           71,
           "medical_physics"
          ],
          [
           "Validity of transition‐zone dosimetry at high atomic number interfaces in megavoltage photon beams",
           "10.1118/1.596553",
           2003,
           "Measurement of dose or dose perturbation factors at high atomic number interfaces are usually performed with a thin‐window parallel‐plate ion chamber. In a transition region, under nonequilibrium conditions, accuracy of ion chamber readings for the dose measurements has often been questioned. This paper critically analyzes the factors (stopping power ratio and charge collection) for the dose measurements at interfaces. Monte Carlo simulations were performed to investigate the secondary electron spectrum produced by photon beams and to calculate the stopping power ratios at the point of measurement. The validity of dose measurements was studied for the photon beams in the range of Co‐60 gamma rays to 24‐MV x rays at bone and lead interfaces with polystyrene, using thermoluminescent dosimeters, extrapolation chamber and several types of commercially available parallel‐plate ion chambers. It is observed that for energies >10 MV most parallel‐plate chambers can be used to measure dose accurately. At lower energies, however significant differences between measured doses with different detectors were noticed. It is suggested that at high‐Z interfaces and lower energies, the dose measurements should be performed with ultrathin‐window parallel‐plate ion chambers or extrapolation chambers.",
           32,
           "medical_physics"
          ],
          [
           "A clinically relevant <scp>IMRT QA</scp> workflow: Design and validation",
           "10.1002/mp.12838",
           2018,
           "PurposeThe purpose of this study was to determine clinically relevant pass/question/fail criteria for gamma analysis of intensity‐modulated radiation therapy quality assurance (IMRT QA) plans, identify which plans should be further analyzed with dose–volume histogram (DVH) metrics, and create a workflow for performing that DVH‐based analysis.MethodsA total of 11 plans, 5 prostate and 6 head/neck, were selected to represent known good plans based on their high‐passing rate using conventional IMRT QA criteria. These were modified by moving the programmed MLC positions to underdose the target or overdose important structures by varying amounts. Commercially available hardware/software was used to measure and analyze all plans (76 total) using 4%/3 mm, 3%/3 mm, 3%/2 mm, and 2%/2 mm gamma criteria. Two receiver operator characteristic (ROC) curves per criterion were created to assess effective passing rates. One ROC curve was to find a higher threshold that determined a clear pass and the second to find a lower threshold to determine a clear failure. Plans between these two thresholds need DVH‐based analysis to assess the clinical consequence of the dose difference. The modified plans were analyzed in the planning system and reconstructed in commercially available DVH‐based analysis software to access the accuracy and usefulness of the software.ResultsAnalysis of the ROC curves showed optimal pass and fail thresholds for plan error detection per criterion to achieve clinically relevant sensitivity and specificity. Based on measurement uncertainty and pass/fail ranges, 3%/2 mm gamma criteria with a pass threshold of 95% and a fail threshold of 90% were most optimal. DVH analysis showed good agreement with all reconstructed plans except where the changes to the MLC patterns caused the periphery of the target to be underdosed. For questionable plans, comparing the organ‐specific DVHs to the physician‐provided planning constraints proved to be an efficient and effective workflow since plans for which the target dose was slightly high or where organs at risk were underdosed could be released for the treatment without consulting the physician for a clinical decision.ConclusionThis work indicates the potential for appreciable improvement in error detection for IMRT QA. Using effective pass/fail thresholds to determine plans that need DVH‐based analysis minimizes the need for excessive, time‐consuming, analysis, and making use of the dosimetric constraints of the plan minimizes the burden on physicians. Overall, DVH‐based analysis is a powerful tool that can provide substantial insight over the traditional approach that does not provide structure‐specific data.",
           8,
           "medical_physics"
          ],
          [
           "Technical Note: Scanner dependence of adaptive statistical iterative reconstruction with 3D noise power spectrum central frequency and noise magnitude ratios",
           "10.1002/mp.15104",
           2021,
           "PurposeIn this study, the noise reduction properties of the adaptive statistical iterative reconstruction (IR) on two different CT scanners of 64 and 256‐slice were compared and their differences were assessed.Methods and materialsThe homogeneous module of the ACR CT phantom was scanned on the 64 and 256 slices CT scanners from the same vendor in the range of 15–40 mA. On each scanner, the data were reconstructed using filtered back projection (FBP) and at all strengths of IR with the STANDARD kernel. For each reconstruction, a 3D noise power spectrum (NPS) was calculated and the central frequency ratio in the xy plane (CFRxy), CFR in the z‐direction (CFRz), and noise magnitude ratio (NMR) were derived. CFR is the central frequency ratio of NPS between the denoised image and the FBP image, and NMR is the ratio of the areas under the NPS curves. Ideally, both CFRxy and CFRz should be near 1, indicating minimal texture changes in both xy and z directions, while NMR should be as close to 0 as possible, indicating more noise reduction.ResultsWhen comparing strengths with equivalent impact on noise texture, IR on the 64‐slice reduced the noise magnitude in the xy plane more than that on the 256‐slice. In the z‐direction, the IR on the 256‐slice produced a central frequency shift on the 256‐slice but not on the 64‐slice. In addition, the noise reduction effects of the IR on the 256‐slice were affected when radiation exposure was below 2.0 mGy, but there was no observable dose‐dependence on the 64‐slice.ConclusionsOur noise property analysis revealed that iterative reconstructions on different scanner platforms from the same vendor can be distinct, with unique effects on the noise texture and magnitude in CT images. The IR on a 64‐slice scanner provides slightly enhanced noise reduction and maintains a noise reduction rate independent of dose, unlike the one on a 256‐slice scanner. Notably, the IR on the 64‐slice scanner was a 2D noise reduction technique (NRT), while the one on the 256‐slice was a 3D NRT. These observations showcase the impact of different NRTs on clinical CT images, even when comparing the same NRT on different scanners.",
           2,
           "medical_physics"
          ],
          [
           "A comparison of the respiratory signals acquired by different respiratory monitoring systems used in respiratory gated radiotherapy",
           "10.1118/1.3512798",
           2010,
           "Purpose:Respiratory monitoring systems are used to detect the respiratory phase of patients during the planning and administration of respiratory gated radiotherapy by using four‐dimensional computed tomography (4DCT) or 4D positron‐emission tomography/CT (4DPET/CT) and the linear accelerator (linac), respectively. Generally, identical respiratory monitoring systems are used for 4DCT, 4DPET/CT, and linac. However, different systems are sometimes used in combination because the accessibility of the respiratory monitoring systems may differ by manufacturer. The combined use of different respiratory monitoring systems in phase‐based gating is of concern because the differences in the timing of tags (end‐respiration signals algorithmically determined by the respiratory monitoring system), defined by the two systems, may result in phase differences. The purpose of this study is to estimate this difference and evaluate its effect on 4DCT data.Methods:Ten patients (seven men and three women) with a median age of 75 yr (range: 57–84 yr) were treated by gated stereotactic body radiation therapy between April and December 2009. Two types of respiratory monitoring systems—RPM (Varian Medical Systems) and AZ‐733V (Anzai MEDICAL)—were placed on the abdominal surface of the patients, and the respiratory signals were acquired by both systems. The relationship between the amplitude peak and the tag obtained by each respiratory system was analyzed for each patient. Further, the 4DCT images were reconstructed by using the signals obtained from both the RPM and the AZ‐733V systems, and the tumor volumes and the tumor centroid positions in the craniocaudal plane were analyzed for each patient.Results:The correlation factor between the respiratory signals from the RPM system and AZ‐733V system was 0.990 (range: 0.940–0.994). The amplitude peak of the RPM system corresponded well with that of the AZ‐733V system. The deviation of the phase difference for all the patients ranged from  to . In the case of some patients, differences were noted between the two systems in the estimation of the tumor centroid position and tumor shape.Conclusions:The estimation of the position of the tumor centroid and tumor shape may vary with the use of different respiratory monitoring systems. This implies that it is preferable to use the same respiratory monitoring system with 4DCT, 4DPET‐CT, and linac.",
           38,
           "medical_physics"
          ],
          [
           "Learning low‐dose CT degradation from unpaired data with flow‐based model",
           "10.1002/mp.15886",
           2022,
           "BackgroundThere has been growing interest in low‐dose computed tomography (LDCT) for reducing the X‐ray radiation to patients. However, LDCT always suffers from complex noise in reconstructed images. Although deep learning‐based methods have shown their strong performance in LDCT denoising, most of them require a large number of paired training data of normal‐dose CT (NDCT) images and LDCT images, which are hard to acquire in the clinic. Lack of paired training data significantly undermines the practicability of supervised deep learning‐based methods. To alleviate this problem, unsupervised or weakly supervised deep learning‐based methods are required.PurposeWe aimed to propose a method that achieves LDCT denoising without training pairs. Specifically, we first trained a neural network in a weakly supervised manner to simulate LDCT images from NDCT images. Then, simulated training pairs could be used for supervised deep denoising networks.MethodsWe proposed a weakly supervised method to learn the degradation of LDCT from unpaired LDCT and NDCT images. Concretely, LDCT and normal‐dose images were fed into one shared flow‐based model and projected to the latent space. Then, the degradation between low‐dose and normal‐dose images was modeled in the latent space. Finally, the model was trained by minimizing the negative log‐likelihood loss with no requirement of paired training data. After training, an NDCT image can be input to the trained flow‐based model to generate the corresponding LDCT image. The simulated image pairs of NDCT and LDCT can be further used to train supervised denoising neural networks for test.ResultsOur method achieved much better performance on LDCT image simulation compared with the most widely used image‐to‐image translation method, CycleGAN, according to the radial noise power spectrum. The simulated image pairs could be used for any supervised LDCT denoising neural networks. We validated the effectiveness of our generated image pairs on a classic convolutional neural network, REDCNN, and a novel transformer‐based model, TransCT. Our method achieved mean peak signal‐to‐noise ratio (PSNR) of 24.43dB, mean structural similarity (SSIM) of 0.785 on an abdomen CT dataset, mean PSNR of 33.88dB, mean SSIM of 0.797 on a chest CT dataset, which outperformed several traditional CT denoising methods, the same network trained by CycleGAN‐generated data, and a novel transfer learning method. Besides, our method was on par with the supervised networks in terms of visual effects.ConclusionWe proposed a flow‐based method to learn LDCT degradation from only unpaired training data. It achieved impressive performance on LDCT synthesis. Next, we could train neural networks with the generated paired data for LDCT denoising. The denoising results are better than traditional and weakly supervised methods, comparable to supervised deep learning methods.",
           5,
           "medical_physics"
          ],
          [
           "Development of a computerized method for identifying the posteroanterior and lateral views of chest radiographs by use of a template matching technique",
           "10.1118/1.1487426",
           2002,
           "In picture archiving and communications systems (PACS) or digital archiving systems, the information on the posteroanterior (PA) and lateral views for chest radiographs is often not recorded or is recorded incorrectly. However, it is necessary to identify the PA or lateral view correctly and automatically for quantitative analysis of chest images for computer‐aided diagnosis. Our purpose in this study was to develop a computerized method for correctly identifying either PA or lateral views of chest radiographs. Our approach is to examine the similarity of a chest image with templates that represent the average chest images of the PA or lateral view for various types of patients. By use of a template matching technique with nine template images for patients of different size in two steps, correlation values were obtained for determining whether a chest image is either a PA or a lateral view. The templates for PA and lateral views were prepared from 447 PA and 200 lateral chest images. For a validation test, this scheme was applied to 1,000 test images consisting of 500 PA and 500 lateral chest radiographs, which are different from training cases. In the first step, 924 (92.4%) of the cases were correctly identified by comparison of the correlation values obtained with the three templates for medium‐size patients. In the second step, the correlation values with the six templates for small and large patients were compared, and all of the remaining unidentifiable cases were identified correctly.",
           26,
           "medical_physics"
          ],
          [
           "Quantitative assessment of ensemble coherency in contrast‐free ultrasound microvasculature imaging",
           "10.1002/mp.14918",
           2021,
           "PurposeContrast‐free visualization of microvascular blood flow (MBF) using ultrasound can play a valuable role in diagnosis and detection of diseases. In this study, we demonstrate the importance of quantifying ensemble coherence for robust MBF imaging. We propose a novel approach to quantify ensemble coherence by estimating the local spatiotemporal correlation (LSTC) image, and evaluate its efficacy through simulation and in vivo studies.MethodsThe in vivo patient studies included three volunteers with a suspicious breast tumor, 15 volunteers with a suspicious thyroid tumor, and two healthy volunteers for renal MBF imaging. The breast data displayed negligible prior motion and were used for simulation analysis involving synthetically induced motion, to assess its impact on ensemble coherency and motion artifacts in MBF images. The in vivo thyroid data involved complex physiological motion due to its proximity to the pulsating carotid artery, which was used to assess the in vivo efficacy of the proposed technique. Further, in vivo renal MBF images demonstrated the feasibility of using the proposed ensemble coherence metric for curved array‐based MBF imaging involving phase conversion. All ultrasound data were acquired at high imaging frame rates and the tissue signal was suppressed using spatiotemporal clutter filtering. Thyroid tissue motion was estimated using two‐dimensional normalized cross correlation‐based speckle tracking, which was subsequently used for ensemble motion correction. The coherence of the MBF image was quantified based on Casorati correlation of the Doppler ensemble.ResultsThe simulation results demonstrated that an increase in ensemble motion corresponded with a decrease in ensemble coherency, which reciprocally degraded the MBF images. Further the data acquired from breast tumors demonstrated higher ensemble coherency than that from thyroid tumors. Motion correction improved the coherence of the thyroid MBF images, which substantially improved its visualization. The proposed coherence metrics were also useful in assessing the ensemble coherence for renal MBF imaging. The results also demonstrated that the proposed coherence metric can be reliably estimated from downsampled ensembles (by up to 90), thus allowing improved computational efficiency for potential applications in real‐time MBF imaging.ConclusionsThis pilot study demonstrates the importance of assessing ensemble coherency in contrast‐free MBF imaging. The proposed LSTC image quantified coherence of the Doppler ensemble for robust MBF imaging. The results obtained from this pilot study are promising, and warrant further development and in vivo validation.",
           9,
           "medical_physics"
          ],
          [
           "Estimation of absorbed radiation doses to skin and S‐values for organs at risk due to nasal administration of PET agents using Monte Carlo simulations",
           "10.1002/mp.14669",
           2020,
           "PurposeThe intranasal (IN) administration of radiopharmaceuticals is of interest in being a viable route for the delivery of radiopharmaceuticals that do not ordinarily cross the blood–brain barrier (BBB). However, to be viable in a patient population, good image quality as well as safety of the administration should be demonstrated. This work provides radiation dosimetry calculations and simulations related to the radiation safety of performing such experiments in a human cohort.MethodsWe performed Monte Carlo (MC) simulations to estimate radiation dose to the skin inside a cylindrical model of the nasal cavity assuming a homogenous distribution layer of 11C and 18F and calculated a geometry conversion factor (FP‐C) which can be used to convert from a planar geometry to a cylindrical geometry using more widely available software tools. We compared radiation doses from our simulated cylindrical geometry with the planar dose estimates employing our geometry conversion factor from VARSKIN 6.1 software and also from an analytical equation. Furthermore, in order to estimate radiation dosimetry to surrounding organs of interest, we performed a voxelized MC simulation of a fixed radioactivity inside the nasal cavity and calculated S‐values to organs such as the eyes, thyroid, and brain.ResultsMC simulations of contamination scenarios using planar absorbed doses of 15.50 and 8.60 mGy/MBq for 18F and 11C, respectively, and 35.70 and 19.80 mGy/MBq per hour for cylindrical geometries, leading to determination of an FP‐C of 2.3. Planar absorbed doses (also in units of mGy/MBq) determined by the analytical equation were 16.96 and 8.68 (18F and 11C) and using VARSKIN were 16.60 and 9.26 (18F and 11C), respectively. Application of FP‐C to these results demonstrates values with a maximum difference of 9.41% from the cylindrical geometry MC calculation, demonstrating that when accounting for geometry, more simplistic techniques can be utilized to estimate IN dosimetry. Voxelized MC simulations of radiation dosimetry from a fixed source of 1 MBq of activity confined to the nasal cavity resulted in S‐values to the thyroid, eyes, and brain of 1.72 x 10−6, 1.93 x 10−5, and 3.51 x 10−6 mGy/MBq·s, respectively, for 18F and 1.80 × 10−6, 1.95 × 10−5, and 3.54 × 10−6 mGy/MBq·s for 11C.ConclusionDosimetry concerns about IN administrations of PET radiotracers should be considered before clinical use. Values presented in the simulations such as the S‐values can be further used for assessment of absorbed doses in cases of IN administration, and can be used to develop and adapt specific study protocols. All three presented methods provided similar results when considering the use of a geometry conversion factor for planar to cylindrical geometry, demonstrating that standard tools rather than dedicate MC simulations may be used to perform dose calculations in nasal administrations.",
           2,
           "medical_physics"
          ],
          [
           "Monte Carlo calculations for reference dosimetry of electron beams with the PTW Roos and NE2571 ion chambers",
           "10.1118/1.4829577",
           2013,
           "Purpose:To investigate recommendations for reference dosimetry of electron beams and gradient effects for the NE2571 chamber and to provide beam quality conversion factors using Monte Carlo simulations of the PTW Roos and NE2571 ion chambers.Methods:The EGSnrc code system is used to calculate the absorbed dose‐to‐water and the dose to the gas in fully modeled ion chambers as a function of depth in water. Electron beams are modeled using realistic accelerator simulations as well as beams modeled as collimated point sources from realistic electron beam spectra or monoenergetic electrons. Beam quality conversion factors are calculated with ratios of the doses to water and to the air in the ion chamber in electron beams and a cobalt‐60 reference field. The overall ion chamber correction factor is studied using calculations of water‐to‐air stopping power ratios.Results:The use of an effective point of measurement shift of 1.55 mm from the front face of the PTW Roos chamber, which places the point of measurement inside the chamber cavity, minimizes the difference betweenR50, the beam quality specifier, calculated from chamber simulations compared to that obtained using depth‐dose calculations in water. A similar shift minimizes the variation of the overall ion chamber correction factor with depth to the practical range and reduces the root‐mean‐square deviation of a fit to calculated beam quality conversion factors at the reference depth as a function of R50. Similarly, an upstream shift of 0.34 rcav allows a more accurate determination of R50 from NE2571 chamber calculations and reduces the variation of the overall ion chamber correction factor with depth. The determination of the gradient correction using a shift of 0.22 rcav optimizes the root‐mean‐square deviation of a fit to calculated beam quality conversion factors if all beams investigated are considered. However, if only clinical beams are considered, a good fit to results for beam quality conversion factors is obtained without explicitly correcting for gradient effects. The inadequacy of R50 to uniquely specify beam quality for the accurate selection of kQ factors is discussed. Systematic uncertainties in beam quality conversion factors are analyzed for the NE2571 chamber and amount to between 0.4% and 1.2% depending on assumptions used.Conclusions:The calculated beam quality conversion factors for the PTW Roos chamber obtained here are in good agreement with literature data. These results characterize the use of an NE2571 ion chamber for reference dosimetry of electron beams even in low‐energy beams.",
           22,
           "medical_physics"
          ],
          [
           "The advantages of absorbed‐dose calibration factors",
           "10.1118/1.596921",
           2003,
           "A formalism for clinical external beam dosimetry based on use of ion chamber absorbed‐dose calibration factors is outlined in the context and notation of the AAPM TG‐21 protocol. It is shown that basing clinical dosimetry on absorbed‐dose calibration factors ND leads to considerable simplification and reduced uncertainty in dose measurement. In keeping with a protocol which is used in Germany, a quantity kQ is defined which relates an absorbed‐dose calibration factor in a beam of quality Q0 to that in a beam of quality Q. For 38 cylindrical ion chambers, two sets of values are presented for ND/NX and Ngas/ND and for kQ for photon beams with beam quality specified by the  ratio. One set is based on TG‐21's protocol to allow the new formalism to be used while maintaining equivalence to the TG‐21 protocol. To demonstrate the magnitude of the overall error in the TG‐21 protocol, the other set uses corrected versions of the TG‐21 equations and the more consistent physical data of the IAEA Code of Practice. Comparisons are made to procedures based on air‐kerma or exposure calibration factors and it is shown that accuracy and simplicity are gained by avoiding the determination of Ngas from NX. It is also shown that the kQ approach simplifies the use of plastic phantoms in photon beams since kQ values change by less than 0.6% compared to those in water although an overall correction factor of 0.973 is needed to go from absorbed dose in water calibration factors to those in PMMA or polystyrene. Values of kQ calculated using the IAEA Code of Practice are presented but are shown to be anomalous because of the way the effective point of measurement changes for 60Co beams. In photon beams the major difference between the IAEA Code of Practice and the corrected AAPM TG‐21 protocol is shown to be the Prepl correction factor. Calculated kQ curves and three parameter equations for them are presented for each wall material and are shown to represent accurately the kQ curve for all ion chambers in this study with a wall of that specified material and a thickness less than 0.25 g/cm2. Values of kQ can be measured using the primary standards for absorbed dose in photon beams.",
           37,
           "medical_physics"
          ],
          [
           "Characterization of the phantom material Virtual Water™ in high‐energy photon and electron beams",
           "10.1118/1.2174186",
           2006,
           "The material Virtual Water™ has been characterized in photon and electron beams. Range‐scaling factors and fluence correction factors were obtained, the latter with an uncertainty of around 0.2%. This level of uncertainty means that it may be possible to perform dosimetry in a solid phantom with an accuracy approaching that of measurements in water. Two formulations of Virtual Water™ were investigated with nominally the same elemental composition but differing densities. For photon beams neither formulation showed exact water equivalence—the water/Virtual Water™ dose ratio varied with the depth of measurement with a difference of over 1% at  depth. However, by using a density (range) scaling factor very good agreement  between water and Virtual Water™ at all depths was obtained. In the case of electron beams a range‐scaling factor was also required to match the shapes of the depth dose curves in water and Virtual Water™. However, there remained a difference in the measured fluence in the two phantoms after this scaling factor had been applied. For measurements around the peak of the depth‐dose curve and the reference depth this difference showed some small energy dependence but was in the range 0.1%–0.4%. Perturbation measurements have indicated that small slabs of material upstream of a detector have a small ( effect) on the chamber reading but material behind the detector can have a larger effect. This has consequences for the design of experiments and in the comparison of measurements and Monte Carlo‐derived values.",
           32,
           "medical_physics"
          ],
          [
           "SU‐FF‐T‐181: An Investigation of Surface Dose Changes for Therapeutic Kilovoltage X‐Ray Beams with Underlying Lead Shielding",
           "10.1118/1.1997862",
           2005,
           "Purpose: The effect on surface dose from underlying lead shielding in water was investigated for therapeutic kilovoltage x‐ray beams by experimental and Monte Carlo methods. Method and Materials: A Farmer type ionisation chamber was used to measure the surface dose in a water phantom for x‐ray beams with energies from 75 to 135 kVp. A 5 mm thick lead sheet was positioned at various depths below the surface. The surface dose ratio was calculated by comparison with the surface dose with no lead sheet present. A Monte Carlo model of the x‐ray beam and the phantom was generated using the EGSnrcMP code (V4.2). The initial energy spectrum was determined using an empirical method and verified by calculation of depth dose data. The dose was scored in a 1 mm thick slab at the phantom surface. The change in surface dose was calculated as a function of depth to the lead and compared to measured data. Results: The reduction in surface dose was a function of x‐ray beam energy, beam area and the depth of water to the lead. As the depth of water to the lead sheet decreased, there was a reduction in the surface dose. With the 8 cm diameter applicator and 1 cm depth of water to the lead, the surface dose ratio was 0.918 for the 75 kVp x‐ray beam and 0.890 for the 100 kVp x‐ray beam. For the smaller applicators, there was less reduction in the surface dose ratios. Surface dose ratios calculated by the EGSnrcMP code were in good agreement with measured data, with a maximum deviation of 1.2%. Conclusion: The surface dose for kilovoltage x‐ray beams is reduced when lead is underlying in the phantom. The Monte Carlo results indicate the model is sufficiently accurate to predict changes in the surface dose.",
           1,
           "medical_physics"
          ],
          [
           "Backprojection‐filtration reconstruction without invoking a spatially varying weighting factor",
           "10.1118/1.3285041",
           2010,
           "Purpose:To develop a backprojection‐filtration (BPF) algorithm with improved noise properties over the existing BPF algorithm through utilizing (approximate) redundant information in circular cone‐beam or fan‐beam scans.Methods:The backprojection steps in the existing filtered‐backprojection (FBP) and BPF algorithms for fan‐beam and cone‐beam projections invoke spatially varying weighting factors, which may not only increase the computational load in image reconstruction but also, more importantly, result in reconstruction artifacts. Redundant information in fan‐beam projections has been exploited for eliminating the weighting factor in the existing FBP algorithm. However, the new FBP algorithm cannot be applied to image reconstruction in a region of interest from transversely truncated data. In this work, the authors identify approximate data redundancy in circular cone‐beam projections and propose a new BPF algorithm in which the approximate data redundancy is exploited for eliminating the spatially varying weighting factor in the existing BPF algorithm.Results:The authors have implemented and evaluated the proposed BPF algorithm in numerical studies of reconstructing 3D images from both the nontruncated and truncated projection data in a circular cone‐beam scan. The results of numerical studies demonstrate that the proposed BPF algorithm retains the resolution property of the existing BPF algorithm, and that it can also reconstruct accurately ROI images from truncated data. More importantly, the results also indicate that the proposed BPF algorithm not only is computationally more efficient but also yields generally lower image variances than the existing BPF algorithm.Conclusions:A BPF algorithm was proposed that not only retains the desirable properties of the existing BPF algorithm but also possesses improved computational and noise properties over the latter.",
           6,
           "medical_physics"
          ],
          [
           "High performance lung nodule detection schemes in CT using local and global information",
           "10.1118/1.4737109",
           2012,
           "Purpose:A key issue in current computer‐aided diagnostic (CAD) schemes for nodule detection in CT is the large number of false positives, because current schemes use only global three‐dimensional (3D) information to detect nodules and discard useful local two‐dimensional (2D) information. Thus, the authors integrated local and global information to markedly improve the performance levels of CAD schemes.Methods:Our database was obtained from the standard CT lung nodule database created by the Lung Image Database Consortium (LIDC). It consisted of 85 CT scans with 111 nodules of 3 mm or larger in diameter. The 111 nodules were confirmed by at least two of the four radiologists participated in the LIDC. Twenty‐six nodules were missed by two of the four radiologists and were thus very difficult to detect. The authors developed five CAD schemes for nodule detection in CT using global 3D information (3D scheme), local 2D information (2D scheme), and both local and global information (2D + 3D scheme, 2D − 3D scheme, and 3D − 2D scheme). The 3D scheme, which was developed previously, used only global 3D information and discarded local 2D information, as other CAD schemes did. The 2D scheme used a uniform viewpoint reformation technique to decompose a 3D nodule candidate into a set of 2D reformatted images generated from representative viewpoints, and selected and used “effective” 2D reformatted images to remove false positives. The 2D + 3D scheme, 2D − 3D scheme, and 3D − 2D scheme used complementary local and global information in different ways to further improve the performance of lung nodule detection. The authors employed a leave‐one‐scan‐out testing method for evaluation of the performance levels of the five CAD schemes.Results:At the sensitivities of 85%, 80%, and 75%, the existing 3D scheme reported 17.3, 7.4, and 2.8 false positives per scan, respectively; the 2D scheme improved the detection performance and reduced the numbers of false positives to 7.6, 2.5, and 1.3 per scan; the 2D + 3D scheme further reduced those to 2.7, 1.9, and 0.6 per scan; the 2D − 3D scheme reduced those to 7.6, 2.1, and 0.8 per scan; and the 3D − 2D scheme reduced those to 17.3, 1.6, and 1.0 per scan.Conclusions:The local 2D information appears to be more useful than the global 3D information for nodule detection, particularly, when it is integrated with 3D information.",
           20,
           "medical_physics"
          ],
          [
           "Exposure values around an x‐ray scanning transaxial tomograph (EMI scanner)",
           "10.1118/1.594194",
           2003,
           "Measurements of exposure accumulated in a one‐month period in and around a scanning x‐ray transaxial tomograph are reported. For the unit studied (the EMI neurological scanner) values measured indicate that the shielding required is “minimal.”",
           5,
           "medical_physics"
          ],
          [
           "Automatic coronary artery plaque thickness comparison between baseline and follow‐up CCTA images",
           "10.1002/mp.13993",
           2019,
           "PurposeCurrently, coronary plaque changes are manually compared between a baseline and follow‐up coronary computed tomography angiography (CCTA) images for long‐term coronary plaque development investigation. We propose an automatic method to measure the plaque thickness change over time.MethodsWe model the lumen and vessel wall for both the baseline coronary artery tree (CAT‐BL) and follow‐up coronary artery tree (CAT‐FU) as smooth three‐dimensional (3D) surfaces using a subdivision fitting scheme with the same coarse meshes by which the correspondence among these surface points is generated. Specifically, a rigid point set registration is used to transform the coarse mesh from the CAT‐FU to CAT‐BL. The plaque thickness and the thickness difference is calculated as the distance between corresponding surface points. To evaluate the registration accuracy, the average distance between manually defined markers on clinical scans is calculated. Artificial CAT‐BL and CAT‐FU pairs were created to simulate the plaque decrease and increase over time.ResultsFor 116 pairs of markers from nine clinical scans, the average marker distance after registration was 0.95 ± 0.98 mm (two times the voxel size). On the 10 artificial pairs of datasets, the proposed method successfully located the plaque changes. The average of the calculated plaque thickness difference is the same as the corresponding created value (standard deviation ± 0.1 mm).ConclusionsThe proposed method automatically calculates local coronary plaque thickness differences over time and can be used for 3D visualization of plaque differences. The analysis and reporting of coronary plaque progression and regression will benefit from an automatic plaque thickness comparison.",
           4,
           "medical_physics"
          ],
          [
           "Experimental determination of the convolution kernel for the study of the spatial response of a detector",
           "10.1118/1.598182",
           2002,
           "One of the most important parameters in the characterization of a detector is its spatial convolution kernel. This kernel contains all of the information about the influence that the detector size has on the measured beam profile. In this paper we present an experimental method for the determination of the spatial convolution kernel for commonly used detectors that are employed in the x‐ray profile measurement:  diode, and ionization minichamber. Our work is based on first assuming a step function pattern on a photographic film is known and is a perfect step function. The kernel of the densitometer system was then derived from the deconvolution of the scanned profile to the step function. Next a film was exposed to a penumbra area of an x‐ray beam from a linac. The film was scanned using the same densitometer. The “real profile” that emerges from a linear accelerator was derived by the deconvolution of the scanned profile using the now known kernel of the film densitometer. Under the same irradiation condition the x‐ray profile was measured with other detectors and with this information we obtained the convolution kernels for these detectors by solving numerically their basic convolution integrals. The results show that the Gaussian convolution kernel is the most consistent with the measurements. The best numerical values for the FWHM of the kernels are 1.1 mm, 2.2 mm, and 5.4 mm for densitometer, diode, and minichamber, respectively.",
           72,
           "medical_physics"
          ],
          [
           "Nonstationary noise characteristics of the helical scan and its impact on image quality and artifacts",
           "10.1118/1.598026",
           2002,
           "Helical computed tomography has replaced the conventional step‐and‐shoot CT in many clinical applications. Because of its clinical importance, a number of comparative studies have been performed to evaluate its performance parameters, such as the noise and the slice sensitivity profile. In this paper, the nonstationary noise characteristics of helical images are carefully examined. Their impact on the low contrast detectability and three‐dimensional (3‐D) image artifacts is assessed. An analytical equation is derived to relate the interactions between various helical reconstruction schemes and the fan‐beam filtered backprojection algorithm. We demonstrate that for many popular helical weights, the noise variation within the field of view of the reconstruction is close to a factor of 3. Several approaches to overcome the undesired characteristics are proposed.",
           45,
           "medical_physics"
          ],
          [
           "Confidence limit variation for a single IMRT system following the TG119 protocol",
           "10.1118/1.3555298",
           2011,
           "Purpose:To evaluate the robustness of TG119‐based quality assurance metrics for an IMRT system.Methods:Four planners constructed treatment plans for the five IMRT test cases described in TG119. All plans were delivered to a solid water phantom in one treatment session in order to minimize session‐dependent variation from phantom setup, film quality, machine performance, etc. Composite measurements utilized film and an ionization chamber. Per‐field measurements were collected using a diode array device at an effective depth of 5 cm. All data collected were analyzed using the TG119 specifications to determine the confidence limit values for each planner separately and then compared.Results:The mean variance of ion chamber measurements for each planner was within 1.7% of the planned dose. The resulting confidence limits were 3.13%, 1.98%, 3.65%, and 4.39%. Confidence limit values determined by composite film analysis were 8.06%, 13.4%, 9.30%, and 16.5%. Confidence limits from per‐field measurements were 1.55%, 0.00%, 0.00%, and 2.89%.Conclusions:For a single IMRT system, the accuracy assessment provided by TG119‐based quality assurance metrics showed significant variations in the confidence limits between planners across all composite and per‐field evaluations. This observed variation is likely due to the different levels of modulation between each planner's set of plans. Performing the TG119 evaluation using plans produced by a single planner may not provide an adequate estimation of IMRT system accuracy.",
           11,
           "medical_physics"
          ],
          [
           "Effects of x‐ray tube current and voltage on effective focalspot size",
           "10.1118/1.1637286",
           2003,
           "In general, the dimensions of the effective focal spot of an x‐ray tube vary with tube current and voltage. This dependence on tube operating conditions has been noted in the literature but has not been investigated in detail. Star phantom measurements of seven focal spots for four x‐ray tubes operated at a variety of tube voltages and currents show that effective focal‐spot size varies as . This dependence may be suppressed for the focal‐spot dimension perpendicular to the tube axis, however, because of auxiliary electrostatic focusing. Experimental data are presented with a theoretical explanation of the relationship between effective focal‐spot size and tube operating conditions.",
           20,
           "medical_physics"
          ],
          [
           "Evaluation of uncertainty predictions and dose output for model‐based dose calculations for megavoltage photon beams",
           "10.1118/1.2207316",
           2006,
           "In many radiotherapy clinics an independent verification of the number of monitor units (MU) used to deliver the prescribed dose to the target volume is performed prior to the treatment start. Traditionally this has been done by using methods mainly based on empirical factors which, at least to some extent, try to separate the influence from input parameters such as field size, depth, distance, etc. The growing complexity of modern treatment techniques does however make this approach increasingly difficult, both in terms of practical application and in terms of the reliability of the results. In the present work the performance of a model‐based approach, describing the influence from different input parameters through actual modeling of the physical effects, has been investigated in detail. The investigated model is based on two components related to megavoltage photon beams; one describing the exiting energy fluence per delivered MU, and a second component describing the dose deposition through a pencil kernel algorithm solely based on a measured beam quality index. Together with the output calculations, the basis of a method aiming to predict the inherent calculation uncertainties in individual treatment setups has been developed. This has all emerged from the intention of creating a clinical dose/MU verification tool that requires an absolute minimum of commissioned input data. This evaluation was focused on irregular field shapes and performed through comparison with output factors measured at 5, 10, and  depth in ten multileaf collimated fields on four different linear accelerators with varying multileaf collimator designs. The measurements were performed both in air and in water and the results of the two components of the model were evaluated separately and combined. When compared with the corresponding measurements the resulting deviations in the calculated output factors were in most cases smaller than 1% and in all cases smaller than 1.7%. The distribution describing the calculation errors in the total dose output has a mean value of  and a standard deviation of 0.47%. In the dose calculations a previously developed correction of the pencil kernel was applied that managed to contract the error distribution considerably. A detailed analysis of the predicted uncertainties versus the observed deviations suggests that the predictions indeed can be used as a basis for creating action levels and tracking dose calculation errors in homogeneous media.",
           15,
           "medical_physics"
          ],
          [
           "The Phantoms of Medical and Health Physics",
           "10.1118/1.4960370",
           2016,
           "The Phantoms of Medical and Health Physics. Devices for Research and Development. Editors. L. DeWerd and M. Kissick., Springer‐Verlag, Heidelberg, New York, 2014. 286 pp. Price: $129.00. ISBN: 978‐1‐4614‐8303‐8. Price: $99.00. ISBN: 978‐1‐4614‐8304‐5 (hardcover)",
           5,
           "medical_physics"
          ],
          [
           "Verification of Gamma Knife extend system based fractionated treatment planning using EBT2 film",
           "10.1118/1.4832138",
           2013,
           "Purpose:This paper presents EBT2 film verification of fractionated treatment planning with the Gamma Knife (GK) extend system, a relocatable frame system for multiple‐fraction or serial multiple‐session radiosurgery.Methods:A human head shaped phantom simulated the verification process for fractionated Gamma Knife treatment. Phantom preparation for Extend Frame based treatment planning involved creating a dental impression, fitting the phantom to the frame system, and acquiring a stereotactic computed tomography (CT) scan. A CT scan (Siemens, Emotion 6) of the phantom was obtained with following parameters: Tube voltage—110 kV, tube current—280 mA, pixel size—0.5 × 0.5 and 1 mm slice thickness. A treatment plan with two 8 mm collimator shots and three sectors blocking in each shot was made. Dose prescription of 4 Gy at 100% was delivered for the first fraction out of the two fractions planned. Gafchromic EBT2 film (ISP Wayne, NJ) was used as 2D verification dosimeter in this process. Films were cut and placed inside the film insert of the phantom for treatment dose delivery. Meanwhile a set of films from the same batch were exposed from 0 to 12 Gy doses for calibration purposes. An EPSON (Expression 10000 XL) scanner was used for scanning the exposed films in transparency mode. Scanned films were analyzed with inhouse written MATLAB codes.Results:Gamma index analysis of film measurement in comparison with TPS calculated dose resulted in high pass rates >90% for tolerance criteria of 1%/1 mm. The isodose overlay and linear dose profiles of film measured and computed dose distribution on sagittal and coronal plane were in close agreement.Conclusions:Through this study, the authors propose treatment verification QA method for Extend frame based fractionated Gamma Knife radiosurgery using EBT2 film.",
           6,
           "medical_physics"
          ],
          [
           "The feasibility study of XACT imaging for characterizing osteoporosis",
           "10.1002/mp.15906",
           2022,
           "BackgroundOsteoporosis is a progressive bone disease that is characterized by a decrease in bone mass and the deterioration in bone microarchitecture, which might be related to age and space travel. An unmet need exists for the development of novel imaging technologies to characterize osteoporosis.PurposeThe purpose of our study is to investigate the feasibility of X‐ray‐induced acoustic computed tomography (XACT) imaging for osteoporosis detection.MethodsAn in‐house simulation workflow was developed to assess the ability of XACT for osteoporosis detection. To evaluate this simulation workflow, a three‐dimensional digital bone phantom for XACT imaging was created by a series of two‐dimensional micro‐computed tomography (micro‐CT) slices of normal and osteoporotic bones in mice. In XACT imaging, the initial acoustic pressure rise caused by the X‐ray induce acoustic (XA) effect is proportional to bone density. First, region growing was deployed for image segmentation of different materials inside the bone. Then k‐wave simulations were deployed to model XA wave propagation, attenuation, and detection. Finally, the time‐varying pressure signals detected at each transducer location were used to reconstruct the XACT image with a time‐reversal reconstruction algorithm.ResultsThrough the simulated XACT images, cortical porosity has been calculated, and XA signal spectra slopes have been analyzed for the detection of osteoporosis. The results have demonstrated that osteoporotic bones have lower bone mineral density and higher spectra slopes. These findings from XACT images were in good agreement with porosity calculation from micro‐CT images.ConclusionThis work explores the feasibility of using XACT imaging as a new imaging tool for Osteoporosis detection. Considering that acoustic signals are generated by X‐ray absorption, XACT imaging can be combined with traditional X‐ray imaging that holds potential for clinical management of osteoporosis and other bone diseases.",
           2,
           "medical_physics"
          ],
          [
           "The use of computed radiography plates to determine light and radiation field coincidence",
           "10.1118/1.4823775",
           2013,
           "Purpose:Photo‐stimulable phosphor computed radiography (CR) has characteristics that allow the output to be manipulated by both radiation and optical light. The authors have developed a method that uses these characteristics to carry out radiation field and light field coincidence quality assurance on linear accelerators.Methods:CR detectors from Kodak were used outside their cassettes to measure both radiation and light field edges from a Varian linear accelerator. The CR detector was first exposed to a radiation field and then to a slightly smaller light field. The light impinged on the detectorˈs latent image, removing to an extent the portion exposed to the light field. The detector was then digitally scanned. AMATLAB‐based algorithm was developed to automatically analyze the images and determine the edges of the light and radiation fields, the vector between the field centers, and the crosshair center. Radiographic film was also used as a control to confirm the radiation field size.Results:Analysis showed a high degree of repeatability with the proposed method. Results between the proposed method and radiographic film showed excellent agreement of the radiation field. The effect of varying monitor units and light exposure time was tested and found to be very small. Radiation and light field sizes were determined with an uncertainty of less than 1 mm, and light and crosshair centers were determined within 0.1 mm.Conclusions:A new method was developed to digitally determine the radiation and light field size using CR photo‐stimulable phosphor plates. The method is quick and reproducible, allowing for the streamlined and robust assessment of light and radiation field coincidence, with no observer interpretation needed.",
           2,
           "medical_physics"
          ],
          [
           "Development of a neonate X‐ray phantom for 2D imaging applications using single‐tone inkjet printing",
           "10.1002/mp.15086",
           2021,
           "PurposeInkjet printers can be used to fabricate anthropomorphic phantoms by the use of iodine‐doped ink. However, challenges persist in implementing this technique. The calibration from grayscale to ink density is complex and time‐consuming. The purpose of this work is to develop a printing methodology that requires a simpler calibration and is less dependent on printer characteristics to produce the desired range of x‐ray attenuation values.MethodsConventional grayscale printing was substituted by single‐tone printing; that is, the superposition of pure black layers of iodinated ink. Printing was performed with a consumer‐grade inkjet printer using ink made of potassium‐iodide (KI) dissolved in water at 1 g/ml. A calibration for the attenuation of ink was measured using a commercial x‐ray system at 70 kVp. A neonate radiograph obtained at 70 kVp served as an anatomical model. The attenuation map of the neonate radiograph was processed into a series of single‐tone images. Single‐tone images were printed, stacked, and imaged at 70 kVp. The phantom was evaluated by comparing attenuation values between the printed phantom and the original radiograph; attenuation maps were compared using the structural similarity index measure (SSIM), while attenuation histograms were compared using the Kullback–Leibler (KL) divergence. A region of interest (ROI)‐based analysis was also performed, where the attenuation distribution within given ROIs was compared between phantom and patient. The phantom sharpness was evaluated in terms of modulation transfer function (MTF) estimates and signal spread profiles of high spatial resolution features in the image.ResultsThe printed phantom required 36 pages. The printing queue was automated and it took about 2 h to print the phantom. The radiograph of the printed phantom demonstrated a close resemblance to the original neonate radiograph. The SSIM of the phantom with respect to that of the patient was 0.53. Both patient and phantom attenuation histograms followed similar distributions, and the KL divergence between such histograms was 0.20. The ROI‐based analysis showed that the largest deviations from patient attenuation values were observed at the higher and lower ends of the attenuation range. The limiting resolution of the proposed methodology was about 1 mm.ConclusionA methodology to generate a neonate phantom for 2D imaging applications, using single‐tone printing, was developed. This method only requires a single‐value calibration and required less than 2 h to print a complete phantom.",
           3,
           "medical_physics"
          ],
          [
           "SU‐E‐J‐120: A Phantom‐Based Comparison of Lung Tumor Planning Target Volumes and Organs a Risk Dose Reduction Between 4D‐CT and 3D‐CT",
           "10.1118/1.4814332",
           2013,
           "Purpose: Lung tumor motion due to respiration necessitates using large margins when creating a planning target volume (PTV). As tumor movement of up to 5 cm has been reported by several investigators, accurate investigation of the internal margin (IM) to 3D CTV is necessary. The purpose of this study was to compare the differences in volume between PTVs generated using 4D‐CT (4D PTV) and 3D‐CT (3D PTV) for varying degrees of tumor motion and to evaluate the differences in dose to normal lung and spinal cord. Methods: A movable phantom was used to simulate lung movement (Figure 1). Three blocks of rubber were attached to the phantom and a 3D‐CT and a 4D‐CT were taken. Then, PTVs were delineated and compared. After that, the PTVs were transferred to a Rando phantom for dose analysis. Also, investigation of varying displacements of lung tumor was done using four blocks of rubber attached to a movable phantom with different known displacements (Figure 2). Results: The average reduction in PTV volumes using 4D‐CT was 33.8%. This led to average decreases of 19.2%, 20.1% and 33.8% for lung V20, mean lung dose and maximum spinal cord dose, respectively (Table 1)., Investigation of varying displacements of lung tumor shows that if tumors move more than 4 cm, the 4D PTV may be equal to or larger than the 3D PTV(Table 2).Figures 3 shows overlapping of PTVs of tumors with 2 cm motion and 4 cm motion in 3D and 4D. Conclusion: It can be concluded that 4D‐CT reduces organ at risk doses. For lung tumors with large displacements, 4D‐CT is a promising method because the exact IM in the direction of tumor motion is achieved. In these cases, the use of 3D causes not only unnecessary dose to normal tissue but also missing part of the tumor (Figure 3).",
           0,
           "medical_physics"
          ],
          [
           "SU‐E‐J‐109: Registration/Segmentation for Adaptive Radiotherapy Using the Jensen Renyi Divergence",
           "10.1118/1.4814321",
           2013,
           "Purpose: For the purposes of adaptive radiotherapy, the consolidation of offline and online imaging modalities requires costly registration, resegmentation and re‐optimization. The Jensen Renyi (JR) divergence is a non‐parametric generalized statistical measure that can be applied as an energy function for all three of these objectives. Further efficiency and accuracy can be attained by coupling the objective functions such that they iteratively reinforce one another. Methods: The JR divergence was used as an energy function and with a finite difference scheme, the level set differential equation was solved for an active contour along with the energy gradient of control points placed using an adaptive mesh. The segmentation portion has been validated using three data sets; PET and CBCT images of an in‐house phantom for various image qualities, 7 PET scans of head and neck cases from the Louvain database and 22 PET/CT scans of patients with non‐small cell lung carcinoma from the MAASTRO database. Results: Segmentation of an in‐house phantom using the JR divergence showed a marked improvement in concordance index (CI) by almost a factor of 2 compared to the mutual information metric below SNR values of 35.3 and 24.0 for the CBCT and PET images. Average CI for the 7 Louvain cases was found to be 0.56. An average error in estimating the maximal tumor diameters of the 22 MAASTRO cases was found to be 63%, 19.5% and 14% using CT, PET and combined PET/ CT modalities. Conclusion: The JR divergence metric was applied to the task of segmentation using a level sets active contour. It was found to provide improved noise tolerance and competitive segmentation accuracy compared to 9 other PET segmentation methods. A coupled segmentation/registration scheme has been implemented using the JR divergence. Validation is currently being performed using plasticized pig lungs. Funding was provided by the Natural Sciences and Engineering Research Council of Canada. (NSERC‐RGPIN 397711‐11) and the Research Institute of the McGill University Health Centre. HZ is supported by the Swiss National Science Foundation under grant SNSF 31003A‐135576, Geneva Cancer League and the Indo‐Swiss Joint Research Programme ISJRP 138866.",
           0,
           "medical_physics"
          ],
          [
           "TU‐FF‐A4‐01: Virtual Simulator Design for Collision Prevention During External Radiotherapy Planning",
           "10.1118/1.2962656",
           2008,
           "Purpose: Collision avoidance of the treatment accelerator components such as gantry, table, collimators, jaws, and fixation devices with the patient is one of the biggest concerns in external treatment planning. Most commercial treatment planning systems do not include collision prevention simulation step. On the other hand, a fool‐proof collision‐map, lookup table, and simpler analytical method guard only against the most apparent collisions. Thus, a comprehensive virtual simulator design for collision avoidance is very useful for external radiotherapy planning. Method and Materials: An accurate modeling of the treatment accelerator is possible with geometric data. Three‐dimensional patient modeling is also possible from the patient's CT data. Since each component in the data bank is described as an independent mesh modeling based on the type of associated polygons, relative position changes can be described easily for the device dynamics simulation. The relative motions of the gantry and the treatment table are collected from the treatment plan and the graphical user interface generates the events at the given time intervals. This visual system is incorporated with the treatment planning simulation system. Results: The quality verification of our virtual simulator for the potential collision has been performed with two combinations of treatment table and gantry rotations where a collision is eminent based on the visual assessment. The planner can search for beam paths with minimal critical structure interference before extensive optimization process. A database of CT and MR scans for all tumor sites is being built, which provide useful information to map all potential collision possibilities for all treatment isocenters. Conclusion: The important benefits of this virtual simulator is the replacement of the conventional laborious procedures required for the expensive hardware simulator unit, the efficiency increment, the accuracy improvement of radiation treatment procedure, and the cost reduction in terms of time and physical patient's presence.",
           0,
           "medical_physics"
          ],
          [
           "Texture classification‐based segmentation of lung affected by interstitial pneumonia in high‐resolution CT",
           "10.1118/1.3003066",
           2008,
           "Accurate and automated lung field (LF) segmentation in high‐resolution computed tomography (HRCT) is highly challenged by the presence of pathologies affecting lung borders, also affecting the performance of computer‐aided diagnosis (CAD) schemes. In this work, a two‐dimensional LF segmentation algorithm adapted to interstitial pneumonia (IP) patterns is presented. The algorithm employs ‐means clustering followed by a filling operation to obtain an initial LF order estimate. The final LF border is obtained by an iterative support vector machine neighborhood labeling of border pixels based on gray level and wavelet coefficient statistics features. A second feature set based on gray level averaging and gradient features was also investigated to evaluate its effect on segmentation performance of the proposed method. The proposed method is evaluated on a dataset of 22 HRCT cases spanning a range of IP patterns such as ground glass, reticular, and honeycombing. The accuracy of the method is assessed using area overlap and shape differentiation metrics (, , and ), by comparing automatically derived lung borders to manually traced ones, and further compared to a gray level thresholding‐based (GLT‐based) method. Accuracy of the methods evaluated is also compared to interobserver variability. The proposed method incorporating gray level and wavelet coefficient statistics demonstrated the highest segmentation accuracy, averaged over left and right LFs (, , , and ), which is statistically significant (two‐tailed student's  test for paired data, ) with respect to all metrics considered as compared to the proposed method incorporating gray level averaging and gradient features (, , , and ) and the GLT‐based method (, , , and ). The performance of the three segmentation methods, although decreased as IP pattern severity level (mild, moderate, and severe) was increased, did not demonstrate statistically significant difference (two‐tailed student's  test for unpaired data,  for all metrics considered). Finally, the accuracy of the proposed method, based on gray level and wavelet coefficient statistics ranges within interobserver variability. The proposed segmentation method could be used as an initial stage of a CAD scheme for IP patterns.",
           52,
           "medical_physics"
          ],
          [
           "SU‐E‐J‐163: The Imaging Dose to Patients <b>Result</b>ing From the ExacTrac X‐Ray System",
           "10.1118/1.4814375",
           2013,
           "Purpose: There is a lack of reported data on imaging dose from Novalis ExacTrac use for image guided radiotherapy. This investigation is to assess the imaging doses to patients resulting from a variety of clinical default imaging acquisition protocols in the ExacTrac x‐ray imaging system. Methods: Novalis TX ExacTrac x‐ray system (BrainLab, Feldkirchen, Germany) is investigated. This system consists of two floor‐mounted kilovoltage X‐ray tubes projecting obliquely onto two flat‐panel detectors mounted on the ceiling. The dose measurements were performed using an ion chamber inserted in a phantom. The air kerma calibration factor of the ion chamber for x‐ray beams specified by the half‐value layer was obtained from an Accredited Dosimetry Calibration Laboratory. The imaging dose from clinical default protocols including Cranium, Thorax and Abdomen were studied. The phantom, in the size of 30×12×30 cm3, was made from slabs of water‐equivalent materials for low energy x‐rays, PW‐LR (CIRS, Norfolk, VA). Results: The field size of x‐rays from each tube is 20×20 cm2 at the isocenter. Small differences of 5–10 % in measured radiation dose at the isocenter between two x‐ray tubes were observed. The doses measured in the phantom at a depth of 1 cm from the treatment table were 0.05 cGy, 0.16 cGy, and 0.19 cGy resulting from a pair of obliquely beams of Cranium‐heavy, Thorax‐Heavy and Abdomen‐Heavy clinical protocols respectively. It was found that there was up to 77% dose reduction by selecting Abdomen‐Light instead of Abdomen‐Heavy acquisition protocols. Conclusion: Although the imaging doses to patients resulting from a single pair of beams are low, the sum of multiple acquisitions (10‐20 pairs) is still significant, which can be common for one treatment fraction if non‐coplanar beams are used. The imaging doses strongly depend on the image acquisition protocols. During treatment, the low dose protocols should be chosen, given that image quality is not compromised.",
           1,
           "medical_physics"
          ],
          [
           "Quantitative verification of <sup>192</sup>Ir PDR and HDR source structure by pin‐hole autoradiography",
           "10.1118/1.597538",
           2003,
           "For precise localization of the center and determination of the dimensions of the radioactive material within the capsule of brachytherapy sources, we have developed a method based on simultaneous pin‐hole autoradiography of two sources. We constructed a variable magnification pin‐hole camera consisting of two telescopically fitted Plexiglas cylinders which can accommodate two radioactive sources on the plate covering the top cylinder. The 192Ir pulsed and high dose‐rate sources were studied and an 192Ir seed was used as a reference source. The magnification factor was determined from the dimensions of the 192Ir seed image, which was geometrically well defined by a separate transmission radiography experiment. The observed position for the center of radioactivity in the PDR and the HDR source capsules are in agreement with the vendor specifications. The distance from the tip of the PDR capsule to its center of radioactivity was found in this way to be 0.79±0.21 mm, which agrees with the position (0.85 mm) of the pellet situated closer to the tip as specified by the vendor. Quantitative verification of the internal source structure using this method enhances the accuracy with which the dose distribution near brachytherapy sources can be predicted by three‐dimensional Monte Carlo calculations.",
           11,
           "medical_physics"
          ],
          [
           "SU‐E‐T‐380: Evaluation of Patient Specific Machine Delivery Performance Based on Analysis of Trajectory Log Files",
           "10.1118/1.4735467",
           2012,
           "Purpose: Comparison of delivered and treatment planning dose to a phantom is routinely done before first patient treatment for IMRT and VMAT treatment courses, and is an important part of QA program. It is assumed that the delivery parameters are reproducible for each treatment in the course, and additional tests to validate the assumption are rarely performed. We use the analysis of Trajectory log files to verify the interfractional constancy of treatment delivery. Methods: Trajectory Log files present a record of machine coordinate snapshots every 10ms of beam on state. We designed an automated data mining engine capable of extracting machine parameters recorded for the treated fractions for a selected patient, and generating easy to review statistical report quantifying machine delivery performance. The application was tested on 3 head and neck and 4 pelvis test courses in our clinic. Results: The worst observed instant error in Gantry angle position during the delivery of VMAT treatments was 0.22deg, while the time‐averaged gantry error during the delivery was less than 0.002deg. The maximum observed discrepancy between planned and actual treatment position for MLC leaves was 0.11 mm. When machine parameter interfractional variance was analyzed, the worst difference in gantry position between any fraction delivered for a patient was 0.013deg. The worst instantaneous discrepancy between any fraction of treatment for MLC leaves was only 0.028mm. Conclusions: The analysis of Varian TrueBeam accelerator Trajectory Log files generated during the course of treatment of 3 head and neck and 4 pelvis patients showed high reproducibility in dynamics of machine position parameter during the delivery of treatments. Continuous monitoring of treatment logs enables verification of treatment delivery constancy, and should be integrated in clinical QA programs.",
           0,
           "medical_physics"
          ],
          [
           "Truncation correction for oblique filtering lines",
           "10.1118/1.3002416",
           2008,
           "State‐of‐the‐art filtered backprojection (FBP) algorithms often define the filtering operation to be performed along oblique filtering lines in the detector. A limited scan field of view leads to the truncation of those filtering lines, which causes artifacts in the final reconstructed volume. In contrast to the case where filtering is performed solely along the detector rows, no methods are available for the case of oblique filtering lines. In this work, the authors present two novel truncation correction methods which effectively handle data truncation in this case. Method 1 (basic approach) handles data truncation in two successive preprocessing steps by applying a hybrid data extrapolation method, which is a combination of a water cylinder extrapolation and a Gaussian extrapolation. It is independent of any specific reconstruction algorithm. Method 2 (kink approach) uses similar concepts for data extrapolation as the basic approach but needs to be integrated into the reconstruction algorithm. Experiments are presented from simulated data of the FORBILD head phantom, acquired along a partial‐circle‐plus‐arc trajectory. The theoretically exact M‐line algorithm is used for reconstruction. Although the discussion is focused on theoretically exact algorithms, the proposed truncation correction methods can be applied to any FBP algorithm that exposes oblique filtering lines.",
           8,
           "medical_physics"
          ],
          [
           "A conversion method of air kerma from the primary, scatter, and leakage radiations to effective dose for calculating x‐ray shielding barriers in mammography",
           "10.1118/1.1895526",
           2005,
           "In this study, a new approach has been introduced for derivation of the effective dose from air kerma to calculate shielding requirements in mammography facilities. This new approach has been used to compute the conversion coefficients relating air kerma to the effective dose for the mammography reference beam series of the Netherlands Metrology Institute Van Swinden Laboratorium, National Institute of Standards and Technology, and International Atomic Energy Agency laboratories. The results show that, in all cases, the effective dose in mammography energy range is less than 25% of the incident air kerma for the primary and the scatter radiations and does not exceed 75% for the leakage radiation.",
           4,
           "medical_physics"
          ],
          [
           "SU‐FF‐T‐390: A New Linac QA Procedure for the Characterization of Radiation Isocenter and Room Lasers Position",
           "10.1118/1.1998147",
           2005,
           "Purpose: We have designed and implemented a new stereotactic machine QA test. The method is used to characterize gantry sag, couch wobble, cone placement, MLC offset and room lasers position relative to radiation isocenter. An image containing a series of test patterns is generated in a direct and integrated fashion. Method and Materials: Two MLC star patterns, a cone pattern and the laser lines are recorded on the same imaging medium, enabling 0.1 mm accuracy measurements. Phosphor plates are used as the imaging medium due to their unique property that the red light of wall laser erases the radiation information stored on phosphor plates. The room lasers position relative to the radiation isocenter can be measured. The developed QA method consists of four images that measure the gantry sag between 00 and 1800 gantry angles, the position and stability of couch rotational axis, the sag between 900 and 2700 gantry angles, the accuracy of cone placement on the collimator and the position of laser lines relative radiation isocenter. Results: The inherent precision of the numerical algorithms developed is +/− 0.05mm. The inherent accuracy of the method as a whole is +/− 0.1mm. The total irradiation/illumination time is about 10 min per image. Automating the generation of collimator star patterns can reduce this time. The data analysis (including the phosphor plate scanning) is less than 5min. Conclusion: The presented method reproducibly characterizes the radiation isocenter geometry with the high accuracy required for stereotactic surgery. It can replace the standard ball test and it can provide a highly accurate QA procedure for the non‐stereotactic machines.",
           1,
           "medical_physics"
          ],
          [
           "SU‐E‐T‐464: Impact of the Treatment Margin on Tumor Control and Normal Tissue Complication for Prostate Treatment",
           "10.1118/1.4735553",
           2012,
           "Purpose: To investigate the consequence of treatment margin reduction on normal tissue complication probability (NTCP) and tumor control probability (TCP) of prostate external beam treatment. Methods: Intensity modulated rotational radiotherapy plans were generated for 10 prostate patients with 6 different posterior margin sizes from 5mm to 0. The prescription dose is 80Gy for 40 treatment fractions. The dose distributions were recalculated with consideration of the intrafractional motion and the localization error. The statistical uncertainties of the intrafractional motion and the localization error were derived based on the motion tracking data recorded by the Calypso 4D localization system for a large patient population. The TCP and NTCP were calculated based on the dose volume histograms (DVH) of prostate and rectum for plans with different margins using an equivalent uniform dose (EUD) based biological model. The 50% tumor control dose (TCD50) of 60Gy for prostate and the median toxic dose (TD50) of 55Gy for rectum were used in the calculation. Results: The minimum dose of the prostate and the mean dose of the rectum dropped with the decrease of the treatment margin. When the posterior treatment margin was reduced from 5mm to zero, the EUD of prostate decreased from 83Gy (±0.5Gy) to 81Gy (±0.5Gy) and the TCP dropped from 93.2% (±0.1%) to 91.7% (±0.1%), the EUD of the rectum decreased more significantly from 48.9Gy (±0.4Gy) to 32.5Gy (±0.5Gy) and the NTCP dropped from 13.3% (±1.5%) to 0.03% (± 0.01%). Conclusions: The treatment margin size affects the dose to the target and the nearby critical structure. More significant impact on NTCP has been observed than on TCP. This gives us some room to consider the quality of the patient's after‐treatment life. A wise choice of treatment margin can be made based on physician's opinion and patient's preference on the tumor control and the quality of life.",
           1,
           "medical_physics"
          ],
          [
           "TU‐C‐T‐617‐06: Importance of Pre‐Fraction Helical CT Isocenter Verification in Extracranial Stereotactic Radiosurgery",
           "10.1118/1.1998364",
           2005,
           "Purpose: To quantify the impact of pre‐fraction helical CT isocenter verification vs. setup based on planning CT in fractionated extracranial stereotactic radiosurgery. Method and Materials: Treatment plans (Elekta PrecisePlan) and pre‐fraction isocenter verification helical CT scans for 12 patients (40 fractions) were recovered from treatment plan archives. All structures were contoured by a single physician at the time of treatment. Each plan was imported into a customizable treatment plan analysis suite (CERR). Using CERR, pre‐fraction isocenter verification CT scans were fused with the original treatment plan using the external body frame as a reference. The original planned dose distribution was then translated from original treatment plan isocenter to pre‐fraction verification isocenters in each fraction. Dose and volume parameters for pertinent structures were automatically extracted using both registration methods (planned or pre‐fraction scans) for the original treatment plan and for all subsequent fractions. All patients were treated using the pre‐fraction verified isocenter rather than pre‐calculated body frame fiducials as per our institutional policies. Results: GTV volumes on pre‐fraction CTs varied from original planned GTV volume (64%–203%, mean=101.8+/−26.5%) largely due to helical sampling of a mobile target. Using the external body frame as the only setup reference would have resulted in geographic misses (<80% coverage of 95% of GTV) in 7/40 (17.5%) fractions. Pre‐fraction isocenter verification resulted in improved D95 GTV coverage (88–102%, mean=99.3% +/−2.4%) with no geographic misses. Conclusion: The current RTOG protocol (0236) evaluating extracranial stereotactic radiosurgery does not require pre‐fraction CT tumor position verification. Our institutional policy is to verify isocenter/tumor position prior to each fraction via CT. Although helical scanning artifacts are present, pre‐fraction CT‐based isocenter verification may provide more consistent tumor coverage than setup to planned body frame fiducials. Conflict of Interest: Support for this research was provided in part by Elekta, Inc.",
           0,
           "medical_physics"
          ],
          [
           "An evaluation of organic light emitting diode monitors for medical applications: Great timing, but luminance artifacts",
           "10.1118/1.4818056",
           2013,
           "Purpose:In contrast to the dominant medical liquid crystal display (LCD) technology, organic light‐emitting diode (OLED) monitors control the display luminance via separate light‐emitting diodes for each pixel and are therefore supposed to overcome many previously documented temporal artifacts of medical LCDs. We assessed the temporal and luminance characteristics of the only currently available OLED monitor designed for use in the medical treatment field (SONY PVM2551MD) and checked the authors’ main findings with another SONY OLED device (PVM2541).Methods:Temporal properties of the photometric output were measured with an optical transient recorder. Luminances of the three color primaries and white for all 256 digital driving levels (DDLs) were measured with a spectroradiometer. Between the luminances of neighboring DDLs, just noticeable differences were calculated according to a perceptual model developed for medical displays. Luminances of full screen (FS) stimuli were compared to luminances of smaller stimuli with identical DDLs.Results:All measured luminance transition times were below 300 μs. Luminances were independent of the luminance in the preceding frame. However, for the single color primaries, up to 50.5% of the luminances of neighboring DDLs were not perceptually distinguishable. If two color primaries were active simultaneously, between 36.7% and 55.1% of neighboring luminances for increasing DDLs of the third primary were even decreasing. Moreover, luminance saturation effects were observed when too many pixels were active simultaneously. This effect was strongest for white; a small white patch was close to 400 cd/m2, but in FS the luminance of white saturated at 162 cd/m2. Due to different saturation levels, the luminance of FS green and FS yellow could exceed the luminance of FS white for identical DDLs.Conclusions:The OLED temporal characteristics are excellent and superior to those of LCDs. However, the OLEDs revealed severe perceptually relevant artifacts with implications for applicability to medical imaging.",
           10,
           "medical_physics"
          ],
          [
           "A calibration‐free, one‐step method for quantitative photoacoustic tomography",
           "10.1118/1.4760981",
           2012,
           "Purpose: Recently reported quantitative photoacoustic tomography (PAT) has significantly expanded the utilities of PAT because it allows for recovery of tissue optical absorption coefficient which directly correlates with tissue physiological information. However, the recovery of optical absorption coefficient by the existing quantitative PAT approaches strongly depends on the accuracy of absorbed energy density distribution, and on the knowledge of accurate strength and distribution of incident light source. The purpose of this study is to develop a new algorithm for the reconstruction of optical absorption coefficient that does not depend on these initial parameters.Methods: Here the authors propose a novel one‐step reconstruction approach that can directly recover optical absorption coefficient from photoacoustic measurements along boundary domain. The authors validate the method using simulation and phantom experiments.Results: The authors have demonstrated experimental evidence that it is possible to directly recover optical absorption coefficient maps using boundary photoacoustic measurements coupled with the photon diffusion equation in just one step. The authors found that the method described is able to quantitatively reconstruct absorbing objects with different sizes and optical contrast levels.Conclusions: Compared to the authors’ previous two‐step methods, the reconstruction results obtained here show that the one‐step scheme can significantly improve the accuracy of absorption coefficient recovery.",
           24,
           "medical_physics"
          ],
          [
           "A comparison of ionization‐chamber and water‐calorimeter dosimetry for high‐energy x rays",
           "10.1118/1.596595",
           2003,
           "The temperature‐regulated, flexible, water calorimeter developed in the authors' laboratory was shown previously to yield a dose‐to‐water from 4‐MV x rays that is in very close agreement with ionization measurements made in accordance with the AAPM dosimetry protocol. The range of beam energies for this type of comparison has been increased to include 60Co, and 4‐, 6‐ and 25‐MV x rays. The grand mean of the ratios of doses obtained from the calorimeter and ionization chamber, the Cal/Ion ratio, for the four beam energies studied is 1.001±0.001. As no significant trend with beam energy was detected, it is concluded that the calorimeter and ionization chamber yield equally accurate results. Because the calibration of the calorimeter depends solely upon the accuracy with which water temperatures in the range 2–10 °C can be measured, and dose is given by the product of the specific heat of water and the temperature change produced by irradiation, the water calorimeter has the potential to place radiation dosimetry on a much firmer foundation than presently exists.",
           11,
           "medical_physics"
          ],
          [
           "Sci‐Sat AM (2) Therapy‐04: Evaluation of Ultrasound‐Based 3D Positioning System (Restitu by Resonant Medical) for Localizing and Delineating Prostate Targets for Image‐Guided Radiation Treatment: Phantom Study and Estimates of Distortions in US Images of a Patient",
           "10.1118/1.2244700",
           2006,
           "3D‐Ultrasound (US) promises to be a noninvasive alternative to the portal imaging of surgically implanted gold seeds for positioning the prostate before radiation treatment. In this work we have evaluated a new US system, the Restitu, manufactured by Resonant Medical (Montréal). Using a prostate phantom we have measured the base‐line reproducibility of couch shifts calculated with the Restitu software algorithms. We have also attempted to estimate the influence of US image artifacts on the calculated prostate position. Unlike similar early systems (e.g. BAT), Restitu uses 3D‐US to 3D‐US image registration to determine the prostate position relative to the position during the planning CT. If the internal organs remain stationary and the movement of the US probe is invariant during each fraction then we would expect that the calculated results would be immune to US image distortions. However, due primarily to variations in bladder filling, second‐order US artifacts need to be considered. Using 3D‐US images collected on a sample patient with a full and a half‐empty bladder, we have found the error caused by variations in the time of travel of the sound wave to be about −0.8 mm, and the error caused by sound wave refraction at tissue‐urine interfaces to be about 2.1 mm. The combined error, 2.2 mm, is close to the quoted system tolerance of ±2 mm, but may vary due to anatomical differences. These errors can be reduced under consistent full‐bladder operation.",
           0,
           "medical_physics"
          ],
          [
           "TU‐EE‐A2‐06: Are Dosimetric Guidelines of Adult Lung Cancer for Preventing Radiation Pneumonitis Applicable to Pediatric Radiotherapy Involving Lungs?",
           "10.1118/1.2962616",
           2008,
           "Purpose: Pediatric patients with Hodgkin's lymphoma and thoracic or paraspinal sarcomas who received radiotherapy may develop clinically significant radiation pneumonitis (RP) requiring the use of steroids. There are no dosimetric planning guidelines for pediatric lung to assess the likelihood of complication. We reviewed dose‐volume histograms (DVHs) and clinical complication data of 63 children treated on 2 prospective studies and evaluated the applicability of adult planning guidelines and risk models. Method and Materials: Forty children with Hodgkin's lymphoma and 23 with sarcoma receiving radiation to the thorax were studied. Patients with Hodgkin's lymphoma received 25.5 Gy involved‐field radiotherapy. Eight of which received 8 Gy to the entirety of one or both lungs through partial transmission blocks. Patients with sarcomas received 41.4–70.2 Gy conformal radiotherapy to the primary tumor. Clinical data on RP were collected from protocol databases and chart review with IRB approval. DVH parameters V13, V20, mean lung dose and normal tissue complication probability (NTCP) from adult lung models were calculated. Results: Four patients developed RP following radiotherapy. Two required the use of steroids (NCI CTC grade II). Of the 3 patients with Hodgkin's lymphoma who developed RP, 2 had received 8 Gy delivered to their entire right lung. Children with grade II RP have higher total lung DVHs, a V20 ⩾35% and mean lung dose above 16 Gy, consistent with the planning constraints set for adult lung cancer and Hodgkin's lymphoma. However, adult lung NTCP and risk models predicted low probability (0.2–0.3) for children who actually developed RP. Conclusion: The V20 and mean lung dose guidelines developed for adult lung cancer identify children at higher risk for RP. Better understanding of other clinical factors such as chemotherapeutic agents and individual sensitivity may be required to improve the predicability of NTCP models for children.",
           1,
           "medical_physics"
          ],
          [
           "SU‐E‐T‐460: Image Based Treatment Planning for Intraluminal Brachytherapy in Bile Duct Carcinoma",
           "10.1118/1.4814893",
           2013,
           "Purpose: 3D Image based treatment planning for intraluminal brachytherapy in bile duct carcinoma. Methods: Five patients with bile duct carcinoma were treated with definitive radiation therapy. Radiation therapy was delivered by means of external beam radiation therapy (EBRT) combined with HDR brachytherapy.Eclipse v8.6 TPS (Varian Medical Systems, USA) was used for treatment planning.In the diagnostic radiology suite, a flexible guide wire was passed through the biliary stent to a point past the stenosis. Subsequently catheter localisation, dummy wire was inserted and orthogonal films were used to confirm the position. All the patients were scanned on CT scanner (Siemens, Germany) with a slice thickness of 3 mm without any radio opaque dummy. The GTV, CTV OAR were contoured according to ICRU 62.Since the catheter is inserted in biliary stent, the applicator reconstruction is not possible. The first source point was reconstructed from the tip of the stent. From the orthogonal topograph the offset was calculated by measuring the tip of the stent to first dummy source distance. This offset was set in the planning. With the optimum source length the dose was calculated and CTV, OAR doses were quantified. The External and brachytherapy plans were summed to produce resultant DVH. Results: The applicator reconstruction accuracy was found to be within ±2mm. The mean, median dose of GTV, CTV was 32Gy, 23Gy and 18Gy, 13Gy respectively. The mean, median dose for duodenum was 7.6Gy and 2.8Gy. Conclusion: In radiography assisted planning, dose distribution is usually calculated according to the applicator geometry and in addition to fixed reference points. But with 3D brachytherapy planning the doses can be optimised to GTV and can be summed with external plan for clinical evaluation.",
           0,
           "medical_physics"
          ],
          [
           "Thoracic cavity segmentation algorithm using multiorgan extraction and surface fitting in volumetric CT",
           "10.1118/1.4866836",
           2014,
           "Purpose:To develop and validate a semiautomatic segmentation method for thoracic cavity volumetry and mediastinum fat quantification of patients with chronic obstructive pulmonary disease.Methods:The thoracic cavity region was separated by segmenting multiorgans, namely, the rib, lung, heart, and diaphragm. To encompass various lung disease‐induced variations, the inner thoracic wall and diaphragm were modeled by using a three‐dimensional surface‐fitting method. To improve the accuracy of the diaphragm surface model, the heart and its surrounding tissue were segmented by a two‐stage level set method using a shape prior. To assess the accuracy of the proposed algorithm, the algorithm results of 50 patients were compared to the manual segmentation results of two experts with more than 5 years of experience (these manual results were confirmed by an expert thoracic radiologist). The proposed method was also compared to three state‐of‐the‐art segmentation methods. The metrics used to evaluate segmentation accuracy were volumetric overlap ratio (VOR), false positive ratio on VOR (FPRV), false negative ratio on VOR (FNRV), average symmetric absolute surface distance (ASASD), average symmetric squared surface distance (ASSSD), and maximum symmetric surface distance (MSSD).Results:In terms of thoracic cavity volumetry, the mean ± SD VOR, FPRV, and FNRV of the proposed method were (98.17 ± 0.84)%, (0.49 ± 0.23)%, and (1.34 ± 0.83)%, respectively. The ASASD, ASSSD, and MSSD for the thoracic wall were 0.28 ± 0.12, 1.28 ± 0.53, and 23.91 ± 7.64 mm, respectively. The ASASD, ASSSD, and MSSD for the diaphragm surface were 1.73 ± 0.91, 3.92 ± 1.68, and 27.80 ± 10.63 mm, respectively. The proposed method performed significantly better than the other three methods in terms of VOR, ASASD, and ASSSD.Conclusions:The proposed semiautomatic thoracic cavity segmentation method, which extracts multiple organs (namely, the rib, thoracic wall, diaphragm, and heart), performed with high accuracy and may be useful for clinical purposes.",
           7,
           "medical_physics"
          ],
          [
           "Re‐evaluation of the dose to the cyst wall in P‐32 radiocolloid treatments of cystic brain tumors using the Dose–Point–Kernel and Monte Carlo methods",
           "10.1118/1.1599652",
           2003,
           "Intracavity instillation of β‐emitting colloid pharmaceuticals is a common technique used to treat cystic brain tumors. Most of the dosimetric calculations that have been reported in the literature for this problem are based on empirical formulas derived by Loevinger. Concentration of P‐32 radiolabeled solution for the delivery of a prescribed dose (200 Gy to the cyst wall) has been published previously using this formalism in what we refer to as a standard nomogram. The calculations using the Loevinger formulas for calculating the P‐32 activity necessary to achieve 200 Gy at the cyst wall is re‐evaluated and compared to numerically computed results based on full Monte Carlo simulations (EGSnrc) and the dose–point–kernel (DPK) integration method. For cyst diameters greater than 1 cm, the new calculations agree well with previously published results (the standard nomogram) to within a few percents. However, for cyst diameters of less than 1 cm, it is shown that the standard nomogram results underestimate the therapeutic activity by a factor of  for very small diameters  New tables based on our calculations are presented and the sources of discrepancies are identified. It is concluded that the new set of data based on our calculations should replace the standard nomogram to administer accurately the target dose to the cyst wall for the smaller diameter cysts ",
           15,
           "medical_physics"
          ],
          [
           "Attenuation and activation characteristics of steel and tungsten and the suitability of these materials for use in a fast neutron multileaf collimator",
           "10.1118/1.1376135",
           2008,
           "A computer controlled multileaf collimator (MLC) is being designed to replace the multirod collimator (MRC) at present used to shape the d(48.5)+Be neutron beam from the Harper Hospital superconducting cyclotron. The computer controlled MLC will improve efficiency and allow for the future development of intensity modulated radiation therapy with neutrons. The existing MRC uses tungsten rods, while the new MLC will use steel as the leaf material. In the current study the attenuation and activation characteristics of steel are compared with those of tungsten to ensure that (a) the attenuation achieved in the MLC is at least equivalent to that of the existing MRC, and (b) that the activation of the steel will not result in a significant change in the activation levels within the treatment room. The latter point is important since personnel exposure (particularly to the radiation therapy technologists) from induced radioactivity must be minimized. Measurement of the neutron beam attenuation in a broad beam geometry showed that a 30 cm thick steel leaf yielded 2.5% transmission. This compared favorably with the 4% transmission obtained with the existing MRC. Irradiation of steel and tungsten samples at different depths in a 30 cm steel block indicated that the activation of steel should be no worse than that of tungsten.",
           6,
           "medical_physics"
          ],
          [
           "Electron beam therapy with coil‐generated magnetic fields",
           "10.1118/1.1711477",
           2004,
           "This paper presents an initial study on the issues involved in the practical implementation of the use of transverse magnetic fields in electron beam therapy. By using such magnetic fields the dose delivered to the tumor region can increase significantly relative to that deposited to the healthy tissue. Initially we calculated the magnetic fields produced by the Helmholtz coil and modified Helmholtz coil configurations. These configurations, which can readily be used to generate high intensity magnetic fields, approximate the idealized magnetic fields studied in our previous publications. It was therefore of interest to perform a detailed study of the fields produced by these configurations. Electron beam dose distributions for 15 MeV electrons were calculated using the ACCEPTM code for a 3T transverse magnetic field produced by the modified Helmholtz configuration. The dose distribution was compared to those obtained with no magnetic field. The results were similar to those obtained in our previous work, where an idealized step function magnetic field was used and a 3T field was shown to be the optimal field strength. A simpler configuration was also studied in which a single external coil was used to generate the field. Electron dose distributions are also presented for a given geometry and given magnetic field strength using this configuration. The results indicate that this method is more difficult to apply to radiotherapy due to its lack of symmetry and its irregularity. For the various configurations dealt with here, a major problem is the need to shield the magnetic field in the beam propagation volume, a topic that must be studied in detail.",
           4,
           "medical_physics"
          ],
          [
           "Objective index of image fidelity for JPEG2000 compressed body CT images",
           "10.1118/1.3129159",
           2009,
           "Compression ratio (CR) has been the de facto standard index of compression level for medical images. The aim of the study is to evaluate the CR, peak signal‐to‐noise ratio (PSNR), and a perceptual quality metric (high‐dynamic range visual difference predictor HDR‐VDP) as objective indices of image fidelity for Joint Photographic Experts Group (JPEG) 2000 compressed body computed tomography (CT) images, from the viewpoint of visually lossless compression approach. A total of 250 body CT images obtained with five different scan protocols (5‐mm‐thick abdomen, 0.67‐mm‐thick abdomen, 5‐mm‐thick lung, 0.67‐mm‐thick lung, and 5‐mm‐thick low‐dose lung) were compressed to one of five CRs (reversible, 6:1, 8:1, 10:1, and 15:1). The PSNR and HDR‐VDP values were calculated for the 250 pairs of the original and compressed images. By alternately displaying an original and its compressed image on the same monitor, five radiologists independently determined if the pair was distinguishable or indistinguishable. The kappa statistic for the interobserver agreement among the five radiologists’ responses was 0.70. According to the radiologists' responses, the number of distinguishable image pairs tended to significantly differ among the five scan protocols at 6:1–10:1 compressions (Fisher‐Freeman‐Halton exact tests). Spearman's correlation coefficients between each of the CR, PSNR, and HDR‐VDP and the number of radiologists who responded as distinguishable were 0.72, −0.77, and 0.85, respectively. Using the radiologists' pooled responses as the reference standards, the areas under the receiver–operating–characteristic curves for the CR, PSNR, and HDR‐VDP were 0.87, 0.93, and 0.97, respectively, showing significant differences between the CR and PSNR , or HDR‐VDP , and between the PSNR and HDR‐VDP . In conclusion, the CR is less suitable than the PSNR or HDR‐VDP as an objective index of image fidelity for JPEG2000 compressed body CT images. The HDR‐VDP is more promising than the PSNR as such an index.",
           13,
           "medical_physics"
          ],
          [
           "SU‐E‐T‐337: Dynamic Tomotherapy Delivery with Running‐Start‐Stop: Comparing to Conventional Tomotherapy and VMAT Deliveries",
           "10.1118/1.4735424",
           2012,
           "Purpose: Despite of superior target dose uniformity, previous studies of helical tomotherapy (HT) show inferior longitudinal conformity and longer deliver time compared to volumetric‐modulated arc therapy (VMAT) plans, due to fixed jaw size with conventional HT. Dynamic delivery techniques were introduced to overcome these problems. This study is to compare the dosimetric performance of dynamic tomotherapy delivery (5.0cm jaw running‐start‐stop (RSS)) with fixed jaw HT and VMAT deliveries. Methods: Sixteen patient cases, including brain, head&neck (HN), lung and prostate, were selected and de‐identified prior to treatment planning. VMAT plans were generated using Varian RapidArc™ (RA) (one or two arcs) and HT plans using TomoTherapy® (fixed 2.5cm jaw). The tomotherapy RSS plans were generated using tomotherapy's research engine and optimized based on 5.0cm dynamic jaw, which allows larger jaw opening for lower dose gradient and smaller jaw opening at the target border when sharp penumbra is required. All 16 cases were planned based on identical contours, prescriptions, and planning objectives. Dose indices for targets and critical organs were compared based on dose‐volume histograms, delivery time, and monitor units. Results: The average delivery time was reduced from 4.8min (HT) to 2.92min (RSS). RSS showed comparable target dose homogeneity to HT. Three delivery techniques showed comparable normal tissue sparing for lung cases, with improved sparing of cord with RSS. For prostate cases, RSS showed improved bladder and rectum doses compared to HT due to better longitudinal sparing. Superior normal tissue sparing was observed in RSS plans for optical nerves in brain cases and larynx or parotids for HN cases. Conclusions: Tomotherapy RSS with 5.0cm dynamic jaw is overall comparable, if not better, to 2.5cm fixed jaw HT, with faster treatment delivery. It also showed improved longitudinal dose conformity to critical structures adjacent to the target, which is comparable to RA technique. Yu Chen is employee of Accuray‐Tomotherapy, Inc.",
           1,
           "medical_physics"
          ],
          [
           "Output variation from an intensity modulating dynamic collimator",
           "10.1118/1.1493782",
           2002,
           "Intensity modulated radiation therapy (IMRT) offers a method of delivering radiation dose conforming to the shape of targets while minimizing the dose to the surrounding tissue and nearby critical organs. One popular device is the NOMOS MIMiC Collimator coupled to the CORVUS treatment planning system. The MIMiC collimator, mounted on a linac head, opens and closes one or more of its 40 small leaves as determined by the planner while the linac delivers radiation and the gantry rotates. This dynamic IMRT allows the intensity to be modulated yielding a highly conformal dose distribution. However, the dose output becomes a function of the detailed manner in which the leaves open and close, since the opening and closing are not instantaneous. We investigate the effect of switch rates and delay in the open/close events on the output profiles. The output is enhanced as the switch rate increases. The enhancement factor at any point of measurement is dependent on its distance from the central plane. We interpret these variations in terms of a simple model, which includes the effect of leaf travel time during the process of opening and closing. We also include the time delay in establishing the specified pressure in the pneumonic device, which controls the opening and closing of the leaves. The information presented here offers a means for incorporating these output changes into the planning system. This may avoid the current situation where many patient plans need to be renormalized based on the actual measurement taken during the delivery of the specified intensity pattern to a phantom.",
           1,
           "medical_physics"
          ],
          [
           "SU‐E‐T‐333: Immobilization for Proton Therapy ‐ How Is It Different to Photon Therapy?",
           "10.1118/1.4735420",
           2012,
           "Purpose: To describe considerations in proton therapy immobilization and the effects which design elements have on the proton dose distribution. Methods: Proton therapy has dose distribution advantages over photons through the Bragg peak. This high dose region and sharp distal fall off that produces no primary particle exit dose can be placed at any point within the patient leading to the use of fewer beams and lower integral doses. Proton patient immobilization needs to reduce patient motion to the largest extent feasible, as is the case with other radiation therapy modalities, but also needs to consider the effect of the immobilization device on the proton range and whether this is accurately reflected in the dose calculation. Results: Our proton treatment center has treated patients with protons for over 20 years, and the development of effective immobilization methods has been an integral part of this experience. For the various anatomic sites, specific devices have been developed that position and immobilize the patient reproducibly and effectively. Attention was paid to minimal proton water equivalent thickness (WET) to minimize the effect on proton beam penumbra. The WET of each immobilization material has been well characterized and incorporated in the (CT‐based) proton range calculation to minimize systematic errors in the proton range uncertainty. In our experience, proton immobilization devices should have beveled edges when possible to avoid edge effects that can drastically affect the depth of proton penetration. Effective use of internal immobilization, such a rectal balloons or breath holding, is also important to minimize ITV margins and suppress motion‐related beam range uncertainties that are unique to proton therapy. Conclusions: In proton therapy patient immobilization, additional considerations are needed to ensure that the immobilization device does not negatively impact the proton dose distribution and its uncertainty.",
           0,
           "medical_physics"
          ],
          [
           "Automated volume analysis of head and neck lesions on CT scans using 3D level set segmentation",
           "10.1118/1.2794174",
           2007,
           "The authors have developed a semiautomatic system for segmentation of a diverse set of lesions in head and neck CT scans. The system takes as input an approximate bounding box, and uses a multistage level set to perform the final segmentation. A data set consisting of 69 lesions marked on 33 scans from 23 patients was used to evaluate the performance of the system. The contours from automatic segmentation were compared to both 2D and 3D gold standard contours manually drawn by three experienced radiologists. Three performance metric measures were used for the comparison. In addition, a radiologist provided quality ratings on a 1 to 10 scale for all of the automatic segmentations. For this pilot study, the authors observed that the differences between the automatic and gold standard contours were larger than the interobserver differences. However, the system performed comparably to the radiologists, achieving an average area intersection ratio of  compared to an average of  between two radiologists. The average absolute area error was  compared to , and the average 2D distance was 1.38 mm compared to 0.84 mm between the radiologists. In addition, the quality rating data showed that, despite the very lax assumptions made on the lesion characteristics in designing the system, the automatic contours approximated many of the lesions very well.",
           36,
           "medical_physics"
          ],
          [
           "Velocity measurement based on bolus tracking with the aid of three‐dimensional reconstruction from digital subtraction angiography",
           "10.1118/1.597990",
           2002,
           "The problem of blood flow measurement in x‐ray angiography using measurements of the leading edge of the contrast bolus as it traverses the vascular bed is considered. A new technique for velocity measurement is presented based upon the ratio of the temporal derivative to the spatial derivative of the contrast bolus in the direction of flow. With the addition of a small correction factor, the value obtained is shown to reflect the transport velocity, or the velocity at which the contrast is transported down the vessel of interest. Most blood flow measurements based on bolus tracking techniques are actually using the contrast transport velocity to represent the blood flow velocity. Because of the streaming that occurs due to laminary flow conditions, the measured transport velocity is found to be somewhere between the average and the peak (central) fluid velocities for measurements taken during the traversal of the bolus leading edge. The spatial and temporal variation of the transport velocity are found to be consistent with the bolus motion expected in the presence of laminar flow. From x‐ray images of contrast passage through simple tubes, we find that the derivative method measures the transport velocity during passage of the bolus leading edge. In most cases of laminar blood flow, the leading edge transport velocity can be 20%–40% higher than the average blood velocity.",
           7,
           "medical_physics"
          ],
          [
           "A study of the effect of cone shielding in intraoperative radiotherapy",
           "10.1118/1.597584",
           2003,
           "The primary goal of intraoperative radiation therapy is to irradiate the intraoperatively determined tumor target volume with a single fraction of tumoroidal dose while minimizing the dose to all adjacent healthy tissues. To reduce dose outside the treatment volume, lead sheets are often used to cover the external surface of the cone tip thus providing a shielding for the tissues outside the field. In this paper, the effect of the shielding on the depth dose distributions and dose profiles at different depths is studied based on experimental data. The results were also compared against an EGS4 Monte Carlo code for the same geometry as the measurements. The cones varied in size having diameters of 5 cm, 7 cm, and 9 cm, and the electron energies ranged from 6 MeV to 22 MeV. The depth dose curves and dose profiles (at two different depths in the phantom) were measured and computed with and without the lead shielding for the various combinations of cone sizes and electron energies using a water phantom to simulate the patient. It was found that the presence of lead increases on average across the treatment area the dose to the tumor from 2% up to 5%, while the dose outside the cone was reduced by as much as 75%. Both measurements and calculations were found to be in agreement.",
           7,
           "medical_physics"
          ],
          [
           "Determination of the thermal neutron flux in a fast neutron beam by use of a boron‐coated ionization chamber",
           "10.1118/1.597630",
           2003,
           "The thermal neutron distribution in slow and fast neutron beams is usually determined using the foil activation method. In this work a small magnesium walled ionization chamber, in which the inner surface of the wall has been coated with 10B to increase the sensitivity for thermal neutrons, is used to estimate the thermal neutron component of the beam. After calibration and determination of the directional response in a thermal neutron beam a comparison with foil activation at different depths in water was performed to investigate the reliability of the ionization measurements. The chamber was used in a computer controlled water phantom to measure the depth and lateral distribution of the thermal neutron dose. With this arrangement two‐dimensional scans of the thermal neutrons could be performed quickly and with high accuracy.",
           17,
           "medical_physics"
          ],
          [
           "Dosimetric evaluation of photon dose calculation under jaw and MLC shielding",
           "10.1118/1.4820443",
           2013,
           "Purpose:The accuracy of photon dose calculation algorithms in out‐of‐field regions is often neglected, despite its importance for organs at risk and peripheral dose evaluation. The present work has assessed this for the anisotropic analytical algorithm (AAA) and the Acuros‐XB algorithms implemented in the Eclipse treatment planning system. Specifically, the regions shielded by the jaw, or the MLC, or both MLC and jaw for flattened and unflattened beams have been studied.Methods:The accuracy in out‐of‐field dose under different conditions was studied for two different algorithms. Measured depth doses out of the field, for different field sizes and various distances from the beam edge were compared with the corresponding AAA and Acuros‐XB calculations in water. Four volumetric modulated arc therapy plans (in the RapidArc form) were optimized in a water equivalent phantom, PTW Octavius, to obtain a region always shielded by the MLC (or MLC and jaw) during the delivery. Doses to different points located in the shielded region and in a target‐like structure were measured with an ion chamber, and results were compared with the AAA and Acuros‐XB calculations. Photon beams of 6 and 10 MV, flattened and unflattened were used for the tests.Results:Good agreement between calculated and measured depth doses was found using both algorithms for all points measured at depth greater than 3 cm. The mean dose differences (±1SD) were −8% ± 16%, −3% ± 15%, −16% ± 18%, and −9% ± 16% for measurements vs AAA calculations and −10% ± 14%, −5% ± 12%, −19% ± 17%, and −13% ± 14% for Acuros‐XB, for 6X, 6 flattening‐filter free (FFF), 10X, and 10FFF beams, respectively. The same figures for dose differences relative to the open beam central axis dose were: −0.1% ± 0.3%, 0.0% ± 0.4%, −0.3% ± 0.3%, and −0.1% ± 0.3% for AAA and −0.2% ± 0.4%, −0.1% ± 0.4%, −0.5% ± 0.5%, and −0.3% ± 0.4% for Acuros‐XB. Buildup dose was overestimated with AAA, while Acuros‐XB gave results more consistent with measurements. From RapidArc plan analysis the average difference between calculation and measurement in the shielded region was −0.3% ± 0.4% and −2.5% ± 1.2% for AAA and Acuros‐XB, respectively, relative to the mean target dose value (1.6% ± 2.3%, −12.7% ± 4.0% if relative to each local value). These values were compared with the corresponding differences in the target structure: −0.7% ± 2.3% for AAA, and −0.5% ± 2.3% for Acuros‐XB.Conclusions:The two algorithms analyzed showed encouraging results in predicting out‐of‐field region dose for clinical use.",
           15,
           "medical_physics"
          ],
          [
           "Whole‐body tumor segmentation from PET/CT images using a two‐stage cascaded neural network with camouflaged object detection mechanisms",
           "10.1002/mp.16438",
           2023,
           "BackgroundWhole‐body Metabolic Tumor Volume (MTVwb) is an independent prognostic factor for overall survival in lung cancer patients. Automatic segmentation methods have been proposed for MTV calculation. Nevertheless, most of existing methods for patients with lung cancer only segment tumors in the thoracic region.PurposeIn this paper, we present a Two‐Stage cascaded neural network integrated with Camouflaged Object Detection mEchanisms (TS‐Code‐Net) for automatic segmenting tumors from whole‐body PET/CT images.MethodsFirstly, tumors are detected from the Maximum Intensity Projection (MIP) images of PET/CT scans, and tumors' approximate localizations along z‐axis are identified. Secondly, the segmentations are performed on PET/CT slices that contain tumors identified by the first step. Camouflaged object detection mechanisms are utilized to distinguish the tumors from their surrounding regions that have similar Standard Uptake Values (SUV) and texture appearance. Finally, the TS‐Code‐Net is trained by minimizing the total loss that incorporates the segmentation accuracy loss and the class imbalance loss.ResultsThe performance of the TS‐Code‐Net is tested on a whole‐body PET/CT image data‐set including 480 Non‐Small Cell Lung Cancer (NSCLC) patients with five‐fold cross‐validation using image segmentation metrics. Our method achieves 0.70, 0.76, and 0.70, for Dice, Sensitivity and Precision, respectively, which demonstrates the superiority of the TS‐Code‐Net over several existing methods related to metastatic lung cancer segmentation from whole‐body PET/CT images.ConclusionsThe proposed TS‐Code‐Net is effective for whole‐body tumor segmentation of PET/CT images. Codes for TS‐Code‐Net are available at: https://github.com/zyj19/TS‐Code‐Net.",
           2,
           "medical_physics"
          ],
          [
           "Statistical cerebrovascular segmentation in three‐dimensional rotational angiography based on maximum intensity projections",
           "10.1118/1.2001820",
           2005,
           "Segmentation of three‐dimensional rotational angiography (3D‐RA) can provide quantitative 3D morphological information of vasculature. The expectation maximization‐(EM‐) based segmentation techniques have been widely used in the medical image processing community, because of the implementation simplicity, and computational efficiency of the approach. In a brain 3D‐RA, vascular regions usually occupy a very small proportion (around 1%) inside an entire image volume. This severe imbalance between the intensity distributions of vessels and background can lead to inaccurate statistical modeling in the EM‐based segmentation methods, and thus adversely affect the segmentation quality for 3D‐RA. In this paper we present a new method for the extraction of vasculature in 3D‐RA images. The new method is fully automatic and computationally efficient. As compared with the original 3D‐RA volume, there is a larger proportion (around 20%) of vessels in its corresponding maximum intensity projection (MIP) image. The proposed method exploits this property to increase the accuracy of statistical modeling with the EM algorithm. The algorithm takes an iterative approach to compiling the 3D vascular segmentation progressively with the segmentation of MIP images along the three principal axes, and use a winner‐takes‐all strategy to combine the results obtained along individual axes. Experimental results on 12 3D‐RA clinical datasets indicate that the segmentations obtained by the new method exhibit a high degree of agreement to the ground truth segmentations and are comparable to those produced by the manual optimal global thresholding method.",
           14,
           "medical_physics"
          ],
          [
           "Evaluation of brachytherapy lung implant dose distributions from photon‐emitting sources due to tissue heterogeneities",
           "10.1118/1.3641872",
           2011,
           "Purpose:Photon‐emitting brachytherapy sources are used for permanent implantation to treat lung cancer. However, the current brachytherapy dose calculation formalism assumes a homogeneous water medium without considering the influence of radiation scatter or tissue heterogeneities. The purpose of this study was to determine the dosimetric effects of tissue heterogeneities for permanent lung brachytherapy.Methods:The MCNP5 v1.40 radiation transport code was used for Monte Carlo (MC) simulations. Point sources with energies of 0.02, 0.03, 0.05, 0.1, 0.2, and 0.4 MeV were simulated to cover the range of pertinent brachytherapy energies and to glean dosimetric trends independent of specific radionuclide emissions. Source positions from postimplant CT scans of five patient implants were used for source coordinates, with dose normalized to 200 Gy at the center of each implant. With the presence of fibrosis (around the implant), cortical bone, lung, and healthy tissues, dose distributions andPTVDVH were calculated using the MCNP *FMESH4 tally and the NIST mass‐energy absorption coefficients. This process was repeated upon replacing all tissues with water. For all photon energies, 109 histories were simulated to achieve statistical errors (k = 1) typically of 1%.Results:The mean PTV doses calculated using tissue heterogeneities for all five patients changed (compared to dose to water) by only a few percent over the examined photon energy range, as did PTV dose at the implant center. ThePTVV100 values were 81.2%, 90.0% (as normalized), 94.3%, 93.9%, 92.7%, and 92.2% for 0.02, 0.03, 0.05, 0.1, 0.2, and 0.4 MeV source photons, respectively. Relative to water, the maximum bone doses were higher by factors of 3.7, 5.1, 5.2, 2.4, 1.2, and 1.0 The maximum lung doses were about 0.98, 0.94, 0.91, 0.94, 0.97, and 0.99. Relative to water, the maximum healthy tissue doses at the mediastinal position were higher by factors of 9.8, 2.2, 1.3, 1.1, 1.1, and 1.1. However, the maximum doses to these healthy tissues were only 3.1, 7.2, 11.3, 10.9, 9.0, and 8.1 Gy while maximum bone doses were 66, 177, 236, 106, 49, and 39 Gy, respectively. Similarly, maximum lung doses were 55, 66, 73, 74, 73, and 73 Gy, respectively.Conclusions:The current brachytherapy dose calculation formalism overestimates PTV dose and significantly underestimates doses to bone and healthy tissue. Further investigation using specific brachytherapy source models and patient‐based CT datasets as MC input may indicate whether the observed trends can be generalized for low‐energy lung brachytherapy dosimetry.",
           8,
           "medical_physics"
          ],
          [
           "3D reconstruction of a patient‐specific surface model of the proximal femur from calibrated x‐ray radiographs: A validation studya)",
           "10.1118/1.3089423",
           2009,
           "Twenty‐three femurs (one plastic bone and twenty‐two cadaver bones) with both nonpathologic and pathologic cases were considered to validate a statistical shape model based technique for three‐dimensional (3D) reconstruction of a patient‐specific surface model from calibrated x‐ray radiographs. The 3D reconstruction technique is based on an iterative nonrigid registration of the features extracted from a statistically instantiated 3D surface model to those interactively identified from the radiographs. The surface models reconstructed from the radiographs were compared to the associated ground truths derived either from a 3D CT‐scan reconstruction method or from a 3D laser‐scan reconstruction method and an average error distance of 0.95 mm were found. Compared to the existing works, our approach has the advantage of seamlessly handling both nonpathologic and pathologic cases even when the statistical shape model that we used was constructed from surface models of nonpathologic bones.",
           33,
           "medical_physics"
          ],
          [
           "Automatic quantitative analysis of in‐stent restenosis using FD‐OCT <i>in vivo</i> intra‐arterial imaging",
           "10.1118/1.4803461",
           2013,
           "Purpose:A new segmentation technique is implemented for automatic lumen area extraction and stent strut detection in intravascular optical coherence tomography (OCT) images for the purpose of quantitative analysis of in‐stent restenosis (ISR). In addition, a user‐friendly graphical user interface (GUI) is developed based on the employed algorithm toward clinical use.Methods:Four clinical datasets of frequency‐domain OCT scans of the human femoral artery were analyzed. First, a segmentation method based on fuzzy C means (FCM) clustering and wavelet transform (WT) was applied toward inner luminal contour extraction. Subsequently, stent strut positions were detected by utilizing metrics derived from the local maxima of the wavelet transform into the FCM membership function.Results:The inner lumen contour and the position of stent strut were extracted with high precision. Compared to manual segmentation by an expert physician, the automatic lumen contour delineation had an average overlap value of 0.917 ± 0.065 for all OCT images included in the study. The strut detection procedure achieved an overall accuracy of 93.80% and successfully identified 9.57 ± 0.5 struts for every OCT image. Processing time was confined to approximately 2.5 s per OCT frame.Conclusions:A new fast and robust automatic segmentation technique combining FCM and WT for lumen border extraction and strut detection in intravascular OCT images was designed and implemented. The proposed algorithm integrated in a GUI represents a step forward toward the employment of automated quantitative analysis of ISR in clinical practice.",
           20,
           "medical_physics"
          ],
          [
           "Photon scatter in portal images: Physical characteristics of pencil beam kernels generated using the <scp>EGS</scp> Monte Carlo code",
           "10.1118/1.598833",
           2002,
           "Pencil beam kernels describing scattered photon fluence behind homogeneous water slabs at various air gap distances were generated using the EGS Monte Carlo code. Photon scatter fluence was scored in separate bins based on the particle's history: singly scattered, multiply scattered, and bremsstrahlung and positron annihilation photons. Simultaneously, the mean energy and mean angle with respect to the incident photon pencil beam were tallied. Kernels were generated for incident photon pencil beams exhibiting monoenergetic spectra of 2.0 and 10.0 MeV, and polyenergetic spectra representative of 6 and 24 MV beams. Reciprocity was used to generate scatter fractions on the central axis for various field sizes, phantom thicknesses, and air gaps. The scatter kernels were further characterized by full width at half‐maximum estimates. Modulation transfer functions were calculated, providing theoretical estimates of the limit of performance of portal imaging systems due to the intrinsic scattering of photon radiation through the patient.",
           27,
           "medical_physics"
          ],
          [
           "Evaluation of the accuracy of fetal dose estimates using TG‐36 data",
           "10.1118/1.2710332",
           2007,
           "The American Association of Physicists in Medicine Radiation Therapy Committee Task Group 36 report (TG‐36) provides guidelines for managing radiation therapy of pregnant patients. Included in the report are data that can be used to estimate the dose to the fetus. The purpose of this study is to evaluate the accuracy of these fetal dose estimates as compared to clinically measured values. TG‐36 calculations were performed and compared with measurements of the fetal dose made in vivo or in appropriately‐designed phantoms. Calculation and measurement data was collected for eight pregnant patients who underwent radiation therapy at the MD Anderson Cancer Center as well as for several fetal dose studies in the literature. The maximum measured unshielded fetal dose was , which was 1.5% of the prescription dose. For all cases, TG‐36 calculations and measured fetal doses differed by up to a factor of 3—the ratio of the calculated to measured dose ranged from 0.34 to 2.93. On average, TG‐36 calculations underestimated the measured dose by 31%. No significant trends in the relationship between the calculated and measured fetal doses were found based on the distance from, or the size of, the treatment field.",
           17,
           "medical_physics"
          ],
          [
           "Commissioning of output factors for uniform scanning proton beams",
           "10.1118/1.3569581",
           2011,
           "Purpose:Current commercial treatment planning systems are not able to accurately predict output factors and calculate monitor units for proton fields. Patient‐specific field output factors are thus determined by either measurements or empirical modeling based on commissioning data. The objective of this study is to commission output factors for uniform scanning beams utilized at the ProCure proton therapy centers.Methods:Using water phantoms and a plane parallel ionization chamber, the authors first measured output factors with a fixed 10 cm diameter aperture as a function of proton range and modulation width for clinically available proton beams with ranges between 4 and 31.5 cm and modulation widths between 2 and 15 cm. The authors then measured the output factor as a function of collimated field size at various calibration depths for proton beams of various ranges and modulation widths. The authors further examined the dependence of the output factor on the scanning area (i.e., uncollimated proton field), snout position, and phantom material. An empirical model was developed to calculate the output factor for patient‐specific fields and the model‐predicted output factors were compared to measurements.Results:The output factor increased with proton range and field size, and decreased with modulation width. The scanning area and snout position have a small but non‐negligible effect on the output factors. The predicted output factors based on the empirical modeling agreed within 2% of measurements for all prostate treatment fields and within 3% for 98.5% of all treatment fields.Conclusions:Comprehensive measurements at a large subset of available beam conditions are needed to commission output factors for proton therapy beams. The empirical modeling agrees well with the measured output factor data. This investigation indicates that it is possible to accurately predict output factors and thus eliminate or reduce time‐consuming patient‐specific output measurements for proton treatments.",
           32,
           "medical_physics"
          ],
          [
           "Implementation of output prediction models for a passively double‐scattered proton therapy system",
           "10.1118/1.4965046",
           2016,
           "PurposeTwo output (cGy/MU) prediction models (one existing and one newly developed) for a passively double‐scattered proton therapy system are implemented and investigated for clinical use. Variations of each model are tested for accuracy in order to determine the most viable prediction model.MethodsThe first output prediction model [model (1)] is a semianalytical model proposed by Kooy et al. [Phys. Med. Biol. 50, 5847–5856 (2005)], which employs three main factors. The first factor (basic output prediction) uses a unique combined parameter [r = (R − M)/M] of range (R) and modulation [M; spread‐out Bragg peak (SOBP) width] along with option specific fitting parameters. The second factor takes into account minor source shifts using a linear fit due to varying beamline configurations for different options. The final factor accounts for a condition where the point of measurement is not at the isocenter or away from the middle of the SOBP based on an inverse‐square correction. The second model [model (2)] is a novel quartic polynomial fit of the basic output prediction whose idea was inspired by the first model. Different variations in the definition of R and M at distal (D) and proximal (P) ends resulted in the exploration of three variations of r for both models: r1 = (RD90 − MD90−P95)/MD90−P95, r2 = [(RD90 + ΔR1) − m × (MD90−P95 + ΔR1)]/[m × (MD90−P95 + ΔR1)], where ΔR1 is an offset between RD80 and RD90 and m is a ratio between MD90−P95 and theoretical , and r3 = [(RD90 − 0.305) − 0.801 × MD90−P95]/(0.801 × MD90−P95), where 0.305 (ΔR2) is an offset between RD90 and RD100 and 0.801 is a ratio between MD90−P95 and measured MD100−P100. Output measurements for 177 sets of R and M from all 24 options are compared to outputs predicted by both the models of three variations of r.ResultsThe mean differences between measurements and predictions ([predicted − measured]/measured × 100%) were −0.41% ± 1.78% (r1), 0.03% ± 1.53% (r2), and 0.05% ± 1.20% (r3) for model (1), and 0.27% ± 1.36% (r1), 0.71% ± 1.51% (r2), and −0.05% ± 1.20% (r3) for model (2). For a passing prediction rate with a difference threshold of ±3%, model (1) showed slightly worse results than model (2) using r1 (91.5% vs 94.4%). In general, small (M < 4 g/cm2) and close‐to‐full modulations produced larger discrepancies. However, 100% output predictions using r3 were confined within ±3% of measurements for both models and the difference between the models was not substantial (mean difference: 0.05% vs −0.05%).ConclusionsThe first existing model has proven to be a successful predictor of output for our compact double‐scattering proton therapy system. The new model performed comparably to the first model and showed better performance in some options due to a great degree of flexibility of a polynomial fit. Both models performed well using r3. Either model with r3 thus can serve well as an output prediction calculator.",
           5,
           "medical_physics"
          ],
          [
           "SU‐GG‐T‐558: OPTIS2 ‐ PSI's New Ocular Proton Therapy Facility",
           "10.1118/1.2962307",
           2008,
           "Since 1984 nearly 5000 patients with eye tumors, primarily ocular melanomas, were treated by a 72 MeV Phillips cyclotron within the OPTIS program (local tumor control 98%@10y). In the frame work of the PROSCAN project a dedicated superconducting cyclotron (COMET) is in clinical operation since February 2007. The aim of OPTIS2 project, an entirely new facility for the treatment ocular tumors with COMET, is to match the clinical success of OPTIS. Using the COMET/PROSCAN facility the beam intensity at the start of the OPTIS2 nozzle is 30 times lower than that currently used at the OPTIS facility. If we would keep using the OPTIS nozzle the treatment time would increase dramatically. Therefore, the new nozzle utilizes a double scattering technique with multiple‐ring second‐scattering foils which increases the nozzle efficiency by factor of 10, keeping the maximum treatment time under one minute. Due to the difference in scattering techniques the OPTIS2 and OPTIS beams are not identical. But the major characteristics, distal‐ and lateral‐ dose fall‐off are comparable. The flatness and symmetry have actually been improved. In OPTIS2 reliance on a single analog X‐ray film provider and extensive operator experience will be diminished by introducing digital imaging and computer aided semi‐automatic patient positioning. A new imaging and patient positioning concept has been developed, bringing together techniques and software already clinically tested at the Center de Protontherapie Orsay (France) and the Hahn Meitner Institut (Germany). OPTIS2 is designed and built from scratch, providing a continuation of the existing proton therapy program OPTIS, with comparable beam characteristics, whilst obtaining its protons from COMET. Beam commissioning and system testing is currently underway. A first patient treatment is scheduled for summer 2008.",
           3,
           "medical_physics"
          ],
          [
           "Dosimetry for ocular proton beam therapy at the Harvard Cyclotron Laboratory based on the ICRU Report 59",
           "10.1118/1.1487425",
           2002,
           "The Massachusetts General Hospital, the Harvard Cyclotron Laboratory (HCL), and the Massachusetts Eye and Ear Infirmary have treated almost 3000 patients with ocular disease using high‐energy external‐beam proton radiation therapy since 1975. The absorbed dose standard for ocular proton therapy beams at HCL was based on a fluence measurement with a Faraday cup (FC). A majority of proton therapy centers worldwide, however, use an absorbed dose standard that is based on an ionization chamber (IC) technique. The ion chamber calibration is deduced from a measurement in a reference  photon field together with a calculated correction factor that takes into account differences in a chamber's response in  and proton fields. In this work, we implemented an ionization chamber‐based absolute dosimetry system for the HCL ocular beamline based on the recommendations given in Report 59 by the International Commission on Radiation Units and Measurements. Comparative measurements revealed that the FC system yields an absorbed dose to water value that is 1.1% higher than was obtained with the IC system. That difference is small compared with the experimental uncertainties and is clinically insignificant. In June of 1998, we adopted the IC‐based method as our standard practice for the ocular beam.",
           30,
           "medical_physics"
          ],
          [
           "Field size dependence of the output factor in passively scattered proton therapy: Influence of range, modulation, air gap, and machine settings",
           "10.1118/1.3152111",
           2009,
           "At the Francis H. Burr Proton Therapy Center field specific output factors (i.e., dose per monitor unit) for patient treatments were modeled for all beamlines (two gantries, fixed stereotactic, and fixed eye beamline). The authors evaluated the accuracy of dose calculation and output model for small fields. Measurements in a water phantom were performed in three of our beamlines quantifying the dependency of the output factor on the field size for a variety of proton ranges. The influence of snout size, air gap, modulation, and second scatterer was investigated. The impact of field size on output depends strongly on the depth of interest. The air gap has a notable influence on small field outputs. A field size specific correction factor to the output is necessary if the latter was modeled or measured without the custom hardware in place. The output was shown to be field size dependent even for large fields, indicating an effect beyond charged particle disequilibrium caused by lateral scatter.",
           29,
           "medical_physics"
          ],
          [
           "Magnetic resonance imaging of microbubbles in a superheated emulsion chamber for brachytherapy dosimetry",
           "10.1118/1.598441",
           2002,
           "This paper describes development of magnetic resonance imaging (MRI) techniques for three‐dimensional (3D) imaging of a position‐sensitive detector for brachytherapy dosimetry. The detector is a 0.5 l chamber containing an emulsion of halocarbon‐115 droplets in a tissue‐equivalent glycerin‐based gel. The halocarbon droplets are highly superheated and expand into vapor microbubbles upon irradiation. Brachytherapy sources can be inserted into the superheated emulsion chamber to create distributions of bubbles. Three‐dimensional MRI of the chamber is then performed. A 3D gradient‐echo technique was optimized for spatial resolution and contrast between bubbles and gel. Susceptibility gradients at the interfaces between bubbles and gel are exploited to enhance contrast so microscopic bubbles can be imaged using relatively large voxel sizes. Three‐dimensional gradient‐echo images are obtained with an isotropic resolution of 300 μm over a  field‐of‐view in an imaging time of 14 min. A post‐processing technique was developed to semi‐automatically segment the bubbles from the images and to assess dose distributions based on the measured bubble densities. Relative dose distributions are computed from MR images for a  brachytherapy source and the results compare favorably to relative radial dose distributions calculated as recommended by Task Group 43 of the American Association of Physicists in Medicine.",
           8,
           "medical_physics"
          ],
          [
           "Radiation dose estimation using preclinical imaging with ‐metaiodobenzylguanidine (MIBG) PET",
           "10.1118/1.3480965",
           2010,
           "Purpose:A pretherapy‐metaiodobenzylguanidine (MIBG) positron emission tomography (PET)/computed tomography (CT) provides a potential method to estimate radiation dose to normal organs, as well as tumors prior to ‐MIBG treatment of neuroblastoma or pheochromocytoma. The aim of this work was to estimate human‐equivalent internal radiation dose of ‐MIBG using PET/CT data in a murine xenograft model.Methods:Athymic mice subcutaneously implanted with NB1691 cells that express high levels of human norepinephrine transporter were imaged using small animal microPET/CT over 96 h (approximate imaging time points: 0.5, 2, 24, 52, and 96 h) after intravenous administration of 3.07–4.84 MBq of ‐MIBG via tail vein. The tumors did not accumulate ‐MIBG to a detectable level. All four animals were considered as control and organ radiation dosimetry was performed. Volumes of interest were drawn on the coregistered CT images for thyroid, heart, lung, liver, kidney, and bladder, and transferred to PET images to obtain pharmacokinetic data. Based on tabulated organ mass distributions for both mice and adult male human, preclinical pharmacokinetic data were extrapolated to their human‐equivalent values. Radiation dose estimations for different age groups were performed using the OLINDA|EXM software with modified tissue weighting factors in the recent International Commission on Radiological Protection (ICRP) Publication 103.Results:The mean effective dose from‐MIBG using weighting factors from ICRP 103 to the adult male was estimated at 0.25 mSv/MBq. In different age groups, effective doses using values from ICRP 103 were estimated as follows: Adult female: 0.34, 15‐yr‐old: 0.39 mSv/MBq, 10‐yr‐old: 0.58 mSv/MBq, 5‐yr‐old: 1.03 mSv/MBq, 1‐yr‐old: 1.92 mSv/MBq, and newborn: 3.75 mSv/MBq. For comparison, the reported effective dose equivalent of ‐NaI for adult male (25% thyroid uptake, MIRD Dose Estimate Report No. 5) was 6.5 mSv/MBq.Conclusions:The authors estimated human‐equivalent internal radiation dose of‐MIBG using preclinical imaging data. As a reference, the effective dose estimation showed that ‐MIBG would deliver less radiation dose than ‐NaI, a radiotracer already being used in patients with thyroid cancer.",
           57,
           "medical_physics"
          ],
          [
           "A dosimetric comparison of  versus  for HDR prostate brachytherapy",
           "10.1118/1.2126821",
           2005,
           "For the purpose of evaluating the use of  for prostate High Dose Rate brachytherapy (HDR), a hypothetical  source is assumed with the exact same design of the new microSelectron source replacing the  active core by pure  metal. Monte Carlo simulation is employed for the full dosimetric characterization of both sources and results are compared following the AAPM TG‐43 dosimetric formalism. Monte Carlo calculated dosimetry results are incorporated in a commercially available treatment planning system , which features an inverse treatment planning option based on a multiobjective dose optimization engine. The quality of prostate HDR brachytherapy using the real  and hypothetical  source is compared in a comprehensive analysis of different prostate implants in terms of the multiobjective dose optimization solutions as well as treatment quality indices such as Dose Volume Histograms (DVH) and the Conformal Index (COIN). Given that scattering overcompensates for absorption in intermediate photon energies and distances in the range of interest to prostate HDR brachytherapy,  proves at least equivalent to  irrespective of prostate volume. This has to be evaluated in view of the shielding requirements for the  energies that are minimal relative to that for .",
           23,
           "medical_physics"
          ],
          [
           "Imaging characteristics of x‐ray capillary optics in digital mammography",
           "10.1118/1.597703",
           2003,
           "Computed radiography (CR) has shown promise in digital mammographic screening due to its good low spatial frequency MTF and its relatively wide exposure latitude. The CR image format has not gained acceptance clinically because of reduced high spatial frequency resolution as compared to film‐screen images. X‐ray capillary optics, aligned between the breast and CR phosphor imaging plate, will capture primary x‐ray photons almost exclusively. Due to the very small angle of acceptance, scattered photons angled more than about 1.6×10−3 radians from primary trajectory will not be accepted at the capillary optic entrance. The virtual elimination of detected scatter means almost 100% of the possible primary contrast should be visible in the image. In addition, the image can be magnified without focal spot blurring. Effective resolution of CR images can be increased by a factor equal to that magnification. Clinical implementation of future capillary optics are expected to be either in the form of a large, stationary, post‐patient optic that accepts primary from the entire breast or a fan‐shaped optic that is scanned across the breast. Measurements of a test capillary optic showed a reduction of scatter fraction to 0.018. Images of a lucite contrast detail phantom revealed a corresponding increase in image contrast when compared to anti‐scatter grid and no grid methods. Spectral transmission measurements using a high‐purity germanium detector showed good primary transmission (45%–50%) in the mammographic energy range. The MTF measurements of both stationary and scanned capillary optics showed improvement at the 5% MTF level to 8.4 mm−1 for scanned optics and 9.2 mm−1 for stationary optics representing a 68% and 84% respective increase over the CR MTF without magnification or capillary optics.",
           24,
           "medical_physics"
          ],
          [
           "Fluorometer for endoscopic diagnosis of tumors",
           "10.1118/1.595521",
           2003,
           "A filter fluorometer suitable for endoscopic applications has been developed for detection and characterization of superficial tumors by the fluorescence of a previously injected, tumor‐specific agent, hematoporphyrin derivative. Fluorescence is excited by violet light conducted through a fiberoptic lightguide in the endoscope, and the fluorescence emission together with reflected violet are collected by another fiberoptic lightguide. The red fluorescence and violet are separated by a dichroic mirror and filter and detected in photomultiplier tubes. The ratio of the fluorescence signal to the reflected violet signal is proportional to the ratio of the fluorescence yield to the violet reflectivity but is insensitive to variations in distance, angle, and violet power. The instrument may be useful for localizing small tumors, and for quantitative measurements of the amount of hematoporphyrin derivative in the tumor, a requirement for accurate dosimetry in photoradiation therapy.",
           40,
           "medical_physics"
          ],
          [
           "Accurate quantification of width and density of bone structures by computed tomography",
           "10.1118/1.2769102",
           2007,
           "In computed tomography (CT), the representation of edges between objects of different densities is influenced by the limited spatial resolution of the scanner. This results in the misrepresentation of density of narrow objects, leading to errors of up to  and more. Our interest is in the imaging and measurement of narrow bone structures, and the issues are the same for imaging with clinical CT scanners, peripheral quantitative CT scanners or micro CT scanners. Mathematical models, phantoms and tests with patient data led to the following procedures: (i) extract density profiles at one‐degree increments from the CT images at right angles to the bone boundary; (ii) consider the outer and inner edge of each profile separately due to different adjacent soft tissues; (iii) measure the width of each profile based on a threshold at fixed percentage of the difference between the soft‐tissue value and a first approximated bone value; (iv) correct the underlying material density of bone for each profile based on the measured width with the help of the density‐versus‐width curve obtained from computer simulations and phantom measurements. This latter curve is specific to a certain scanner and is not dependent on the densities of the tissues within the range seen in patients. This procedure allows the calculation of the material density of bone. Based on phantom measurements, we estimate the density error to be below  relative to the density of normal bone and the bone‐width error about one tenth of a pixel size.",
           29,
           "medical_physics"
          ],
          [
           "Radionuclide spatial distribution and dose deposition for <i>in vitro</i> assessments of <sup>212</sup>Pb‐αVCAM‐1 targeted alpha therapy",
           "10.1002/mp.13969",
           2019,
           "PurposeTargeted alpha therapy (TAT) takes advantage of the short‐range and high‐linear energy transfer of α‐particles and is increasingly used, especially for the treatment of metastatic lesions. Nevertheless, dosimetry of α‐emitters is challenging for the very same reasons, even for in vitro experiments. Assumptions, such as the uniformity of the distribution of radionuclides in the culture medium, are commonly made, which could have a profound impact on dose calculations. In this study we measured the spatial distribution of α‐emitting 212Pb coupled to an anti‐VCAM‐1 antibody (212Pb‐αVCAM‐1) and its evolution over time in the context of in vitro irradiations.MethodsTwo experimental setups were implemented without cells to measure α‐particle count rates and energy spectra in culture medium containing 15 kBq of 212Pb‐α‐VCAM‐1. Silicon detectors were placed above and below cell culture dishes for 20 h. One of the dishes had a 2.5‐µm‐thick mylar‐base allowing easy detection of the α‐particles. Monte Carlo simulations were performed to analyze experimental spectra. Experimental setups were modeled and α‐energy spectra were simulated in the silicon detectors for different decay positions in the culture medium. Simulated spectra were then used to deconvolute experimental spectra to determine the spatial distribution of 212Pb‐αVCAM‐1 in the medium. This distribution was finally used to calculate the dose deposition in cell culture experiments.ResultsExperimental count rates and energy spectra showed differences in measurements taken at the top and the bottom of dishes and temporal variations that did not follow 212Pb decay. The radionuclide spatial distribution was shown to be composed of a uniform distribution and concentration gradients at the top and the bottom, which were subjected to temporal variations that may be explained by gravity and electrostatic attraction. The absorbed dose in cells calculated from this distribution was compared with the dose expected for a uniform and static distribution and found to be 1.75 times higher, which is highly significant to interpret biological observations.ConclusionsThis study demonstrated that accurate dosimetry of α‐emitters requires the experimental determination of radionuclide spatial and temporal distribution and highlighted that in vitro assessment of dose for TAT cannot only rely on a uniform distribution of activity in the culture medium. The reliability and reproducibility of future experiments should benefit from specifically developed dosimetry tools and methods.",
           7,
           "medical_physics"
          ],
          [
           "Comprehensive Brachytherapy: Physical and Clinical Aspects.",
           "10.1118/1.4826194",
           2013,
           "Comprehensive Brachytherapy: Physical and Clinical Aspects. Venselaar J., Baltas D., Meigooni A., Hoskin P., Imaging in Medical Diagnosis and Therapy, William R. Hendee, Series Editor. CRC/Taylor & Francis Group, Boca Raton, FL, 2013. Hardback 535 pp. Price: $199.95. ISBN: 9781439844984.",
           3,
           "medical_physics"
          ],
          [
           "Assessment of variation in Elekta<sup>®</sup> plastic spherical‐calibration phantom and its impact on the Leksell Gamma Knife<sup>®</sup> calibration",
           "10.1118/1.3481508",
           2010,
           "Purpose:Traditionally, the dose‐rate calibration (output) of the Leksell Gamma Knife® (LGK) unit is performed using a 160 mm diameter plastic spherical phantom provided by the vendor of the LGK, Elekta Instrument AB. The purpose of this study was to evaluate variations in the Elekta spherical phantom and to assess its impact and use for the LGK calibration.Methods:Altogether, 13 phantoms from six different centers were acquired, 10 of these phantoms were manufactured within the past 10 years and the last 3 approximately 15–20 years ago. To assess variation in phantoms, the diameter and mass densities were measured. To assess the impact on LGK calibration, the output of two models of LGK (LGK Perfexion™ and LGK 4C) were measured under identical irradiation conditions using all 13 phantoms for each LGK model.Results:The mean measured deviation in diameter from expected nominal 160 mm for 13 phantoms was 0.51 mm (range of 0.09–1.51 mm). The mean measured phantom mass density for 13 phantoms was (range of ). The percentage deviation of output for individual phantom from mean of 13 phantom outputs ranged from −0.37% to 0.55% for LGK Perfexion™. Similarly, the percentage deviation of output for individual phantom from mean of 13 phantom outputs ranged from −0.72% to 0.47% for LGK 4C.Conclusions:This study demonstrated that small variations in terms of phantom size and mass density of the phantom material do not have a significant impact on dose‐rate measurements of the Leksell Gamma Knife®. Also, date of manufacture of the phantom did not show up to be a significant factor in this study.",
           18,
           "medical_physics"
          ],
          [
           "An improved analytical model for CT dose simulation with a new look at the theory of CT dose",
           "10.1118/1.2122507",
           2005,
           "Gagne [Med. Phys. 16, 29–37 (1989)] has previously described a model for predicting the sensitivity and dose profiles in the slice‐width  direction for CT scanners. The model, developed prior to the advent of multidetector CT scanners, is still widely used; however, it does not account for the effect of anode tilt on the penumbra or include the heel effect, both of which are increasingly important for the wider beams (up to ) of contemporary, multidetector scanners. Additionally, it applied only on (or near) the axis of rotation, and did not incorporate the photon energy spectrum. The improved model described herein transcends all of the aforementioned limitations of the Gagne model, including extension to the peripheral phantom axes. Comparison of simulated and measured dose data provides experimental validation of the model, including verification of the superior match to the penumbra provided by the tilted‐anode model, as well as the observable effects on the cumulative dose distribution. The initial motivation for the model was to simulate the quasiperiodic dose distribution on the peripheral, phantom axes resulting from a helical scan series in order to facilitate the implementation of an improved method of CT dose measurement utilizing a short ion chamber, as proposed by Dixon [Med. Phys. 30, 1272–1280 (2003)]. A more detailed set of guidelines for implementing such measurements is also presented in this paper. In addition, some fundamental principles governing CT dose which have not previously been clearly enunciated follow from the model, and a fundamental (energy‐based) quantity dubbed “CTDI‐aperture” is introduced.",
           35,
           "medical_physics"
          ],
          [
           "Metal–polysiloxane shields for radiation therapy of maxillo–facial tumors",
           "10.1118/1.596724",
           2003,
           "In the treatment of some head and neck lesions with high‐intensity radiation (teletherapy), an essential procedure is the application of an individually customized shielding appliance, which is designed, modeled, and formed into a working extra‐ or intraoral stent for the purpose of sparing healthy tissues. The present state of the art is slow and technique intensive, which can add to patient discomfort and inconvenience during molding and fabrication. A new formulation is described, which offers speed and ease of forming a moldable composite stent especially for intraoral use. Interleaved stacks of calibrated thin radiochromic film strips and soft‐tissue‐simulating plastic (polystyrene) layers gave a means of mapping one‐ or two‐dimensional profiles of dose distributions adjacent to the high‐density shielding materials using a spectrophotometer equipped with a gel scanner or a scanning laser‐beam microdensitometer. Tests using collimated gamma‐ray beams from a 60Co teletherapy unit were made in order to measure the dose distribution near interfaces of tissue‐simulating polymer and the composite stent material with and without mixtures of metals (Ag–Cu and Sn–Sb). These results show that quickly formed composites made of a flexible resin with high concentrations of powdered spherical metal alloys provide effective custom‐designed shielding, and, with a thin overlayer of the resin without metal, a diminished back‐scattered radiation dose to normal tissues. An example of a successful formulation is a mixture of 90% by weight Ag–Cu alloy powder in a vinyl polysiloxane resin. This material is a moldable putty which, upon polymerization, forms a rigid elastomeric material, providing a half‐value layer of ≊2.5 to 2.8 cm for a gamma‐ray beam from a 60Co source.",
           24,
           "medical_physics"
          ],
          [
           "Calculation of enhanced dynamic wedge factors for symmetric and asymmetric photon fields",
           "10.1118/1.598313",
           2002,
           "A method is introduced to calculate wedge factors for an enhanced dynamic wedge (EDW). An analytic formula has been derived that allows the determination of wedge factors at the center of symmetric and asymmetric photon fields. The formalism is an extension of the “MU fraction approximation,” which holds that the dynamic wedge factor is equal to the fraction of MU delivered to the point of calculation. Extensive data are presented, comparing measured enhanced dynamic wedge factors with the current method and the MU fraction model for both symmetric and asymmetric fields. For both 6 and 18 MV photons, the current method demonstrates improved results: Agreement to within 1% is obtained in all symmetric fields and within 2% for all asymmetric fields compared with discrepancies of up to 4% obtained with the MU fraction model.",
           40,
           "medical_physics"
          ],
          [
           "Methods to determine the fluorescence and Auger spectra due to decay of radionuclides or due to a single atomic‐subshell ionization and comparisons with experiments",
           "10.1118/1.599020",
           2002,
           "The aim of this work is to describe methods of determining the fluorescence and Auger spectra due to decay of radionuclides or a single atomic‐subshell ionization. First discussed is the electron vacancy generation in an atomic subshell by ionization, internal‐conversion decay, or electron‐capture decay. Later discussed is the status of electron vacancy following emission of fluorescence x rays and Auger electrons. Special attention is given to the relaxation probabilities and the procedures to calculate energies of released electrons. Also discussed are the Monte Carlo and deterministic methods to calculate vacancy cascades.",
           17,
           "medical_physics"
          ],
          [
           "New low‐contrast resolution phantoms for computed tomography",
           "10.1118/1.598516",
           2002,
           "Computed tomography (CT) has been established as a major imaging modality in diagnostic radiology. Accordingly, acceptance testing and quality control of CT scanners is of great importance. While most procedures and phantoms for testing are widely accepted, there is still discussion and uncertainty about low‐contrast (LC) sensitivity. In our opinion this unsatisfactory situation is caused at least in part by the lack of suitable phantoms for LC resolution measurements. We investigated the commonly used phantoms for LC detectability, the Catphan, and for LC resolution, the ATS phantom. While the Catphan showed stable object contrasts, the ATS phantom's measured contrast exhibited a strong dependence on temperature and x‐ray quality. Based on newly developed polyurethane resin materials, we designed and tested a LC resolution phantom with several different contrast steps. The object contrasts showed no dependence on temperature and beam quality. The new LC resolution phantom proved to be very suitable for measuring a scanner's low‐contrast sensitivity in the image plane, one of the most important image quality parameters. To assess LC resolution in three dimensions we designed an additional phantom with rows of spherical objects. A first prototype was evaluated in a multicenter study. The setup proved to be very helpful to quantify the in‐plane and axial LC sensitivity of spiral CT scan modes.",
           20,
           "medical_physics"
          ],
          [
           "The dosimetric properties of an intraoperative radiation therapy applicator system for a Mevatron‐80",
           "10.1118/1.596338",
           2003,
           "An applicator system for intraoperative radiation therapy has been fabricated which does not require physical docking with the accelerator. A dosimetric study has been completed which documents the properties of this system for a variety of electron beam energies, applicator sizes, collimator settings, both primary and secondary, and source–surface distance (SSD) settings. Sensitivity of the system to common misalignment errors was also determined. Results indicate (a) applicator leakage of less than 5%, (b) beam flatness to within plus or minus 5% at the dMAX with a single primary collimator setting, (c) smooth changes in output with cone size, beam energy and SSD, and (d) negligible changes in dose distributions within alignment errors permitted by the system.",
           10,
           "medical_physics"
          ],
          [
           "EchoSeed Model 6733 Iodine‐125 brachytherapy source: Improved dosimetric characterization using the MCNP5 Monte Carlo code",
           "10.1118/1.4736418",
           2012,
           "This study primarily aimed to obtain the dosimetric characteristics of the Model 6733 125I seed (EchoSeed) with improved precision and accuracy using a more up‐to‐date Monte‐Carlo code and data (MCNP5) compared to previously published results, including an uncertainty analysis. Its secondary aim was to compare the results obtained using the MCNP5, MCNP4c2, and PTRAN codes for simulation of this low‐energy photon‐emitting source. The EchoSeed geometry and chemical compositions together with a published 125I spectrum were used to perform dosimetric characterization of this source as per the updated AAPM TG‐43 protocol. These simulations were performed in liquid water material in order to obtain the clinically applicable dosimetric parameters for this source model. Dose rate constants in liquid water, derived from MCNP4c2 and MCNP5 simulations, were found to be 0.993 cGyh−1 U−1 (±1.73%) and 0.965 cGyh−1 U−1 (±1.68%), respectively. Overall, the MCNP5 derived radial dose and 2D anisotropy functions results were generally closer to the measured data (within ±4%) than MCNP4c and the published data for PTRAN code (Version 7.43), while the opposite was seen for dose rate constant. The generally improved MCNP5 Monte Carlo simulation may be attributed to a more recent and accurate cross‐section library. However, some of the data points in the results obtained from the above‐mentioned Monte Carlo codes showed no statistically significant differences. Derived dosimetric characteristics in liquid water are provided for clinical applications of this source model.",
           8,
           "medical_physics"
          ],
          [
           "Spatial response of synthetic microDiamond and diode detectors measured with kilovoltage synchrotron radiation",
           "10.1002/mp.12733",
           2017,
           "PurposeTo map the spatial response of four solid‐state radiation detectors of types commonly used for radiotherapy dosimetry.MethodsPTW model 60016 Diode P, 60017 Diode E, 60018 Diode SRS, and 60019 microDiamond detectors were radiographed using a high resolution conventional X‐ray system. Their spatial response was then investigated using a 0.1 mm diameter beam of 95 keV average energy photons generated by a synchrotron. The detectors were scanned through the beam while their signal was recorded as a function of position, to map the response. These 2D response maps were created in both the end‐on and side‐on orientations.ResultsThe results show the location and size of the active region. End‐on, the active area was determined to be centrally located and within 0.2 mm of the manufacturer's specified diameter. The active areas of the 60016 Diode P, 60017 Diode E, 60018 Diode SRS detectors are uniform to within approximately 5%. The 60019 microDiamond showed local variations up to 30%. The extra‐cameral signal in the microDiamond was calculated from the side‐on scan to be approximately 8% of the signal from the active element.ConclusionsThe spatial response of four solid‐state detectors has been measured. The technique yielded information about the location and uniformity of the active area, and the extra‐cameral signal, for the beam quality used.",
           25,
           "medical_physics"
          ],
          [
           "Fiber‐optic, real‐time dosimeter based on optically stimulated luminescence of  and KBr:Eu for potential use in the radiotherapy of cancer",
           "10.1118/1.1758349",
           2004,
           "This thesis describes a single‐fiber dosimetry system based on optically stimulated luminescence (OSL) of artificially grown single crystals of  and KBr:Eu, with potential application in the medical field, especially in radio oncology. Small fiber‐shaped dosimeters with dimensions (diameter/length) on the order of 500 μm/5 mm are attached to one end of an optical fiber, resulting in fiber probes with diameters of less than 1 mm and lengths of up to 15 m. The opposite end of the fiber is connected to an OSL reader that contains a stimulation light source (laser) and a photomultiplier tube that is used for luminescence detection. During irradiation, an optomechanical shutter periodically allows laser light to be transmitted down the optical fiber, to stimulate the luminescence response from the dosimeter being irradiated at a remote location. The luminescence measured during each interval of laser stimulation is indicative of the radiation dose absorbed in the dosimeter since the previous stimulation. The integral absorbed dose is obtained via a summation procedure from the measured dose fractions. Several operating procedures and data processing algorithms were developed in order to increase the speed and accuracy of the measurements, and integrated into the software that controls automated operation of the OSL readers. Periodic modulation of the stimulation also allows the OSL signal to be discriminated from background fluorescence, and thus yields measurements that are unaffected by Čerenkov light (the so‐called “stem effect”). Depending on the type of material used, the speed of the measurements, expressed as the time required to estimate an individual dose fraction, can be as short as 67 ms. Integral dose estimates from real‐time OSL of  and KBr:Eu were obtained for water‐phantom irradiations performed with medical teletherapy sources, and were found to agree within 3.7% and 2.8%, respectively, with reference measurements from ionization chambers. We also investigated the possibility of using the fiber OSL readers for other purposes, such as two‐dimensional mapping of dose distributions on compacted layers of  grains, and detection of low‐level doses, for possible application in Homeland Security projects.",
           2,
           "medical_physics"
          ],
          [
           "Comparison of organ doses for patients undergoing balloon brachytherapy of the breast with HDR  or electronic sources using Monte Carlo simulations in a heterogeneous human phantoma)",
           "10.1118/1.3292292",
           2010,
           "Purpose:Accelerated partial breast irradiation via interstitial balloon brachytherapy is a fast and effective treatment method for certain early stage breast cancers. The radiation can be delivered using a conventional high‐dose rate (HDR) gamma‐emitting source or a novel electronic brachytherapy (eBx) source which uses lower energy x rays that do not penetrate as far within the patient. A previous study [A. Dickler, M. C. Kirk, N. Seif, K. Griem, K. Dowlatshahi, D. Francescatti, and R. A. Abrams, “A dosimetric comparison of MammoSite high‐dose‐rate brachytherapy and Xoft Axxent electronic brachytherapy,” Brachytherapy 6, 164–168 (2007)] showed that the target dose is similar for HDR  and eBx. This study compares these sources based on the dose received by healthy organs and tissues away from the treatment site.Methods:A virtual patient with left breast cancer was represented by a whole‐body, tissue‐heterogeneous female voxel phantom. Monte Carlo methods were used to calculate the dose to healthy organs in a virtual patient undergoing balloon brachytherapy of the left breast with HDR or eBx sources. The dose‐volume histograms for a few organs which received large doses were also calculated. Additional simulations were performed with all tissues in the phantom defined as water to study the effect of tissue inhomogeneities.Results:For both HDR and eBx, the largest mean organ doses were received by the ribs, thymus gland, left lung, heart, and sternum which were close to the brachytherapy source in the left breast. eBx yielded mean healthy organ doses that were more than a factor of  smaller than for HDR  for all organs considered, except for the three closest ribs. Excluding these ribs, the average and median dose‐reduction factors were  and , respectively. The volume distribution of doses in nearby soft tissue organs that were outside the PTV were also improved with eBx. However, the maximum dose to the closest rib with the eBx source was 5.4 times greater than that of the HDR  source. The ratio of tissue‐to‐water maximum rib dose for the eBx source was .Conclusions:The results of this study indicate that eBx may offer lower toxicity to most healthy tissues, except nearby bone. TG‐43 methods have a tendency to underestimate dose to bone, especially the ribs. Clinical studies evaluating the negative health effects caused by irradiating healthy organs are needed so that physicians can better understand when HDR or eBx might best benefit a patient.",
           22,
           "medical_physics"
          ],
          [
           "Monte Carlo modeling of small photon fields: Quantifying the impact of focal spot size on source occlusion and output factors, and exploring miniphantom design for small‐field measurements",
           "10.1118/1.3152866",
           2009,
           "The accuracy with which Monte Carlo models of photon beams generated by linear accelerators (linacs) can describe small‐field dose distributions depends on the modeled width of the electron beam profile incident on the linac target. It is known that the electron focal spot width affects penumbra and cross‐field profiles; here, the authors explore the extent to which source occlusion reduces linac output for smaller fields and larger spot sizes. A BEAMnrc Monte Carlo linac model has been used to investigate the variation in penumbra widths and small‐field output factors with electron spot size. A formalism is developed separating head scatter factors into source occlusion and flattening filter factors. Differences between head scatter factors defined in terms of in‐air energy fluence, collision kerma, and terma are explored using Monte Carlo calculations. Estimates of changes in kerma‐based source occlusion and flattening filter factors with field size and focal spot width are obtained by calculating doses deposited in a narrow 2 mm wide virtual “milliphantom” geometry. The impact of focal spot size on phantom scatter is also explored. Modeled electron spot sizes of 0.4–0.7 mm FWHM generate acceptable matches to measured penumbra widths. However the 0.5 cm field output factor is quite sensitive to electron spot width, the measured output only being matched by calculations for a 0.7 mm spot width. Because the spectra of the unscattered primary  and head‐scattered  photon energy fluences differ, miniphantom‐based collision kerma measurements do not scale precisely with total in‐air energy fluence  but with . For most field sizes, on‐axis collision kerma is independent of the focal spot size; but for a 0.5 cm field size and 1.0 mm spot width, it is reduced by around 7% mostly due to source occlusion. The phantom scatter factor of the 0.5 cm field also shows some spot size dependence, decreasing by 6% (relative) as spot size is increased from 0.1 to 1.0 mm. The dependence of small‐field source occlusion and output factors on the focal spot size makes this a significant factor in Monte Carlo modeling of small  fields. Changes in penumbra width with spot size are not sufficiently large to accurately pinpoint spot widths. Consequently, while Monte Carlo models based exclusively on large‐field data can quite accurately predict small‐field profiles and PDDs, in the absence of experimental methods of determining incident electron beam profiles it will remain necessary to measure small‐field output factors, fine‐tuning modeled spot sizes to ensure good matching between the Monte Carlo and the measured output factors.",
           71,
           "medical_physics"
          ],
          [
           "Impact of interseed attenuation and tissue composition for permanent prostate implants",
           "10.1118/1.2168295",
           2006,
           "The purpose is to evaluate the impact of interseed attenuation and prostate composition for prostate treatment plans with  permanent seed implants using the Monte Carlo (MC) method. The effect of seed density (number of seeds per prostate unit volume) is specifically investigated. The study focuses on treatment plans that were generated for clinical cases. For each plan, four different dose calculation techniques are compared: TG‐43 based calculation, superposition MC, full MC with water prostate, and full MC with realistic prostate tissue. The prostate tissue description is from the ICRP report 23 (W. S. Snyer, M. J. Cook, E. S. Nasset, L. R. Karkhausen, G. P. Howells, and I. H. Tipton, “Report of the task group on reference man,” Technical Report 23, International Commission on Radiological Protection, 1974). According to the comparisons, the seed density has an influence on interseed attenuation. A plan with a typical low seed density ( seeds in a  prostate) suffers a 1.2% drop in the CTV  value due to interseed attenuation. A drop of 3.0% is calculated for a higher seed density (75 0.3  seeds, same prostate). The influence of the prostate composition is similar for all seed densities and prostate sizes. The difference between MC simulations in water and MC simulations in prostate tissue is between 4.4% and 4.8% for the  parameter. Overall, the effect on  is ranging from 5.8% to 12.8% when comparing clinically approved TG‐43 and MC simulations in prostate tissue. The impact varies from one patient to the other and depends on the prostate size and the number of seeds. This effect can reach a significant level when reporting correlations between clinical effect and deposited dose.",
           60,
           "medical_physics"
          ],
          [
           "Investigation of energy dependence of EBT and EBT‐2 Gafchromic film",
           "10.1118/1.3291622",
           2010,
           "Purpose:The purpose of this study was to quantify the extent of energy dependence of Gafchromic film to x‐ray energies ranging in quality from 105 kVp to 6 MV, and relate this dependency to the film's chemical composition and date of production.Methods:Lots of Gafchromic EBT film manufactured in 2004 and 2005 together with more recent batches produced in 2007 were evaluated for energy dependence. Multiple batches of EBT‐2 film were also evaluated. Energy dependence was quantified as—the ratio of net optical density (netOD) measured at a given energy  relative to the netOD measured at 6 MV, as measured on a linear accelerator.  was evaluated for beam qualities of 105 and 220 kVp on a clinical orthovoltage unit using two separate techniques—a flatbed scanner (Epson) and a real‐time fiber‐optic readout system. Neutron activation analysis for chlorine and bromine content was performed on all the films to determine whether the composition of the film had changed between batches of film exhibiting different energy dependence responses.Results:For batches of EBT manufactured in 2007, was 0.75 and  was 0.85, indicating an under‐response at orthovoltage energies. These results were confirmed using both the Epson flatbed scanner as well as the real‐time readout system. For batches of EBT film manufactured before 2006,  ranged from 0.9 to 1.0. The results from the neutron activation analysis confirmed a direct relationship between the concentration of chlorine and the magnitude of under‐response at orthovoltage energies. EBT‐2 film exhibited  values ranging from 0.79 (under‐response) to 1.20 (over‐response) among batches containing varying concentrations of bromine, chlorine, and potassium.Conclusions:The results of this study indicated that differences in energy response of EBT and EBT‐2 films were due to differences in the chemical composition and therefore the effective atomic number of the film, which have changed over time. To achieve an energy independent dosimeter over a range of kilovoltage energies, the effective atomic number of the dosimeter must be closely matched to that of water. Small deviations in chemical composition can lead to large deviations in response as a function of energy.",
           70,
           "medical_physics"
          ],
          [
           "Verification of the plan dosimetry for high dose rate brachytherapy using metal–oxide–semiconductor field effect transistor detectors",
           "10.1118/1.2736288",
           2007,
           "The feasibility of a recently designed metal–oxide–semiconductor field effect transistor (MOSFET) dosimetry system for dose verification of high dose rate (HDR) brachytherapy treatment planning was investigated. MOSFET detectors were calibrated with a  NE‐2571 Farmer‐type ionization chamber in water. Key characteristics of the MOSFET detectors, such as the energy dependence, that will affect phantom measurements with HDR  sources were measured. The MOSFET detector was then applied to verify the dosimetric accuracy of HDR brachytherapy treatments in a custom‐made water phantom. Three MOSFET detectors were calibrated independently, with the calibration factors ranging from . A distance dependent energy response was observed, significant within  from the source. The new MOSFET detector has a good reproducibility , small angular effect , and good dose linearity . It was observed that the MOSFET detectors had a linear response to dose until the threshold voltage reached approximately  for  source measurements. Further comparison of phantom measurements using MOSFET detectors with dose calculations by a commercial treatment planning system for computed tomography‐based brachytherapy treatment plans showed that the mean relative deviation was  for dose points  away from the source and  for dose points located  away. The percentage deviations between the measured doses and the planned doses were below 5% for all the measurements. The MOSFET detector, with its advantages of small physical size and ease of use, is a reliable tool for quality assurance of HDR brachytherapy. The phantom verification method described here is universal and can be applied to other HDR brachytherapy treatments.",
           47,
           "medical_physics"
          ],
          [
           "An unsupervised automatic segmentation algorithm for breast tissue classification of dedicated breast computed tomography images",
           "10.1002/mp.12920",
           2018,
           "PurposeTo develop and evaluate a new automatic classification algorithm to identify voxels containing skin, vasculature, adipose, and fibroglandular tissue in dedicated breast CT images.MethodsThe proposed algorithm combines intensity‐ and region‐based segmentation methods with energy minimizing splines and unsupervised data mining approaches for classifying and segmenting the different tissue types. Breast skin segmentation is achieved by a region‐growing method which uses constraints from the previously extracted skin centerline to add robustness to the model and to reduce the false positive rate. An energy minimizing active contour model is then used to classify adipose tissue voxels by including gradient flow and region‐based features. Finally, blood vessels are separated from fibroglandular tissue by a k‐means clustering algorithm based on automatically extracted shape‐based features. To evaluate the accuracy of the algorithm, two sets of 15 different patient breast CT scans, each acquired with different breast CT systems and acquisition settings were obtained. Three slices from each scan were manually segmented under the supervision of an experienced breast radiologist and considered the gold standard. Comparisons with manual segmentation were quantified using five similarity metrics: Dice similarity coefficient (DSC), sensitivity, conformity coefficient, and two Hausdorff distance measures. To evaluate the robustness to image noise, the segmentation was repeated after separately adding Gaussian noise with increasing standard deviation (in four steps, from 0.01 to 0.04) to an additional 15 slices from the first dataset. In addition, to evaluate vasculature classification, three different pre‐ and postcontrast injection patient breast CT images were classified and compared. Finally, DSC was also used for quantitative comparisons with previously proposed approaches for breast CT tissue classification using 10 images from the first dataset.ResultsThe algorithm showed a high accuracy in classifying the different tissue types for both breast CT systems, with an average DSC of 95% and 90% for the first and second image dataset, respectively. Furthermore, it demonstrated to be robust to image noise with a robustness to image noise of 85%, 83%, 79%, and 71% for the images corrupted with the four increasing noise levels. Previous methods for breast tissues classification resulted, for the tested dataset, in an average global DSC of 87%, while our approach resulted in a global average DSC of 94.5%.ConclusionsThe proposed algorithm resulted in accurate and robust breast tissue classification, with no prior training or threshold setting. Potential applications include breast density quantification and tissue pattern characterization (both biomarkers of cancer development), simulation‐based radiation dose analysis, and patient data‐based phantom design, which could be used for further breast imaging research.",
           25,
           "medical_physics"
          ],
          [
           "Pre‐discard estimation of radioactivated materials in positron emission tomography cyclotron systems and concrete walls of a cyclotron vault",
           "10.1002/mp.13492",
           2019,
           "PurposeThe concrete vault, cyclotron body, and peripheral equipment in a cyclotron room become radioactivated by neutrons generated by operating an unshielded cyclotron. Radionuclides and the amounts of radioactivated materials must be identified before discarding a cyclotron system. The present study aimed to reduce the amounts of concrete from cyclotron vaults, as well as cyclotron components and peripheral equipment, that will be disposed of as radioactivated waste by clarifying the nature and quantity of radioactivated materials remaining in facilities after cyclotron operations have ceased.MethodsCylindrical concrete cores were bored into all four walls, ceiling, and floor of a room where a Cypris 370 cyclotron had been operated for 22.8 yr and then cooled for 40 months. The accelerated particles comprised protons and deuterons with constant energy of 18 and 10 MeV, respectively. The types and amounts of radionuclides in these cores, in 38 components of the cyclotron including the yoke, and in 13 pieces of equipment in the room, were determined by γ‐ray spectrometry. Concentrations of radioactivity were also calculated using an updated version of Particle and Heavy Ion Transport System and DCHAIN‐SP. Amounts of materials with both measured and calculated total radioactivity concentration (ΣD) of <0.1 Bq/g were identified as being nonradioactivated.ResultsThe major radionuclides in the concrete were 60Co and 152Eu. The radioactivated concrete was distributed to a depth of <38 cm. Most cyclotron components and equipment were radioactivated by neutrons. The major radionuclides in cyclotron components and equipment were 54Mn, 60Co, and 65Zn. A 33% volume of the yoke was regarded as nonradioactivated.ConclusionsThe estimated amount of radioactivated waste in the concrete was about 70,000 kg (12.5% of the total concrete). Most components of the cyclotron except for the 33% volume of the yoke (20% of the cyclotron body), as well as most peripheral equipment in the room, were radioactivated. Part‐by‐part assessments of radioactive materials using measurements and calculations could distinguish nonradioactive from radioactive materials before they are discarded.",
           1,
           "medical_physics"
          ],
          [
           "Description and dosimetric verification of the <scp>PEREGRINE</scp> Monte Carlo dose calculation system for photon beams incident on a water phantom",
           "10.1118/1.1381551",
           2002,
           "PEREGRINE is a three‐dimensional Monte Carlo dose calculation system written specifically for radiotherapy. This paper describes the implementation and overall dosimetric accuracy of PEREGRINE physics algorithms, beam model, and beam commissioning procedure. Particle‐interaction data, tracking geometries, scoring, variance reduction, and statistical analysis are described. The BEAM code system is used to model the treatment‐independent accelerator head, resulting in the identification of primary and scattered photon sources and an electron contaminant source. The magnitude of the electron source is increased to improve agreement with measurements in the buildup region in the largest fields. Published measurements provide an estimate of backscatter on monitor chamber response. Commissioning consists of selecting the electron beam energy, determining the scale factor that defines dose per monitor unit, and describing treatment‐dependent beam modifiers. We compare calculations with measurements in a water phantom for open fields, wedges, blocks, and a multileaf collimator for 6 and 18 MV Varian Clinac 2100C photon beams. All calculations are reported as dose per monitor unit. Aside from backscatter estimates, no additional, field‐specific normalization is included in comparisons with measurements. Maximum discrepancies were less than either 2% of the maximum dose or 1.2 mm in isodose position for all field sizes and beam modifiers.",
           137,
           "medical_physics"
          ],
          [
           "Computed tomography dose measurements with radiochromic films and a flatbed scanner",
           "10.1118/1.3271584",
           2009,
           "Gafchromic® XR‐QA films were developed for patient dosimetry in diagnostic radiology. A possible application of these films is the measurement of doses in computed tomography. In this study a method to evaluate the CTDI using Gafchromic XR‐QA film and a flatbed scanner was developed and tested. Film samples were cut to dimensions of  in order to have an integration area similar to that of a pencil ionization chamber, with the possibility of changing the integration length. Prior to exposing these films to a computed tomography beam, the angular dependence of the film dose response was investigated by exposing film strips to a static x‐ray beam at different angles in the range 0°–180°. A difference of 49% was found between the response with the axis beam parallel to the film surface (90°) and with the axis beam perpendicular (0° and 180°). Integrating over a 360° exposure like the one in computed tomography, a difference of less than 2% was estimated, which is comparable with the measurement error obtainable with XR‐QA film. A calibration with a CT beam in the scout mode was performed and film strips were then exposed to single axial scans and to helical scans both in air and in phantoms. Two different types of flatbed scanners were used to read the film samples, a Microtek ScanMaker 9800XL scanner and an Epson Expression 10000 XL scanner, and the accuracy of the results were compared. For beam collimations above 10 mm differences between CTDI measured by film and CTDI measured by ionization chamber below 9% were found for the Epson scanner, with an average estimated error at  level of 5%. For the Microtek scanner and for the same film samples, differences below 11% with an average error at  level of 8% were founded. The  uncertainty of the measured CTDI was provided by the method for each measurement, and it was shown that about the 95% of the differences between the CTDI measurements with radiochromic films and with the ionization chamber were below the estimated  uncertainty, for both scanners. After an accurate calibration procedure and the consideration of the uncertainty associated with the measurement, Gafchromic® XR‐QA films can be used to evaluate the CTDI.",
           39,
           "medical_physics"
          ],
          [
           "The three parameter equivalent spectra as an index of beam quality",
           "10.1118/1.596223",
           2003,
           "A parametric spectral model based on the work of Birch and Marshall is used to characterize the x‐ray spectra of a specific x‐ray system. Using least‐squares comparison between measured and calculated attenuation data, an equivalent spectrum (EQSPEC) is iteratively found which very closely matches the measured attenuation characteristics of the x‐ray system. The resulting parametric spectrum is a function of the anode angle (θ), equivalent kilovoltage (kVeq), and the equivalent aluminum filtration (Aleq), and these three parameters can serve as very concise yet very accurate indices of beam quality. The utility of the EQSPEC for characterization and reporting of x‐ray spectra (and thus beam quality) may have numerous applications in diagnostic imaging procedures where spectral quality is an important consideration.",
           36,
           "medical_physics"
          ],
          [
           "Comparison of different computed radiography systems: Physical characterization and contrast detail analysis",
           "10.1118/1.3284539",
           2010,
           "Purpose:In this study, five different units based on three different technologies—traditional computed radiography (CR) units with granular phosphor and single‐side reading, granular phosphor and dual‐side reading, and columnar phosphor and line‐scanning reading—are compared in terms of physical characterization and contrast detail analysis.Methods:The physical characterization of the five systems was obtained with the standard beam condition RQA5. Three of the units have been developed by FUJIFILM (FCR ST‐VI, FCR ST‐BD, and FCR Velocity U), one by Kodak (Direct View CR 975), and one by Agfa (DX‐S). The quantitative comparison is based on the calculation of the modulation transfer function (MTF), noise power spectrum (NPS), and detective quantum efficiency (DQE). Noise investigation was also achieved by using a relative standard deviation analysis. Psychophysical characterization is assessed by performing a contrast detail analysis with an automatic reading of CDRAD images.Results:The most advanced units based on columnar phosphors provide MTF values in line or better than those from conventional CR systems. The greater thickness of the columnar phosphor improves the efficiency, allowing for enhanced noise properties. In fact, NPS values for standard CR systems are remarkably higher for all the investigated exposures and especially for frequencies up to 3.5 lp/mm. As a consequence, DQE values for the three units based on columnar phosphors and line‐scanning reading, or granular phosphor and dual‐side reading, are neatly better than those from conventional CR systems. Actually, DQE values of about 40% are easily achievable for all the investigated exposures.Conclusions:This study suggests that systems based on the dual‐side reading or line‐scanning reading with columnar phosphors provide a remarkable improvement when compared to conventional CR units and yield results in line with those obtained from most digital detectors for radiography.",
           23,
           "medical_physics"
          ],
          [
           "Electron beam therapy with transverse magnetic fields",
           "10.1118/1.598490",
           2002,
           "Detailed Monte Carlo electron transport simulations were carried out for the purpose of investigating the possibility of improving electron dose distribution for therapeutic applications, by using transverse magnetic fields. The case studied here is that of a 15 MeV electron beam of 6 cm diameter. The electrons pass through 4 cm of field‐free tissue and a transverse magnetic field is applied for depth greater than 4 cm. A field of 3 T was found to improve the skin sparing factor by a factor of 2, when compared to field‐free irradiation. A field of 2 T could also have a significant effect although less pronounced than 3 T while, for the case at hand, a magnetic field of only 1 T is not effective. The results here include detailed energy deposition contours in three dimensions.",
           21,
           "medical_physics"
          ],
          [
           "Vision 20/20: Mammographic breast density and its clinical applications",
           "10.1118/1.4935141",
           2015,
           "Breast density is a strong predictor of the failure of mammography screening to detect breast cancer and is a strong predictor of the risk of developing breast cancer. The many imaging options that are now available for imaging dense breasts show great promise, but there is still the question of determining which women are “dense” and what imaging modality is suitable for individual women. To date, mammographic breast density has been classified according to the Breast Imaging‐Reporting and Data System (BI‐RADS) categories from visual assessment, but this is known to be very subjective. Despite many research reports, the authors believe there has been a lack of physics‐led and evidence‐based arguments about what breast density actually is, how it should be measured, and how it should be used. In this paper, the authors attempt to start correcting this situation by reviewing the history of breast density research and the debates generated by the advocacy movement. The authors review the development of breast density estimation from pattern analysis to area‐based analysis, and the current automated volumetric breast density (VBD) analysis. This is followed by a discussion on seeking the ground truth of VBD and mapping volumetric methods to BI‐RADS density categories. The authors expect great improvement in VBD measurements that will satisfy the needs of radiologists, epidemiologists, surgeons, and physicists. The authors believe that they are now witnessing a paradigm shift toward personalized breast screening, which is going to see many more cancers being detected early, with the use of automated density measurement tools as an important component.",
           35,
           "medical_physics"
          ],
          [
           "A new radiation shielding block material for radiation therapy",
           "10.1118/1.1809767",
           2004,
           "In recent years, lead has been recognized as a source of environmental pollution; this includes lead use for radiation shielding in radiotherapy. We looked for a new material that could be a lead substitute. We chose a material composed of tungsten and resin. We compared the attenuation coefficient of the material with those of lead and Lipowitz's metal, and found the material has a higher attenuation coefficient than the other two. The material may be used as a substitute for lead because it is easy to fabricate and friendly to the environment.",
           15,
           "medical_physics"
          ],
          [
           "Electrons as the cause of the observed <i>d</i><sub>max</sub> shift with field size in high energy photon beams",
           "10.1118/1.594580",
           2003,
           "For megavoltage x‐ray beams, it is well known that the percent depth‐dose increases considerably with field size in the buildup region, resulting in a significant shift in the apparent position of maximum dose, dmax. The nature of this increase has been investigated using a sweeping magnet placed just below the treatment head of a 25‐MV linac. Measurements show that for increasing magnetic fields the dose in the buildup region is continually reduced, until a point is reached beyond which no additional reduction is observed. Here the buildup curve is essentially field size independent. These results clearly show that electrons are the primary cause of dose increase with field size in the buildup region, in contrast to a recent publication claiming that scattered photons are the cause. Further measurements were made by blocking out the primary beam at the level of the jaws and measuring the depth dose of the scattered electrons originating from the jaws. The results show that a thickness of approximately 1 g cm−2, of either polystyrene or lead, reduces the dose by a factor of two, providing further evidence that the scattered component of the beam consists of low energy electrons.",
           71,
           "medical_physics"
          ],
          [
           "Validity of transition‐zone dosimetry at high atomic number interfaces in megavoltage photon beams",
           "10.1118/1.596553",
           2003,
           "Measurement of dose or dose perturbation factors at high atomic number interfaces are usually performed with a thin‐window parallel‐plate ion chamber. In a transition region, under nonequilibrium conditions, accuracy of ion chamber readings for the dose measurements has often been questioned. This paper critically analyzes the factors (stopping power ratio and charge collection) for the dose measurements at interfaces. Monte Carlo simulations were performed to investigate the secondary electron spectrum produced by photon beams and to calculate the stopping power ratios at the point of measurement. The validity of dose measurements was studied for the photon beams in the range of Co‐60 gamma rays to 24‐MV x rays at bone and lead interfaces with polystyrene, using thermoluminescent dosimeters, extrapolation chamber and several types of commercially available parallel‐plate ion chambers. It is observed that for energies >10 MV most parallel‐plate chambers can be used to measure dose accurately. At lower energies, however significant differences between measured doses with different detectors were noticed. It is suggested that at high‐Z interfaces and lower energies, the dose measurements should be performed with ultrathin‐window parallel‐plate ion chambers or extrapolation chambers.",
           32,
           "medical_physics"
          ],
          [
           "A clinically relevant <scp>IMRT QA</scp> workflow: Design and validation",
           "10.1002/mp.12838",
           2018,
           "PurposeThe purpose of this study was to determine clinically relevant pass/question/fail criteria for gamma analysis of intensity‐modulated radiation therapy quality assurance (IMRT QA) plans, identify which plans should be further analyzed with dose–volume histogram (DVH) metrics, and create a workflow for performing that DVH‐based analysis.MethodsA total of 11 plans, 5 prostate and 6 head/neck, were selected to represent known good plans based on their high‐passing rate using conventional IMRT QA criteria. These were modified by moving the programmed MLC positions to underdose the target or overdose important structures by varying amounts. Commercially available hardware/software was used to measure and analyze all plans (76 total) using 4%/3 mm, 3%/3 mm, 3%/2 mm, and 2%/2 mm gamma criteria. Two receiver operator characteristic (ROC) curves per criterion were created to assess effective passing rates. One ROC curve was to find a higher threshold that determined a clear pass and the second to find a lower threshold to determine a clear failure. Plans between these two thresholds need DVH‐based analysis to assess the clinical consequence of the dose difference. The modified plans were analyzed in the planning system and reconstructed in commercially available DVH‐based analysis software to access the accuracy and usefulness of the software.ResultsAnalysis of the ROC curves showed optimal pass and fail thresholds for plan error detection per criterion to achieve clinically relevant sensitivity and specificity. Based on measurement uncertainty and pass/fail ranges, 3%/2 mm gamma criteria with a pass threshold of 95% and a fail threshold of 90% were most optimal. DVH analysis showed good agreement with all reconstructed plans except where the changes to the MLC patterns caused the periphery of the target to be underdosed. For questionable plans, comparing the organ‐specific DVHs to the physician‐provided planning constraints proved to be an efficient and effective workflow since plans for which the target dose was slightly high or where organs at risk were underdosed could be released for the treatment without consulting the physician for a clinical decision.ConclusionThis work indicates the potential for appreciable improvement in error detection for IMRT QA. Using effective pass/fail thresholds to determine plans that need DVH‐based analysis minimizes the need for excessive, time‐consuming, analysis, and making use of the dosimetric constraints of the plan minimizes the burden on physicians. Overall, DVH‐based analysis is a powerful tool that can provide substantial insight over the traditional approach that does not provide structure‐specific data.",
           8,
           "medical_physics"
          ],
          [
           "Technical Note: Scanner dependence of adaptive statistical iterative reconstruction with 3D noise power spectrum central frequency and noise magnitude ratios",
           "10.1002/mp.15104",
           2021,
           "PurposeIn this study, the noise reduction properties of the adaptive statistical iterative reconstruction (IR) on two different CT scanners of 64 and 256‐slice were compared and their differences were assessed.Methods and materialsThe homogeneous module of the ACR CT phantom was scanned on the 64 and 256 slices CT scanners from the same vendor in the range of 15–40 mA. On each scanner, the data were reconstructed using filtered back projection (FBP) and at all strengths of IR with the STANDARD kernel. For each reconstruction, a 3D noise power spectrum (NPS) was calculated and the central frequency ratio in the xy plane (CFRxy), CFR in the z‐direction (CFRz), and noise magnitude ratio (NMR) were derived. CFR is the central frequency ratio of NPS between the denoised image and the FBP image, and NMR is the ratio of the areas under the NPS curves. Ideally, both CFRxy and CFRz should be near 1, indicating minimal texture changes in both xy and z directions, while NMR should be as close to 0 as possible, indicating more noise reduction.ResultsWhen comparing strengths with equivalent impact on noise texture, IR on the 64‐slice reduced the noise magnitude in the xy plane more than that on the 256‐slice. In the z‐direction, the IR on the 256‐slice produced a central frequency shift on the 256‐slice but not on the 64‐slice. In addition, the noise reduction effects of the IR on the 256‐slice were affected when radiation exposure was below 2.0 mGy, but there was no observable dose‐dependence on the 64‐slice.ConclusionsOur noise property analysis revealed that iterative reconstructions on different scanner platforms from the same vendor can be distinct, with unique effects on the noise texture and magnitude in CT images. The IR on a 64‐slice scanner provides slightly enhanced noise reduction and maintains a noise reduction rate independent of dose, unlike the one on a 256‐slice scanner. Notably, the IR on the 64‐slice scanner was a 2D noise reduction technique (NRT), while the one on the 256‐slice was a 3D NRT. These observations showcase the impact of different NRTs on clinical CT images, even when comparing the same NRT on different scanners.",
           2,
           "medical_physics"
          ],
          [
           "A comparison of the respiratory signals acquired by different respiratory monitoring systems used in respiratory gated radiotherapy",
           "10.1118/1.3512798",
           2010,
           "Purpose:Respiratory monitoring systems are used to detect the respiratory phase of patients during the planning and administration of respiratory gated radiotherapy by using four‐dimensional computed tomography (4DCT) or 4D positron‐emission tomography/CT (4DPET/CT) and the linear accelerator (linac), respectively. Generally, identical respiratory monitoring systems are used for 4DCT, 4DPET/CT, and linac. However, different systems are sometimes used in combination because the accessibility of the respiratory monitoring systems may differ by manufacturer. The combined use of different respiratory monitoring systems in phase‐based gating is of concern because the differences in the timing of tags (end‐respiration signals algorithmically determined by the respiratory monitoring system), defined by the two systems, may result in phase differences. The purpose of this study is to estimate this difference and evaluate its effect on 4DCT data.Methods:Ten patients (seven men and three women) with a median age of 75 yr (range: 57–84 yr) were treated by gated stereotactic body radiation therapy between April and December 2009. Two types of respiratory monitoring systems—RPM (Varian Medical Systems) and AZ‐733V (Anzai MEDICAL)—were placed on the abdominal surface of the patients, and the respiratory signals were acquired by both systems. The relationship between the amplitude peak and the tag obtained by each respiratory system was analyzed for each patient. Further, the 4DCT images were reconstructed by using the signals obtained from both the RPM and the AZ‐733V systems, and the tumor volumes and the tumor centroid positions in the craniocaudal plane were analyzed for each patient.Results:The correlation factor between the respiratory signals from the RPM system and AZ‐733V system was 0.990 (range: 0.940–0.994). The amplitude peak of the RPM system corresponded well with that of the AZ‐733V system. The deviation of the phase difference for all the patients ranged from  to . In the case of some patients, differences were noted between the two systems in the estimation of the tumor centroid position and tumor shape.Conclusions:The estimation of the position of the tumor centroid and tumor shape may vary with the use of different respiratory monitoring systems. This implies that it is preferable to use the same respiratory monitoring system with 4DCT, 4DPET‐CT, and linac.",
           38,
           "medical_physics"
          ],
          [
           "Learning low‐dose CT degradation from unpaired data with flow‐based model",
           "10.1002/mp.15886",
           2022,
           "BackgroundThere has been growing interest in low‐dose computed tomography (LDCT) for reducing the X‐ray radiation to patients. However, LDCT always suffers from complex noise in reconstructed images. Although deep learning‐based methods have shown their strong performance in LDCT denoising, most of them require a large number of paired training data of normal‐dose CT (NDCT) images and LDCT images, which are hard to acquire in the clinic. Lack of paired training data significantly undermines the practicability of supervised deep learning‐based methods. To alleviate this problem, unsupervised or weakly supervised deep learning‐based methods are required.PurposeWe aimed to propose a method that achieves LDCT denoising without training pairs. Specifically, we first trained a neural network in a weakly supervised manner to simulate LDCT images from NDCT images. Then, simulated training pairs could be used for supervised deep denoising networks.MethodsWe proposed a weakly supervised method to learn the degradation of LDCT from unpaired LDCT and NDCT images. Concretely, LDCT and normal‐dose images were fed into one shared flow‐based model and projected to the latent space. Then, the degradation between low‐dose and normal‐dose images was modeled in the latent space. Finally, the model was trained by minimizing the negative log‐likelihood loss with no requirement of paired training data. After training, an NDCT image can be input to the trained flow‐based model to generate the corresponding LDCT image. The simulated image pairs of NDCT and LDCT can be further used to train supervised denoising neural networks for test.ResultsOur method achieved much better performance on LDCT image simulation compared with the most widely used image‐to‐image translation method, CycleGAN, according to the radial noise power spectrum. The simulated image pairs could be used for any supervised LDCT denoising neural networks. We validated the effectiveness of our generated image pairs on a classic convolutional neural network, REDCNN, and a novel transformer‐based model, TransCT. Our method achieved mean peak signal‐to‐noise ratio (PSNR) of 24.43dB, mean structural similarity (SSIM) of 0.785 on an abdomen CT dataset, mean PSNR of 33.88dB, mean SSIM of 0.797 on a chest CT dataset, which outperformed several traditional CT denoising methods, the same network trained by CycleGAN‐generated data, and a novel transfer learning method. Besides, our method was on par with the supervised networks in terms of visual effects.ConclusionWe proposed a flow‐based method to learn LDCT degradation from only unpaired training data. It achieved impressive performance on LDCT synthesis. Next, we could train neural networks with the generated paired data for LDCT denoising. The denoising results are better than traditional and weakly supervised methods, comparable to supervised deep learning methods.",
           5,
           "medical_physics"
          ],
          [
           "Development of a computerized method for identifying the posteroanterior and lateral views of chest radiographs by use of a template matching technique",
           "10.1118/1.1487426",
           2002,
           "In picture archiving and communications systems (PACS) or digital archiving systems, the information on the posteroanterior (PA) and lateral views for chest radiographs is often not recorded or is recorded incorrectly. However, it is necessary to identify the PA or lateral view correctly and automatically for quantitative analysis of chest images for computer‐aided diagnosis. Our purpose in this study was to develop a computerized method for correctly identifying either PA or lateral views of chest radiographs. Our approach is to examine the similarity of a chest image with templates that represent the average chest images of the PA or lateral view for various types of patients. By use of a template matching technique with nine template images for patients of different size in two steps, correlation values were obtained for determining whether a chest image is either a PA or a lateral view. The templates for PA and lateral views were prepared from 447 PA and 200 lateral chest images. For a validation test, this scheme was applied to 1,000 test images consisting of 500 PA and 500 lateral chest radiographs, which are different from training cases. In the first step, 924 (92.4%) of the cases were correctly identified by comparison of the correlation values obtained with the three templates for medium‐size patients. In the second step, the correlation values with the six templates for small and large patients were compared, and all of the remaining unidentifiable cases were identified correctly.",
           26,
           "medical_physics"
          ],
          [
           "Quantitative assessment of ensemble coherency in contrast‐free ultrasound microvasculature imaging",
           "10.1002/mp.14918",
           2021,
           "PurposeContrast‐free visualization of microvascular blood flow (MBF) using ultrasound can play a valuable role in diagnosis and detection of diseases. In this study, we demonstrate the importance of quantifying ensemble coherence for robust MBF imaging. We propose a novel approach to quantify ensemble coherence by estimating the local spatiotemporal correlation (LSTC) image, and evaluate its efficacy through simulation and in vivo studies.MethodsThe in vivo patient studies included three volunteers with a suspicious breast tumor, 15 volunteers with a suspicious thyroid tumor, and two healthy volunteers for renal MBF imaging. The breast data displayed negligible prior motion and were used for simulation analysis involving synthetically induced motion, to assess its impact on ensemble coherency and motion artifacts in MBF images. The in vivo thyroid data involved complex physiological motion due to its proximity to the pulsating carotid artery, which was used to assess the in vivo efficacy of the proposed technique. Further, in vivo renal MBF images demonstrated the feasibility of using the proposed ensemble coherence metric for curved array‐based MBF imaging involving phase conversion. All ultrasound data were acquired at high imaging frame rates and the tissue signal was suppressed using spatiotemporal clutter filtering. Thyroid tissue motion was estimated using two‐dimensional normalized cross correlation‐based speckle tracking, which was subsequently used for ensemble motion correction. The coherence of the MBF image was quantified based on Casorati correlation of the Doppler ensemble.ResultsThe simulation results demonstrated that an increase in ensemble motion corresponded with a decrease in ensemble coherency, which reciprocally degraded the MBF images. Further the data acquired from breast tumors demonstrated higher ensemble coherency than that from thyroid tumors. Motion correction improved the coherence of the thyroid MBF images, which substantially improved its visualization. The proposed coherence metrics were also useful in assessing the ensemble coherence for renal MBF imaging. The results also demonstrated that the proposed coherence metric can be reliably estimated from downsampled ensembles (by up to 90), thus allowing improved computational efficiency for potential applications in real‐time MBF imaging.ConclusionsThis pilot study demonstrates the importance of assessing ensemble coherency in contrast‐free MBF imaging. The proposed LSTC image quantified coherence of the Doppler ensemble for robust MBF imaging. The results obtained from this pilot study are promising, and warrant further development and in vivo validation.",
           9,
           "medical_physics"
          ],
          [
           "Estimation of absorbed radiation doses to skin and S‐values for organs at risk due to nasal administration of PET agents using Monte Carlo simulations",
           "10.1002/mp.14669",
           2020,
           "PurposeThe intranasal (IN) administration of radiopharmaceuticals is of interest in being a viable route for the delivery of radiopharmaceuticals that do not ordinarily cross the blood–brain barrier (BBB). However, to be viable in a patient population, good image quality as well as safety of the administration should be demonstrated. This work provides radiation dosimetry calculations and simulations related to the radiation safety of performing such experiments in a human cohort.MethodsWe performed Monte Carlo (MC) simulations to estimate radiation dose to the skin inside a cylindrical model of the nasal cavity assuming a homogenous distribution layer of 11C and 18F and calculated a geometry conversion factor (FP‐C) which can be used to convert from a planar geometry to a cylindrical geometry using more widely available software tools. We compared radiation doses from our simulated cylindrical geometry with the planar dose estimates employing our geometry conversion factor from VARSKIN 6.1 software and also from an analytical equation. Furthermore, in order to estimate radiation dosimetry to surrounding organs of interest, we performed a voxelized MC simulation of a fixed radioactivity inside the nasal cavity and calculated S‐values to organs such as the eyes, thyroid, and brain.ResultsMC simulations of contamination scenarios using planar absorbed doses of 15.50 and 8.60 mGy/MBq for 18F and 11C, respectively, and 35.70 and 19.80 mGy/MBq per hour for cylindrical geometries, leading to determination of an FP‐C of 2.3. Planar absorbed doses (also in units of mGy/MBq) determined by the analytical equation were 16.96 and 8.68 (18F and 11C) and using VARSKIN were 16.60 and 9.26 (18F and 11C), respectively. Application of FP‐C to these results demonstrates values with a maximum difference of 9.41% from the cylindrical geometry MC calculation, demonstrating that when accounting for geometry, more simplistic techniques can be utilized to estimate IN dosimetry. Voxelized MC simulations of radiation dosimetry from a fixed source of 1 MBq of activity confined to the nasal cavity resulted in S‐values to the thyroid, eyes, and brain of 1.72 x 10−6, 1.93 x 10−5, and 3.51 x 10−6 mGy/MBq·s, respectively, for 18F and 1.80 × 10−6, 1.95 × 10−5, and 3.54 × 10−6 mGy/MBq·s for 11C.ConclusionDosimetry concerns about IN administrations of PET radiotracers should be considered before clinical use. Values presented in the simulations such as the S‐values can be further used for assessment of absorbed doses in cases of IN administration, and can be used to develop and adapt specific study protocols. All three presented methods provided similar results when considering the use of a geometry conversion factor for planar to cylindrical geometry, demonstrating that standard tools rather than dedicate MC simulations may be used to perform dose calculations in nasal administrations.",
           2,
           "medical_physics"
          ],
          [
           "Monte Carlo calculations for reference dosimetry of electron beams with the PTW Roos and NE2571 ion chambers",
           "10.1118/1.4829577",
           2013,
           "Purpose:To investigate recommendations for reference dosimetry of electron beams and gradient effects for the NE2571 chamber and to provide beam quality conversion factors using Monte Carlo simulations of the PTW Roos and NE2571 ion chambers.Methods:The EGSnrc code system is used to calculate the absorbed dose‐to‐water and the dose to the gas in fully modeled ion chambers as a function of depth in water. Electron beams are modeled using realistic accelerator simulations as well as beams modeled as collimated point sources from realistic electron beam spectra or monoenergetic electrons. Beam quality conversion factors are calculated with ratios of the doses to water and to the air in the ion chamber in electron beams and a cobalt‐60 reference field. The overall ion chamber correction factor is studied using calculations of water‐to‐air stopping power ratios.Results:The use of an effective point of measurement shift of 1.55 mm from the front face of the PTW Roos chamber, which places the point of measurement inside the chamber cavity, minimizes the difference betweenR50, the beam quality specifier, calculated from chamber simulations compared to that obtained using depth‐dose calculations in water. A similar shift minimizes the variation of the overall ion chamber correction factor with depth to the practical range and reduces the root‐mean‐square deviation of a fit to calculated beam quality conversion factors at the reference depth as a function of R50. Similarly, an upstream shift of 0.34 rcav allows a more accurate determination of R50 from NE2571 chamber calculations and reduces the variation of the overall ion chamber correction factor with depth. The determination of the gradient correction using a shift of 0.22 rcav optimizes the root‐mean‐square deviation of a fit to calculated beam quality conversion factors if all beams investigated are considered. However, if only clinical beams are considered, a good fit to results for beam quality conversion factors is obtained without explicitly correcting for gradient effects. The inadequacy of R50 to uniquely specify beam quality for the accurate selection of kQ factors is discussed. Systematic uncertainties in beam quality conversion factors are analyzed for the NE2571 chamber and amount to between 0.4% and 1.2% depending on assumptions used.Conclusions:The calculated beam quality conversion factors for the PTW Roos chamber obtained here are in good agreement with literature data. These results characterize the use of an NE2571 ion chamber for reference dosimetry of electron beams even in low‐energy beams.",
           22,
           "medical_physics"
          ],
          [
           "The advantages of absorbed‐dose calibration factors",
           "10.1118/1.596921",
           2003,
           "A formalism for clinical external beam dosimetry based on use of ion chamber absorbed‐dose calibration factors is outlined in the context and notation of the AAPM TG‐21 protocol. It is shown that basing clinical dosimetry on absorbed‐dose calibration factors ND leads to considerable simplification and reduced uncertainty in dose measurement. In keeping with a protocol which is used in Germany, a quantity kQ is defined which relates an absorbed‐dose calibration factor in a beam of quality Q0 to that in a beam of quality Q. For 38 cylindrical ion chambers, two sets of values are presented for ND/NX and Ngas/ND and for kQ for photon beams with beam quality specified by the  ratio. One set is based on TG‐21's protocol to allow the new formalism to be used while maintaining equivalence to the TG‐21 protocol. To demonstrate the magnitude of the overall error in the TG‐21 protocol, the other set uses corrected versions of the TG‐21 equations and the more consistent physical data of the IAEA Code of Practice. Comparisons are made to procedures based on air‐kerma or exposure calibration factors and it is shown that accuracy and simplicity are gained by avoiding the determination of Ngas from NX. It is also shown that the kQ approach simplifies the use of plastic phantoms in photon beams since kQ values change by less than 0.6% compared to those in water although an overall correction factor of 0.973 is needed to go from absorbed dose in water calibration factors to those in PMMA or polystyrene. Values of kQ calculated using the IAEA Code of Practice are presented but are shown to be anomalous because of the way the effective point of measurement changes for 60Co beams. In photon beams the major difference between the IAEA Code of Practice and the corrected AAPM TG‐21 protocol is shown to be the Prepl correction factor. Calculated kQ curves and three parameter equations for them are presented for each wall material and are shown to represent accurately the kQ curve for all ion chambers in this study with a wall of that specified material and a thickness less than 0.25 g/cm2. Values of kQ can be measured using the primary standards for absorbed dose in photon beams.",
           37,
           "medical_physics"
          ],
          [
           "Characterization of the phantom material Virtual Water™ in high‐energy photon and electron beams",
           "10.1118/1.2174186",
           2006,
           "The material Virtual Water™ has been characterized in photon and electron beams. Range‐scaling factors and fluence correction factors were obtained, the latter with an uncertainty of around 0.2%. This level of uncertainty means that it may be possible to perform dosimetry in a solid phantom with an accuracy approaching that of measurements in water. Two formulations of Virtual Water™ were investigated with nominally the same elemental composition but differing densities. For photon beams neither formulation showed exact water equivalence—the water/Virtual Water™ dose ratio varied with the depth of measurement with a difference of over 1% at  depth. However, by using a density (range) scaling factor very good agreement  between water and Virtual Water™ at all depths was obtained. In the case of electron beams a range‐scaling factor was also required to match the shapes of the depth dose curves in water and Virtual Water™. However, there remained a difference in the measured fluence in the two phantoms after this scaling factor had been applied. For measurements around the peak of the depth‐dose curve and the reference depth this difference showed some small energy dependence but was in the range 0.1%–0.4%. Perturbation measurements have indicated that small slabs of material upstream of a detector have a small ( effect) on the chamber reading but material behind the detector can have a larger effect. This has consequences for the design of experiments and in the comparison of measurements and Monte Carlo‐derived values.",
           32,
           "medical_physics"
          ],
          [
           "SU‐FF‐T‐181: An Investigation of Surface Dose Changes for Therapeutic Kilovoltage X‐Ray Beams with Underlying Lead Shielding",
           "10.1118/1.1997862",
           2005,
           "Purpose: The effect on surface dose from underlying lead shielding in water was investigated for therapeutic kilovoltage x‐ray beams by experimental and Monte Carlo methods. Method and Materials: A Farmer type ionisation chamber was used to measure the surface dose in a water phantom for x‐ray beams with energies from 75 to 135 kVp. A 5 mm thick lead sheet was positioned at various depths below the surface. The surface dose ratio was calculated by comparison with the surface dose with no lead sheet present. A Monte Carlo model of the x‐ray beam and the phantom was generated using the EGSnrcMP code (V4.2). The initial energy spectrum was determined using an empirical method and verified by calculation of depth dose data. The dose was scored in a 1 mm thick slab at the phantom surface. The change in surface dose was calculated as a function of depth to the lead and compared to measured data. Results: The reduction in surface dose was a function of x‐ray beam energy, beam area and the depth of water to the lead. As the depth of water to the lead sheet decreased, there was a reduction in the surface dose. With the 8 cm diameter applicator and 1 cm depth of water to the lead, the surface dose ratio was 0.918 for the 75 kVp x‐ray beam and 0.890 for the 100 kVp x‐ray beam. For the smaller applicators, there was less reduction in the surface dose ratios. Surface dose ratios calculated by the EGSnrcMP code were in good agreement with measured data, with a maximum deviation of 1.2%. Conclusion: The surface dose for kilovoltage x‐ray beams is reduced when lead is underlying in the phantom. The Monte Carlo results indicate the model is sufficiently accurate to predict changes in the surface dose.",
           1,
           "medical_physics"
          ],
          [
           "Backprojection‐filtration reconstruction without invoking a spatially varying weighting factor",
           "10.1118/1.3285041",
           2010,
           "Purpose:To develop a backprojection‐filtration (BPF) algorithm with improved noise properties over the existing BPF algorithm through utilizing (approximate) redundant information in circular cone‐beam or fan‐beam scans.Methods:The backprojection steps in the existing filtered‐backprojection (FBP) and BPF algorithms for fan‐beam and cone‐beam projections invoke spatially varying weighting factors, which may not only increase the computational load in image reconstruction but also, more importantly, result in reconstruction artifacts. Redundant information in fan‐beam projections has been exploited for eliminating the weighting factor in the existing FBP algorithm. However, the new FBP algorithm cannot be applied to image reconstruction in a region of interest from transversely truncated data. In this work, the authors identify approximate data redundancy in circular cone‐beam projections and propose a new BPF algorithm in which the approximate data redundancy is exploited for eliminating the spatially varying weighting factor in the existing BPF algorithm.Results:The authors have implemented and evaluated the proposed BPF algorithm in numerical studies of reconstructing 3D images from both the nontruncated and truncated projection data in a circular cone‐beam scan. The results of numerical studies demonstrate that the proposed BPF algorithm retains the resolution property of the existing BPF algorithm, and that it can also reconstruct accurately ROI images from truncated data. More importantly, the results also indicate that the proposed BPF algorithm not only is computationally more efficient but also yields generally lower image variances than the existing BPF algorithm.Conclusions:A BPF algorithm was proposed that not only retains the desirable properties of the existing BPF algorithm but also possesses improved computational and noise properties over the latter.",
           6,
           "medical_physics"
          ],
          [
           "High performance lung nodule detection schemes in CT using local and global information",
           "10.1118/1.4737109",
           2012,
           "Purpose:A key issue in current computer‐aided diagnostic (CAD) schemes for nodule detection in CT is the large number of false positives, because current schemes use only global three‐dimensional (3D) information to detect nodules and discard useful local two‐dimensional (2D) information. Thus, the authors integrated local and global information to markedly improve the performance levels of CAD schemes.Methods:Our database was obtained from the standard CT lung nodule database created by the Lung Image Database Consortium (LIDC). It consisted of 85 CT scans with 111 nodules of 3 mm or larger in diameter. The 111 nodules were confirmed by at least two of the four radiologists participated in the LIDC. Twenty‐six nodules were missed by two of the four radiologists and were thus very difficult to detect. The authors developed five CAD schemes for nodule detection in CT using global 3D information (3D scheme), local 2D information (2D scheme), and both local and global information (2D + 3D scheme, 2D − 3D scheme, and 3D − 2D scheme). The 3D scheme, which was developed previously, used only global 3D information and discarded local 2D information, as other CAD schemes did. The 2D scheme used a uniform viewpoint reformation technique to decompose a 3D nodule candidate into a set of 2D reformatted images generated from representative viewpoints, and selected and used “effective” 2D reformatted images to remove false positives. The 2D + 3D scheme, 2D − 3D scheme, and 3D − 2D scheme used complementary local and global information in different ways to further improve the performance of lung nodule detection. The authors employed a leave‐one‐scan‐out testing method for evaluation of the performance levels of the five CAD schemes.Results:At the sensitivities of 85%, 80%, and 75%, the existing 3D scheme reported 17.3, 7.4, and 2.8 false positives per scan, respectively; the 2D scheme improved the detection performance and reduced the numbers of false positives to 7.6, 2.5, and 1.3 per scan; the 2D + 3D scheme further reduced those to 2.7, 1.9, and 0.6 per scan; the 2D − 3D scheme reduced those to 7.6, 2.1, and 0.8 per scan; and the 3D − 2D scheme reduced those to 17.3, 1.6, and 1.0 per scan.Conclusions:The local 2D information appears to be more useful than the global 3D information for nodule detection, particularly, when it is integrated with 3D information.",
           20,
           "medical_physics"
          ],
          [
           "Exposure values around an x‐ray scanning transaxial tomograph (EMI scanner)",
           "10.1118/1.594194",
           2003,
           "Measurements of exposure accumulated in a one‐month period in and around a scanning x‐ray transaxial tomograph are reported. For the unit studied (the EMI neurological scanner) values measured indicate that the shielding required is “minimal.”",
           5,
           "medical_physics"
          ],
          [
           "Automatic coronary artery plaque thickness comparison between baseline and follow‐up CCTA images",
           "10.1002/mp.13993",
           2019,
           "PurposeCurrently, coronary plaque changes are manually compared between a baseline and follow‐up coronary computed tomography angiography (CCTA) images for long‐term coronary plaque development investigation. We propose an automatic method to measure the plaque thickness change over time.MethodsWe model the lumen and vessel wall for both the baseline coronary artery tree (CAT‐BL) and follow‐up coronary artery tree (CAT‐FU) as smooth three‐dimensional (3D) surfaces using a subdivision fitting scheme with the same coarse meshes by which the correspondence among these surface points is generated. Specifically, a rigid point set registration is used to transform the coarse mesh from the CAT‐FU to CAT‐BL. The plaque thickness and the thickness difference is calculated as the distance between corresponding surface points. To evaluate the registration accuracy, the average distance between manually defined markers on clinical scans is calculated. Artificial CAT‐BL and CAT‐FU pairs were created to simulate the plaque decrease and increase over time.ResultsFor 116 pairs of markers from nine clinical scans, the average marker distance after registration was 0.95 ± 0.98 mm (two times the voxel size). On the 10 artificial pairs of datasets, the proposed method successfully located the plaque changes. The average of the calculated plaque thickness difference is the same as the corresponding created value (standard deviation ± 0.1 mm).ConclusionsThe proposed method automatically calculates local coronary plaque thickness differences over time and can be used for 3D visualization of plaque differences. The analysis and reporting of coronary plaque progression and regression will benefit from an automatic plaque thickness comparison.",
           4,
           "medical_physics"
          ],
          [
           "Experimental determination of the convolution kernel for the study of the spatial response of a detector",
           "10.1118/1.598182",
           2002,
           "One of the most important parameters in the characterization of a detector is its spatial convolution kernel. This kernel contains all of the information about the influence that the detector size has on the measured beam profile. In this paper we present an experimental method for the determination of the spatial convolution kernel for commonly used detectors that are employed in the x‐ray profile measurement:  diode, and ionization minichamber. Our work is based on first assuming a step function pattern on a photographic film is known and is a perfect step function. The kernel of the densitometer system was then derived from the deconvolution of the scanned profile to the step function. Next a film was exposed to a penumbra area of an x‐ray beam from a linac. The film was scanned using the same densitometer. The “real profile” that emerges from a linear accelerator was derived by the deconvolution of the scanned profile using the now known kernel of the film densitometer. Under the same irradiation condition the x‐ray profile was measured with other detectors and with this information we obtained the convolution kernels for these detectors by solving numerically their basic convolution integrals. The results show that the Gaussian convolution kernel is the most consistent with the measurements. The best numerical values for the FWHM of the kernels are 1.1 mm, 2.2 mm, and 5.4 mm for densitometer, diode, and minichamber, respectively.",
           72,
           "medical_physics"
          ],
          [
           "Nonstationary noise characteristics of the helical scan and its impact on image quality and artifacts",
           "10.1118/1.598026",
           2002,
           "Helical computed tomography has replaced the conventional step‐and‐shoot CT in many clinical applications. Because of its clinical importance, a number of comparative studies have been performed to evaluate its performance parameters, such as the noise and the slice sensitivity profile. In this paper, the nonstationary noise characteristics of helical images are carefully examined. Their impact on the low contrast detectability and three‐dimensional (3‐D) image artifacts is assessed. An analytical equation is derived to relate the interactions between various helical reconstruction schemes and the fan‐beam filtered backprojection algorithm. We demonstrate that for many popular helical weights, the noise variation within the field of view of the reconstruction is close to a factor of 3. Several approaches to overcome the undesired characteristics are proposed.",
           45,
           "medical_physics"
          ],
          [
           "Confidence limit variation for a single IMRT system following the TG119 protocol",
           "10.1118/1.3555298",
           2011,
           "Purpose:To evaluate the robustness of TG119‐based quality assurance metrics for an IMRT system.Methods:Four planners constructed treatment plans for the five IMRT test cases described in TG119. All plans were delivered to a solid water phantom in one treatment session in order to minimize session‐dependent variation from phantom setup, film quality, machine performance, etc. Composite measurements utilized film and an ionization chamber. Per‐field measurements were collected using a diode array device at an effective depth of 5 cm. All data collected were analyzed using the TG119 specifications to determine the confidence limit values for each planner separately and then compared.Results:The mean variance of ion chamber measurements for each planner was within 1.7% of the planned dose. The resulting confidence limits were 3.13%, 1.98%, 3.65%, and 4.39%. Confidence limit values determined by composite film analysis were 8.06%, 13.4%, 9.30%, and 16.5%. Confidence limits from per‐field measurements were 1.55%, 0.00%, 0.00%, and 2.89%.Conclusions:For a single IMRT system, the accuracy assessment provided by TG119‐based quality assurance metrics showed significant variations in the confidence limits between planners across all composite and per‐field evaluations. This observed variation is likely due to the different levels of modulation between each planner's set of plans. Performing the TG119 evaluation using plans produced by a single planner may not provide an adequate estimation of IMRT system accuracy.",
           11,
           "medical_physics"
          ],
          [
           "Effects of x‐ray tube current and voltage on effective focalspot size",
           "10.1118/1.1637286",
           2003,
           "In general, the dimensions of the effective focal spot of an x‐ray tube vary with tube current and voltage. This dependence on tube operating conditions has been noted in the literature but has not been investigated in detail. Star phantom measurements of seven focal spots for four x‐ray tubes operated at a variety of tube voltages and currents show that effective focal‐spot size varies as . This dependence may be suppressed for the focal‐spot dimension perpendicular to the tube axis, however, because of auxiliary electrostatic focusing. Experimental data are presented with a theoretical explanation of the relationship between effective focal‐spot size and tube operating conditions.",
           20,
           "medical_physics"
          ],
          [
           "Evaluation of uncertainty predictions and dose output for model‐based dose calculations for megavoltage photon beams",
           "10.1118/1.2207316",
           2006,
           "In many radiotherapy clinics an independent verification of the number of monitor units (MU) used to deliver the prescribed dose to the target volume is performed prior to the treatment start. Traditionally this has been done by using methods mainly based on empirical factors which, at least to some extent, try to separate the influence from input parameters such as field size, depth, distance, etc. The growing complexity of modern treatment techniques does however make this approach increasingly difficult, both in terms of practical application and in terms of the reliability of the results. In the present work the performance of a model‐based approach, describing the influence from different input parameters through actual modeling of the physical effects, has been investigated in detail. The investigated model is based on two components related to megavoltage photon beams; one describing the exiting energy fluence per delivered MU, and a second component describing the dose deposition through a pencil kernel algorithm solely based on a measured beam quality index. Together with the output calculations, the basis of a method aiming to predict the inherent calculation uncertainties in individual treatment setups has been developed. This has all emerged from the intention of creating a clinical dose/MU verification tool that requires an absolute minimum of commissioned input data. This evaluation was focused on irregular field shapes and performed through comparison with output factors measured at 5, 10, and  depth in ten multileaf collimated fields on four different linear accelerators with varying multileaf collimator designs. The measurements were performed both in air and in water and the results of the two components of the model were evaluated separately and combined. When compared with the corresponding measurements the resulting deviations in the calculated output factors were in most cases smaller than 1% and in all cases smaller than 1.7%. The distribution describing the calculation errors in the total dose output has a mean value of  and a standard deviation of 0.47%. In the dose calculations a previously developed correction of the pencil kernel was applied that managed to contract the error distribution considerably. A detailed analysis of the predicted uncertainties versus the observed deviations suggests that the predictions indeed can be used as a basis for creating action levels and tracking dose calculation errors in homogeneous media.",
           15,
           "medical_physics"
          ],
          [
           "The Phantoms of Medical and Health Physics",
           "10.1118/1.4960370",
           2016,
           "The Phantoms of Medical and Health Physics. Devices for Research and Development. Editors. L. DeWerd and M. Kissick., Springer‐Verlag, Heidelberg, New York, 2014. 286 pp. Price: $129.00. ISBN: 978‐1‐4614‐8303‐8. Price: $99.00. ISBN: 978‐1‐4614‐8304‐5 (hardcover)",
           5,
           "medical_physics"
          ],
          [
           "Verification of Gamma Knife extend system based fractionated treatment planning using EBT2 film",
           "10.1118/1.4832138",
           2013,
           "Purpose:This paper presents EBT2 film verification of fractionated treatment planning with the Gamma Knife (GK) extend system, a relocatable frame system for multiple‐fraction or serial multiple‐session radiosurgery.Methods:A human head shaped phantom simulated the verification process for fractionated Gamma Knife treatment. Phantom preparation for Extend Frame based treatment planning involved creating a dental impression, fitting the phantom to the frame system, and acquiring a stereotactic computed tomography (CT) scan. A CT scan (Siemens, Emotion 6) of the phantom was obtained with following parameters: Tube voltage—110 kV, tube current—280 mA, pixel size—0.5 × 0.5 and 1 mm slice thickness. A treatment plan with two 8 mm collimator shots and three sectors blocking in each shot was made. Dose prescription of 4 Gy at 100% was delivered for the first fraction out of the two fractions planned. Gafchromic EBT2 film (ISP Wayne, NJ) was used as 2D verification dosimeter in this process. Films were cut and placed inside the film insert of the phantom for treatment dose delivery. Meanwhile a set of films from the same batch were exposed from 0 to 12 Gy doses for calibration purposes. An EPSON (Expression 10000 XL) scanner was used for scanning the exposed films in transparency mode. Scanned films were analyzed with inhouse written MATLAB codes.Results:Gamma index analysis of film measurement in comparison with TPS calculated dose resulted in high pass rates >90% for tolerance criteria of 1%/1 mm. The isodose overlay and linear dose profiles of film measured and computed dose distribution on sagittal and coronal plane were in close agreement.Conclusions:Through this study, the authors propose treatment verification QA method for Extend frame based fractionated Gamma Knife radiosurgery using EBT2 film.",
           6,
           "medical_physics"
          ],
          [
           "The feasibility study of XACT imaging for characterizing osteoporosis",
           "10.1002/mp.15906",
           2022,
           "BackgroundOsteoporosis is a progressive bone disease that is characterized by a decrease in bone mass and the deterioration in bone microarchitecture, which might be related to age and space travel. An unmet need exists for the development of novel imaging technologies to characterize osteoporosis.PurposeThe purpose of our study is to investigate the feasibility of X‐ray‐induced acoustic computed tomography (XACT) imaging for osteoporosis detection.MethodsAn in‐house simulation workflow was developed to assess the ability of XACT for osteoporosis detection. To evaluate this simulation workflow, a three‐dimensional digital bone phantom for XACT imaging was created by a series of two‐dimensional micro‐computed tomography (micro‐CT) slices of normal and osteoporotic bones in mice. In XACT imaging, the initial acoustic pressure rise caused by the X‐ray induce acoustic (XA) effect is proportional to bone density. First, region growing was deployed for image segmentation of different materials inside the bone. Then k‐wave simulations were deployed to model XA wave propagation, attenuation, and detection. Finally, the time‐varying pressure signals detected at each transducer location were used to reconstruct the XACT image with a time‐reversal reconstruction algorithm.ResultsThrough the simulated XACT images, cortical porosity has been calculated, and XA signal spectra slopes have been analyzed for the detection of osteoporosis. The results have demonstrated that osteoporotic bones have lower bone mineral density and higher spectra slopes. These findings from XACT images were in good agreement with porosity calculation from micro‐CT images.ConclusionThis work explores the feasibility of using XACT imaging as a new imaging tool for Osteoporosis detection. Considering that acoustic signals are generated by X‐ray absorption, XACT imaging can be combined with traditional X‐ray imaging that holds potential for clinical management of osteoporosis and other bone diseases.",
           2,
           "medical_physics"
          ],
          [
           "The use of computed radiography plates to determine light and radiation field coincidence",
           "10.1118/1.4823775",
           2013,
           "Purpose:Photo‐stimulable phosphor computed radiography (CR) has characteristics that allow the output to be manipulated by both radiation and optical light. The authors have developed a method that uses these characteristics to carry out radiation field and light field coincidence quality assurance on linear accelerators.Methods:CR detectors from Kodak were used outside their cassettes to measure both radiation and light field edges from a Varian linear accelerator. The CR detector was first exposed to a radiation field and then to a slightly smaller light field. The light impinged on the detectorˈs latent image, removing to an extent the portion exposed to the light field. The detector was then digitally scanned. AMATLAB‐based algorithm was developed to automatically analyze the images and determine the edges of the light and radiation fields, the vector between the field centers, and the crosshair center. Radiographic film was also used as a control to confirm the radiation field size.Results:Analysis showed a high degree of repeatability with the proposed method. Results between the proposed method and radiographic film showed excellent agreement of the radiation field. The effect of varying monitor units and light exposure time was tested and found to be very small. Radiation and light field sizes were determined with an uncertainty of less than 1 mm, and light and crosshair centers were determined within 0.1 mm.Conclusions:A new method was developed to digitally determine the radiation and light field size using CR photo‐stimulable phosphor plates. The method is quick and reproducible, allowing for the streamlined and robust assessment of light and radiation field coincidence, with no observer interpretation needed.",
           2,
           "medical_physics"
          ],
          [
           "Development of a neonate X‐ray phantom for 2D imaging applications using single‐tone inkjet printing",
           "10.1002/mp.15086",
           2021,
           "PurposeInkjet printers can be used to fabricate anthropomorphic phantoms by the use of iodine‐doped ink. However, challenges persist in implementing this technique. The calibration from grayscale to ink density is complex and time‐consuming. The purpose of this work is to develop a printing methodology that requires a simpler calibration and is less dependent on printer characteristics to produce the desired range of x‐ray attenuation values.MethodsConventional grayscale printing was substituted by single‐tone printing; that is, the superposition of pure black layers of iodinated ink. Printing was performed with a consumer‐grade inkjet printer using ink made of potassium‐iodide (KI) dissolved in water at 1 g/ml. A calibration for the attenuation of ink was measured using a commercial x‐ray system at 70 kVp. A neonate radiograph obtained at 70 kVp served as an anatomical model. The attenuation map of the neonate radiograph was processed into a series of single‐tone images. Single‐tone images were printed, stacked, and imaged at 70 kVp. The phantom was evaluated by comparing attenuation values between the printed phantom and the original radiograph; attenuation maps were compared using the structural similarity index measure (SSIM), while attenuation histograms were compared using the Kullback–Leibler (KL) divergence. A region of interest (ROI)‐based analysis was also performed, where the attenuation distribution within given ROIs was compared between phantom and patient. The phantom sharpness was evaluated in terms of modulation transfer function (MTF) estimates and signal spread profiles of high spatial resolution features in the image.ResultsThe printed phantom required 36 pages. The printing queue was automated and it took about 2 h to print the phantom. The radiograph of the printed phantom demonstrated a close resemblance to the original neonate radiograph. The SSIM of the phantom with respect to that of the patient was 0.53. Both patient and phantom attenuation histograms followed similar distributions, and the KL divergence between such histograms was 0.20. The ROI‐based analysis showed that the largest deviations from patient attenuation values were observed at the higher and lower ends of the attenuation range. The limiting resolution of the proposed methodology was about 1 mm.ConclusionA methodology to generate a neonate phantom for 2D imaging applications, using single‐tone printing, was developed. This method only requires a single‐value calibration and required less than 2 h to print a complete phantom.",
           3,
           "medical_physics"
          ],
          [
           "SU‐E‐J‐120: A Phantom‐Based Comparison of Lung Tumor Planning Target Volumes and Organs a Risk Dose Reduction Between 4D‐CT and 3D‐CT",
           "10.1118/1.4814332",
           2013,
           "Purpose: Lung tumor motion due to respiration necessitates using large margins when creating a planning target volume (PTV). As tumor movement of up to 5 cm has been reported by several investigators, accurate investigation of the internal margin (IM) to 3D CTV is necessary. The purpose of this study was to compare the differences in volume between PTVs generated using 4D‐CT (4D PTV) and 3D‐CT (3D PTV) for varying degrees of tumor motion and to evaluate the differences in dose to normal lung and spinal cord. Methods: A movable phantom was used to simulate lung movement (Figure 1). Three blocks of rubber were attached to the phantom and a 3D‐CT and a 4D‐CT were taken. Then, PTVs were delineated and compared. After that, the PTVs were transferred to a Rando phantom for dose analysis. Also, investigation of varying displacements of lung tumor was done using four blocks of rubber attached to a movable phantom with different known displacements (Figure 2). Results: The average reduction in PTV volumes using 4D‐CT was 33.8%. This led to average decreases of 19.2%, 20.1% and 33.8% for lung V20, mean lung dose and maximum spinal cord dose, respectively (Table 1)., Investigation of varying displacements of lung tumor shows that if tumors move more than 4 cm, the 4D PTV may be equal to or larger than the 3D PTV(Table 2).Figures 3 shows overlapping of PTVs of tumors with 2 cm motion and 4 cm motion in 3D and 4D. Conclusion: It can be concluded that 4D‐CT reduces organ at risk doses. For lung tumors with large displacements, 4D‐CT is a promising method because the exact IM in the direction of tumor motion is achieved. In these cases, the use of 3D causes not only unnecessary dose to normal tissue but also missing part of the tumor (Figure 3).",
           0,
           "medical_physics"
          ],
          [
           "SU‐E‐J‐109: Registration/Segmentation for Adaptive Radiotherapy Using the Jensen Renyi Divergence",
           "10.1118/1.4814321",
           2013,
           "Purpose: For the purposes of adaptive radiotherapy, the consolidation of offline and online imaging modalities requires costly registration, resegmentation and re‐optimization. The Jensen Renyi (JR) divergence is a non‐parametric generalized statistical measure that can be applied as an energy function for all three of these objectives. Further efficiency and accuracy can be attained by coupling the objective functions such that they iteratively reinforce one another. Methods: The JR divergence was used as an energy function and with a finite difference scheme, the level set differential equation was solved for an active contour along with the energy gradient of control points placed using an adaptive mesh. The segmentation portion has been validated using three data sets; PET and CBCT images of an in‐house phantom for various image qualities, 7 PET scans of head and neck cases from the Louvain database and 22 PET/CT scans of patients with non‐small cell lung carcinoma from the MAASTRO database. Results: Segmentation of an in‐house phantom using the JR divergence showed a marked improvement in concordance index (CI) by almost a factor of 2 compared to the mutual information metric below SNR values of 35.3 and 24.0 for the CBCT and PET images. Average CI for the 7 Louvain cases was found to be 0.56. An average error in estimating the maximal tumor diameters of the 22 MAASTRO cases was found to be 63%, 19.5% and 14% using CT, PET and combined PET/ CT modalities. Conclusion: The JR divergence metric was applied to the task of segmentation using a level sets active contour. It was found to provide improved noise tolerance and competitive segmentation accuracy compared to 9 other PET segmentation methods. A coupled segmentation/registration scheme has been implemented using the JR divergence. Validation is currently being performed using plasticized pig lungs. Funding was provided by the Natural Sciences and Engineering Research Council of Canada. (NSERC‐RGPIN 397711‐11) and the Research Institute of the McGill University Health Centre. HZ is supported by the Swiss National Science Foundation under grant SNSF 31003A‐135576, Geneva Cancer League and the Indo‐Swiss Joint Research Programme ISJRP 138866.",
           0,
           "medical_physics"
          ],
          [
           "TU‐FF‐A4‐01: Virtual Simulator Design for Collision Prevention During External Radiotherapy Planning",
           "10.1118/1.2962656",
           2008,
           "Purpose: Collision avoidance of the treatment accelerator components such as gantry, table, collimators, jaws, and fixation devices with the patient is one of the biggest concerns in external treatment planning. Most commercial treatment planning systems do not include collision prevention simulation step. On the other hand, a fool‐proof collision‐map, lookup table, and simpler analytical method guard only against the most apparent collisions. Thus, a comprehensive virtual simulator design for collision avoidance is very useful for external radiotherapy planning. Method and Materials: An accurate modeling of the treatment accelerator is possible with geometric data. Three‐dimensional patient modeling is also possible from the patient's CT data. Since each component in the data bank is described as an independent mesh modeling based on the type of associated polygons, relative position changes can be described easily for the device dynamics simulation. The relative motions of the gantry and the treatment table are collected from the treatment plan and the graphical user interface generates the events at the given time intervals. This visual system is incorporated with the treatment planning simulation system. Results: The quality verification of our virtual simulator for the potential collision has been performed with two combinations of treatment table and gantry rotations where a collision is eminent based on the visual assessment. The planner can search for beam paths with minimal critical structure interference before extensive optimization process. A database of CT and MR scans for all tumor sites is being built, which provide useful information to map all potential collision possibilities for all treatment isocenters. Conclusion: The important benefits of this virtual simulator is the replacement of the conventional laborious procedures required for the expensive hardware simulator unit, the efficiency increment, the accuracy improvement of radiation treatment procedure, and the cost reduction in terms of time and physical patient's presence.",
           0,
           "medical_physics"
          ],
          [
           "Texture classification‐based segmentation of lung affected by interstitial pneumonia in high‐resolution CT",
           "10.1118/1.3003066",
           2008,
           "Accurate and automated lung field (LF) segmentation in high‐resolution computed tomography (HRCT) is highly challenged by the presence of pathologies affecting lung borders, also affecting the performance of computer‐aided diagnosis (CAD) schemes. In this work, a two‐dimensional LF segmentation algorithm adapted to interstitial pneumonia (IP) patterns is presented. The algorithm employs ‐means clustering followed by a filling operation to obtain an initial LF order estimate. The final LF border is obtained by an iterative support vector machine neighborhood labeling of border pixels based on gray level and wavelet coefficient statistics features. A second feature set based on gray level averaging and gradient features was also investigated to evaluate its effect on segmentation performance of the proposed method. The proposed method is evaluated on a dataset of 22 HRCT cases spanning a range of IP patterns such as ground glass, reticular, and honeycombing. The accuracy of the method is assessed using area overlap and shape differentiation metrics (, , and ), by comparing automatically derived lung borders to manually traced ones, and further compared to a gray level thresholding‐based (GLT‐based) method. Accuracy of the methods evaluated is also compared to interobserver variability. The proposed method incorporating gray level and wavelet coefficient statistics demonstrated the highest segmentation accuracy, averaged over left and right LFs (, , , and ), which is statistically significant (two‐tailed student's  test for paired data, ) with respect to all metrics considered as compared to the proposed method incorporating gray level averaging and gradient features (, , , and ) and the GLT‐based method (, , , and ). The performance of the three segmentation methods, although decreased as IP pattern severity level (mild, moderate, and severe) was increased, did not demonstrate statistically significant difference (two‐tailed student's  test for unpaired data,  for all metrics considered). Finally, the accuracy of the proposed method, based on gray level and wavelet coefficient statistics ranges within interobserver variability. The proposed segmentation method could be used as an initial stage of a CAD scheme for IP patterns.",
           52,
           "medical_physics"
          ],
          [
           "SU‐E‐J‐163: The Imaging Dose to Patients <b>Result</b>ing From the ExacTrac X‐Ray System",
           "10.1118/1.4814375",
           2013,
           "Purpose: There is a lack of reported data on imaging dose from Novalis ExacTrac use for image guided radiotherapy. This investigation is to assess the imaging doses to patients resulting from a variety of clinical default imaging acquisition protocols in the ExacTrac x‐ray imaging system. Methods: Novalis TX ExacTrac x‐ray system (BrainLab, Feldkirchen, Germany) is investigated. This system consists of two floor‐mounted kilovoltage X‐ray tubes projecting obliquely onto two flat‐panel detectors mounted on the ceiling. The dose measurements were performed using an ion chamber inserted in a phantom. The air kerma calibration factor of the ion chamber for x‐ray beams specified by the half‐value layer was obtained from an Accredited Dosimetry Calibration Laboratory. The imaging dose from clinical default protocols including Cranium, Thorax and Abdomen were studied. The phantom, in the size of 30×12×30 cm3, was made from slabs of water‐equivalent materials for low energy x‐rays, PW‐LR (CIRS, Norfolk, VA). Results: The field size of x‐rays from each tube is 20×20 cm2 at the isocenter. Small differences of 5–10 % in measured radiation dose at the isocenter between two x‐ray tubes were observed. The doses measured in the phantom at a depth of 1 cm from the treatment table were 0.05 cGy, 0.16 cGy, and 0.19 cGy resulting from a pair of obliquely beams of Cranium‐heavy, Thorax‐Heavy and Abdomen‐Heavy clinical protocols respectively. It was found that there was up to 77% dose reduction by selecting Abdomen‐Light instead of Abdomen‐Heavy acquisition protocols. Conclusion: Although the imaging doses to patients resulting from a single pair of beams are low, the sum of multiple acquisitions (10‐20 pairs) is still significant, which can be common for one treatment fraction if non‐coplanar beams are used. The imaging doses strongly depend on the image acquisition protocols. During treatment, the low dose protocols should be chosen, given that image quality is not compromised.",
           1,
           "medical_physics"
          ],
          [
           "Quantitative verification of <sup>192</sup>Ir PDR and HDR source structure by pin‐hole autoradiography",
           "10.1118/1.597538",
           2003,
           "For precise localization of the center and determination of the dimensions of the radioactive material within the capsule of brachytherapy sources, we have developed a method based on simultaneous pin‐hole autoradiography of two sources. We constructed a variable magnification pin‐hole camera consisting of two telescopically fitted Plexiglas cylinders which can accommodate two radioactive sources on the plate covering the top cylinder. The 192Ir pulsed and high dose‐rate sources were studied and an 192Ir seed was used as a reference source. The magnification factor was determined from the dimensions of the 192Ir seed image, which was geometrically well defined by a separate transmission radiography experiment. The observed position for the center of radioactivity in the PDR and the HDR source capsules are in agreement with the vendor specifications. The distance from the tip of the PDR capsule to its center of radioactivity was found in this way to be 0.79±0.21 mm, which agrees with the position (0.85 mm) of the pellet situated closer to the tip as specified by the vendor. Quantitative verification of the internal source structure using this method enhances the accuracy with which the dose distribution near brachytherapy sources can be predicted by three‐dimensional Monte Carlo calculations.",
           11,
           "medical_physics"
          ],
          [
           "SU‐E‐T‐380: Evaluation of Patient Specific Machine Delivery Performance Based on Analysis of Trajectory Log Files",
           "10.1118/1.4735467",
           2012,
           "Purpose: Comparison of delivered and treatment planning dose to a phantom is routinely done before first patient treatment for IMRT and VMAT treatment courses, and is an important part of QA program. It is assumed that the delivery parameters are reproducible for each treatment in the course, and additional tests to validate the assumption are rarely performed. We use the analysis of Trajectory log files to verify the interfractional constancy of treatment delivery. Methods: Trajectory Log files present a record of machine coordinate snapshots every 10ms of beam on state. We designed an automated data mining engine capable of extracting machine parameters recorded for the treated fractions for a selected patient, and generating easy to review statistical report quantifying machine delivery performance. The application was tested on 3 head and neck and 4 pelvis test courses in our clinic. Results: The worst observed instant error in Gantry angle position during the delivery of VMAT treatments was 0.22deg, while the time‐averaged gantry error during the delivery was less than 0.002deg. The maximum observed discrepancy between planned and actual treatment position for MLC leaves was 0.11 mm. When machine parameter interfractional variance was analyzed, the worst difference in gantry position between any fraction delivered for a patient was 0.013deg. The worst instantaneous discrepancy between any fraction of treatment for MLC leaves was only 0.028mm. Conclusions: The analysis of Varian TrueBeam accelerator Trajectory Log files generated during the course of treatment of 3 head and neck and 4 pelvis patients showed high reproducibility in dynamics of machine position parameter during the delivery of treatments. Continuous monitoring of treatment logs enables verification of treatment delivery constancy, and should be integrated in clinical QA programs.",
           0,
           "medical_physics"
          ],
          [
           "Truncation correction for oblique filtering lines",
           "10.1118/1.3002416",
           2008,
           "State‐of‐the‐art filtered backprojection (FBP) algorithms often define the filtering operation to be performed along oblique filtering lines in the detector. A limited scan field of view leads to the truncation of those filtering lines, which causes artifacts in the final reconstructed volume. In contrast to the case where filtering is performed solely along the detector rows, no methods are available for the case of oblique filtering lines. In this work, the authors present two novel truncation correction methods which effectively handle data truncation in this case. Method 1 (basic approach) handles data truncation in two successive preprocessing steps by applying a hybrid data extrapolation method, which is a combination of a water cylinder extrapolation and a Gaussian extrapolation. It is independent of any specific reconstruction algorithm. Method 2 (kink approach) uses similar concepts for data extrapolation as the basic approach but needs to be integrated into the reconstruction algorithm. Experiments are presented from simulated data of the FORBILD head phantom, acquired along a partial‐circle‐plus‐arc trajectory. The theoretically exact M‐line algorithm is used for reconstruction. Although the discussion is focused on theoretically exact algorithms, the proposed truncation correction methods can be applied to any FBP algorithm that exposes oblique filtering lines.",
           8,
           "medical_physics"
          ],
          [
           "A conversion method of air kerma from the primary, scatter, and leakage radiations to effective dose for calculating x‐ray shielding barriers in mammography",
           "10.1118/1.1895526",
           2005,
           "In this study, a new approach has been introduced for derivation of the effective dose from air kerma to calculate shielding requirements in mammography facilities. This new approach has been used to compute the conversion coefficients relating air kerma to the effective dose for the mammography reference beam series of the Netherlands Metrology Institute Van Swinden Laboratorium, National Institute of Standards and Technology, and International Atomic Energy Agency laboratories. The results show that, in all cases, the effective dose in mammography energy range is less than 25% of the incident air kerma for the primary and the scatter radiations and does not exceed 75% for the leakage radiation.",
           4,
           "medical_physics"
          ],
          [
           "SU‐FF‐T‐390: A New Linac QA Procedure for the Characterization of Radiation Isocenter and Room Lasers Position",
           "10.1118/1.1998147",
           2005,
           "Purpose: We have designed and implemented a new stereotactic machine QA test. The method is used to characterize gantry sag, couch wobble, cone placement, MLC offset and room lasers position relative to radiation isocenter. An image containing a series of test patterns is generated in a direct and integrated fashion. Method and Materials: Two MLC star patterns, a cone pattern and the laser lines are recorded on the same imaging medium, enabling 0.1 mm accuracy measurements. Phosphor plates are used as the imaging medium due to their unique property that the red light of wall laser erases the radiation information stored on phosphor plates. The room lasers position relative to the radiation isocenter can be measured. The developed QA method consists of four images that measure the gantry sag between 00 and 1800 gantry angles, the position and stability of couch rotational axis, the sag between 900 and 2700 gantry angles, the accuracy of cone placement on the collimator and the position of laser lines relative radiation isocenter. Results: The inherent precision of the numerical algorithms developed is +/− 0.05mm. The inherent accuracy of the method as a whole is +/− 0.1mm. The total irradiation/illumination time is about 10 min per image. Automating the generation of collimator star patterns can reduce this time. The data analysis (including the phosphor plate scanning) is less than 5min. Conclusion: The presented method reproducibly characterizes the radiation isocenter geometry with the high accuracy required for stereotactic surgery. It can replace the standard ball test and it can provide a highly accurate QA procedure for the non‐stereotactic machines.",
           1,
           "medical_physics"
          ],
          [
           "SU‐E‐T‐464: Impact of the Treatment Margin on Tumor Control and Normal Tissue Complication for Prostate Treatment",
           "10.1118/1.4735553",
           2012,
           "Purpose: To investigate the consequence of treatment margin reduction on normal tissue complication probability (NTCP) and tumor control probability (TCP) of prostate external beam treatment. Methods: Intensity modulated rotational radiotherapy plans were generated for 10 prostate patients with 6 different posterior margin sizes from 5mm to 0. The prescription dose is 80Gy for 40 treatment fractions. The dose distributions were recalculated with consideration of the intrafractional motion and the localization error. The statistical uncertainties of the intrafractional motion and the localization error were derived based on the motion tracking data recorded by the Calypso 4D localization system for a large patient population. The TCP and NTCP were calculated based on the dose volume histograms (DVH) of prostate and rectum for plans with different margins using an equivalent uniform dose (EUD) based biological model. The 50% tumor control dose (TCD50) of 60Gy for prostate and the median toxic dose (TD50) of 55Gy for rectum were used in the calculation. Results: The minimum dose of the prostate and the mean dose of the rectum dropped with the decrease of the treatment margin. When the posterior treatment margin was reduced from 5mm to zero, the EUD of prostate decreased from 83Gy (±0.5Gy) to 81Gy (±0.5Gy) and the TCP dropped from 93.2% (±0.1%) to 91.7% (±0.1%), the EUD of the rectum decreased more significantly from 48.9Gy (±0.4Gy) to 32.5Gy (±0.5Gy) and the NTCP dropped from 13.3% (±1.5%) to 0.03% (± 0.01%). Conclusions: The treatment margin size affects the dose to the target and the nearby critical structure. More significant impact on NTCP has been observed than on TCP. This gives us some room to consider the quality of the patient's after‐treatment life. A wise choice of treatment margin can be made based on physician's opinion and patient's preference on the tumor control and the quality of life.",
           1,
           "medical_physics"
          ],
          [
           "TU‐C‐T‐617‐06: Importance of Pre‐Fraction Helical CT Isocenter Verification in Extracranial Stereotactic Radiosurgery",
           "10.1118/1.1998364",
           2005,
           "Purpose: To quantify the impact of pre‐fraction helical CT isocenter verification vs. setup based on planning CT in fractionated extracranial stereotactic radiosurgery. Method and Materials: Treatment plans (Elekta PrecisePlan) and pre‐fraction isocenter verification helical CT scans for 12 patients (40 fractions) were recovered from treatment plan archives. All structures were contoured by a single physician at the time of treatment. Each plan was imported into a customizable treatment plan analysis suite (CERR). Using CERR, pre‐fraction isocenter verification CT scans were fused with the original treatment plan using the external body frame as a reference. The original planned dose distribution was then translated from original treatment plan isocenter to pre‐fraction verification isocenters in each fraction. Dose and volume parameters for pertinent structures were automatically extracted using both registration methods (planned or pre‐fraction scans) for the original treatment plan and for all subsequent fractions. All patients were treated using the pre‐fraction verified isocenter rather than pre‐calculated body frame fiducials as per our institutional policies. Results: GTV volumes on pre‐fraction CTs varied from original planned GTV volume (64%–203%, mean=101.8+/−26.5%) largely due to helical sampling of a mobile target. Using the external body frame as the only setup reference would have resulted in geographic misses (<80% coverage of 95% of GTV) in 7/40 (17.5%) fractions. Pre‐fraction isocenter verification resulted in improved D95 GTV coverage (88–102%, mean=99.3% +/−2.4%) with no geographic misses. Conclusion: The current RTOG protocol (0236) evaluating extracranial stereotactic radiosurgery does not require pre‐fraction CT tumor position verification. Our institutional policy is to verify isocenter/tumor position prior to each fraction via CT. Although helical scanning artifacts are present, pre‐fraction CT‐based isocenter verification may provide more consistent tumor coverage than setup to planned body frame fiducials. Conflict of Interest: Support for this research was provided in part by Elekta, Inc.",
           0,
           "medical_physics"
          ],
          [
           "An evaluation of organic light emitting diode monitors for medical applications: Great timing, but luminance artifacts",
           "10.1118/1.4818056",
           2013,
           "Purpose:In contrast to the dominant medical liquid crystal display (LCD) technology, organic light‐emitting diode (OLED) monitors control the display luminance via separate light‐emitting diodes for each pixel and are therefore supposed to overcome many previously documented temporal artifacts of medical LCDs. We assessed the temporal and luminance characteristics of the only currently available OLED monitor designed for use in the medical treatment field (SONY PVM2551MD) and checked the authors’ main findings with another SONY OLED device (PVM2541).Methods:Temporal properties of the photometric output were measured with an optical transient recorder. Luminances of the three color primaries and white for all 256 digital driving levels (DDLs) were measured with a spectroradiometer. Between the luminances of neighboring DDLs, just noticeable differences were calculated according to a perceptual model developed for medical displays. Luminances of full screen (FS) stimuli were compared to luminances of smaller stimuli with identical DDLs.Results:All measured luminance transition times were below 300 μs. Luminances were independent of the luminance in the preceding frame. However, for the single color primaries, up to 50.5% of the luminances of neighboring DDLs were not perceptually distinguishable. If two color primaries were active simultaneously, between 36.7% and 55.1% of neighboring luminances for increasing DDLs of the third primary were even decreasing. Moreover, luminance saturation effects were observed when too many pixels were active simultaneously. This effect was strongest for white; a small white patch was close to 400 cd/m2, but in FS the luminance of white saturated at 162 cd/m2. Due to different saturation levels, the luminance of FS green and FS yellow could exceed the luminance of FS white for identical DDLs.Conclusions:The OLED temporal characteristics are excellent and superior to those of LCDs. However, the OLEDs revealed severe perceptually relevant artifacts with implications for applicability to medical imaging.",
           10,
           "medical_physics"
          ],
          [
           "A calibration‐free, one‐step method for quantitative photoacoustic tomography",
           "10.1118/1.4760981",
           2012,
           "Purpose: Recently reported quantitative photoacoustic tomography (PAT) has significantly expanded the utilities of PAT because it allows for recovery of tissue optical absorption coefficient which directly correlates with tissue physiological information. However, the recovery of optical absorption coefficient by the existing quantitative PAT approaches strongly depends on the accuracy of absorbed energy density distribution, and on the knowledge of accurate strength and distribution of incident light source. The purpose of this study is to develop a new algorithm for the reconstruction of optical absorption coefficient that does not depend on these initial parameters.Methods: Here the authors propose a novel one‐step reconstruction approach that can directly recover optical absorption coefficient from photoacoustic measurements along boundary domain. The authors validate the method using simulation and phantom experiments.Results: The authors have demonstrated experimental evidence that it is possible to directly recover optical absorption coefficient maps using boundary photoacoustic measurements coupled with the photon diffusion equation in just one step. The authors found that the method described is able to quantitatively reconstruct absorbing objects with different sizes and optical contrast levels.Conclusions: Compared to the authors’ previous two‐step methods, the reconstruction results obtained here show that the one‐step scheme can significantly improve the accuracy of absorption coefficient recovery.",
           24,
           "medical_physics"
          ],
          [
           "A comparison of ionization‐chamber and water‐calorimeter dosimetry for high‐energy x rays",
           "10.1118/1.596595",
           2003,
           "The temperature‐regulated, flexible, water calorimeter developed in the authors' laboratory was shown previously to yield a dose‐to‐water from 4‐MV x rays that is in very close agreement with ionization measurements made in accordance with the AAPM dosimetry protocol. The range of beam energies for this type of comparison has been increased to include 60Co, and 4‐, 6‐ and 25‐MV x rays. The grand mean of the ratios of doses obtained from the calorimeter and ionization chamber, the Cal/Ion ratio, for the four beam energies studied is 1.001±0.001. As no significant trend with beam energy was detected, it is concluded that the calorimeter and ionization chamber yield equally accurate results. Because the calibration of the calorimeter depends solely upon the accuracy with which water temperatures in the range 2–10 °C can be measured, and dose is given by the product of the specific heat of water and the temperature change produced by irradiation, the water calorimeter has the potential to place radiation dosimetry on a much firmer foundation than presently exists.",
           11,
           "medical_physics"
          ],
          [
           "Sci‐Sat AM (2) Therapy‐04: Evaluation of Ultrasound‐Based 3D Positioning System (Restitu by Resonant Medical) for Localizing and Delineating Prostate Targets for Image‐Guided Radiation Treatment: Phantom Study and Estimates of Distortions in US Images of a Patient",
           "10.1118/1.2244700",
           2006,
           "3D‐Ultrasound (US) promises to be a noninvasive alternative to the portal imaging of surgically implanted gold seeds for positioning the prostate before radiation treatment. In this work we have evaluated a new US system, the Restitu, manufactured by Resonant Medical (Montréal). Using a prostate phantom we have measured the base‐line reproducibility of couch shifts calculated with the Restitu software algorithms. We have also attempted to estimate the influence of US image artifacts on the calculated prostate position. Unlike similar early systems (e.g. BAT), Restitu uses 3D‐US to 3D‐US image registration to determine the prostate position relative to the position during the planning CT. If the internal organs remain stationary and the movement of the US probe is invariant during each fraction then we would expect that the calculated results would be immune to US image distortions. However, due primarily to variations in bladder filling, second‐order US artifacts need to be considered. Using 3D‐US images collected on a sample patient with a full and a half‐empty bladder, we have found the error caused by variations in the time of travel of the sound wave to be about −0.8 mm, and the error caused by sound wave refraction at tissue‐urine interfaces to be about 2.1 mm. The combined error, 2.2 mm, is close to the quoted system tolerance of ±2 mm, but may vary due to anatomical differences. These errors can be reduced under consistent full‐bladder operation.",
           0,
           "medical_physics"
          ],
          [
           "TU‐EE‐A2‐06: Are Dosimetric Guidelines of Adult Lung Cancer for Preventing Radiation Pneumonitis Applicable to Pediatric Radiotherapy Involving Lungs?",
           "10.1118/1.2962616",
           2008,
           "Purpose: Pediatric patients with Hodgkin's lymphoma and thoracic or paraspinal sarcomas who received radiotherapy may develop clinically significant radiation pneumonitis (RP) requiring the use of steroids. There are no dosimetric planning guidelines for pediatric lung to assess the likelihood of complication. We reviewed dose‐volume histograms (DVHs) and clinical complication data of 63 children treated on 2 prospective studies and evaluated the applicability of adult planning guidelines and risk models. Method and Materials: Forty children with Hodgkin's lymphoma and 23 with sarcoma receiving radiation to the thorax were studied. Patients with Hodgkin's lymphoma received 25.5 Gy involved‐field radiotherapy. Eight of which received 8 Gy to the entirety of one or both lungs through partial transmission blocks. Patients with sarcomas received 41.4–70.2 Gy conformal radiotherapy to the primary tumor. Clinical data on RP were collected from protocol databases and chart review with IRB approval. DVH parameters V13, V20, mean lung dose and normal tissue complication probability (NTCP) from adult lung models were calculated. Results: Four patients developed RP following radiotherapy. Two required the use of steroids (NCI CTC grade II). Of the 3 patients with Hodgkin's lymphoma who developed RP, 2 had received 8 Gy delivered to their entire right lung. Children with grade II RP have higher total lung DVHs, a V20 ⩾35% and mean lung dose above 16 Gy, consistent with the planning constraints set for adult lung cancer and Hodgkin's lymphoma. However, adult lung NTCP and risk models predicted low probability (0.2–0.3) for children who actually developed RP. Conclusion: The V20 and mean lung dose guidelines developed for adult lung cancer identify children at higher risk for RP. Better understanding of other clinical factors such as chemotherapeutic agents and individual sensitivity may be required to improve the predicability of NTCP models for children.",
           1,
           "medical_physics"
          ],
          [
           "SU‐E‐T‐460: Image Based Treatment Planning for Intraluminal Brachytherapy in Bile Duct Carcinoma",
           "10.1118/1.4814893",
           2013,
           "Purpose: 3D Image based treatment planning for intraluminal brachytherapy in bile duct carcinoma. Methods: Five patients with bile duct carcinoma were treated with definitive radiation therapy. Radiation therapy was delivered by means of external beam radiation therapy (EBRT) combined with HDR brachytherapy.Eclipse v8.6 TPS (Varian Medical Systems, USA) was used for treatment planning.In the diagnostic radiology suite, a flexible guide wire was passed through the biliary stent to a point past the stenosis. Subsequently catheter localisation, dummy wire was inserted and orthogonal films were used to confirm the position. All the patients were scanned on CT scanner (Siemens, Germany) with a slice thickness of 3 mm without any radio opaque dummy. The GTV, CTV OAR were contoured according to ICRU 62.Since the catheter is inserted in biliary stent, the applicator reconstruction is not possible. The first source point was reconstructed from the tip of the stent. From the orthogonal topograph the offset was calculated by measuring the tip of the stent to first dummy source distance. This offset was set in the planning. With the optimum source length the dose was calculated and CTV, OAR doses were quantified. The External and brachytherapy plans were summed to produce resultant DVH. Results: The applicator reconstruction accuracy was found to be within ±2mm. The mean, median dose of GTV, CTV was 32Gy, 23Gy and 18Gy, 13Gy respectively. The mean, median dose for duodenum was 7.6Gy and 2.8Gy. Conclusion: In radiography assisted planning, dose distribution is usually calculated according to the applicator geometry and in addition to fixed reference points. But with 3D brachytherapy planning the doses can be optimised to GTV and can be summed with external plan for clinical evaluation.",
           0,
           "medical_physics"
          ],
          [
           "Thoracic cavity segmentation algorithm using multiorgan extraction and surface fitting in volumetric CT",
           "10.1118/1.4866836",
           2014,
           "Purpose:To develop and validate a semiautomatic segmentation method for thoracic cavity volumetry and mediastinum fat quantification of patients with chronic obstructive pulmonary disease.Methods:The thoracic cavity region was separated by segmenting multiorgans, namely, the rib, lung, heart, and diaphragm. To encompass various lung disease‐induced variations, the inner thoracic wall and diaphragm were modeled by using a three‐dimensional surface‐fitting method. To improve the accuracy of the diaphragm surface model, the heart and its surrounding tissue were segmented by a two‐stage level set method using a shape prior. To assess the accuracy of the proposed algorithm, the algorithm results of 50 patients were compared to the manual segmentation results of two experts with more than 5 years of experience (these manual results were confirmed by an expert thoracic radiologist). The proposed method was also compared to three state‐of‐the‐art segmentation methods. The metrics used to evaluate segmentation accuracy were volumetric overlap ratio (VOR), false positive ratio on VOR (FPRV), false negative ratio on VOR (FNRV), average symmetric absolute surface distance (ASASD), average symmetric squared surface distance (ASSSD), and maximum symmetric surface distance (MSSD).Results:In terms of thoracic cavity volumetry, the mean ± SD VOR, FPRV, and FNRV of the proposed method were (98.17 ± 0.84)%, (0.49 ± 0.23)%, and (1.34 ± 0.83)%, respectively. The ASASD, ASSSD, and MSSD for the thoracic wall were 0.28 ± 0.12, 1.28 ± 0.53, and 23.91 ± 7.64 mm, respectively. The ASASD, ASSSD, and MSSD for the diaphragm surface were 1.73 ± 0.91, 3.92 ± 1.68, and 27.80 ± 10.63 mm, respectively. The proposed method performed significantly better than the other three methods in terms of VOR, ASASD, and ASSSD.Conclusions:The proposed semiautomatic thoracic cavity segmentation method, which extracts multiple organs (namely, the rib, thoracic wall, diaphragm, and heart), performed with high accuracy and may be useful for clinical purposes.",
           7,
           "medical_physics"
          ],
          [
           "Re‐evaluation of the dose to the cyst wall in P‐32 radiocolloid treatments of cystic brain tumors using the Dose–Point–Kernel and Monte Carlo methods",
           "10.1118/1.1599652",
           2003,
           "Intracavity instillation of β‐emitting colloid pharmaceuticals is a common technique used to treat cystic brain tumors. Most of the dosimetric calculations that have been reported in the literature for this problem are based on empirical formulas derived by Loevinger. Concentration of P‐32 radiolabeled solution for the delivery of a prescribed dose (200 Gy to the cyst wall) has been published previously using this formalism in what we refer to as a standard nomogram. The calculations using the Loevinger formulas for calculating the P‐32 activity necessary to achieve 200 Gy at the cyst wall is re‐evaluated and compared to numerically computed results based on full Monte Carlo simulations (EGSnrc) and the dose–point–kernel (DPK) integration method. For cyst diameters greater than 1 cm, the new calculations agree well with previously published results (the standard nomogram) to within a few percents. However, for cyst diameters of less than 1 cm, it is shown that the standard nomogram results underestimate the therapeutic activity by a factor of  for very small diameters  New tables based on our calculations are presented and the sources of discrepancies are identified. It is concluded that the new set of data based on our calculations should replace the standard nomogram to administer accurately the target dose to the cyst wall for the smaller diameter cysts ",
           15,
           "medical_physics"
          ],
          [
           "Attenuation and activation characteristics of steel and tungsten and the suitability of these materials for use in a fast neutron multileaf collimator",
           "10.1118/1.1376135",
           2008,
           "A computer controlled multileaf collimator (MLC) is being designed to replace the multirod collimator (MRC) at present used to shape the d(48.5)+Be neutron beam from the Harper Hospital superconducting cyclotron. The computer controlled MLC will improve efficiency and allow for the future development of intensity modulated radiation therapy with neutrons. The existing MRC uses tungsten rods, while the new MLC will use steel as the leaf material. In the current study the attenuation and activation characteristics of steel are compared with those of tungsten to ensure that (a) the attenuation achieved in the MLC is at least equivalent to that of the existing MRC, and (b) that the activation of the steel will not result in a significant change in the activation levels within the treatment room. The latter point is important since personnel exposure (particularly to the radiation therapy technologists) from induced radioactivity must be minimized. Measurement of the neutron beam attenuation in a broad beam geometry showed that a 30 cm thick steel leaf yielded 2.5% transmission. This compared favorably with the 4% transmission obtained with the existing MRC. Irradiation of steel and tungsten samples at different depths in a 30 cm steel block indicated that the activation of steel should be no worse than that of tungsten.",
           6,
           "medical_physics"
          ],
          [
           "Electron beam therapy with coil‐generated magnetic fields",
           "10.1118/1.1711477",
           2004,
           "This paper presents an initial study on the issues involved in the practical implementation of the use of transverse magnetic fields in electron beam therapy. By using such magnetic fields the dose delivered to the tumor region can increase significantly relative to that deposited to the healthy tissue. Initially we calculated the magnetic fields produced by the Helmholtz coil and modified Helmholtz coil configurations. These configurations, which can readily be used to generate high intensity magnetic fields, approximate the idealized magnetic fields studied in our previous publications. It was therefore of interest to perform a detailed study of the fields produced by these configurations. Electron beam dose distributions for 15 MeV electrons were calculated using the ACCEPTM code for a 3T transverse magnetic field produced by the modified Helmholtz configuration. The dose distribution was compared to those obtained with no magnetic field. The results were similar to those obtained in our previous work, where an idealized step function magnetic field was used and a 3T field was shown to be the optimal field strength. A simpler configuration was also studied in which a single external coil was used to generate the field. Electron dose distributions are also presented for a given geometry and given magnetic field strength using this configuration. The results indicate that this method is more difficult to apply to radiotherapy due to its lack of symmetry and its irregularity. For the various configurations dealt with here, a major problem is the need to shield the magnetic field in the beam propagation volume, a topic that must be studied in detail.",
           4,
           "medical_physics"
          ],
          [
           "Objective index of image fidelity for JPEG2000 compressed body CT images",
           "10.1118/1.3129159",
           2009,
           "Compression ratio (CR) has been the de facto standard index of compression level for medical images. The aim of the study is to evaluate the CR, peak signal‐to‐noise ratio (PSNR), and a perceptual quality metric (high‐dynamic range visual difference predictor HDR‐VDP) as objective indices of image fidelity for Joint Photographic Experts Group (JPEG) 2000 compressed body computed tomography (CT) images, from the viewpoint of visually lossless compression approach. A total of 250 body CT images obtained with five different scan protocols (5‐mm‐thick abdomen, 0.67‐mm‐thick abdomen, 5‐mm‐thick lung, 0.67‐mm‐thick lung, and 5‐mm‐thick low‐dose lung) were compressed to one of five CRs (reversible, 6:1, 8:1, 10:1, and 15:1). The PSNR and HDR‐VDP values were calculated for the 250 pairs of the original and compressed images. By alternately displaying an original and its compressed image on the same monitor, five radiologists independently determined if the pair was distinguishable or indistinguishable. The kappa statistic for the interobserver agreement among the five radiologists’ responses was 0.70. According to the radiologists' responses, the number of distinguishable image pairs tended to significantly differ among the five scan protocols at 6:1–10:1 compressions (Fisher‐Freeman‐Halton exact tests). Spearman's correlation coefficients between each of the CR, PSNR, and HDR‐VDP and the number of radiologists who responded as distinguishable were 0.72, −0.77, and 0.85, respectively. Using the radiologists' pooled responses as the reference standards, the areas under the receiver–operating–characteristic curves for the CR, PSNR, and HDR‐VDP were 0.87, 0.93, and 0.97, respectively, showing significant differences between the CR and PSNR , or HDR‐VDP , and between the PSNR and HDR‐VDP . In conclusion, the CR is less suitable than the PSNR or HDR‐VDP as an objective index of image fidelity for JPEG2000 compressed body CT images. The HDR‐VDP is more promising than the PSNR as such an index.",
           13,
           "medical_physics"
          ],
          [
           "SU‐E‐T‐337: Dynamic Tomotherapy Delivery with Running‐Start‐Stop: Comparing to Conventional Tomotherapy and VMAT Deliveries",
           "10.1118/1.4735424",
           2012,
           "Purpose: Despite of superior target dose uniformity, previous studies of helical tomotherapy (HT) show inferior longitudinal conformity and longer deliver time compared to volumetric‐modulated arc therapy (VMAT) plans, due to fixed jaw size with conventional HT. Dynamic delivery techniques were introduced to overcome these problems. This study is to compare the dosimetric performance of dynamic tomotherapy delivery (5.0cm jaw running‐start‐stop (RSS)) with fixed jaw HT and VMAT deliveries. Methods: Sixteen patient cases, including brain, head&neck (HN), lung and prostate, were selected and de‐identified prior to treatment planning. VMAT plans were generated using Varian RapidArc™ (RA) (one or two arcs) and HT plans using TomoTherapy® (fixed 2.5cm jaw). The tomotherapy RSS plans were generated using tomotherapy's research engine and optimized based on 5.0cm dynamic jaw, which allows larger jaw opening for lower dose gradient and smaller jaw opening at the target border when sharp penumbra is required. All 16 cases were planned based on identical contours, prescriptions, and planning objectives. Dose indices for targets and critical organs were compared based on dose‐volume histograms, delivery time, and monitor units. Results: The average delivery time was reduced from 4.8min (HT) to 2.92min (RSS). RSS showed comparable target dose homogeneity to HT. Three delivery techniques showed comparable normal tissue sparing for lung cases, with improved sparing of cord with RSS. For prostate cases, RSS showed improved bladder and rectum doses compared to HT due to better longitudinal sparing. Superior normal tissue sparing was observed in RSS plans for optical nerves in brain cases and larynx or parotids for HN cases. Conclusions: Tomotherapy RSS with 5.0cm dynamic jaw is overall comparable, if not better, to 2.5cm fixed jaw HT, with faster treatment delivery. It also showed improved longitudinal dose conformity to critical structures adjacent to the target, which is comparable to RA technique. Yu Chen is employee of Accuray‐Tomotherapy, Inc.",
           1,
           "medical_physics"
          ],
          [
           "Output variation from an intensity modulating dynamic collimator",
           "10.1118/1.1493782",
           2002,
           "Intensity modulated radiation therapy (IMRT) offers a method of delivering radiation dose conforming to the shape of targets while minimizing the dose to the surrounding tissue and nearby critical organs. One popular device is the NOMOS MIMiC Collimator coupled to the CORVUS treatment planning system. The MIMiC collimator, mounted on a linac head, opens and closes one or more of its 40 small leaves as determined by the planner while the linac delivers radiation and the gantry rotates. This dynamic IMRT allows the intensity to be modulated yielding a highly conformal dose distribution. However, the dose output becomes a function of the detailed manner in which the leaves open and close, since the opening and closing are not instantaneous. We investigate the effect of switch rates and delay in the open/close events on the output profiles. The output is enhanced as the switch rate increases. The enhancement factor at any point of measurement is dependent on its distance from the central plane. We interpret these variations in terms of a simple model, which includes the effect of leaf travel time during the process of opening and closing. We also include the time delay in establishing the specified pressure in the pneumonic device, which controls the opening and closing of the leaves. The information presented here offers a means for incorporating these output changes into the planning system. This may avoid the current situation where many patient plans need to be renormalized based on the actual measurement taken during the delivery of the specified intensity pattern to a phantom.",
           1,
           "medical_physics"
          ],
          [
           "SU‐E‐T‐333: Immobilization for Proton Therapy ‐ How Is It Different to Photon Therapy?",
           "10.1118/1.4735420",
           2012,
           "Purpose: To describe considerations in proton therapy immobilization and the effects which design elements have on the proton dose distribution. Methods: Proton therapy has dose distribution advantages over photons through the Bragg peak. This high dose region and sharp distal fall off that produces no primary particle exit dose can be placed at any point within the patient leading to the use of fewer beams and lower integral doses. Proton patient immobilization needs to reduce patient motion to the largest extent feasible, as is the case with other radiation therapy modalities, but also needs to consider the effect of the immobilization device on the proton range and whether this is accurately reflected in the dose calculation. Results: Our proton treatment center has treated patients with protons for over 20 years, and the development of effective immobilization methods has been an integral part of this experience. For the various anatomic sites, specific devices have been developed that position and immobilize the patient reproducibly and effectively. Attention was paid to minimal proton water equivalent thickness (WET) to minimize the effect on proton beam penumbra. The WET of each immobilization material has been well characterized and incorporated in the (CT‐based) proton range calculation to minimize systematic errors in the proton range uncertainty. In our experience, proton immobilization devices should have beveled edges when possible to avoid edge effects that can drastically affect the depth of proton penetration. Effective use of internal immobilization, such a rectal balloons or breath holding, is also important to minimize ITV margins and suppress motion‐related beam range uncertainties that are unique to proton therapy. Conclusions: In proton therapy patient immobilization, additional considerations are needed to ensure that the immobilization device does not negatively impact the proton dose distribution and its uncertainty.",
           0,
           "medical_physics"
          ],
          [
           "Automated volume analysis of head and neck lesions on CT scans using 3D level set segmentation",
           "10.1118/1.2794174",
           2007,
           "The authors have developed a semiautomatic system for segmentation of a diverse set of lesions in head and neck CT scans. The system takes as input an approximate bounding box, and uses a multistage level set to perform the final segmentation. A data set consisting of 69 lesions marked on 33 scans from 23 patients was used to evaluate the performance of the system. The contours from automatic segmentation were compared to both 2D and 3D gold standard contours manually drawn by three experienced radiologists. Three performance metric measures were used for the comparison. In addition, a radiologist provided quality ratings on a 1 to 10 scale for all of the automatic segmentations. For this pilot study, the authors observed that the differences between the automatic and gold standard contours were larger than the interobserver differences. However, the system performed comparably to the radiologists, achieving an average area intersection ratio of  compared to an average of  between two radiologists. The average absolute area error was  compared to , and the average 2D distance was 1.38 mm compared to 0.84 mm between the radiologists. In addition, the quality rating data showed that, despite the very lax assumptions made on the lesion characteristics in designing the system, the automatic contours approximated many of the lesions very well.",
           36,
           "medical_physics"
          ],
          [
           "Velocity measurement based on bolus tracking with the aid of three‐dimensional reconstruction from digital subtraction angiography",
           "10.1118/1.597990",
           2002,
           "The problem of blood flow measurement in x‐ray angiography using measurements of the leading edge of the contrast bolus as it traverses the vascular bed is considered. A new technique for velocity measurement is presented based upon the ratio of the temporal derivative to the spatial derivative of the contrast bolus in the direction of flow. With the addition of a small correction factor, the value obtained is shown to reflect the transport velocity, or the velocity at which the contrast is transported down the vessel of interest. Most blood flow measurements based on bolus tracking techniques are actually using the contrast transport velocity to represent the blood flow velocity. Because of the streaming that occurs due to laminary flow conditions, the measured transport velocity is found to be somewhere between the average and the peak (central) fluid velocities for measurements taken during the traversal of the bolus leading edge. The spatial and temporal variation of the transport velocity are found to be consistent with the bolus motion expected in the presence of laminar flow. From x‐ray images of contrast passage through simple tubes, we find that the derivative method measures the transport velocity during passage of the bolus leading edge. In most cases of laminar blood flow, the leading edge transport velocity can be 20%–40% higher than the average blood velocity.",
           7,
           "medical_physics"
          ],
          [
           "A study of the effect of cone shielding in intraoperative radiotherapy",
           "10.1118/1.597584",
           2003,
           "The primary goal of intraoperative radiation therapy is to irradiate the intraoperatively determined tumor target volume with a single fraction of tumoroidal dose while minimizing the dose to all adjacent healthy tissues. To reduce dose outside the treatment volume, lead sheets are often used to cover the external surface of the cone tip thus providing a shielding for the tissues outside the field. In this paper, the effect of the shielding on the depth dose distributions and dose profiles at different depths is studied based on experimental data. The results were also compared against an EGS4 Monte Carlo code for the same geometry as the measurements. The cones varied in size having diameters of 5 cm, 7 cm, and 9 cm, and the electron energies ranged from 6 MeV to 22 MeV. The depth dose curves and dose profiles (at two different depths in the phantom) were measured and computed with and without the lead shielding for the various combinations of cone sizes and electron energies using a water phantom to simulate the patient. It was found that the presence of lead increases on average across the treatment area the dose to the tumor from 2% up to 5%, while the dose outside the cone was reduced by as much as 75%. Both measurements and calculations were found to be in agreement.",
           7,
           "medical_physics"
          ],
          [
           "Determination of the thermal neutron flux in a fast neutron beam by use of a boron‐coated ionization chamber",
           "10.1118/1.597630",
           2003,
           "The thermal neutron distribution in slow and fast neutron beams is usually determined using the foil activation method. In this work a small magnesium walled ionization chamber, in which the inner surface of the wall has been coated with 10B to increase the sensitivity for thermal neutrons, is used to estimate the thermal neutron component of the beam. After calibration and determination of the directional response in a thermal neutron beam a comparison with foil activation at different depths in water was performed to investigate the reliability of the ionization measurements. The chamber was used in a computer controlled water phantom to measure the depth and lateral distribution of the thermal neutron dose. With this arrangement two‐dimensional scans of the thermal neutrons could be performed quickly and with high accuracy.",
           17,
           "medical_physics"
          ],
          [
           "Dosimetric evaluation of photon dose calculation under jaw and MLC shielding",
           "10.1118/1.4820443",
           2013,
           "Purpose:The accuracy of photon dose calculation algorithms in out‐of‐field regions is often neglected, despite its importance for organs at risk and peripheral dose evaluation. The present work has assessed this for the anisotropic analytical algorithm (AAA) and the Acuros‐XB algorithms implemented in the Eclipse treatment planning system. Specifically, the regions shielded by the jaw, or the MLC, or both MLC and jaw for flattened and unflattened beams have been studied.Methods:The accuracy in out‐of‐field dose under different conditions was studied for two different algorithms. Measured depth doses out of the field, for different field sizes and various distances from the beam edge were compared with the corresponding AAA and Acuros‐XB calculations in water. Four volumetric modulated arc therapy plans (in the RapidArc form) were optimized in a water equivalent phantom, PTW Octavius, to obtain a region always shielded by the MLC (or MLC and jaw) during the delivery. Doses to different points located in the shielded region and in a target‐like structure were measured with an ion chamber, and results were compared with the AAA and Acuros‐XB calculations. Photon beams of 6 and 10 MV, flattened and unflattened were used for the tests.Results:Good agreement between calculated and measured depth doses was found using both algorithms for all points measured at depth greater than 3 cm. The mean dose differences (±1SD) were −8% ± 16%, −3% ± 15%, −16% ± 18%, and −9% ± 16% for measurements vs AAA calculations and −10% ± 14%, −5% ± 12%, −19% ± 17%, and −13% ± 14% for Acuros‐XB, for 6X, 6 flattening‐filter free (FFF), 10X, and 10FFF beams, respectively. The same figures for dose differences relative to the open beam central axis dose were: −0.1% ± 0.3%, 0.0% ± 0.4%, −0.3% ± 0.3%, and −0.1% ± 0.3% for AAA and −0.2% ± 0.4%, −0.1% ± 0.4%, −0.5% ± 0.5%, and −0.3% ± 0.4% for Acuros‐XB. Buildup dose was overestimated with AAA, while Acuros‐XB gave results more consistent with measurements. From RapidArc plan analysis the average difference between calculation and measurement in the shielded region was −0.3% ± 0.4% and −2.5% ± 1.2% for AAA and Acuros‐XB, respectively, relative to the mean target dose value (1.6% ± 2.3%, −12.7% ± 4.0% if relative to each local value). These values were compared with the corresponding differences in the target structure: −0.7% ± 2.3% for AAA, and −0.5% ± 2.3% for Acuros‐XB.Conclusions:The two algorithms analyzed showed encouraging results in predicting out‐of‐field region dose for clinical use.",
           15,
           "medical_physics"
          ],
          [
           "Whole‐body tumor segmentation from PET/CT images using a two‐stage cascaded neural network with camouflaged object detection mechanisms",
           "10.1002/mp.16438",
           2023,
           "BackgroundWhole‐body Metabolic Tumor Volume (MTVwb) is an independent prognostic factor for overall survival in lung cancer patients. Automatic segmentation methods have been proposed for MTV calculation. Nevertheless, most of existing methods for patients with lung cancer only segment tumors in the thoracic region.PurposeIn this paper, we present a Two‐Stage cascaded neural network integrated with Camouflaged Object Detection mEchanisms (TS‐Code‐Net) for automatic segmenting tumors from whole‐body PET/CT images.MethodsFirstly, tumors are detected from the Maximum Intensity Projection (MIP) images of PET/CT scans, and tumors' approximate localizations along z‐axis are identified. Secondly, the segmentations are performed on PET/CT slices that contain tumors identified by the first step. Camouflaged object detection mechanisms are utilized to distinguish the tumors from their surrounding regions that have similar Standard Uptake Values (SUV) and texture appearance. Finally, the TS‐Code‐Net is trained by minimizing the total loss that incorporates the segmentation accuracy loss and the class imbalance loss.ResultsThe performance of the TS‐Code‐Net is tested on a whole‐body PET/CT image data‐set including 480 Non‐Small Cell Lung Cancer (NSCLC) patients with five‐fold cross‐validation using image segmentation metrics. Our method achieves 0.70, 0.76, and 0.70, for Dice, Sensitivity and Precision, respectively, which demonstrates the superiority of the TS‐Code‐Net over several existing methods related to metastatic lung cancer segmentation from whole‐body PET/CT images.ConclusionsThe proposed TS‐Code‐Net is effective for whole‐body tumor segmentation of PET/CT images. Codes for TS‐Code‐Net are available at: https://github.com/zyj19/TS‐Code‐Net.",
           2,
           "medical_physics"
          ],
          [
           "Statistical cerebrovascular segmentation in three‐dimensional rotational angiography based on maximum intensity projections",
           "10.1118/1.2001820",
           2005,
           "Segmentation of three‐dimensional rotational angiography (3D‐RA) can provide quantitative 3D morphological information of vasculature. The expectation maximization‐(EM‐) based segmentation techniques have been widely used in the medical image processing community, because of the implementation simplicity, and computational efficiency of the approach. In a brain 3D‐RA, vascular regions usually occupy a very small proportion (around 1%) inside an entire image volume. This severe imbalance between the intensity distributions of vessels and background can lead to inaccurate statistical modeling in the EM‐based segmentation methods, and thus adversely affect the segmentation quality for 3D‐RA. In this paper we present a new method for the extraction of vasculature in 3D‐RA images. The new method is fully automatic and computationally efficient. As compared with the original 3D‐RA volume, there is a larger proportion (around 20%) of vessels in its corresponding maximum intensity projection (MIP) image. The proposed method exploits this property to increase the accuracy of statistical modeling with the EM algorithm. The algorithm takes an iterative approach to compiling the 3D vascular segmentation progressively with the segmentation of MIP images along the three principal axes, and use a winner‐takes‐all strategy to combine the results obtained along individual axes. Experimental results on 12 3D‐RA clinical datasets indicate that the segmentations obtained by the new method exhibit a high degree of agreement to the ground truth segmentations and are comparable to those produced by the manual optimal global thresholding method.",
           14,
           "medical_physics"
          ],
          [
           "Evaluation of brachytherapy lung implant dose distributions from photon‐emitting sources due to tissue heterogeneities",
           "10.1118/1.3641872",
           2011,
           "Purpose:Photon‐emitting brachytherapy sources are used for permanent implantation to treat lung cancer. However, the current brachytherapy dose calculation formalism assumes a homogeneous water medium without considering the influence of radiation scatter or tissue heterogeneities. The purpose of this study was to determine the dosimetric effects of tissue heterogeneities for permanent lung brachytherapy.Methods:The MCNP5 v1.40 radiation transport code was used for Monte Carlo (MC) simulations. Point sources with energies of 0.02, 0.03, 0.05, 0.1, 0.2, and 0.4 MeV were simulated to cover the range of pertinent brachytherapy energies and to glean dosimetric trends independent of specific radionuclide emissions. Source positions from postimplant CT scans of five patient implants were used for source coordinates, with dose normalized to 200 Gy at the center of each implant. With the presence of fibrosis (around the implant), cortical bone, lung, and healthy tissues, dose distributions andPTVDVH were calculated using the MCNP *FMESH4 tally and the NIST mass‐energy absorption coefficients. This process was repeated upon replacing all tissues with water. For all photon energies, 109 histories were simulated to achieve statistical errors (k = 1) typically of 1%.Results:The mean PTV doses calculated using tissue heterogeneities for all five patients changed (compared to dose to water) by only a few percent over the examined photon energy range, as did PTV dose at the implant center. ThePTVV100 values were 81.2%, 90.0% (as normalized), 94.3%, 93.9%, 92.7%, and 92.2% for 0.02, 0.03, 0.05, 0.1, 0.2, and 0.4 MeV source photons, respectively. Relative to water, the maximum bone doses were higher by factors of 3.7, 5.1, 5.2, 2.4, 1.2, and 1.0 The maximum lung doses were about 0.98, 0.94, 0.91, 0.94, 0.97, and 0.99. Relative to water, the maximum healthy tissue doses at the mediastinal position were higher by factors of 9.8, 2.2, 1.3, 1.1, 1.1, and 1.1. However, the maximum doses to these healthy tissues were only 3.1, 7.2, 11.3, 10.9, 9.0, and 8.1 Gy while maximum bone doses were 66, 177, 236, 106, 49, and 39 Gy, respectively. Similarly, maximum lung doses were 55, 66, 73, 74, 73, and 73 Gy, respectively.Conclusions:The current brachytherapy dose calculation formalism overestimates PTV dose and significantly underestimates doses to bone and healthy tissue. Further investigation using specific brachytherapy source models and patient‐based CT datasets as MC input may indicate whether the observed trends can be generalized for low‐energy lung brachytherapy dosimetry.",
           8,
           "medical_physics"
          ],
          [
           "Enhancements to commissioning techniques and quality assurance of brachytherapy treatment planning systems that use model‐based dose calculation algorithmsa)",
           "10.1118/1.3429131",
           2010,
           "The current standard for brachytherapy dose calculations is based on the AAPM TG‐43 formalism. Simplifications used in the TG‐43 formalism have been challenged by many publications over the past decade. With the continuous increase in computing power, approaches based on fundamental physics processes or physics models such as the linear‐Boltzmann transport equation are now applicable in a clinical setting. Thus, model‐based dose calculation algorithms (MBDCAs) have been introduced to address TG‐43 limitations for brachytherapy. The MBDCA approach results in a paradigm shift, which will require a concerted effort to integrate them properly into the radiation therapy community. MBDCA will improve treatment planning relative to the implementation of the traditional TG‐43 formalism by accounting for individualized, patient‐specific radiation scatter conditions, and the radiological effect of material heterogeneities differing from water. A snapshot of the current status of MBDCA and AAPM Task Group reports related to the subject of QA recommendations for brachytherapy treatment planning is presented. Some simplified Monte Carlo simulation results are also presented to delineate the effects MBDCA are called to account for and facilitate the discussion on suggestions for (i) new QA standards to augment current societal recommendations, (ii) consideration of dose specification such as dose to medium in medium, collisional kerma to medium in medium, or collisional kerma to water in medium, and (iii) infrastructure needed to uniformly introduce these new algorithms. Suggestions in this Vision 20/20 article may serve as a basis for developing future standards to be recommended by professional societies such as the AAPM, ESTRO, and ABS toward providing consistent clinical implementation throughout the brachytherapy community and rigorous quality management of MBDCA‐based treatment planning systems.",
           48,
           "medical_physics"
          ],
          [
           "Effect of improved TLD dosimetry on the determination of dose rate constants for <sup>125</sup>I and <sup>103</sup>Pd brachytherapy seeds",
           "10.1118/1.4895003",
           2014,
           "Purpose:To more accurately account for the relative intrinsic energy dependence and relative absorbed‐dose energy dependence of TLDs when used to measure dose rate constants (DRCs) for 125I and 103Pd brachytherapy seeds, to thereby establish revised “measured values” for all seeds and compare the revised values with Monte Carlo and consensus values.Methods:The relative absorbed‐dose energy dependence, frel, for TLDs and the phantom correction, Pphant, are calculated for 125I and 103Pd seeds using the EGSnrc BrachyDose and DOSXYZnrc codes. The original energy dependence and phantom corrections applied to DRC measurements are replaced by calculated (frel)−1 and Pphant values for 24 different seed models. By comparing the modified measured DRCs to the MC values, an appropriate relative intrinsic energy dependence, , is determined. The new Pphant values and relative absorbed‐dose sensitivities, , calculated as the product of (frel)−1 and , are used to individually revise the measured DRCs for comparison with Monte Carlo calculated values and TG‐43U1 or TG‐43U1S1 consensus values.Results:In general, frel is sensitive to the energy spectra and models of the brachytherapy seeds. Values may vary up to 8.4% among 125I and 103Pd seed models and common TLD shapes. Pphant values depend primarily on the isotope used. Deduced  values are 1.074 ± 0.015 and 1.084 ± 0.026 for 125I and 103Pd seeds, respectively. For (1 mm)3 chips, this implies an overall absorbed‐dose sensitivity relative to 60Co or 6 MV calibrations of 1.51 ± 1% and 1.47 ± 2% for 125I and 103Pd seeds, respectively, as opposed to the widely used value of 1.41. Values of Pphant calculated here have much lower statistical uncertainties than literature values, but systematic uncertainties from density and composition uncertainties are significant. Using these revised values with the literature's DRC measurements, the average discrepancies between revised measured values and Monte Carlo values are 1.2% and 0.2% for 125I and 103Pd seeds, respectively, compared to average discrepancies for the original measured values of 4.8%. On average, the revised measured values are 4.3% and 5.9% lower than the original measured values for 103Pd and 125I seeds, respectively. The average of revised DRCs and Monte Carlo values is 3.8% and 2.8% lower for 125I and 103Pd seeds, respectively, than the consensus values in TG‐43U1 or TG‐43U1S1.Conclusions:This work shows that frel is TLD shape and seed model dependent suggesting a need to update the generalized energy response dependence, i.e., relative absorbed‐dose sensitivity, measured 25 years ago and applied often to DRC measurements of 125I and 103Pd brachytherapy seeds. The intrinsic energy dependence for LiF TLDs deduced here is consistent with previous dosimetry studies and emphasizes the need to revise the DRC consensus values reported by TG‐43U1 or TG‐43U1S1.",
           14,
           "medical_physics"
          ],
          [
           "A spectroscopic study of the chromatic properties of GafChromic™EBT3 films",
           "10.1118/1.4941312",
           2016,
           "Purpose:This work provides an interpretation of the chromatic properties of GafChromic™EBT3 films based on the chemical nature of the polydiacetylene (PDA) molecules formed upon interaction with ionizing radiation. The EBT3 films become optically less transparent with increasing radiation dose as a result of the radiation‐induced polymerization of diacetylene monomers. In contrast to empirical quantification of the chromatic properties, less attention has been given to the underlying molecular mechanism that induces the strong decrease in transparency.Methods:Unlaminated GafChromic™EBT3 films were irradiated with a 6 MV photon beam to dose levels up to 20 Gy. The optical absorption properties of the films were investigated using visible (vis) spectroscopy. The presence of PDA molecules in the active layer of the EBT3 films was investigated using Raman spectroscopy, which probes the vibrational modes of the molecules in the layer. The vibrational modes assigned to PDA's were used in a theoretical vis‐absorption model to fit our experimental vis‐absorption spectra. From the fit parameters, one can assess the relative contribution of different PDA conformations and the length distribution of PDA's in the film.Results:Vis‐spectroscopy shows that the optical density increases with dose in the full region of the visible spectrum. The Raman spectrum is dominated by two vibrational modes, most notably by the ν(C≡C) and the ν(C=C) stretching modes of the PDA backbone. By fitting the vis‐absorption model to experimental spectra, it is found that the active layer contains two distinct PDA conformations with different absorption properties and reaction kinetics. Furthermore, the mean PDA conjugation length is found to be 2–3 orders of magnitude smaller than the crystals PDA's are embedded in.Conclusions:Vis‐ and Raman spectroscopy provided more insight into the molecular nature of the radiochromic properties of EBT3 films through the identification of the excited states of PDA and the presence of two PDA conformations. The improved knowledge on the molecular composition of EBT3's active layer provides a framework for future fundamental modeling of the dose–response.",
           29,
           "medical_physics"
          ],
          [
           "AAPM Task Group Report 261: Comprehensive quality control methodology and management of dental and maxillofacial cone beam computed tomography (CBCT) systems",
           "10.1002/mp.16911",
           2024,
           "Cone‐beam computed tomography (CBCT) systems specifically designed and manufactured for dental, maxillofacial imaging (MFI) and otolaryngology (OLR) applications have been commercially available in the United States since 2001 and have been in widespread clinical use since. Until recently, there has been a lack of professional guidance available for medical physicists about how to assess and evaluate the performance of these systems and about the establishment and management of quality control (QC) programs. The owners and users of dental CBCT systems may have only a rudimentary understanding of this technology, including how it differs from conventional multidetector CT (MDCT) in terms of acceptable radiation safety practices. Dental CBCT systems differ from MDCT in several ways and these differences are described. This report provides guidance to medical physicists and serves as a basis for stakeholders to make informed decisions regarding how to manage and develop a QC program for dental CBCT systems. It is important that a medical physicist with experience in dental CBCT serves as a resource on this technology and the associated radiation protection best practices. The medical physicist should be involved at the pre‐installation stage to ensure that a CBCT room configuration allows for a safe and efficient workflow and that structural shielding, if needed, is designed into the architectural plans. Acceptance testing of new installations should include assessment of mechanical alignment of patient positioning lasers and x‐ray beam collimation and benchmarking of essential image quality performance parameters such as image uniformity, noise, contrast‐to‐noise ratio (CNR), spatial resolution, and artifacts. Several approaches for quantifying radiation output from these systems are described, including simply measuring the incident air‐kerma (Kair) at the entrance surface of the image receptor. These measurements are to be repeated at least annually as part of routine QC by the medical physicist. QC programs for dental CBCT, at least in the United States, are often driven by state regulations, accreditation program requirements, or manufacturer recommendations.",
           0,
           "medical_physics"
          ],
          [
           "Computer‐aided diagnosis in chest radiography",
           "10.1118/1.1376645",
           2008,
           "Automating mass chest screening for tuberculosis (TB) requires segmentation and texture analysis in chest radiographs. Several rule‐based schemes, pixel classifiers, and active shape model techniques for segmenting lung fields in chest radiographs are described and compared. An improved version of the active shape model segmentation technique, originally developed by Cootes and Taylor from Manchester University, UK, is described that uses optimal local features to steer the segmentation process and outperforms the original method in segmentation tasks for several types of medical images: chest radiographs and slices from MRI brain data. In order to segment the posterior ribs in PA chest radiographs, a statistical model of the complete rib cage is constructed using principal components analysis and a method is described to fit this model to input images automatically. For texture analysis, an extension is proposed to the framework of locally orderless images, a multiscale description of local histograms recently proposed by Koenderink and Van Doorn from Utrecht University, The Netherlands. The segmentation and texture analysis techniques are combined into a single method that automatically detects textural abnormalities in chest radiographs and estimates the probability that an image contains abnormalities. The method was evaluated on two databases. On a 200 case database of clinical chest films with interstitial disease from the University of Chicago, excellent results are obtained (area under the ROC curve  The results for a 600 case database from a TB screening program are encouraging (area under the ROC curve ",
           13,
           "medical_physics"
          ],
          [
           "SU‐C‐BRA‐01: Efficient Generation of Beamlet Arrays with Hybrid Multileaf Collimator for Grid Therapy",
           "10.1118/1.3611461",
           2011,
           "Purpose: To develop a simple method of generating megavoltage beamlet arrays for efficient grid therapy. Methods: Multileaf collimators (MLC) were constructed by mounting equally‐spaced, rectangular, lead sheets on Varian linac block trays, in a divergent geometry. The lead leaves were positioned orthogonal to the same alternating leaf pattern beneath a Varian MLC. Lead sheets with nominal thicknesses of 6.4, 3.2 and 1.6 mm resulted in projected beamlets at linac isocenter of 10×10, 5×5 and 5×2.5 mm respectively. Relative to an open beam, the symmetric grid beam area is 25% open, 50% shadow of single MLC leaf and 25% shadow of overlapping MLC leaves. Kodak EDR‐2 film, ISP Gafchromic EBT film and leuco crystal violet micelle gels with optical cone beam CT readout were used to characterize dose distributions. The impact of the x‐ray beam flattening filter was measured by operating the Varian 2100 series linac in 6 MV mode with and without the filter. Modulation ratios were recorded at water depths of 15 to 200 mm. Orthogonal 5×5 mm grid beams offset by 5 mm were delivered to a 95 mm diameter cylinder of gel in a cubic water phantom at 100 mm depths. Results: Dose rates from beamlet arrays and single beamlets, defined by linac jaws, were similar. Removing the flattening filter doubled the dose rate but had a minor effect on dose modulation. Optical density modulation ratio (5×5 mm beamlet / single leaf shadow) decreased from 7 at 15 mm to 4 at 200 mm depth in water. The gel 3D distribution demonstrated the anticipated features of intersecting diverging beamlet arrays with central dose modulations of 3.5. Conclusions: A hybrid system of orthogonal linac and block tray MLC leaves provides a simple method of generating arrays of megavoltage photon beamlets for efficient delivery of grid therapy.W Francis was partially supported by a London Regional Cancer Program Small Grants for grid therapy development.",
           2,
           "medical_physics"
          ],
          [
           "Modeling and incorporating cardiac‐induced lung tissue motion in a breathing motion model",
           "10.1118/1.4866888",
           2014,
           "Purpose:The purpose of this work is to develop a cardiac‐induced lung motion model to be integrated into an existing breathing motion model.Methods:The authors’ proposed cardiac‐induced lung motion model represents the lung tissueˈs specific response to the subjectˈs cardiac cycle. The model is mathematically defined as a product of a converging polynomial functionh of the cardiac phase (c) and the maximum displacement  of each voxel () among all the cardiac phases. The function h(c) was estimated from cardiac‐gated MR imaging of ten healthy volunteers using an Akaike Information Criteria optimization algorithm. For each volunteer, a total of 24 short‐axis and 18 radial planar views were acquired on a 1.5 T MR scanner during a series of 12–15 s breath‐hold maneuvers. Each view contained 30 temporal frames of equal time‐duration beginning with the end‐diastolic cardiac phase. The frames in each of the planar views were resampled to create a set of three‐dimensional (3D) anatomical volumes representing thoracic anatomy at different cardiac phases. A 3D multiresolution optical flow deformable image registration algorithm was used to quantify the difference in tissue position between the end‐diastolic cardiac phase and the remaining cardiac phases. To account for image noise, voxel displacements whose maximum values were less than 0.3 mm, were excluded. In addition, the blood vessels were segmented and excluded in order to eliminate registration artifacts caused by blood‐flow.Results:The average cardiac‐induced lung motions for displacements greater than 0.3 mm were found to be 0.86 ± 0.74 and 0.97 ± 0.93 mm in the left and right lungs, respectively. The average model residual error for the ten healthy volunteers was found to be 0.29 ± 0.08 mm in the left lung and 0.38 ± 0.14 mm in the right lung for tissue displacements greater than 0.3 mm. The relative error decreased with increasing cardiac‐induced lung tissue motion. While the relative error was > 60% for submillimeter cardiac‐induced lung tissue motion, the relative error decreased to < 5% for cardiac‐induced lung tissue motion that exceeded 10 mm in displacement.Conclusions:The authors’ studies implied that modeling and including cardiac‐induced lung motion would improve breathing motion model accuracy for tissues with cardiac‐induced motion greater than 0.3 mm.",
           7,
           "medical_physics"
          ],
          [
           "Integrated multicriterial optimization of beam angles and intensity profiles for coplanar and noncoplanar head and neck IMRT and implications for VMAT",
           "10.1118/1.4736803",
           2012,
           "Purpose:To quantify improved salivary gland sparing for head and neck cancer patients using intensity‐modulated radiotherapy (IMRT) plans based on integrated computerized optimization of beam orientations and intensity profiles. To assess if optimized nonzero couch angles also improve VMAT plans.Methods:Our in‐house developed algorithm iCycle was used for automated generation of multicriterial optimized plans with optimized beam orientations and intensity profiles, and plans with optimized profiles for preselected beam arrangements. For 20 patients, five IMRT plans, based on one “wish‐list,” were compared: (i) and (ii) seven‐ and nine‐beam equiangular coplanar plans (iCycle7equi, iCycle9equi), (iii) and (iv) nine‐beam plans with optimized coplanar and noncoplanar beam orientations (iCyclecopl, iCyclenoncopl), and (v) a nine‐beam coplanar plan with optimized gantry angles and one optimized couch rotation (iCyclecouch). VMAT plans without and with this optimized couch rotation were evaluated.Results:iCyclenoncopl resulted in the best salivary gland sparing, while iCyclecouch yielded similar results for 18 patients. For iCycle7equi, submandibular gland NTCP values were on average 5% higher. iCycle9equi performed better than iCycle7equi. iCyclecopl showed further improvement. Application of the optimized couch angle from iCyclecouch also improved NTCP values in VMAT plans.Conclusions:iCycle allows objective comparison of competing planning strategies. Integrated optimization of beam profiles and angles can significantly improve normal tissue sparing, yielding optimal results for iCyclenoncopl.",
           50,
           "medical_physics"
          ],
          [
           "Dosimetry of a radioactive coronary balloon dilitation catheter for treatment of neointimal hyperplasia",
           "10.1118/1.597761",
           2003,
           "Recent reports suggest that intraluminal irradiation of coronary arteries in conjunction with balloon angioplasty reduces proliferation of smooth muscle cells and neointima formation, thereby inhibiting restenosis. One possible irradiation technique is to inflate the balloon dilitation catheter with a radioactive solution. This has advantages over other proposed irradiation procedures, in that accurate source positioning and uniform dose to the vessel wall are assured. Several high‐energy beta‐minus emitters may be suitable for this application. We present experimental measurements and analytical calculations of the dose distribution around a 3‐mm‐diam by 20‐mm‐long balloon filled with 90Y‐chloride solution. The dose rate at the surface of the balloon is approximately 0.14 cGy/s per mCi/ml (3.78×10−11 Gy/s per Bq/ml), with the dose decreasing to 53% at 0.5 mm, and <5% at 3.5‐mm radial distance. 90Y and other possible isotopes are currently available at specific concentrations ≥50 mCi/ml (1.85×109 Bq/ml), which enables the delivery of 20 Gy in less than 5 min. The dosimetric and radiation safety advantages of this system warrant further feasibility studies. Issues of concern include incorporating the beta‐emitter into a suitable chemical form, and assessing organ and whole body doses in the (<1 in 103) event of balloon failure.",
           50,
           "medical_physics"
          ],
          [
           "Models in radiotherapy: Definition of decision criteria",
           "10.1118/1.595707",
           2003,
           "A method is presented by which dose distributions in radiotherapy may be judged. This method, based on statistical decision theory, combines the calculated probabilities of radiation induced complications (including failure to control disease) with the therapist's judgment of the morbidity of each complication to yield a single value representing the clinical utility of the dose distribution. Using this figure of merit, alternative dose distributions can be compared on a clinical basis. If the morbidities associated with each injury are satisfactorily estimated, and the dose response parameters are adjusted to match clinical experience, this method can be used to evaluate novel treatment techniques prior to their implementation. Automatic optimization algorithms can be used to maximize the figure of merit as a function of the physical treatment parameters so as to provide a statistically optimal treatment.",
           49,
           "medical_physics"
          ],
          [
           "AAPM Task Group Report 272: Comprehensive acceptance testing and evaluation of fluoroscopy imaging systems",
           "10.1002/mp.15429",
           2022,
           "Modern fluoroscopes used for image guidance have become quite complex. Adding to this complexity are the many regulatory and accreditation requirements that must be fulfilled during acceptance testing of a new unit. Further, some of these acceptance tests have pass/fail criteria, whereas others do not, making acceptance testing a subjective and time‐consuming task. The AAPM Task Group 272 Report spells out the details of tests that are required and gives visibility to some of the tests that while not yet required are recommended as good practice. The organization of the report begins with the most complicated fluoroscopes used in interventional radiology or cardiology and continues with general fluoroscopy and mobile C‐arms. Finally, the appendices of the report provide useful information, an example report form and topics that needed their own section due to the level of detail.",
           4,
           "medical_physics"
          ],
          [
           "Super‐Monte Carlo: A 3‐D electron beam dose calculation algorithm",
           "10.1118/1.597842",
           2003,
           "An electron beam dose calculation algorithm has been developed which is based on a superposition of pregenerated Monte Carlo electron track kernels. Electrons are transported through media of varying density and atomic number using electron tracks produced in water. The perturbation of the electron fluence due to each material encountered by the electrons is explicitly accounted for by considering the effect of (i) varying stopping power, (ii) scattering power, and (iii) radiation yield. For each step of every electron track, these parameters affect the step length, the step direction, and the energy deposited in that step respectively. Dose distributions in both homogeneous water and nonwaterlike phantoms, and heterogeneous phantoms show consistent agreement with “standard” Monte Carlo results. For the same statistical uncertainty in broad beam geometries, this new calculation method uses a factor of 9 less computation time than a full Monte Carlo simulation.",
           42,
           "medical_physics"
          ],
          [
           "Treatment planning for a small animal using Monte Carlo simulation",
           "10.1118/1.2805254",
           2007,
           "The development of a small animal model for radiotherapy research requires a complete setup of customized imaging equipment, irradiators, and planning software that matches the sizes of the subjects. The purpose of this study is to develop and demonstrate the use of a flexible in‐house research environment for treatment planning on small animals. The software package, called DOSCTP, provides a user‐friendly platform for DICOM computed tomography‐based Monte Carlo dose calculation using the EGSnrcMP‐based DOSXYZnrc code. Validation of the treatment planning was performed by comparing the dose distributions for simple photon beam geometries calculated through the Pinnacle3 treatment planning system and measurements. A treatment plan for a mouse based on a CT image set by a 360‐deg photon arc is demonstrated. It is shown that it is possible to create 3D conformal treatment plans for small animals with consideration of inhomogeneities using small photon beam field sizes in the diameter range of 0.5–5 cm, with conformal dose covering the target volume while sparing the surrounding critical tissue. It is also found that Monte Carlo simulation is suitable to carry out treatment planning dose calculation for small animal anatomy with voxel size about one order of magnitude smaller than that of the human.",
           33,
           "medical_physics"
          ],
          [
           "Technical note: Design and initial evaluation of a novel physical breast phantom to monitor image quality in digital breast tomosynthesis",
           "10.1002/mp.15498",
           2022,
           "PurposeTo describe the creation process of a new breast phantom specifically designed to monitor quality control (QC) metrics consistency over several months in digital breast tomosynthesis (DBT).MethodsThe semi‐anthropomorphic Tomomam® phantom was designed and evaluated twice monthly on a single Hologic Selenia Dimensions® unit over 5 months. The phantom is manufactured in a one‐piece epoxy resin homogeneous material as the basis for manufacturing, simulating breast tissue as 50% equivalent glandular (GL)/50% equivalent adipose (AD) and compressed thickness of 60 mm. The distribution of test objects on different planes inside the phantom should allow the quantification of 10 image quality metrics: reproducibility, signal difference‐to‐noise ratio (SDNR), geometric distortions in the plane, missing or added tissue at chest wall, at the top and bottom of images stack and lateral sides, in‐plane homogeneity, image scoring, artifact spread function (ASF), geometric distortions in the volume. SDNR was quantified according to GL and AD tissues. Tolerance criteria per parameter were described to analyze results over the study time.ResultsMean scores were equal to 15.4, 15.0, and 11.6 for masses, microcalcifications, and fibers, respectively. A large difference between GL and AD tissues for SDNR metrics was noted over the study time: the best results were obtained from GL tissues. Both geometric distortions and local homogeneity in the plane conformed to expected values. The mean volume value of the triangular prism was 11.3% greater than the expected value due to a reconstruction height equal to 66 mm instead of 60 mm.ConclusionsIn this study, we monitored several QC metrics discriminating GL and AD tissues by using a new breast phantom developed by us. The preliminary clinical tests demonstrated that the Tomomam® phantom could be used to reliably and efficiently track 10 QC metrics with a single acquisition. More data need to be acquired to refine tolerance criteria for some metrics. ",
           2,
           "medical_physics"
          ],
          [
           "Interactive prostate segmentation using atlas‐guided semi‐supervised learning and adaptive feature selection",
           "10.1118/1.4898200",
           2014,
           "Purpose:Accurate prostate segmentation is necessary for maximizing the effectiveness of radiation therapy of prostate cancer. However, manual segmentation from 3D CT images is very time‐consuming and often causes large intra‐ and interobserver variations across clinicians. Many segmentation methods have been proposed to automate this labor‐intensive process, but tedious manual editing is still required due to the limited performance. In this paper, the authors propose a new interactive segmentation method that can (1) flexibly generate the editing result with a few scribbles or dots provided by a clinician, (2) fast deliver intermediate results to the clinician, and (3) sequentially correct the segmentations from any type of automatic or interactive segmentation methods.Methods:The authors formulate the editing problem as a semisupervised learning problem which can utilize a priori knowledge of training data and also the valuable information from user interactions. Specifically, from a region of interest near the given user interactions, the appropriate training labels, which are well matched with the user interactions, can be locally searched from a training set. With voting from the selected training labels, both confident prostate and background voxels, as well as unconfident voxels can be estimated. To reflect informative relationship between voxels, location‐adaptive features are selected from the confident voxels by using regression forest and Fisher separation criterion. Then, the manifold configuration computed in the derived feature space is enforced into the semisupervised learning algorithm. The labels of unconfident voxels are then predicted by regularizing semisupervised learning algorithm.Results:The proposed interactive segmentation method was applied to correct automatic segmentation results of 30 challenging CT images. The correction was conducted three times with different user interactions performed at different time periods, in order to evaluate both the efficiency and the robustness. The automatic segmentation results with the original average Dice similarity coefficient of 0.78 were improved to 0.865–0.872 after conducting 55–59 interactions by using the proposed method, where each editing procedure took less than 3 s. In addition, the proposed method obtained the most consistent editing results with respect to different user interactions, compared to other methods.Conclusions:The proposed method obtains robust editing results with few interactions for various wrong segmentation cases, by selecting the location‐adaptive features and further imposing the manifold regularization. The authors expect the proposed method to largely reduce the laborious burdens of manual editing, as well as both the intra‐ and interobserver variability across clinicians.",
           22,
           "medical_physics"
          ],
          [
           "Integration between <i>in vivo</i> dosimetry and image guided radiotherapy for lung tumors",
           "10.1118/1.3129158",
           2009,
           "The article reports a feasibility study about the potentiality of an in vivo dosimetry method for the adaptive radiotherapy of the lung tumors treated by 3D conformal radiotherapy techniques (3D CRTs). At the moment image guided radiotherapy (IGRT) has been used for this aim, but it requires taking many periodic radiological images during the treatment that increase workload and patient dose. In vivo dosimetry reported here can reduce the above efforts, alerting the medical staff for the commissioning of new radiological images for an eventual adaptive plan. The in vivo dosimetry method applied on 20 patients makes use of the transit signal  on the beam central axis measured by a small ion chamber positioned on an electronic portal imaging device (EPID) or by the EPID itself. The reconstructed in vivo dosimetry at the isocenter point  requires a convolution between the transit signal  and a dose reconstruction factor C that essentially depends on (i) tissue inhomogeneities along the beam central axis and (ii) the in‐patient isocenter depth. The  factors, one for every gantry angle, are obtained by processing the patient's computed tomography scan. The method has been recently applied in some Italian centers to check the radiotherapy of pelvis, breast, head, and thorax treatments. In this work the dose reconstruction was carried out in five centers to check the  in the lung tumor during the 3D CRT, and the results have been used to detect the interfraction tumor anatomy variations that can require new CT imaging and an adaptive plan. In particular, in three centers a small ion chamber was positioned below the patient and used for the  measurement. In two centers, the  signal was obtained directly by 25 central pixels of an  EPID, equipped with commercial software that enabled its use as a stable detector. A tolerance action level of ±6% for every checked beam was assumed. This means that when a difference greater than 6% between the predicted dose by the treatment planning system, , and the  was observed, the clinical action started to detect possible errors. 60% of the patients examined presented morphological changes during the treatment that were checked by the in vivo dosimetry and successively confirmed by the new CT scans. In this work, a patient that showed for all beams  values outside the tolerance level, new CT scans were commissioned for an adaptive plan. Thelung dose volume histograms (DVHs) for a  for fraction suggested the adaptive plan to reduce the dose in lung tissue. The results of this research show that the dose guided radiotherapy (DGRT) by the  reconstruction was feasible for daily or periodic investigation on morphological lung tumor changes. In other words, since during 3D CRT treatments the anatomical lung tumor changes occur frequently, the DGRT can be well integrated with the IGRT.",
           23,
           "medical_physics"
          ],
          [
           "A method for removing arm backscatter from EPID images",
           "10.1118/1.4807640",
           2013,
           "Purpose:To develop a method for removing the support arm backscatter from images acquired using current Varian electronic portal imaging devices (EPIDs).Methods:The effect of arm backscatter on EPID images was modeled using a kernel convolution method. The parameters of the model were optimized by comparing on‐arm images to off‐arm images. The model was used to develop a method to remove the effect of backscatter from measured EPID images. The performance of the backscatter removal method was tested by comparing backscatter corrected on‐arm images to measured off‐arm images for 17 rectangular fields of different sizes and locations on the imager. The method was also tested using on‐ and off‐arm images from 42 intensity modulated radiotherapy (IMRT) fields.Results:Images generated by the backscatter removal method gave consistently better agreement with off‐arm images than images without backscatter correction. For the 17 rectangular fields studied, the root mean square difference of in‐plane profiles compared to off‐arm profiles was reduced from 1.19% (standard deviation 0.59%) on average without backscatter removal to 0.38% (standard deviation 0.18%) when using the backscatter removal method. When comparing to the off‐arm images from the 42 IMRT fields, the mean γ and percentage of pixels with γ < 1 were improved by the backscatter removal method in all but one of the images studied. The mean γ value (1%, 1 mm) for the IMRT fields studied was reduced from 0.80 to 0.57 by using the backscatter removal method, while the mean γ pass rate was increased from 72.2% to 84.6%.Conclusions:A backscatter removal method has been developed to estimate the image acquired by the EPID without any arm backscatter from an image acquired in the presence of arm backscatter. The method has been shown to produce consistently reliable results for a wide range of field sizes and jaw configurations.",
           10,
           "medical_physics"
          ],
          [
           "Four dimensional magnetic resonance imaging with retrospective <i>k</i>‐space reordering: A feasibility study",
           "10.1118/1.4905044",
           2015,
           "Purpose:Current four dimensional magnetic resonance imaging (4D‐MRI) techniques lack sufficient temporal/spatial resolution and consistent tumor contrast. To overcome these limitations, this study presents the development and initial evaluation of a new strategy for 4D‐MRI which is based on retrospective k‐space reordering.Methods:We simulated a k‐space reordered 4D‐MRI on a 4D digital extended cardiac‐torso (XCAT) human phantom. A 2D echo planar imaging MRI sequence [frame rate (F) = 0.448 Hz; image resolution (R) = 256 × 256; number of k‐space segments (NKS) = 4] with sequential image acquisition mode was assumed for the simulation. Image quality of the simulated “4D‐MRI” acquired from the XCAT phantom was qualitatively evaluated, and tumor motion trajectories were compared to input signals. In particular, mean absolute amplitude differences (D) and cross correlation coefficients (CC) were calculated. Furthermore, to evaluate the data sufficient condition for the new 4D‐MRI technique, a comprehensive simulation study was performed using 30 cancer patients’ respiratory profiles to study the relationships between data completeness (Cp) and a number of impacting factors: the number of repeated scans (NR), number of slices (NS), number of respiratory phase bins (NP), NKS, F, R, and initial respiratory phase at image acquisition (P0). As a proof‐of‐concept, we implemented the proposed k‐space reordering 4D‐MRI technique on a T2‐weighted fast spin echo MR sequence and tested it on a healthy volunteer.Results:The simulated 4D‐MRI acquired from the XCAT phantom matched closely to the original XCAT images. Tumor motion trajectories measured from the simulated 4D‐MRI matched well with input signals (D = 0.83 and 0.83 mm, and CC = 0.998 and 0.992 in superior–inferior and anterior–posterior directions, respectively). The relationship between Cp and NR was found best represented by an exponential function (, when NS = 30, NP = 6). At a CP value of 95%, the relative error in tumor volume was 0.66%, indicating that NR at a CP value of 95% (NR,95%) is sufficient. It was found that NR,95% is approximately linearly proportional to NP (r = 0.99), and nearly independent of all other factors. The 4D‐MRI images of the healthy volunteer clearly demonstrated respiratory motion in the diaphragm region with minimal motion induced noise or aliasing.Conclusions:It is feasible to generate respiratory correlated 4D‐MRI by retrospectively reordering k‐space based on respiratory phase. This new technology may lead to the next generation 4D‐MRI with high spatiotemporal resolution and optimal tumor contrast, holding great promises to improve the motion management in radiotherapy of mobile cancers.",
           34,
           "medical_physics"
          ],
          [
           "Deep learning based brain MRI registration driven by local‐signed‐distance fields of segmentation maps",
           "10.1002/mp.16291",
           2023,
           "BackgroundDeep learning based unsupervised registration utilizes the intensity information to align images. To avoid the influence of intensity variation and improve the registration accuracy, unsupervised and weakly‐supervised registration are combined, namely, dually‐supervised registration. However, the estimated dense deformation fields (DDFs) will focus on the edges among adjacent tissues when the segmentation labels are directly used to drive the registration progress, which will decrease the plausibility of brain MRI registration.PurposeIn order to increase the accuracy of registration and ensure the plausibility of registration at the same time, we combine the local‐signed‐distance fields (LSDFs) and intensity images to dually supervise the registration progress. The proposed method not only uses the intensity and segmentation information but also uses the voxelwise geometric distance information to the edges. Hence, the accurate voxelwise correspondence relationships are guaranteed both inside and outside the edges.MethodsThe proposed dually‐supervised registration method mainly includes three enhancement strategies. Firstly, we leverage the segmentation labels to construct their LSDFs to provide more geometrical information for guiding the registration process. Secondly, to calculate LSDFs, we construct an LSDF‐Net, which is composed of 3D dilation layers and erosion layers. Finally, we design the dually‐supervised registration network (VMLSDF) by combining the unsupervised VoxelMorph (VM) registration network and the weakly‐supervised LSDF‐Net, to utilize intensity and LSDF information, respectively.ResultsIn this paper, experiments were then carried out on four public brain image datasets: LPBA40, HBN, OASIS1, and OASIS3. The experimental results show that the Dice similarity coefficient (DSC) and 95% Hausdorff distance (HD) of VMLSDF are higher than those of the original unsupervised VM and the dually‐supervised registration network (VMseg) using intensity images and segmentation labels. At the same time, the percentage of negative Jacobian determinant (NJD) of VMLSDF is lower than VMseg. Our code is freely available at https://github.com/1209684549/LSDF.ConclusionsThe experimental results show that LSDFs can improve the registration accuracy compared with VM and VMseg, and enhance the plausibility of the DDFs compared with VMseg.",
           0,
           "medical_physics"
          ],
          [
           "A theoretical study of H<sub>2</sub>O<sub>2</sub> as the surrogate of dose in minibeam radiotherapy, with a diffusion model considering radical removal process",
           "10.1002/mp.16570",
           2023,
           "BackgroundMinibeam radiation therapy (MBRT) is an innovative dose delivery method with the potential to spare normal tissue while achieving similar tumor control as conventional radiotherapy. However, it is difficult to use a single dose parameter, such as mean dose, to compare different patterns of MBRT due to the spatially fractionated radiation. Also, the mechanism leading to the biological effects is still unknown.PurposeThis study aims to demonstrate that the hydrogen peroxide (H2O2) distribution could serve as a surrogate of dose distribution when comparing different patterns of MBRT.MethodsA free diffusion model (FDM) for H2O2 developed with Fick's second law was compared with a previously published model based on Monte Carlo & convolution method. Since cells form separate compartments that can eliminate H2O2 radicals diffusing inside the cell, a term describing the elimination was introduced into the equation. The FDM and the diffusion model considering removal (DMCR) were compared by simulating various dose rate irradiation schemes and uniform irradiation. Finally, the DMCR was compared with previous microbeam and minibeam animal experiments.ResultsCompared with a previous Monte Carlo & Convolution method, this analytical method provides more accurate results. Furthermore, the new model shows H2O2 concentration distribution instead of the time to achieve a certain H2O2 uniformity. The comparison between FDM and DMCR showed that H2O2 distribution from FDM varied with dose rate irradiation, while DMCR had consistent results. For uniform irradiation, FDM resulted in a Gaussian distribution, while the H2O2 distribution from DMCR was close to the dose distribution. The animal studies’ evaluation showed a correlation between the H2O2 concentration in the valley region and treatment outcomes.ConclusionDMCR is a more realistic model for H2O2 simulation than the FDM. In addition, the H2O2 distribution can be a good surrogate of dose distribution when the minibeam effect could be observed.",
           0,
           "medical_physics"
          ],
          [
           "Self‐reported COVID‐19 infection, and illness severity associated with a large professional‐society meeting of the AAPM in 2022",
           "10.1002/mp.16592",
           2023,
           "BackgroundMany in‐person conferences were suspended during the initial stages of the COVID‐19 pandemic but have recently begun to return to in‐person or hybrid formats. However the incidence and severity of COVID‐19 infection during conferences, as well as behaviors at meetings associated with infection, are not well known.PurposeWe performed a targeted, systematic survey of self‐reported COVID‐19 infection and severity rates among in‐person attendees and potential attendees of a large national medical conference held in hybrid format during the during the Omicron subvariant wave, to provide guidance for future meeting attendees and organizers on COVID‐19 risk.MethodsA survey was sent to all members of the American Association of Physicists in Medicine (AAPM) as well as all attendees of the AAPM 2022 Annual Meeting (held July 10th–14th 2022 in Washington DC) with hybrid format) (total n = 10,627). The survey assessed relevant respondent demographics, views of COVID‐19 and in‐person meetings, COVID‐19 infection during the meeting or the following 7 days, and any COVID‐19 treatment received. Descriptive statistics and multivariable logistic regression with odds ratios (OR) and 95% confidence intervals (CI) were used for analysis.ResultsThe response rate was 13.7% (n = 1464) among the total invitees. Of respondents, 62.9% (n = 921) attended the meeting in person and 37.1% (n = 543) did not. Among in‐person meeting attendees, 82.1% (n = 756) attended indoor social events during the meeting including 67.5% (n = 509) who attended a large, AAPM‐coordinated social event. Reported COVID‐19 infection rates were higher among in‐person attendees (15.3%, n = 141) versus those that did not attend in‐person (6.1%, n = 33) (p < 0.001). Of those infected, 97.9% (n = 138) recovered entirely at home, with the remaining 2 (1.4%) undergoing emergency room visit without admission, and 1 (unvaccinated) individual (0.7%) reported hospital admission. On multivariable analysis of reported in‐person attendee behaviors, only attendance of the large, AAPM‐coordinated social event remained significantly associated with COVID‐19 infection (OR 2.8, CI 1.8–4.2, p < 0.001). Among in‐person attendees, 74.1% (n = 682) agreed that they would feel comfortable attending in‐person conferences in the future, 11.8% (n = 109) disagreed, and 14.0% (n = 129) neither agreed nor disagreed.ConclusionsDespite higher than previously reported COVID‐19 infection rates than prior studies, severity of infection was self‐limited with no hospitalizations among vaccinated attendees. In‐person attendees showed a willingness to return to large‐scale indoor social interaction, with a higher rate of COVID‐19 infection noted among those who attended a large conference‐affiliated social gathering. Most individuals reported feeling comfortable attending other in‐person meetings in the future.",
           0,
           "medical_physics"
          ],
          [
           "The effects of different photon beam energies in stereotactic radiosurgery with cones",
           "10.1002/mp.16435",
           2023,
           "BackgroundStereotactic radiosurgery (SRS) relies on small fields to ablate lesions. Currently, linac based treatment is delivered via circular cones using a 6 MV beam. There is interest in both lower energy photon beams, which can offer steeper dose fall off as well as higher energy photon beams, which have higher dose rates, thus reducing radiation delivery times. Of interest in this study is the 2.5 MV beam developed for imaging applications and both the 6 and 10 MV flattening‐filter‐free (FFF) beams, which can achieve dose rates up to 2400 cGy/min.PurposeThis study aims to assess the benefit and feasibility among different energy beams ranging from 2.5 to 10 MV beams by evaluating the dosimetric effects of each beam and comparing the dose to organs‐at‐risk (OARs) for two separate patient plans. One based on a typical real patient tremor utilizing a 4 mm cone and the other a typical brain metastasis delivered with a 10 mm cone.MethodsThe Monte Carlo codes BEAMnrc/DOSXYZnrc were used to generate beams of 2.5 MV, 6 MV‐FFF, 6 MV‐SRS, 6 MV, 10 MV‐FFF, and 10 MV from a Varian TrueBeam except 6 MV‐SRS, which is taken from a Varian TX model linear accelerator. Each beam's energy spectrum, mean energy, %dd curve, and dose profile were obtained by analyzing the simulated beams. Calculated patient dose distributions were compared among six different energy beam configurations based on a realistic treatment plan for thalamotomy and a conventional brain metastasis plan. Dose to OARs were evaluated using dose–volume histograms for the same target dose coverage.ResultsThe mean energies of photons within the primary beam projected area were insensitive to cone sizes and the values of percentage depth–dose curves (%dd) at d = 5 cm and SSD = 95 cm for a 4 mm (10 mm) cone ranges from 62.6 (64.4) to 82.2 (85.7) for beam energy ranging from 2.5 to 10 MV beams, respectively. Doses to OARs were evaluated among these beams based on real treatment plans delivering 15 000 and 2200 cGy to the target with a 4 and 10 mm cone, respectively. The maximum doses to the brainstem, which is 10 mm away from the isocenter, was found to be 434 (300), 632 (352), 691 (362), 733 (375), 822 (403), and 975 (441) cGy for 2.5 MV, 6 MV‐FFF, 6 MV‐SRS, 6 MV, 10 MV‐FFF, and 10 MV beams delivering 15 000 (2200) cGy target dose, respectively.ConclusionUsing the 6 MV‐SRS as reference, changes of the maximum dose (691 cGy) to the brain stem are −37%, −9%, +6%, +19%, and 41% for 2.5 MV, 6 MV‐FFF, 6 MV, 10 MV‐FFF, and 10 MV beams, respectively, based on the thalamotomy plan, where the “‐” or “+” signs indicate the percentage decrease or increase. Changes of the maximum dose (362 cGy) to brain stem, based on the brain metastasis plan are much less for respective beam energies. The sum of 21 arcs beam‐on time was 39 min on our 6 MV‐SRS beam with 1000 cGy/min for thalamotomy. The beam‐on time can be reduced to 16 min with 10 MV‐FFF.",
           0,
           "medical_physics"
          ],
          [
           "Technical note: The design and validation of a multi‐modality lung phantom",
           "10.1002/mp.16462",
           2023,
           "BackgroundClinically relevant models that enable certain tasks such as calibration of medical imaging devices or techniques, device validation, training healthcare professionals, and more are vital to research throughout the medical field and are referred to as phantoms. Phantoms range in complexity from a vile of water to complex designs that emulate in vivo properties.PurposeSpecific phantoms that model the lungs have focused on replication of tissue properties but lack replication of the anatomy. This limits the use across multiple imaging modalities and for device testing when anatomical considerations as well as tissue properties are needed. This work reports a lung phantom design utilizing materials that accurately mimic the ultrasound and magnetic resonance imaging (MRI) properties of in vivo lungs and includes relevant anatomical equivalence.MethodsThe tissue mimicking materials were selected based on published studies of the materials, through qualitative comparisons of the materials with ultrasound imaging, and quantitative MRI relaxation values. A PVC ribcage was used as the structural support. The muscle/fat combined layer and the skin layer were constructed with various types of silicone with graphite powder added as a scattering agent where appropriate. Lung tissue was mimicked with silicone foam. The pleural layer was replicated by the interface between the muscle/fat layer and the lung tissue layer, requiring no additional material.ResultsThe design was validated by accurately mimicking the distinct tissue layers expected with in vivo lung ultrasound while maintaining tissue‐mimicking relaxation values in MRI as compared to reported values. Comparisons between the muscle/fat material and in vivo muscle/fat tissue demonstrated a 1.9% difference in T1 relaxation and a 19.8% difference in T2 relaxation.ConclusionsQualitative US and quantitative MRI analysis verified the proposed lung phantom design for accurate modeling of the human lungs.",
           0,
           "medical_physics"
          ],
          [
           "Technical Note: New similarity index for radiotherapy and medical imaging",
           "10.1002/mp.14234",
           2020,
           "PurposeTo describe a new similarity index and consider its biomedical applications.MethodsSimilarity index for a pair of objects is defined by the number of shared features and total number of features in these objects. Similarity measure for more than two objects is commonly defined by using pairwise similarity indices. In the current study we suggest a novel similarity index which depends on the number of features shared between multiple objects and does not have the limitations of the recently described similarity measures. In order to introduce the new index, we consider a concept of “commonality.” For a collection of sets \n\n, commonality of a given element equals the number of sets this element belongs to. The similarity index for the compared sets is then defined by a weighted sum of normalized commonalities.ResultsThe considered biomedical applications of the proposed index include comparison of independent delineations of critical cranial structures in MR images and comparison of isodose distributions from different radiotherapy plans.ConclusionsThis study describes a novel similarity index which can be used to assess the similarity of multiple independent delineations of the anatomical structure or similarity of multiple dose distributions. Unlike the commonly used pairwise similarity indices, the new index is defined by the number of elements shared between multiple sets. Potential applications of the suggested similarity index for radiotherapy and medical imaging have been described.",
           1,
           "medical_physics"
          ],
          [
           "Automatic configuration of the reference point method for fully automated multi‐objective treatment planning applied to oropharyngeal cancer",
           "10.1002/mp.14073",
           2020,
           "PurposeIn automated treatment planning, configuration of the underlying algorithm to generate high‐quality plans for all patients of a particular tumor type can be a major challenge. Often, a time‐consuming trial‐and‐error tuning procedure is required. The purpose of this paper is to automatically configure an automated treatment planning algorithm for oropharyngeal cancer patients.MethodsRecently, we proposed a new procedure to automatically configure the reference point method (RPM), a fast automatic multi‐objective treatment planning algorithm. With a well‐tuned configuration, the RPM generates a single Pareto optimal treatment plan with clinically favorable trade‐offs for each patient. The automatic configuration of the RPM requires a set of computed tomography (CT) scans with corresponding dose distributions for training. Previously, we demonstrated for prostate cancer planning with 12 objectives that training with only 9 patients resulted in high‐quality configurations. This paper further develops and explores the new automatic RPM configuration procedure for head and neck cancer planning with 22 objectives. Investigations were performed with planning CT scans of 105 previously treated unilateral or bilateral oropharyngeal cancer patients together with corresponding Pareto optimal treatment plans. These plans were generated with our clinically applied two‐phase ε‐constraint method (Erasmus‐iCycle) for automated multi‐objective treatment planning, ensuring consistent high quality and Pareto optimality of all plans. Clinically relevant, nonconvex criteria, such as dose‐volume parameters and NTCPs, were included to steer the RPM configuration.ResultsTraining sets with 20–50 patients were investigated. Even with 20 training plans, high‐quality configurations of the RPM were feasible. Automated plan generation with the automatically configured RPM resulted in Pareto optimal plans with overall similar or better quality than that of the Pareto optimal database plans.ConclusionsAutomatic configuration of the RPM for automated treatment planning is feasible and drastically reduces the time and workload required when compared to manual tuning of an automated treatment planning algorithm.",
           2,
           "medical_physics"
          ],
          [
           "Impact of transverse magnetic fields on dose response of a radiophotoluminescent glass dosimeter in megavoltage photon beams",
           "10.1002/mp.14054",
           2020,
           "PurposeThe purpose of this study was to investigate the impact of transverse magnetic fields on the dose response of a radiophotoluminescent glass dosimeter (RGD) in megavoltage photon beams.MethodsThe RGD relative response (i.e., RGD dose per absorbed dose to water at the midpoint of the detector in the absence of the detector) was calculated using Monte Carlo (MC) simulations. Note that the Monte Carlo calculations do not account for changes of the signal production per unit dose to the RGD caused by the magnetic field strength. The relative energy response RQ, the relative magnetic response RB, and the relative overall response RQ,B with the transverse magnetic fields of 0–3 T were analyzed as a function of depth, for a 10 cm × 10 cm field in a solid water phantom, for 4–18 MV photons. Although magnetic resonance (MR) linacs with flattening filter free beams are commercially available, flattening filter beams were used to investigate the RGD response in this study. RQ is the response in beam quality Q relative to that in the reference beam with quality 6 MV, RB is the response in beam quality Q with the magnetic field relative to that in beam quality Q without the magnetic field, and the RQ,B is the response in beam quality Q with the magnetic field relative to that in the reference beam with quality 6 MV without the magnetic field. Two RGD orientations were considered: RGD long axis is parallel (direction A) and perpendicular (direction B) to the magnetic field. The reference irradiation conditions were at the depth of 10 cm for a 10 cm × 10 cm field for 6 MV, without the magnetic field. In addition, the influence of a small air‐gap between the holder inner wall and the RGD on the dose response in the magnetic field, Rgap, was analyzed in detail. Rgap is the response in beam quality Q without/with the air‐gap.ResultsRQ decreased by up to 2.7% as the energy increased in the range of 4–18 MV, except in the buildup region. In direction A, the variation of RB owing to the magnetic field strength was below 1.0%, regardless of the photon energy. In contrast, in direction B, RB decreased with increasing magnetic field strength and decreased up to 4.0% at 3 T for 10 MV. The Rgap for 0.03 and 0.05 cm air‐gap models in direction A decreased up to 2.3% and up to 4.0%, respectively.ConclusionsThe variation of RQ,B changed with the direction of the RGD relative to the magnetic field. For dose measurements, RGDs should be positioned with the long axis parallel to the magnetic field, without air‐gaps.",
           0,
           "medical_physics"
          ],
          [
           "GAN and dual‐input two‐compartment model‐based training of a neural network for robust quantification of contrast uptake rate in gadoxetic acid‐enhanced MRI",
           "10.1002/mp.14055",
           2020,
           "PurposeGadoxetic acid uptake rate (k1) obtained from dynamic, contrast‐enhanced (DCE) magnetic resonance imaging (MRI) is a promising measure of regional liver function. Clinical exams are typically poorly temporally characterized, as seen in a low temporal resolution (LTR) compared to high temporal resolution (HTR) experimental acquisitions. Meanwhile, clinical demands incentivize shortening these exams. This study develops a neural network–based approach to quantitation of k1, for increased robustness over current models such as the linearized single‐input, two‐compartment (LSITC) model.MethodsThirty Liver HTR DCE MRI exams were acquired in 22 patients with at least 16 min of postcontrast data sampled at least every 13 s. A simple neural network (NN) with four hidden layers was trained on voxel‐wise LTR data to predict k1. Low temporal resolution data were created by subsampling HTR data to contain six time points, replicating the characteristics of clinical LTR data. Both the total length and the placement of points in the training data were varied considerably to encourage robustness to variation. A generative adversarial network (GAN) was used to generate arterial and portal venous inputs for use in data augmentation based on the dual‐input, two‐compartment, pharmacokinetic model of gadoxetic acid in the liver. The performance of the NN was compared to direct application of LSITC on both LTR and HTR data. The error was assessed when subsampling lengths from 16 to 4 min, enabling assessment of robustness to acquisition length.ResultsFor acquisition lengths of 16 min NRMSE (Normalized Root‐Mean‐Squared Error) in k1 was 0.60, 1.77, and 1.21, for LSITC applied to HTR data, LSITC applied to LTR data, and GAN‐augmented NN applied to LTR data, respectively. As the acquisition length was shortened, errors greatly increased for LSITC approaches by several folds. For acquisitions shorter than 12 min the GAN‐augmented NN approach outperformed the LSITC approach to a statistically significant extent, even with HTR data.ConclusionsThe study indicates that data length is significant for LSITC analysis as applied to DCE data for standard temporal sampling, and that machine learning methods, such as the implemented NN, have potential for much greater resilience to shortened acquisition time than directly fitting to the LSITC model.",
           1,
           "medical_physics"
          ],
          [
           "Simultaneous respiratory motion correction and image reconstruction in 4D‐multi pinhole small animal SPECT",
           "10.1002/mp.13807",
           2019,
           "PurposeRespiratory motion in the chest region during single photon emission computed tomography (SPECT) is a major degrading factor that reduces the accuracy of image quantification. This effect is more notable when the tumor is very small, or the spatial resolution of the imaging system is less than the respiratory motion amplitude. Small animals imaging systems with sub‐millimeter spatial resolution need more attention to the respiratory motion for quantitative studies. We developed a motion‐embedded four‐dimensional (4D)‐multi pinhole SPECT (MPS) reconstruction algorithm for respiratory motion correction. This algorithm makes full use of projection statistics for reconstruction of every individual frame.MethodsThe ROBY phantom with small tumors in liver was generated in eight different phases during one respiratory cycle. The MPS projections were modeled using a fast ray tracing method simulating an MPS acquisition. Individual frames were reconstructed and used for motion estimation. The Demons non‐rigid registration algorithm was used to calculate deformation vector fields (DVFs) for simultaneous motion correction and image reconstruction. A motion‐embedded 4D‐MPS method was used to reconstruct images using all the projections and corresponding DVFs, simultaneously. The 4D‐MPS reconstructed images were compared to the low‐count single frame (LCSF) reconstructed image, the three‐dimensional (3D)‐MPS images reconstructed using individual frames, and post reconstruction registration (PRR) that aligns all individual phases to a reference frame using Demons‐derived DVFs. The tumor volume relative error (TVE), tumor contrast relative error (TCE), and dice index (DI) for 2, 3, and 4 mm liver were calculated and compared for different reconstruction methods.ResultsFor the 4D‐MPS reconstruction method, TVE was reduced and DI was higher compared to PRR, 3D‐MPS, and LCSF. The extent of the improvement was higher for the small tumor size (i.e. 2 mm). For the biggest tumor in contrast 3 (i.e. 4 mm) TVE for 4D‐MPS, PRR, 3D‐MPS and, LCSF were 1.33%, 8%, 8%, and 14.67%, respectively.ConclusionsThe results suggest that motion‐embedded 4D‐MPS method is an effective and practical way for respiratory motion correction. It reconstructs high quality gated frames while using all projection data to reconstruct each frame.",
           1,
           "medical_physics"
          ],
          [
           "Development and testing of SPECT/CT lung phantoms made from expanding polyurethane foam",
           "10.1002/mp.13832",
           2019,
           "PurposeCurrently, single‐photon emission computed tomography (SPECT)/computed tomography (CT) lung phantoms are commonly constructed using polystyrene beads and interstitial radioactive water. However, this approach often results in a phantom with a density (typically −640 HU) that is considerably higher than that of healthy lung (−750 to −850 HU) or diseased lung (−900 to −950 HU). Furthermore, the polystyrene and water phantoms are often quite heterogeneous in both density and activity concentration, especially when reused. This work is devoted to examining methods for creating a more realistic lung phantom for quantitative SPECT/CT using 99mTc‐laced expanding polyurethane foam (EPF).MethodsNumerous aspects of EPF utilization were studied, including stoichiometric mixing to control final foam density and the effect of water during growth. We also tested several ways of molding the foam lung phantoms. The most successful method utilized a three‐part silicone mold that allowed for creation of a two‐lobe phantom, with a different density and activity concentration in each lobe.ResultsThe final phantom design allows for a more anatomically accurate geometry as well as customizable density and activity concentration in the different lobes of the lung. We demonstrated final lung phantom densities between −760 and −690 HU in the “healthy” phantom and −930 to −890 HU in the “unhealthy” phantom tissue. On average, we achieved 15% activity concentration nonuniformity and 12% density nonuniformity within a given lobe.ConclusionsFinal EPF lung phantoms closely matched the densities of both health and diseased lung tissue and had sufficient uniformities in both density and activity concentration for most nuclear medicine applications. Management of component moisture content is critical for phantom reproducibility.",
           1,
           "medical_physics"
          ],
          [
           "Evaluation of a pixelated large format CMOS sensor for x‐ray microbeam radiotherapy",
           "10.1002/mp.13971",
           2019,
           "PurposeCurrent techniques and procedures for dosimetry in microbeams typically rely on radiochromic film or small volume ionization chambers for validation and quality assurance in 2D and 1D, respectively. Whilst well characterized for clinical and preclinical radiotherapy, these methods are noninstantaneous and do not provide real time profile information. The objective of this work is to determine the suitability of the newly developed vM1212 detector, a pixelated CMOS (complementary metal‐oxide‐semiconductor) imaging sensor, for in situ and in vivo verification of x‐ray microbeams.MethodsExperiments were carried out on the vM1212 detector using a 220 kVp small animal radiation research platform (SARRP) at the Helmholtz Centre Munich. A 3 x 3 cm2 square piece of EBT3 film was placed on top of a marked nonfibrous card overlaying the sensitive silicon of the sensor. One centimeter of water equivalent bolus material was placed on top of the film for build‐up. The response of the detector was compared to an Epson Expression 10000XL flatbed scanner using FilmQA Pro with triple channel dosimetry. This was also compared to a separate exposure using 450 µm of silicon as a surrogate for the detector and a Zeiss Axio Imager 2 microscope using an optical microscopy method of dosimetry. Microbeam collimator slits with range of nominal widths of 25, 50, 75, and 100 µm were used to compare beam profiles and determine sensitivity of the detector and both film measurements to different microbeams.ResultsThe detector was able to measure peak and valley profiles in real‐time, a significant reduction from the 24 hr self‐development required by the EBT3 film. Observed full width at half maximum (FWHM) values were larger than the nominal slit widths, ranging from 130 to 190 µm due to divergence. Agreement between the methods was found for peak‐to‐valley dose ratio (PVDR), peak to peak separation and FWHM, but a difference in relative intensity of the microbeams was observed between the detectors.ConclusionsThe investigation demonstrated that pixelated CMOS sensors could be applied to microbeam radiotherapy for real‐time dosimetry in the future, however the relatively large pixel pitch of the vM1212 detector limit the immediate application of the results.",
           6,
           "medical_physics"
          ],
          [
           "Recognition of healthy and cancerous breast cells: Sensing the differences by dielectric spectroscopy",
           "10.1002/mp.14425",
           2020,
           "PurposeThe response of human cells to applied electrical signals depends on the cellular health status, because it is influenced by the composition and structure of the main cellular components. Therefore, electrical impedance‐based techniques can be considered as sensitive tools to investigate healthy or disease state at cellular level. The goal of this study is to show that different types of in vitro cellular lines, related to different health status, can be differentiated using impedance spectra analysis.MethodsThree different types of human breast cell line, corresponding to healthy, cancerous, and metastatic adenocarcinoma cells, were measured by means of electrical impedance spectroscopy. By modeling the investigated cells with proper resistive and capacitive circuital elements, the magnitude of the cell electrical components and spectra of real and imaginary part of dielectric permittivity were obtained. The latter were subsequently examined with a commonly adopted mathematical model, in order to estimate the values of specific dielectric parameters for the three different cellular lines.ResultsThe relative variation of cellular capacitance with respect to that of the culture medium, estimated at 100 Hz, has a larger value for the two types of cancerous cells with respect to the noncancerous type. Furthermore, the ratio between the real and imaginary part of the dielectric permittivity function has larger values for metastatic cells with respect to the normal and nonmetastatic ones. Therefore, the mentioned relative capacitance allows to discriminate between normal and cancerous cells, whereas the results obtained for the dielectric function can discriminate between metastatic and nonmetastatic cells.ConclusionsThis study can be considered as an exploratory investigation of evaluating in vitro the health status of humans cells using selected electrical impedance parameters as potential markers. The obtained results highlight that a standard cultureware system, provided with interdigitated electrodes and appropriate impedance parameters, that is, cellular capacitance and the ratio between the imaginary and real part of cellular dielectric function, can be used to discriminate between healthy and cancerous breast cell lines, as well as different malignancy degrees.",
           3,
           "medical_physics"
          ],
          [
           "Remote afterloading patient‐specific brachytherapy with liquid radioisotope for irradiation of extensive scalp lesions: A Monte Carlo study",
           "10.1002/mp.13561",
           2019,
           "PurposeThe aim of this study is to propose a remote afterloading patient‐specific brachytherapy technique for total scalp irradiation by utilizing liquid radioisotope as well as a three‐dimensional (3D) printer and to find an optimal radioisotope for the suggested technique.MethodsWe designed a brachytherapy device composed of liquid radioisotope tank, tube, patient‐specific applicator, and a thin flexible pouch. The liquid radioisotope tank, tube, and the flexible pouch are interconnected one another to constitute a closed loop system. The pouch is located inside the solid patient‐specific applicator; therefore, when the liquid radioisotope is injected into the pouch, the pouch is inflated and fills the space inside the applicator. The 3D‐printed patient‐specific applicator keeps the uniform thickness of the liquid radioisotope conforming patient's contour. To investigate an optimum condition for the suggested system, we performed Monte Carlo simulation with the GEANT4 simulation toolkit. To find the optimal radioisotope, percent depth doses (PDDs) of P‐32, Sr‐89, Y‐90, and I‐125 solutions were acquired in a rectangular parallelepiped phantom. For the selected radiation source, PDDs as well as dose rates in spherical phantoms with radii of 7.7 cm (infant head size) and 9.1 cm (adult head size) were acquired.ResultsTo deliver prescription doses at 4‐mm depth regions (scalp region), 1‐mm‐thick Y‐90 and 5‐mm‐thick I‐125 in liquid form were found to be feasible for the suggested technique. For both spherical phantoms with radii of 7.7 and 9.1 cm, when delivering 2 Gy at the 4‐mm depth region with the 1‐mm‐thick Y‐90 and 5‐mm‐thick I‐125 sources, 53.3 and 3.8 Gy were delivered at the surface regions, respectively (delivery time = 111.1 and 3.5 min with 1 GBq/ml solutions). The PDDs of Y‐90 and I‐125 became less than 1% at depths greater than 8 and 50 mm, respectively.ConclusionsThe remote afterloading patient‐patient specific brachytherapy with I‐125 or Y‐90 in liquid form seems feasible for total scalp irradiation.",
           0,
           "medical_physics"
          ],
          [
           "Properties of the anisotropy of dose contributions: A planning study on prostate cases",
           "10.1002/mp.13308",
           2018,
           "PurposeTo characterize the static properties of the anisotropy of dose contributions for different treatment techniques on real patient data (prostate cases). From this, we aim to define a class of treatment techniques with invariant anisotropy distribution carrying information of target coverage and organ‐at‐risk (OAR) sparing. The anisotropy presumably is a helpful quantity for plan adaptation problems.MethodsThe anisotropy field is analyzed for different intensity modulated radiotherapy (IMRT) and volumetric modulated arc therapy (VMAT) techniques for a total of ten planning CTs of prostate cases. Primary irradiation directions ranged from 5 to 15. The uniqueness of anisotropy was explored: In particular, the anisotropy distribution inside the planning treatment volume (PTV) and in its vicinity was investigated. Furthermore, deviations of the anisotropy under beam rotations were explored by direct plan comparison as an indicating the susceptibility of each planned technique to changes in the geometric plan configuration. In addition, plan comparisons enabled the categorization of treatment techniques in terms of their anisotropy distribution.ResultsThe anisotropy profile inside the PTV and in the transition between OAR and PTV is independent of the treatment technique as long as a sufficient number of beams contribute to the dose distribution. Techniques with multiple beams constitute a class of almost identical and technique‐independent anisotropy distribution. For this class of techniques, substructures of the anisotropy are particularly pronounced in the PTV, thus offering good options for applying adaptation rules. Additionally, the techniques forming the mentioned class fortunately allow a better OAR sparing at constant PTV coverage. Besides the characterization of the distribution, a pairwise plan comparison reveals each technique's susceptibility to deviations which decreases for an increasing number of primary irradiation directions.ConclusionsTechniques using many irradiation directions form a class of almost identical anisotropy distributions which are assumed to provide a basis for improved adaptation procedures. Encouragingly, these techniques deliver quite invariant anisotropy distributions with respect to rotations correlated with good plan qualities than techniques using few gantry angles. The following will be the next steps toward anisotropy‐based adaptation: first, the quantification of anisotropy regarding organ deformations; and second, establishing the interrelation between the anisotropy and beam shaping.",
           0,
           "medical_physics"
          ],
          [
           "Objective assessment of the effects of tumor motion in radiation therapy",
           "10.1002/mp.13601",
           2019,
           "PurposeInternal organ motion reduces the accuracy and efficacy of radiation therapy. However, there is a lack of tools to objectively (based on a medical or scientific task) assess the dosimetric consequences of motion, especially on an individual basis. We propose to use therapy operating characteristic (TOC) analysis to quantify the effects of motion on treatment efficacy for individual patients. We demonstrate the application of this tool with pancreatic stereotactic body radiation therapy (SBRT) clinical data and explore the origin of motion sensitivity.MethodsThe technique is described as follows. (a) Use tumor‐motion data measured from patients to calculate the motion‐convolved dose of the gross tumor volume (GTV) and the organs at risk (OARs). (b) Calculate tumor control probability (TCP) and normal tissue complication probability (NTCP) from the motion‐convolved dose–volume histograms. (c) Construct TOC curves from TCP and NTCP models. (d) Calculate the area under the TOC curve (AUTOC) and use it as a figure of merit for treatment efficacy. We used tumor motion data measured from patients to calculate the relation between AUTOC and motion magnitude for 25 pancreatic SBRT treatment plans. Furthermore, to explore the driving factor of motion sensitivity of a given plan, we compared the dose distribution of motion‐sensitive plans and motion‐robust plans and studied the dependence of motion sensitivity to motion directions.ResultsOur technique is able to recognize treatment plans that are sensitive to motion. Under the presence of motion, the treatment efficacy of some plans changes from providing high tumor control and low risks of complications to providing no tumor control and high risks of side effects. Several treatment plans experience falloffs in AUTOC at a smaller magnitude of motion than other plans. In our dataset, a potential indicator of a motion‐sensitive treatment plan is that the duodenum is in proximity to the tumor in the SI direction.ConclusionsThe TOC framework can serve as a tool to quantify the effects of internal organ motion in radiation therapy. With pancreatic SBRT clinical data, we applied this tool to study the change in treatment efficacy induced by motion for individual treatment plans. This framework could potentially be used clinically to understand the effects of motion in an individual patient and to design a patient‐specific motion management plan. This framework could also be used in research to evaluate different components of the treatment process, such as motion‐management techniques, treatment‐planning algorithms, and treatment margins.",
           3,
           "medical_physics"
          ],
          [
           "Experimental study of humidity effect on charge measurement of reference ionization chambers in clinical high‐energy photon beams",
           "10.1002/mp.13665",
           2019,
           "PurposeIn the practice code of dosimetry, humidity effect is assumed to be constant as far as the measurements are performed in the relative humidity (RH) range of (20–80)%; thus, the humidity effect can be ignored with a dose uncertainty of 0.15%. This assumption is based on the previous experimental results by Niatel and Guiho. Rogers and Ross calculated the stopping power ratio of humid air and dry air for high‐energy electron beams by using a Monte Carlo code. They demonstrate that the W value, the mean energy required to create an ion pair in air, is independent of the beam quality when the air is dry, and that the traditional humidity correction can be used also for high‐energy photon and electron beams; however, this was only a computational study. In the present study, we measured the humidity correction of Farmer‐type ionization chambers in high‐energy photon beams and determined the W values of humid air using the calculated energy deposition of humid air with a Monte Carlo code. Furthermore, we proposed an analytical expression to determine a practical humidity correction for an ionization chamber as a function of absolute humidity.MethodExperiments were carried out using a clinical linear accelerator (linac, Elekta Precise) at the National Metrology Institute of Japan (NMIJ). A shield box was constructed downstream of the linac and connected to an air processor, which maintained the temperature around 22°C and controlled the humidity in the range of (10–70)% inside the box. We prepared two Farmer‐type ionization chambers: PTW 30013 and Exradin A19. Each ionization chamber was placed inside the box and irradiated with 6‐, 10‐, and 15‐MV high‐energy photon beams from the clinical linac. The energy deposition to the humid air inside the ionization chamber was calculated using the Electron Gamma Shower Version 5 (EGS5) code system.ResultsStabilization for the humidity of the ionization chamber was completed within 3 h. The polarity and ion recombination corrections did not show any change in the humidity range studied. The measured humidity correction and the evaluated W values of humid air in high‐energy photon beams were in good agreement with those by Rogers in TG‐21 and by Niatel in the range of RH (10–70)%.ConclusionHumidity correction of ionization chambers in high‐energy photon beams from the clinical linac was determined experimentally. Using the analytical expression for the energy depositions by EGS5, the analytical expression for the W values was also derived.",
           1,
           "medical_physics"
          ],
          [
           "Performance of the cone beam computed tomography‐based patient positioning system on the Gamma Knife Icon™",
           "10.1002/mp.13740",
           2019,
           "PurposeCone beam computed tomography (CBCT) imaging has been implemented on the Leksell Gamma Knife® Icon™ for assessing patient positioning in mask‐based Gamma Knife radiosurgery. The purpose of this study was to evaluate the performance of the CBCT‐based patient positioning system as a tool for frameless Gamma Knife radiosurgery.MethodsDaily quality assurance (QA) CBCT precision test results from a 12‐month period were analyzed for the geometric accuracy and the stability of the imager. The performance of the image acquisition module and the image registration algorithm was evaluated using an anthropomorphic head phantom (CIRS Inc., Norfolk, VA) and a XYZR axis manual positioning stage (TOAUTO Inc., Guangdong, China). The head phantom was fixed on a mask adaptor and manually translated in the X, Y, Z directions or rotated around the X, Y, Z axes in the range of ±10 mm or ±10º. A CBCT scan was performed after each manual position setup followed by an image registration to the reference scan. To assess the overall setup uncertainties in fractionated treatment, two cylindrical Presage phantoms (Heuris Inc., Skillman, NJ) of 15 cm diameter and 10 cm height were irradiated with identical prescription dose and shot placement following standard mask‐based treatment workflow according to two different fraction schedules: a single fraction treatment of 7.5 Gy and a 5‐fraction treatment with 1.5 Gy per fraction.ResultsThe averaged vector deviations of the four marks from their preset values are 0.087, 0.085, 0.095, and 0.079 mm from the 212 daily QA tests. The averaged displacements in the X, Y, Z coordinates and the pitch, yaw, roll angles from the image registration tests are 0.23, 0.27, 0.14, 0.32º, 0.19º, 0.31º from the manual setup. The corresponding maximum differences are 0.41, 0.33, 0.29 mm, 0.45º, 0.31º, and 0.43º, respectively. Compared to the treatment plan using the 2% & 1 mm criteria, the averaged 2D Gamma passing rate is 98.25% for the measured dose distribution from the Presage phantom with 1‐fraction irradiation and 95.12% for the 5‐fraction irradiation. The averaged Gamma passing rates are 99.53% and 98.16% for the 1‐fraction and 5‐fraction irradiations using the 2% & 2 mm criteria.ConclusionsThe CBCT imager and the image registration algorithm can reproduce phantom position with <0.5 mm/0.5º uncertainty. A systematic contribution from the interfraction phantom repositioning procedure was observed in the Gamma analysis over the irradiated volumes of two end‐to‐end test phantoms.",
           3,
           "medical_physics"
          ],
          [
           "Age‐dependent dose calculations for common PET radionuclides and brain radiotracers in nonhuman primate computational models",
           "10.1002/mp.14333",
           2020,
           "PurposeThe combination of nonhuman primates (NHPs) with the state‐of‐the‐art molecular imaging technologies allows for within‐subject longitudinal research aiming at gaining new insights into human normal and disease conditions and provides an ideal foundation for future translational studies of new diagnostic tools, medical interventions, and therapies. However, radiation dose estimations for nonhuman primates from molecular imaging probes are lacking and are difficult to perform experimentally. The aim of this work is to construct age‐dependent NHP computational model series to estimate the absorbed dose to NHP specimens in common molecular imaging procedures.Materials and methodsA series of NHP models from baby to adult were constructed based on nonuniform rational B‐spline surface (NURBS) representations. Particle transport was simulated using Monte Carlo calculations to estimate S‐values from nine positron‐emitting radionuclides and absorbed doses from PET radiotracers.ResultsRealistic age‐dependent NHP computational model series were developed. For most source‐target pairs in computational NHP models, differences between C‐11 S‐values were between −13.4% and −8.8%/kg difference in body weight while differences between F‐18 S‐values were between −12.9% and −8.0%/kg difference in body weight. The absorbed doses of 11C‐labeled brain receptor substances, 18F‐labeled brain receptor substances, and 18F‐FDG in the brain ranged within 0.047–0.32 mGy/MBq, 0.25–1.63 mGy/MBq, and 0.32–2.12 mGy/MBq, respectively.ConclusionThe absorbed doses to organs are significantly higher in the baby NHP model than in the adult model. These results can be used in translational longitudinal studies to estimate the cumulated absorbed organ doses in NHPs at various ages.",
           0,
           "medical_physics"
          ],
          [
           "On the potential use of dynamic contrast‐enhanced (DCE) MRI parameters as radiomic features of cervical cancer",
           "10.1002/mp.13821",
           2019,
           "PurposeTo evaluate whether the analysis of high‐temporal resolution DCE‐MRI by various tracer kinetic models could yield useful radiomic features in discriminating cervix carcinoma and normal cervix tissue.MethodsForty‐three patients (median age 51 yr; range 26–78 yr) diagnosed with cervical cancer based on postoperative pathology were enrolled in this study with informed consent. DCE‐MRI data with temporal resolution of 2 s were acquired and analyzed using the Tofts (TOFTS), extended Tofts (EXTOFTS), conventional two‐compartment (CC), adiabatic tissue homogeneity (ATH), and distributed parameter (DP) models. Ability of all kinetic parameters in distinguishing tumor from normal tissue was assessed using Mann–Whitney U test and receiver operating characteristic (ROC) curves. Repeatability of parameter estimates due to sampling of arterial input functions (AIFs) was also studied using intraclass correlation (ICC) analysis.ResultsFractional extravascular, extracellular volume (Ve) of all models were significantly smaller in cervix carcinoma than normal cervix tissue, and were associated with large values of area under ROC curve (AUC 0.884–0.961). Capillary permeability PS derived from the ATH, CC, and DP models also yielded large AUC values (0.730, 0.860, and 0.797). Transfer constant Ktrans derived from TOFTS and EXTOFTS models yielded smaller AUC (0.587 and 0.701). Repeatability of parameters derived from all models was robust to AIF sampling, with ICC coefficients typically larger than 0.80.ConclusionsWith the use of high‐temporal resolution DCE‐MRI, all tracer kinetic models could reflect pathophysiological differences between cervix carcinoma and normal tissue (with significant differences in Ve and PS) and potentially yield radiomic features with diagnostic value.",
           5,
           "medical_physics"
          ],
          [
           "Dose–response linearization in radiochromic film dosimetry based on multichannel normalized pixel value with an integrated spectral correction for scanner response variations",
           "10.1002/mp.13818",
           2019,
           "PurposeTo introduce a model that reproducibly linearizes the response from radiochromic film (RCF) dosimetry systems at extended dose range. To introduce a correction method, generated from the same scanned images, which corrects for scanner temporal response variation and scanner bed inhomogeneity.MethodsSix calibration curves were established for different lot numbers of EBT3 GAFCHROMIC™ film model based on four EPSON scanners [10000XL (2 units), 11000XL, 12000XL] at three different centers. These films were calibrated in terms of absorbed dose to water based on TG51 protocol or TRS398 with dose ranges up to 40 Gy. The film response was defined in terms of a proposed normalized pixel value () as a summation of first‐order equations based on information from red, green, and blue channels. The fitting parameters of these equations are chosen in a way that makes the film response equal to dose at the time of calibration. An integrated set of correction factors (one per color channel) was also introduced. These factors account for the spatial and temporal changes in scanning states during calibration and measurements. The combination of  and this “fingerprint” correction formed the basis of this new protocol and it was tested against net optical density () single‐channel dosimetry in terms of accuracy, precision, scanner response variability, scanner bed inhomogeneity, noise, and long‐term stability.ResultsIncorporating multichannel features (RGB) into the normalized pixel value produced linear response to absorbed dose (slope of 1) in all six RCF dosimetry systems considered in this study. The “fingerprint” correction factors of each of these six systems displayed unique patterns at the time of calibration. The application of  to all of these six systems could achieve a level of accuracy of ± 2.0% in the dose range of interest within modeled uncertainty level of 2.0%–3.0% depending on the dose level. Consistent positioning of control and measurement film pieces and integrating the multichannel correction into the response function formalism mitigated possible scanner response variations of as much as ± 10% at lower doses and scanner bed inhomogeneity of ± 8% to the established level of uncertainty at the time of calibration. The system was also able to maintain the same level of accuracy after 3 and 6 months post calibration.ConclusionsCombining response linearity with the integrated correction for scanner response variation lead to a sustainable and practical RCF dosimetry system that mitigated systematic response shifts and it has the potential to reduce errors in reporting relative information from the film response.",
           8,
           "medical_physics"
          ],
          [
           "An analytical model for the upper bound estimation of respiratory motion–induced dose uncertainty in spot‐scanning proton beam therapy",
           "10.1002/mp.13811",
           2019,
           "PurposeWe developed an analytical model of a spot‐scanning beam delivery system to estimate the upper bound of respiratory motion–induced dose uncertainty for a given treatment plan.MethodsThe effective delivery time for each spot position in the treatment plan was calculated on the basis of the parameters of the delivery system. The upper bound of the dose uncertainty was then calculated as a function of the effective delivery time. Two‐dimensional (2D) measurements with a detector array on a one‐dimensional moving platform were obtained to validate the model.ResultsWe performed 351 two‐dimensional measurements on a moving platform for different delivery sequences of a single‐layer uniform pattern and patient treatment field. The measured dose uncertainty was a strong function of the effective delivery time: The shortest effective delivery time resulted in a maximum absolute dose error of >90%, while the longest ones resulted in a maximum absolute dose error of 4.9% for a single layer and 9.7% for a patient field with heterogeneity. The relationship of the effective delivery time and the measured dose uncertainty followed the analytical formula.ConclusionsWith our analytical model, the upper bound of the dose uncertainty due to motion can be estimated in spot‐scanning proton therapy without four‐dimensional dynamic dose calculation.",
           4,
           "medical_physics"
          ],
          [
           "Linac monitor end effect",
           "10.1118/1.594921",
           2003,
           "It is pointed out that method used for accelerator calibration should be consistent with that used to calculate treatment planning dosage. (AIP)",
           1,
           "medical_physics"
          ],
          [
           "Automatic labeling of MR brain images by hierarchical learning of atlas forests",
           "10.1118/1.4941011",
           2016,
           "Purpose:Automatic brain image labeling is highly demanded in the field of medical image analysis. Multiatlas‐based approaches are widely used due to their simplicity and robustness in applications. Also, random forest technique is recognized as an efficient method for labeling, although there are several existing limitations. In this paper, the authors intend to address those limitations by proposing a novel framework based on the hierarchical learning of atlas forests.Methods:Their proposed framework aims to train a hierarchy of forests to better correlate voxels in the MR images with their corresponding labels. There are two specific novel strategies for improving brain image labeling. First, different from the conventional ways of using a single level of random forests for brain labeling, the authors design a hierarchical structure to incorporate multiple levels of forests. In particular, each atlas forest in the bottom level is trained in accordance with each individual atlas, and then the bottom‐level forests are clustered based on their capabilities in labeling. For each clustered group, the authors retrain a new representative forest in the higher level by using all atlases associated with the lower‐level atlas forests in the current group, as well as the tentative label maps yielded from the lower level. This clustering and retraining procedure is conducted iteratively to yield a hierarchical structure of forests. Second, in the testing stage, the authors also present a novel atlas forest selection method to determine an optimal set of atlas forests from the constructed hierarchical structure (by disabling those nonoptimal forests) for accurately labeling the test image.Results:For validating their proposed framework, the authors evaluate it on the public datasets, including Alzheimer's disease neuroimaging initiative, Internet brain segmentation repository, and LONI LPBA40. The authors compare the results with the conventional approaches. The experiments show that the use of the two novel strategies can significantly improve the labeling performance. Note that when more levels are constructed in the hierarchy, the labeling performance can be further improved, but more computational time will be also required.Conclusions:The authors have proposed a novel multiatlas‐based framework for automatic and accurate labeling of brain anatomies, which can achieve accurate labeling results for MR brain images.",
           23,
           "medical_physics"
          ],
          [
           "Model‐based measurements of the diameter of the internal carotid artery in CT angiography images",
           "10.1118/1.3491808",
           2010,
           "Purpose:Computed tomography angiography (CTA) is often used to determine the degree of stenosis in patients that suffer from carotid artery occlusive disease. Accurate and precise measurements of the diameter of the stenosed internal carotid artery are required to make decisions on treatment of the patient. However, the inherent blurring of images hampers a straightforward measurement, especially for smaller vessels. The authors propose a model‐based approach to perform diameter measurements in which explicit allowance is made for the blurring of structures in the images. Three features of the authors' approach are the use of prior knowledge in the fitting of the model at the site of the stenosis, the applicability to vessels both with circular and noncircular cross‐section, and the ability to deal with additional structures close to the arteries such as calcifications.Methods:Noncircular cross‐sections of vessels were modeled with elliptic Fourier descriptors. When calcifications or other high‐intensity structures are adjacent to the lumen, both the lumen and the high‐intensity structures were modeled in order to improve the diameter estimates of the vessel. Measurements were performed in CT scans of a phantom mimicking stenosed carotids and in CTA scans of two patients with an internal carotid stenosis. In an attempt to validate the measurements in CTA images, measurements were also performed in three‐dimensional rotational angiography (3DRA) images of the same patients.Results:The validity of the approach for diameter measurements of cylindrical arteries in CTA images is evident from phantom measurements. When prior knowledge about the enhancement and the blurring parameter was used, accurate and precise diameter estimates were obtained down to a diameter of 0.4 mm. The potential of the presented approach, both with respect to the extension to noncircular cross‐sections and the modeling of adjacent calcifications, appears from the patient data. The accuracy of the size estimates in the patient images could not be unambiguously established because no gold standard was available and the quality of the 3DRA images was often suboptimal.Conclusions:The authors have shown that the inclusion ofa priori information results in accurate and precise diameter measurements of arteries with a small diameter. Furthermore, in patient data, the assumption of a circular cross‐section often appears to be too simple. The extension to noncircular cross‐sections and adjacent calcifications paves the way to realistic modeling of the carotid artery.",
           3,
           "medical_physics"
          ],
          [
           "Method to quickly and accurately calculate absorbed dose from therapeutic and stray photon exposures throughout the entire body in individual patients",
           "10.1002/mp.14018",
           2020,
           "PurposePhoton radiotherapy techniques typically devote considerable attention to limiting the exposure of healthy tissues outside of the target volume. Numerous studies have shown, however, that commercial treatment planning systems (TPSs) significantly underestimate the absorbed dose outside of the treatment field. The purpose of this study was to test the feasibility of quickly and accurately calculating the total absorbed dose to the whole body from photon radiotherapy in individual patients.MethodsWe created an extended TPS by implementing a physics‐based analytical model for the absorbed dose from stray photons during photon therapy into a research TPS. We configured and validated the extended TPS using measurements of 6‐ and 15‐MV photon beams in water‐box and anthropomorphic phantoms. We characterized the additional computation time required for therapeutic and stray dose calculations in a 44 × 30 × 180 cm3 water‐box phantom.ResultsThe extended TPS achieved superior dosimetric accuracy compared to the research TPS in both water and anthropomorphic phantoms, especially outside of the primary treatment field. In the anthropomorphic phantom, the extended TPS increased the generalized gamma index passing rate by a factor of 10 and decreased the median dosimetric discrepancy in the out‐of‐field region by a factor of 26. The extended TPS achieved an average discrepancy <1% in and near the treatment field and <1 mGy/Gy far from the treatment field in the anthropomorphic phantom. Characterization of computation time revealed that on average, the extended TPS only required 7% longer than the research TPS to calculate the total absorbed dose.ConclusionsThe results of this work suggest that it is feasible to quickly and accurately calculate whole‐body doses inside and outside of the therapeutic treatment field in individual patients on a routine basis using physics‐based analytical dose models. This additional capability enables a more personalized approach to minimizing the risk of radiogenic late effects, such as second cancer and cardiac toxicity, as part of the treatment planning process.",
           10,
           "medical_physics"
          ],
          [
           "Automated detection of foveal center in <scp>SD</scp>‐<scp>OCT</scp> images using the saliency of retinal thickness maps",
           "10.1002/mp.12614",
           2017,
           "PurposeTo develop an automated method based on saliency map of the retinal thickness map to determine foveal center in spectral‐domain optical coherence tomography (SD‐OCT) images.MethodsThis paper proposes an automatic method for the detection of the foveal center in SD‐OCT images. Initially, a retinal thickness map is generated by considering the axial distance between the internal limiting membrane (ILM) and the Bruch's membrane (BM). Both the ILM and BM boundaries are automatically segmented by a known retinal segmentation technique. The macular foveal region is identified as a salient feature in the retinal thickness map, and segmented by the saliency detection method based on a human vision attention model. Finally, the foveal center is identified by searching for the lowest point from the determined macular fovea region.ResultsExperimental results in 39 scans from 35 healthy eyes and 58 scans from 29 eyes diagnosed with several stages of age‐related macular degeneration (AMD), from mild or intermediate stages to severe dry or wet stages, demonstrated that the proposed method achieves good performance. The mean radial distance error of the automatically detected foveal center locations when compared to consensus manual determination established by repeated sessions from two expert readers was 52 ± 56 μm for the normal eyes and 73 ± 63 μm for AMD eyes.ConclusionsThe proposed algorithm was more effective for detecting the foveal center automatically in SD‐OCT images than the state‐of‐art methods.",
           8,
           "medical_physics"
          ],
          [
           "Feasibility study of a dual detector configuration concept for simultaneous megavoltage imaging and dose verification in radiotherapy",
           "10.1118/1.4907966",
           2015,
           "Purpose:To test the feasibility of a dual detector concept for comprehensive verification of external beam radiotherapy. Specifically, the authors test the hypothesis that a portal imaging device coupled to a 2D dosimeter provides a system capable of simultaneous imaging and dose verification, and that the presence of each device does not significantly detract from the performance of the other.Methods:The dual detector configuration comprised of a standard radiotherapy electronic portal imaging device (EPID) positioned directly on top of an ionization‐chamber array (ICA) with 2 cm solid water buildup material (between EPID and ICA) and 5 cm solid backscatter material. The dose response characteristics of the ICA and the imaging performance of the EPID in the dual detector configuration were compared to the performance in their respective reference clinical configurations. The reference clinical configurations were 6 cm solid water buildup material, an ICA, and 5 cm solid water backscatter material as the reference dosimetry configuration, and an EPID with no additional buildup or solid backscatter material as the reference imaging configuration. The dose response of the ICA was evaluated by measuring the detector's response with respect to off‐axis position, field size, and transit object thickness. Clinical dosimetry performance was evaluated by measuring a range of clinical intensity‐modulated radiation therapy (IMRT) beams in transit and nontransit geometries. The imaging performance of the EPID was evaluated quantitatively by measuring the contrast‐to‐noise ratio (CNR) and spatial resolution. Images of an anthropomorphic phantom were also used for qualitative assessment.Results:The measured off‐axis and field size response with the ICA in both transit and nontransit geometries for both dual detector configuration and reference dosimetry configuration agreed to within 1%. Transit dose response as a function of object thickness agreed to within 0.5%. All IMRT test patterns and clinical IMRT beams had gamma pass rates of ≥98% at 2%/2 mm criteria. In terms of imaging performance, the measured CNR and spatial resolution (f50) were 263.23 ± 24.85 and 0.4025 ± 1.25 × 10−3 for dual detector configuration and 324 ± 26.65 and 0.4141 ± 1.14 × 10−3 for reference imaging configuration, respectively. The CNR and spatial resolution were quantitatively worse in the dual detector configuration due to the additional backscatter. The difference in imaging performance was not visible in qualitative assessment of phantom images.Conclusions:Combining a commercially available ICA dosimetry device with a conventional EPID did not significantly detract from the performance of either device. Further improvements in imaging performance may be achieved with an optimized design. This study demonstrates the feasibility of a dual detector concept for simultaneous imaging and dosimetry in radiation therapy.",
           7,
           "medical_physics"
          ],
          [
           "Extrapolation of linear attenuation coefficients of biological materials from diagnostic‐energy x‐ray levels to the megavoltage range",
           "10.1118/1.594351",
           2003,
           "A dual‐energy algorithm is used in determining the effective atomic number, atomic density, and electron density of biological substances. These quantities are then used to calculate linear attenuation coefficients at the megavoltage level. The validity of the method is checked several ways, including a comparison of extrapolated values with experimental data reported by Rao and Gregg where linear attenuation coefficients at 60 and 122 keV are used to extrapolate to coefficients at 662 keV. Except for a few instances, the extrapolated values agree quite well with the reported experimental values. This method is also used to calculate coefficients at the 60Co range, and these are compared with experimental values measured in water and various types of tissue‐equivalent materials. An additional algorithm is developed to extrapolate coefficients in water and bone up to 10 MeV. These quantities are compared with accepted values previously reported in the literature.",
           6,
           "medical_physics"
          ],
          [
           "Backscatter factors in the mammographic energy range",
           "10.1118/1.594312",
           2003,
           "Backscatter factors for kVps and half‐value layers typical of mammographic beams have been determined as a function of beam diameter and half‐value layer. The method utilized thin TLD‐100 chips with the scattering medium alternately present and absent. Results indicate that the field‐size dependence of the backscatter factor for lower half‐value layers is less than that shown in the British Journal of Radiology Supplement 11.",
           11,
           "medical_physics"
          ],
          [
           "Saturation curve in gases of high atomic number at pressures up to 8 atm. I. Krypton and xenon",
           "10.1118/1.594186",
           2003,
           "The saturation curve has been studied in xenon and in krypton up to a pressure of 8 atm. An empirical formula has been found that describes the fraction of current collected over a wide range of voltages, pressures, ionization intensities, and electrode spacings. This is of practical value in the design of ionography chambers. For krypton the collection fraction fKr= (1+0.25η−1.74)−1, and for xenon fXe= (1+0.16η−1.88)−1, where η=Fp−0.7Vd−2q−1/2 with F=3.61×10−7 and 2.50×10−7 for krypton and xenon, respectively. The ranges of the variables covered in the experiments were p=1–8 atm, V=5–25 000 V, d=0.3–1.3 cm, and q=4×10−9–6×10−8 A/cm3.",
           4,
           "medical_physics"
          ],
          [
           "Photon and electron response of silicon‐diode neutron detectors",
           "10.1118/1.594403",
           2003,
           "The photon response of silicon‐diode neutron detectors is analyzed theoretically and measured in the 15–25‐MeV region. The main mechanism for producing a response in the diode is shown to be the displacement of silicon atoms by scattering of electrons. If the photon source is an electron accelerator target, the response is mostly due to electrons originating in the target with a smaller contribution from electrons produced in the diode by photons generated at small angles to the beam.",
           6,
           "medical_physics"
          ],
          [
           "Proton–beryllium neutron production at 25–55 MeV",
           "10.1118/1.594375",
           2003,
           "The production of neutrons by stopping 25‐, 35‐, 45‐, and 55‐MeV protons in beryllium has been studied. The yield of neutrons in the forward direction can be approximated by the relation: yield =−0.032×1016⋅E+0.0027×1016⋅E2 neutrons/C sr. The neutron spectra are characterized by a low‐energy evaporation component which has small angular dependence and a high‐energy component which is peaked in the forward direction. Neutrons produced in the forward direction have an average energy approximately 40% of the incident proton energy.",
           25,
           "medical_physics"
          ],
          [
           "Scattered radiation from a neutron collimator",
           "10.1118/1.594382",
           2003,
           "Fast‐neutron beams are being employed in radiotherapy trials and associated radiobiology studies at numerous centers in the U.S., Europe, and Japan. Since collimated beams of various sizes and shapes are employed, it is desirable to know the composition of the scattered radiation component contributed by the collimator. A simple method is shown for deducing the field composition in terms of a three‐component model, from measurements made with three ionization chambers (tissue‐equivalent, graphite, and magnesium). The dose contributed by the scattered radiation in the present example was found to be predominantly due to fast neutrons indistinguishable from those in the primary spectrum (from 35‐MeV D+ on Be). This method may prove useful for measurements in phantoms as well.",
           4,
           "medical_physics"
          ],
          [
           "Calibration in water versus calibration in air for Cobalt‐60 γ rays",
           "10.1118/1.594294",
           2003,
           "In the United States it is common practice to calibrate Cobalt‐60 teletherapy machines ’'in air,” despite recommendations by the International Commission on Radiation Units and Measurements (ICRU) and other organizations that calibration be accomplished by measurement at 5‐cm depth in a water phantom. A comparison has been made between the results of ionization measurements in air at 80.5‐cm distance from the source and in water at 80‐cm source–skin distance (SSD) for the determination of absorbed dose at three depth (5, 10, and 15 cm) for each of three field sizes (6×6, 10×10, and 20×20 cm2), for a total of 42 Cobalt‐60 machines. The mean of the ratio, absorbed dose from in‐water measurements to absorbed dose at the same depth calculated from in‐air measurements, ranged from 1.031±0.013 at 15‐cm depth for a 6×6‐cm2 field size to 1.009±0.007 at 5‐cm depth for a 20×20‐cm2 field size. Reasons for the differences are offered, and compliance with ICRU recommendations is suggested.",
           4,
           "medical_physics"
          ],
          [
           "Dose efficiency and the effects of resolution and noise on detail perceptibility in radiographic magnification",
           "10.1118/1.594902",
           2003,
           "The detail signal–to–noise ratio model of radiographic imaging is quantitatively analyzed in terms of its accuracy in describing observer threshold perceptibility of radiographic detail. The model is found to adequately describe the effects of magnification, scatter radiation, and system resolution on observer threshold perceptibility. However, it is shown that the model does not apply in screen/film radiography for very low contrasts and high scatter conditions due to insufficient optical density contrast. The dose‐to‐information conversion efficiency of a radiographic imaging system is defined and the effects of magnification, scatter, resolution, image processing, detector efficiency, grids, patient table support, field size, and geometry on the dose efficiency of the imaging system are investigated.",
           7,
           "medical_physics"
          ],
          [
           "Effect of asymmetric focal spots in angiography",
           "10.1118/1.594297",
           2003,
           "The effect of asymmetric focal spots in blood vessel imaging is investigated by computer simulation. Phase distortion effects are studied in isolation from MTF effects. Calculations are done for a number of symmetric and asymmetric foci with identical standard deviations. It is concluded that blood vessel image degradation due to focus asymmetry per se is small and that the LSF standard deviation is a useful size parameter for both symmetric and asymmetric foci.",
           3,
           "medical_physics"
          ],
          [
           "A simple source of fluorescent x rays for the study of radiographic imaging systems",
           "10.1118/1.594346",
           2003,
           "The properties of a simple source of fluorescent x rays were investigated with regard to its suitability for the study of radiographic imaging systems. The source, consisting of a diagnostic x‐ray tube, fluorescent targets, and filters, was found to yield highly monoenergetic x‐ray fluxes with intensity sufficient to allow the speed of medium‐ and high‐speed screen–film systems to be studied as a function of x‐ray energy.",
           3,
           "medical_physics"
          ],
          [
           "Measurements of diagnostic x‐ray backscatter by a novel ion chamber method",
           "10.1118/1.595140",
           2003,
           "There is a major gap in backscatter information for diagnostic x‐ray beams. Such information is increasingly needed for dose measurements and calculations, as well as for designing devices and techniques. We have therefore carried out measurements on both low Z materials and metals, using an ion chamber method designed specifically for the purpose. Lucite and two D.R. White tissue substitutes were studied extensively (BR 12 “average breast” and MS 11 “water”). Measured percent backscatter (BS) was greatest for Lucite and least for MS 11, with BR 12 in between. Backscatter buildup is rapid: 50% of full backscatter is achieved with 6 mm thickness for all three materials using mammographic beams and with about 12 mm using general diagnostic beams. A simple relationship between BS and field area permits close estimates of BS values for fields for which measured data is not available. Among metals tested, copper exhibited greatest backscatter (38% BS maximum), aluminum least, and lead in between—information of potential importance in cassette design and similar applications.",
           21,
           "medical_physics"
          ],
          [
           "Fast Fourier digital quantum mottle analysis with application to rare earth intensifying screen systems",
           "10.1118/1.594304",
           2003,
           "The advent of fast Fourier techniques has greatly facilitated the digital analysis of noise power spectra (Wiener spectra) by circumventing the need for the autocorrelation function. We are now able to Fourier analyze film data at about the same rate the microdensitometer–computer system can collect it (1000 points/sec). The new technique has been applied to the analysis of the quantum mottle of several rare earth intensifying screen systems confirming earlier estimates from our pilot studies that such screens are capable of reducing exposure by a factor of about 2 with imaging parameters comparable to those of conventional calcium tungstate systems.",
           26,
           "medical_physics"
          ],
          [
           "Multitask network for thyroid nodule diagnosis based on TI‐RADS",
           "10.1002/mp.15724",
           2022,
           "PurposeAssessment of thyroid nodules is usually relied on the experience of the radiologist and is time‐consuming. Classification model of thyroid nodules cannot only reduce the burden on physicians but also provide objective recommendations. However, most classification models based on deep learning simply give a prediction result of the benignity or malignancy of nodules; thus, physicians have no way of knowing how the deep learning gets the prediction result due to the black‐box nature of neural networks. In this work, we integrate the explainability directly into the outputs generated by the model through combining thyroid imaging reporting and data system (TI‐RADS). The inference process of the proposed method is consistent with doctor's clinical diagnosis process; therefore, doctors can better explain the diagnosis results of the model to the patient.MethodsA multitask network based on TI‐RADS (MTN‐TI‐RADS) for the classification of thyroid nodules is proposed. In this network, a set of TI‐RADS classifications of nodules is first obtained by multitask learning, then the TI‐RADS points and the corresponding risk levels are calculated, and finally, nodules are classified as benign and malignant. The classification process through the network is consistent with the diagnostic process of physician; thus, the results of classification can be easily understood by physicians. In addition, the attention modules are introduced to the spatial and channel domains to let the network focus more on critical features.ResultsTo verify the classification performance of our method, we compared the results obtained through our method with the results of the radiologist's evaluation. For the 781 test nodules in the internal dataset and the 886 test nodules in the external dataset, the sensitivity and specificity of MTN‐TI‐RADS were 0.988, 0.912 in internal dataset, 0.949, 0.930 in external dataset, versus the senior radiologist of 0.925 (), 0.816 (), and 0.910 (), 0.836 (), respectively. And the area under the receiver operating characteristic curve of MTN‐TI‐RADS was 0.981 in internal dataset, 0.973 in external dataset, versus the senior radiologist of 0.905, 0.923. For the internal dataset, we also computed the accuracy of the risk level (TR1 to TR5) and the mean absolute error (MAE). The accuracy of the risk level of the proposed method is 78%, and the MAE is 1.30. The MAE of the total points (0–14 points) is 1.30.ConclusionsAn effective and result‐interpretable end‐to‐end thyroid nodule classification network (MTN‐TI‐RADS) is proposed. MTN‐TI‐RADS has superior ability to classify malignant and benign thyroid nodules compared to senior radiologists. Based on MTN‐TI‐RADS, a classification model with strong interpretation and a high degree of physician trust is constructed. The proposed classification network is consistent with the diagnosis process of physicians, thus is more reliable and interpretable, and has great potential for clinical application.",
           3,
           "medical_physics"
          ],
          [
           "Linearizing mechanisms in conventional tomographic imaging",
           "10.1118/1.594400",
           2003,
           "Implicit in the concept of conventional tomography and in any attempt to characterize the tomographic process by a modulation transfer function is the assumption that the tomographic process is linear. A Fourier decomposition approach and an analysis of nonlinear contributions to the integrated tomographic image intensity are used in this paper to establish the validity of this assumption and to determine the mechanisms by which the tomographic process is effectively linearized.",
           6,
           "medical_physics"
          ],
          [
           "Examination of the factors <i>A</i><sub><i>c</i></sub> and <i>A</i><sub>eq</sub> for cylindrical ion chambers used in cobalt‐60 beams",
           "10.1118/1.594582",
           2003,
           "The calibration of a cobalt‐60 beam in a phantom with an ion chamber, which has been calibrated with respect to exposure, requires the use of a displacement correction factor which essentially corrects the photon fluence for the attenuation and scatter when the chamber with buildup cap is removed and replaced by phantom material. To determine the displacement factor, Ac, a special set of cylindrical ionization chambers with various volumes were constructed out of polystyrene. Tissue–air ratios were measured with these chambers for cobalt‐60 gamma rays in a polystyrene phantom, and the ratio Ac/Aeq was experimentally determined. In order to calculate Ac from this ratio, Aeq was determined also. It was found that Ac depended on chamber diameter only, and not on field size or depth. A value of 0.990 for Aeq is recommended and a table of Ac for chambers of different outer diameters is included.",
           9,
           "medical_physics"
          ],
          [
           "Corrections to absorbed dose calculations for tissue inhomogeneities",
           "10.1118/1.594329",
           2003,
           "Traditional methods for correcting for the presence of tissue inhomogeneities may produce errors as great as 10% at points within or close to the inhomogeneity. A more accurate method is presented which employs tissue–air ratios raised to some power dependent on the relative electron densities of the inhomogeneities involved. Corrections may be made for points that lie within or below an inhomogeneity as well as for multiple inhomogeneities. Measurements were made in phantoms containing aluminum or cork inhomogeneities. Agreement between measured and predicted results was usually within 2%–3%.",
           87,
           "medical_physics"
          ],
          [
           "Any modification of the Born rule leads to a violation of the purification and local tomography principles",
           "10.22331/q-2018-11-06-104",
           2018,
           "Using the existing classification of all alternatives to the measurement postulates of quantum theory we study the properties of bi-partite systems in these alternative theories. We prove that in all these theories the purification principle is violated, meaning that some mixed states are not the reduction of a pure state in a larger system. This allows us to derive the measurement postulates of quantum theory from the structure of pure states and reversible dynamics, and the requirement that the purification principle holds. The violation of the purification principle implies that there is some irreducible classicality in these theories, which appears like an important clue for the problem of deriving the Born rule within the many-worlds interpretation. We also prove that in all such modifications the task of state tomography with local measurements is impossible, and present a simple toy theory displaying all these exotic non-quantum phenomena. This toy model shows that, contrarily to previous claims, it is possible to modify the Born rule without violating the no-signalling principle. Finally, we argue that the quantum measurement postulates are the most non-classical amongst all alternatives.",
           10,
           "quantum"
          ],
          [
           "Universal construction of genuinely entangled subspaces of any size",
           "10.22331/q-2022-11-10-854",
           2022,
           "We put forward a simple construction of genuinely entangled subspaces – subspaces supporting only genuinely multipartite entangled states – of any permissible dimensionality for any number of parties and local dimensions. The method uses nonorthogonal product bases, which are built from totally nonsingular matrices with a certain structure. We give an explicit basis for the constructed subspaces. An immediate consequence of our result is the possibility of constructing in the general multiparty scenario genuinely multiparty entangled mixed states with ranks up to the maximal dimension of a genuinely entangled subspace.",
           4,
           "quantum"
          ],
          [
           "Time-reversal of rank-one quantum strategy functions",
           "10.22331/q-2018-10-04-98",
           2018,
           "The quantum strategy (or quantum combs) framework is a useful tool for reasoning about interactions among entities that process and exchange quantum information over the course of multiple turns. We prove a time-reversal property for a class of linear functions, defined on quantum strategy representations within this framework, that corresponds to the set of rank-one positive semidefinite operators on a certain space. This time-reversal property states that the maximum value obtained by such a function over all valid quantum strategies is also obtained when the direction of time for the function is reversed, despite the fact that the strategies themselves are generally not time reversible. An application of this fact is an alternative proof of a known relationship between the conditional min- and max-entropy of bipartite quantum states, along with generalizations of this relationship.",
           0,
           "quantum"
          ],
          [
           "How to perform the coherent measurement of a curved phase space by continuous isotropic measurement. I. Spin and the Kraus-operator geometry of <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mml:mrow class=\"MJX-TeXAtom-ORD\"><mml:mi mathvariant=\"normal\">S</mml:mi><mml:mi mathvariant=\"normal\">L</mml:mi></mml:mrow><mml:mo stretchy=\"false\">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mrow class=\"MJX-TeXAtom-ORD\"><mml:mi mathvariant=\"double-struck\">C</mml:mi></mml:mrow><mml:mo stretchy=\"false\">)</mml:mo></mml:math>",
           "10.22331/q-2023-08-16-1085",
           2023,
           "The generalized Q-function of a spin system can be considered the outcome probability distribution of a state subjected to a measurement represented by the spin-coherent-state (SCS) positive-operator-valued measure (POVM). As fundamental as the SCS POVM is to the 2-sphere phase-space representation of spin systems, it has only recently been reported that the SCS POVM can be performed for any spin system by continuous isotropic measurement of the three total spin components [E. Shojaee, C. S. Jackson, C. A. Riofrio, A. Kalev, and I. H. Deutsch, Phys. Rev. Lett. 121, 130404 (2018)]. This article develops the theoretical details of the continuous isotropic measurement and places it within the general context of curved-phase-space correspondences for quantum systems. The analysis is in terms of the Kraus operators that develop over the course of a continuous isotropic measurement. The Kraus operators of any spin j are shown to represent elements of the Lie group SL(2,C)&#x2245;Spin(3,C), a complex version of the usual unitary operators that represent elements of SU(2)&#x2245;Spin(3,R). Consequently, the associated POVM elements represent points in the symmetric space SU(2)&#x2216;SL(2,C), which can be recognized as the 3-hyperboloid. Three equivalent stochastic techniques, (Wiener) path integral, (Fokker-Planck) diffusion equation, and stochastic differential equations, are applied to show that the continuous isotropic POVM quickly limits to the SCS POVM, placing spherical phase space at the boundary of the fundamental Lie group SL(2,C) in an operationally meaningful way. Two basic mathematical tools are used to analyze the evolving Kraus operators, the Maurer-Cartan form, modified for stochastic applications, and the Cartan, decomposition associated with the symmetric pair  SU(2) ⊂ SL(2,C). Informed by these tools, the three schochastic techniques are applied directly to the Kraus operators in a representation-independent – and therefore geometric – way (independent of any spectral information about the spin components).The Kraus-operator-centric, geometric treatment applies not just to SU(2) ⊂ SL(2,C), but also to any compact semisimple Lie group and its complexification. The POVM associated with the continuous isotropic measurement of Lie-group generators thus corresponds to a type-IV globally Riemannian symmetric space and limits to the POVM of generalized coherent states. This generalization is the focus of a sequel to this article.",
           2,
           "quantum"
          ],
          [
           "Designing locally maximally entangled quantum states with arbitrary local symmetries",
           "10.22331/q-2021-05-01-450",
           2021,
           "One of the key ingredients of many LOCC protocols in quantum information is a multiparticle (locally) maximally entangled quantum state, aka a critical state, that possesses local symmetries. We show how to design critical states with arbitrarily large local unitary symmetry. We explain that such states can be realised in a quantum system of distinguishable traps with bosons or fermions occupying a finite number of modes. Then, local symmetries of the designed quantum state are equal to the unitary group of local mode operations acting diagonally on all traps. Therefore, such a group of symmetries is naturally protected against errors that occur in a physical realisation of mode operators. We also link our results with the existence of so-called strictly semistable states with particular asymptotic diagonal symmetries. Our main technical result states that the Nth tensor power of any irreducible representation of SU(N) contains a copy of the trivial representation. This is established via a direct combinatorial analysis of Littlewood-Richardson rules utilising certain combinatorial objects which we call telescopes.",
           2,
           "quantum"
          ],
          [
           "Quantum Regularized Least Squares",
           "10.22331/q-2023-04-27-988",
           2023,
           "Linear regression is a widely used technique to fit linear models and finds widespread applications across different areas such as machine learning and statistics. In most real-world scenarios, however, linear regression problems are often ill-posed or the underlying model suffers from overfitting, leading to erroneous or trivial solutions. This is often dealt with by adding extra constraints, known as regularization. In this paper, we use the frameworks of block-encoding and quantum singular value transformation (QSVT) to design the first quantum algorithms for quantum least squares with general &#x2113;2-regularization. These include regularized versions of quantum ordinary least squares, quantum weighted least squares, and quantum generalized least squares. Our quantum algorithms substantially improve upon prior results on quantum ridge regression (polynomial improvement in the condition number and an exponential improvement in accuracy), which is a particular case of our result.To this end, we assume approximate block-encodings of the underlying matrices as input and use robust QSVT algorithms for various linear algebra operations. In particular, we develop a variable-time quantum algorithm for matrix inversion using QSVT, where we use quantum eigenvalue discrimination as a subroutine instead of gapped phase estimation. This ensures that substantially fewer ancilla qubits are required for this procedure than prior results. Owing to the generality of the block-encoding framework, our algorithms are applicable to a variety of input models and can also be seen as improved and generalized versions of prior results on standard (non-regularized) quantum least squares algorithms.",
           0,
           "quantum"
          ],
          [
           "Order preserving maps on quantum measurements",
           "10.22331/q-2022-11-10-853",
           2022,
           "We study the partially ordered set of equivalence classes of quantum measurements endowed with the post-processing partial order. The post-processing order is fundamental as it enables to compare measurements by their intrinsic noise and it gives grounds to define the important concept of quantum incompatibility. Our approach is based on mapping this set into a simpler partially ordered set using an order preserving map and investigating the resulting image. The aim is to ignore unnecessary details while keeping the essential structure, thereby simplifying e.g. detection of incompatibility. One possible choice is the map based on Fisher information introduced by Huangjun Zhu, known to be an order morphism taking values in the cone of positive semidefinite matrices. We explore the properties of that construction and improve Zhu&apos;s incompatibility criterion by adding a constraint depending on the number of measurement outcomes. We generalize this type of construction to other ordered vector spaces and we show that this map is optimal among all quadratic maps.",
           1,
           "quantum"
          ],
          [
           "Quantum Multi-Solution Bernoulli Search with Applications to Bitcoin&amp;apos;s Post-Quantum Security",
           "10.22331/q-2023-03-09-944",
           2023,
           "A proof of work (PoW) is an important cryptographic construct enabling a party to convince others that they invested some effort in solving a computational task. Arguably, its main impact has been in the setting of cryptocurrencies such as Bitcoin and its underlying blockchain protocol, which received significant attention in recent years due to its potential for various applications as well as for solving fundamental distributed computing questions in novel threat models. PoWs enable the linking of blocks in the blockchain data structure and thus the problem of interest is the feasibility of obtaining a sequence (chain) of such proofs. In this work, we examine the hardness of finding such chain of PoWs against quantum strategies. We prove that the chain of PoWs problem reduces to a problem we call multi-solution Bernoulli search, for which we establish its quantum query complexity. Effectively, this is an extension of a threshold direct product theorem to an average-case unstructured search problem. Our proof, adding to active recent efforts, simplifies and generalizes the recording technique of Zhandry (Crypto'19). As an application, we revisit the formal treatment of security of the core of the Bitcoin consensus protocol, the Bitcoin backbone (Eurocrypt'15), against quantum adversaries, while honest parties are classical and show that protocol's security holds under a quantum analogue of the classical “honest majority'' assumption. Our analysis indicates that the security of Bitcoin backbone is guaranteed provided the number of adversarial quantum queries is bounded so that each quantum query is worth O(p&#x2212;1/2) classical ones, where p is the success probability of a single classical query to the protocol's underlying hash function. Somewhat surprisingly, the wait time for safe settlement in the case of quantum adversaries matches the safe settlement time in the classical case.",
           0,
           "quantum"
          ],
          [
           "Parallelization techniques for quantum simulation of fermionic systems",
           "10.22331/q-2023-04-13-975",
           2023,
           "Mapping fermionic operators to qubit operators is an essential step for simulating fermionic systems on a quantum computer. We investigate how the choice of such a mapping interacts with the underlying qubit connectivity of the quantum processor to enable (or impede) parallelization of the resulting Hamiltonian-simulation algorithm. It is shown that this problem can be mapped to a path coloring problem on a graph constructed from the particular choice of encoding fermions onto qubits and the fermionic interactions onto paths. The basic version of this problem is called the weak coloring problem. Taking into account the fine-grained details of the mapping yields what is called the strong coloring problem, which leads to improved parallelization performance. A variety of illustrative analytical and numerical examples are presented to demonstrate the amount of improvement for both weak and strong coloring-based parallelizations. Our results are particularly important for implementation on near-term quantum processors where minimizing circuit depth is necessary for algorithmic feasibility.",
           0,
           "quantum"
          ],
          [
           "Towards a general framework of Randomized Benchmarking incorporating non-Markovian Noise",
           "10.22331/q-2022-12-01-868",
           2022,
           "The rapid progress in the development of quantum devices is in large part due to the availability of a wide range of characterization techniques allowing to probe, test and adjust them. Nevertheless, these methods often make use of approximations that hold in rather simplistic circumstances. In particular, assuming that error mechanisms stay constant in time and have no dependence in the past, is something that will be impossible to do as quantum processors continue scaling up in depth and size. We establish a theoretical framework for the Randomized Benchmarking protocol encompassing temporally-correlated, so-called non-Markovian noise, at the gate level, for any gate set belonging to a wide class of finite groups. We obtain a general expression for the Average Sequence Fidelity (ASF) and propose a way to obtain average gate fidelities of full non-Markovian noise processes. Moreover, we obtain conditions that are fulfilled when an ASF displays authentic non-Markovian deviations. Finally, we show that even though gate-dependence does not translate into a perturbative term within the ASF, as in the Markovian case, the non-Markovian sequence fidelity nevertheless remains stable under small gate-dependent perturbations.",
           2,
           "quantum"
          ],
          [
           "Single-copy activation of Bell nonlocality via broadcasting of quantum states",
           "10.22331/q-2021-07-13-499",
           2021,
           "Activation of Bell nonlocality refers to the phenomenon that some entangled mixed states that admit a local hidden variable model in the standard Bell scenario nevertheless reveal their nonlocal nature in more exotic measurement scenarios. We present such a scenario that involves broadcasting the local subsystems of a single-copy of a bipartite quantum state to multiple parties, and use the scenario to study the nonlocal properties of the two-qubit isotropic state:ρα=α|Φ+⟩⟨Φ+|+(1−α)14.We present two main results, considering that Nature allows for (i) the most general no-signalling correlations, and (ii) the most general quantum correlations at the level of any hidden variable theory. We show that the state does not admit a local hidden variable description for α>0.559 and α>12, in cases (i) and (ii) respectively, which in both cases provides a device-independent certification of the entanglement of the state. These bounds are significantly lower than the previously best-known bound of 0.697 for both Bell nonlocality and device-independent entanglement certification using a single copy of the state. Our results show that strong examples of non-classicality are possible with a small number of resources.",
           5,
           "quantum"
          ],
          [
           "Two-Qubit Pure Entanglement as Optimal Social Welfare Resource in Bayesian Game",
           "10.22331/q-2019-09-09-185",
           2019,
           "Entanglement is of paramount importance in quantum information theory. Its supremacy over classical correlations has been demonstrated in a numerous information theoretic protocols. Here we study possible adequacy of quantum entanglement in Bayesian game theory, particularly in social welfare solution (SWS), a strategy which the players follow to maximize sum of their payoffs. Given a multi-partite quantum state as an advice, players can come up with several correlated strategies by performing local measurements on their parts of the quantum state. A quantum strategy is called quantum-SWS if it is advantageous over a classical equilibrium (CE) strategy in the sense that none of the players has to sacrifice their CE-payoff rather some have incentive and at the same time it maximizes sum of all players' payoffs over all possible quantum advantageous strategies. Quantum state yielding such a quantum-SWS is called a quantum social welfare advice (SWA). We show that any two-qubit pure entangled state, even if it is arbitrarily close to a product state, can serve as quantum-SWA in some Bayesian game. Our result, thus, gives cognizance to the fact that every two-qubit pure entanglement is the best resource for some operational task.",
           11,
           "quantum"
          ],
          [
           "An Improved Approximation Algorithm for Quantum Max-Cut on Triangle-Free Graphs",
           "10.22331/q-2023-11-09-1180",
           2023,
           "We give an approximation algorithm for Quantum Max-Cut which works by rounding an SDP relaxation to an entangled quantum state. The SDP is used to choose the parameters of a variational quantum circuit. The entangled state is then represented as the quantum circuit applied to a product state. It achieves an approximation ratio of 0.582 on triangle-free graphs. The previous best algorithms of Anshu, Gosset, Morenz, and Parekh, Thompson achieved approximation ratios of 0.531 and 0.533 respectively. In addition, we study the EPR Hamiltonian, which we argue is a natural intermediate problem which isolates some key quantum features of local Hamiltonian problems. For the EPR Hamiltonian, we give an approximation algorithm with approximation ratio 1/2 on all graphs.",
           2,
           "quantum"
          ],
          [
           "The boundaries and twist defects of the color code and their applications to topological quantum computation",
           "10.22331/q-2018-10-19-101",
           2018,
           "The color code is both an interesting example of an exactly solved topologically ordered phase of matter and also among the most promising candidate models to realize fault-tolerant quantum computation with minimal resource overhead. The contributions of this work are threefold. First of all, we build upon the abstract theory of boundaries and domain walls of topological phases of matter to comprehensively catalog the objects realizable in color codes. Together with our classification we also provide lattice representations of these objects which include three new types of boundaries as well as a generating set for all 72 color code twist defects. Our work thus provides an explicit toy model that will help to better understand the abstract theory of domain walls. Secondly, we discover a number of interesting new applications of the cataloged objects for quantum information protocols. These include improved methods for performing quantum computations by code deformation, a new four-qubit error-detecting code, as well as families of new quantum error-correcting codes we call stellated color codes, which encode logical qubits at the same distance as the next best color code, but using approximately half the number of physical qubits. To the best of our knowledge, our new topological codes have the highest encoding rate of local stabilizer codes with bounded-weight stabilizers in two dimensions. Finally, we show how the boundaries and twist defects of the color code are represented by multiple copies of other phases. Indeed, in addition to the well studied comparison between the color code and two copies of the surface code, we also compare the color code to two copies of the three-fermion model. In particular, we find that this analogy offers a very clear lens through which we can view the symmetries of the color code which gives rise to its multitude of domain walls.",
           39,
           "quantum"
          ],
          [
           "Quantum metrology with full and fast quantum control",
           "10.22331/q-2017-09-06-27",
           2017,
           "We establish general limits on how precise a parameter, e.g. frequency or the strength of a magnetic field, can be estimated with the aid of full and fast quantum control. We consider uncorrelated noisy evolutions of N qubits and show that fast control allows to fully restore the Heisenberg scaling (~1/N^2) for all rank-one Pauli noise except dephasing. For all other types of noise the asymptotic quantum enhancement is unavoidably limited to a constant-factor improvement over the standard quantum limit (~1/N) even when allowing for the full power of fast control. The latter holds both in the single-shot and infinitely-many repetitions scenarios. However, even in this case allowing for fast quantum control helps to increase the improvement factor. Furthermore, for frequency estimation with finite resource we show how a parallel scheme utilizing any fixed number of entangled qubits but no fast quantum control can be outperformed by a simple, easily implementable, sequential scheme which only requires entanglement between one sensing and one auxiliary qubit.",
           83,
           "quantum"
          ],
          [
           "Efficient qubit phase estimation using adaptive measurements",
           "10.22331/q-2021-06-04-467",
           2021,
           "Estimating correctly the quantum phase of a physical system is a central problem in quantum parameter estimation theory due to its wide range of applications from quantum metrology to cryptography. Ideally, the optimal quantum estimator is given by the so-called quantum Cramér-Rao bound, so any measurement strategy aims to obtain estimations as close as possible to it. However, more often than not, the current state-of-the-art methods to estimate quantum phases fail to reach this bound as they rely on maximum likelihood estimators of non-identifiable likelihood functions. In this work we thoroughly review various schemes for estimating the phase of a qubit, identifying the underlying problem which prohibits these methods to reach the quantum Cramér-Rao bound, and propose a new adaptive scheme based on covariant measurements to circumvent this problem. Our findings are carefully checked by Monte Carlo simulations, showing that the method we propose is both mathematically and experimentally more realistic and more efficient than the methods currently available.",
           4,
           "quantum"
          ],
          [
           "A-unital Operations and Quantum Conditional Entropy",
           "10.22331/q-2022-02-02-641",
           2022,
           "Negative quantum conditional entropy states are key ingredients for information theoretic tasks such as superdense coding, state merging and one-way entanglement distillation. In this work, we ask: how does one detect if a channel is useful in preparing negative conditional entropy states? We answer this question by introducing the class of A-unital channels, which we show are the largest class of conditional entropy non-decreasing channels. We also prove that A-unital channels are precisely the completely free operations for the class of states with non-negative conditional entropy. Furthermore, we study the relationship between A-unital channels and other classes of channels pertinent to the resource theory of entanglement. We then prove similar results for ACVENN: a previously defined, relevant class of states and also relate the maximum and minimum conditional entropy of a state with its von Neumann entropy.\nThe definition of A-unital channels naturally lends itself to a procedure for determining membership of channels in this class. Thus, our work is valuable for the detection of resourceful channels in the context of conditional entropy.",
           2,
           "quantum"
          ],
          [
           "The geometry of passivity for quantum systems and a novel elementary derivation of the Gibbs state",
           "10.22331/q-2021-03-15-411",
           2021,
           "Passivity is a fundamental concept that constitutes a necessary condition for any quantum system to attain thermodynamic equilibrium, and for a notion of temperature to emerge. While extensive work has been done that exploits this, the transition from passivity at a single-shot level to the completely passive Gibbs state is technically clear but lacks a good over-arching intuition. Here, we reformulate passivity for quantum systems in purely geometric terms. This description makes the emergence of the Gibbs state from passive states entirely transparent. Beyond clarifying existing results, it also provides novel analysis for non-equilibrium quantum systems. We show that, to every passive state, one can associate a simple convex shape in a 2-dimensional plane, and that the area of this shape measures the degree to which the system deviates from the manifold of equilibrium states. This provides a novel geometric measure of athermality with relations to both ergotropy and β--athermality.",
           6,
           "quantum"
          ],
          [
           "Graphical Methods in Device-Independent Quantum Cryptography",
           "10.22331/q-2019-05-27-146",
           2019,
           "We introduce a framework for graphical security proofs in device-independent quantum cryptography using the methods of categorical quantum mechanics. We are optimistic that this approach will make some of the highly complex proofs in quantum cryptography more accessible, facilitate the discovery of new proofs, and enable automated proof verification. As an example of our framework, we reprove a previous result from device-independent quantum cryptography: any linear randomness expansion protocol can be converted into an unbounded randomness expansion protocol. We give a graphical proof of this result, and implement part of it in the Globular proof assistant.",
           1,
           "quantum"
          ],
          [
           "Limits of Short-Time Evolution of Local Hamiltonians",
           "10.22331/q-2022-06-27-744",
           2022,
           "Evolutions of local Hamiltonians in short times are expected to remain local and thus limited. In this paper, we validate this intuition by proving some limitations on short-time evolutions of local time-dependent Hamiltonians. We show that the distribution of the measurement output of short-time (at most logarithmic) evolutions of local Hamiltonians are concentrated and satisfy an isoperimetric inequality. To showcase explicit applications of our results, we study the MAXCUT problem and conclude that quantum annealing needs at least a run-time that scales logarithmically in the problem size to beat classical algorithms on MAXCUT. To establish our results, we also prove a Lieb-Robinson bound that works for time-dependent Hamiltonians which might be of independent interest.",
           1,
           "quantum"
          ],
          [
           "Characterizing and mitigating coherent errors in a trapped ion quantum processor using hidden inverses",
           "10.22331/q-2023-05-15-1006",
           2023,
           "Quantum computing testbeds exhibit high-fidelity quantum control over small collections of qubits, enabling performance of precise, repeatable operations followed by measurements. Currently, these noisy intermediate-scale devices can support a sufficient number of sequential operations prior to decoherence such that near term algorithms can be performed with proximate accuracy (like chemical accuracy for quantum chemistry problems). While the results of these algorithms are imperfect, these imperfections can help bootstrap quantum computer testbed development. Demonstrations of these algorithms over the past few years, coupled with the idea that imperfect algorithm performance can be caused by several dominant noise sources in the quantum processor, which can be measured and calibrated during algorithm execution or in post-processing, has led to the use of noise mitigation to improve typical computational results. Conversely, benchmark algorithms coupled with noise mitigation can help diagnose the nature of the noise, whether systematic or purely random. Here, we outline the use of coherent noise mitigation techniques as a characterization tool in trapped-ion testbeds. We perform model-fitting of the noisy data to determine the noise source based on realistic physics focused noise models and demonstrate that systematic noise amplification coupled with error mitigation schemes provides useful data for noise model deduction. Further, in order to connect lower level noise model details with application specific performance of near term algorithms, we experimentally construct the loss landscape of a variational algorithm under various injected noise sources coupled with error mitigation techniques. This type of connection enables application-aware hardware codesign, in which the most important noise sources in specific applications, like quantum chemistry, become foci of improvement in subsequent hardware generations.",
           0,
           "quantum"
          ],
          [
           "Quantum and Classical Bayesian Agents",
           "10.22331/q-2022-05-16-713",
           2022,
           "We describe a general approach to modeling rational decision-making agents who adopt either quantum or classical mechanics based on the Quantum Bayesian (QBist) approach to quantum theory. With the additional ingredient of a scheme by which the properties of one agent may influence another, we arrive at a flexible framework for treating multiple interacting quantum and classical Bayesian agents. We present simulations in several settings to illustrate our construction: quantum and classical agents receiving signals from an exogenous source, two interacting classical agents, two interacting quantum agents, and interactions between classical and quantum agents. A consistent treatment of multiple interacting users of quantum theory may allow us to properly interpret existing multi-agent protocols and could suggest new approaches in other areas such as quantum algorithm design.",
           1,
           "quantum"
          ],
          [
           "Operational interpretation of the vacuum and process matrices for identical particles",
           "10.22331/q-2023-04-20-986",
           2023,
           "This work overviews the single-particle two-way communication protocol recently introduced by del Santo and Dakić (dSD), and analyses it using the process matrix formalism. We give a detailed account of the importance and the operational meaning of the interaction of an agent with the vacuum – in particular its role in the process matrix description. Our analysis shows that the interaction with the vacuum should be treated as an operation, on equal footing with all other interactions. This raises the issue of counting such operations in an operational manner. Motivated by this analysis, we apply the process matrix formalism to capped Fock spaces using the framework of second quantisation, in order to characterise protocols with an indefinite number of identical particles.",
           1,
           "quantum"
          ],
          [
           "Physical Implementability of Linear Maps and Its Application in Error Mitigation",
           "10.22331/q-2021-12-07-600",
           2021,
           "Completely positive and trace-preserving maps characterize physically implementable quantum operations. On the other hand, general linear maps, such as positive but not completely positive maps, which can not be physically implemented, are fundamental ingredients in quantum information, both in theoretical and practical perspectives. This raises the question of how well one can simulate or approximate the action of a general linear map by physically implementable operations. In this work, we introduce a systematic framework to resolve this task using the quasiprobability decomposition technique. We decompose a target linear map into a linear combination of physically implementable operations and introduce the physical implementability measure as the least amount of negative portion that the quasiprobability must pertain, which directly quantifies the cost of simulating a given map using physically implementable quantum operations. We show this measure is efficiently computable by semidefinite programs and prove several properties of this measure, such as faithfulness, additivity, and unitary invariance. We derive lower and upper bounds in terms of the Choi operator's trace norm and obtain analytic expressions for several linear maps of practical interests. Furthermore, we endow this measure with an operational meaning within the quantum error mitigation scenario: it establishes the lower bound of the sampling cost achievable via the quasiprobability decomposition technique. In particular, for parallel quantum noises, we show that global error mitigation has no advantage over local error mitigation.",
           20,
           "quantum"
          ],
          [
           "Reinforcement Learning with Neural Networks for Quantum Multiple Hypothesis Testing",
           "10.22331/q-2022-01-26-633",
           2022,
           "Reinforcement learning with neural networks (RLNN) has recently demonstrated great promise for many problems, including some problems in quantum information theory. In this work, we apply RLNN to quantum hypothesis testing and determine the optimal measurement strategy for distinguishing between multiple quantum states {&#x03C1;j} while minimizing the error probability. In the case where the candidate states correspond to a quantum system with many qubit subsystems, implementing the optimal measurement on the entire system is experimentally infeasible. We use RLNN to find locally-adaptive measurement strategies that are experimentally feasible, where only one quantum subsystem is measured in each round. We provide numerical results which demonstrate that RLNN successfully finds the optimal local approach, even for candidate states up to 20 subsystems. We additionally demonstrate that the RLNN strategy meets or exceeds the success probability for a modified locally greedy approach in each random trial.While the use of RLNN is highly successful for designing adaptive local measurement strategies, in general a significant gap can exist between the success probability of the optimal locally-adaptive measurement strategy and the optimal collective measurement. We build on previous work to provide a set of necessary and sufficient conditions for collective protocols to strictly outperform locally adaptive protocols. We also provide a new example which, to our knowledge, is the simplest known state set exhibiting a significant gap between local and collective protocols. This result raises interesting new questions about the gap between theoretically optimal measurement strategies and practically implementable measurement strategies.",
           0,
           "quantum"
          ],
          [
           "Graph-theoretic approach to Bell experiments with low detection efficiency",
           "10.22331/q-2023-02-16-922",
           2023,
           "Bell inequality tests where the detection efficiency is below a certain threshold &#x03B7;crit can be simulated with local hidden-variable models. Here, we introduce a method to identify Bell tests requiring low &#x03B7;crit and relatively low dimension d of the local quantum systems. The method has two steps. First, we show a family of bipartite Bell inequalities for which, for correlations produced by maximally entangled states, &#x03B7;crit can be upper bounded by a function of some invariants of graphs, and use it to identify correlations that require small &#x03B7;crit. We present examples in which, for maximally entangled states, &#x03B7;crit&#x2264;0.516 for d=16, &#x03B7;crit&#x2264;0.407 for d=28, and &#x03B7;crit&#x2264;0.326 for d=32. We also show evidence that the upper bound for &#x03B7;crit can be lowered down to 0.415 for d=16 and present a method to make the upper bound of &#x03B7;crit arbitrarily small by increasing the dimension and the number of settings. All these upper bounds for &#x03B7;crit are valid (as it is the case in the literature) assuming no noise. The second step is based on the observation that, using the initial state and measurement settings identified in the first step, we can construct Bell inequalities with smaller &#x03B7;crit and better noise robustness. For that, we use a modified version of Gilbert's algorithm that takes advantage of the automorphisms of the graphs used in the first step. We illustrate its power by explicitly developing an example in which &#x03B7;crit is 12.38&#x0025; lower and the required visibility is 14.62&#x0025; lower than the upper bounds obtained in the first step. The tools presented here may allow for developing high-dimensional loophole-free Bell tests and loophole-free Bell nonlocality over long distances.",
           3,
           "quantum"
          ],
          [
           "Coherent information of a quantum channel or its complement is generically positive",
           "10.22331/q-2022-08-11-775",
           2022,
           "The task of determining whether a given quantum channel has positive capacity to transmit quantum information is a fundamental open problem in quantum information theory. In general, the coherent information needs to be computed for an unbounded number of copies of a channel in order to detect a positive value of its quantum capacity. However, in this paper, we show that the coherent information of a single copy of a randomly selected channel is positive almost surely if the channel's output space is larger than its environment. Hence, in this case, a single copy of the channel typically suffices to determine positivity of its quantum capacity. Put differently, channels with zero coherent information have measure zero in the subset of channels for which the output space is larger than the environment. On the other hand, if the environment is larger than the channel's output space, identical results hold for the channel's complement.",
           1,
           "quantum"
          ],
          [
           "Randomized Benchmarking as Convolution: Fourier Analysis of Gate Dependent Errors",
           "10.22331/q-2021-11-16-581",
           2021,
           "We show that the Randomized Benchmarking (RB) protocol is a convolution amenable to Fourier space analysis. By adopting the mathematical framework of Fourier transforms of matrix-valued functions on groups established in recent work from Gowers and Hatami \\cite{GH15}, we provide an alternative proof of Wallman's \\cite{Wallman2018} and Proctor's \\cite{Proctor17} bounds on the effect of gate-dependent noise on randomized benchmarking. We show explicitly that as long as our faulty gate-set is close to the targeted representation of the Clifford group, an RB sequence is described by the exponential decay of a process that has exactly two eigenvalues close to one and the rest close to zero. This framework also allows us to construct a gauge in which the average gate-set error is a depolarizing channel parameterized by the RB decay rates, as well as a gauge which maximizes the fidelity with respect to the ideal gate-set.",
           14,
           "quantum"
          ],
          [
           "Resource-Optimized Fermionic Local-Hamiltonian Simulation on a Quantum Computer for Quantum Chemistry",
           "10.22331/q-2021-07-26-509",
           2021,
           "The ability to simulate a fermionic system on a quantum computer is expected to revolutionize chemical engineering, materials design, nuclear physics, to name a few. Thus, optimizing the simulation circuits is of significance in harnessing the power of quantum computers. Here, we address this problem in two aspects. In the fault-tolerant regime, we optimize the Rz and T gate counts along with the ancilla qubit counts required, assuming the use of a product-formula algorithm for implementation. We obtain a savings ratio of two in the gate counts and a savings ratio of eleven in the number of ancilla qubits required over the state of the art. In the pre-fault tolerant regime, we optimize the two-qubit gate counts, assuming the use of the variational quantum eigensolver (VQE) approach. Specific to the latter, we present a framework that enables bootstrapping the VQE progression towards the convergence of the ground-state energy of the fermionic system. This framework, based on perturbation theory, is capable of improving the energy estimate at each cycle of the VQE progression, by about a factor of three closer to the known ground-state energy compared to the standard VQE approach in the test-bed, classically-accessible system of the water molecule. The improved energy estimate in turn results in a commensurate level of savings of quantum resources, such as the number of qubits and quantum gates, required to be within a pre-specified tolerance from the known ground-state energy. We also explore a suite of generalized transformations of fermion to qubit operators and show that resource-requirement savings of up to more than 20%, in small instances, is possible.",
           11,
           "quantum"
          ],
          [
           "Black holes as clouded mirrors: the Hayden-Preskill protocol with symmetry",
           "10.22331/q-2023-02-21-928",
           2023,
           "The Hayden-Preskill protocol is a qubit-toy model of the black hole information paradox. Based on the assumption of scrambling, it was revealed that quantum information is instantly leaked out from the quantum many-body system that models a black hole. In this paper, we extend the protocol to the case where the system has symmetry and investigate how the symmetry affects the leakage of information. We especially focus on the conservation of the number of up-spins. Developing a partial decoupling approach, we first show that the symmetry induces a delay of leakage and an information remnant. We then clarify the physics behind them: the delay is characterized by thermodynamic properties of the system associated with the symmetry, and the information remnant is closely related to the symmetry-breaking of the initial state. These relations bridge the information leakage problem to macroscopic physics of quantum many-body systems and allow us to investigate the information leakage only in terms of physical properties of the system.",
           4,
           "quantum"
          ],
          [
           "Whenever a quantum environment emerges as a classical system, it behaves like a measuring apparatus",
           "10.22331/q-2019-08-26-179",
           2019,
           "We study the dynamics of a quantum system Γ with an environment Ξ made of N elementary quantum components. We aim at answering the following questions: can the evolution of Γ be characterized by some general features when N becomes very large, regardless of the specific form of its interaction with each and every component of Ξ? In other terms: should we expect all quantum systems with a macroscopic environment to undergo a somehow similar evolution? And if yes, of what type? In order to answer these questions we use well established results from large-N quantum field theories, particularly referring to the conditions ensuring a large-N quantum model to be effectively described by a classical theory. We demonstrate that the fulfillment of these conditions, when properly imported into the framework of the open quantum systems dynamics, guarantees that the evolution of Γ is always of the same type of that expected if Ξ were a measuring apparatus, no matter the details of the actual interaction. On the other hand, such details are found to determine the specific basis w.r.t. which Γ undergoes the decoherence dictated by the dynamical description of the quantum measurement process. This result wears two hats: on the one hand it clarifies the physical origin of the formal statement that, under certain conditions, any channel from ρΓ to ρΞ takes the form of a measure-and-prepare map, as recently shown in Ref. \\cite{BrandaoPH15}; on the other hand, it formalizes the qualitative argument that the reason why we do not observe state superpositions is the continual measurement performed by the environment.",
           14,
           "quantum"
          ],
          [
           "Near-deterministic hybrid generation of arbitrary photonic graph states using a single quantum emitter and linear optics",
           "10.22331/q-2023-04-27-992",
           2023,
           "Since linear-optical two-photon gates are inherently probabilistic, measurement-based implementations are particularly well suited for photonic platforms: a large highly-entangled photonic resource state, called a graph state, is consumed through measurements to perform a computation. The challenge is thus to produce these graph states. Several generation procedures, which use either interacting quantum emitters or efficient spin-photon interface, have been proposed to create these photonic graph states deterministically. Yet, these solutions are still out of reach experimentally since the state-of-the-art is the generation of a linear graph state. Here, we introduce near-deterministic solutions for the generation of graph states using the current quantum emitter capabilities. We propose hybridizing quantum-emitter-based graph state generation with all-photonic fusion gates to produce graph states of complex topology near-deterministically. Our results should pave the way towards the practical implementation of resource-efficient quantum information processing, including measurement-based quantum communication and quantum computing.",
           7,
           "quantum"
          ],
          [
           "The battle of clean and dirty qubits in the era of partial error correction",
           "10.22331/q-2023-07-13-1060",
           2023,
           "When error correction becomes possible it will be necessary to dedicate a large number of physical qubits to each logical qubit. Error correction allows for deeper circuits to be run, but each additional physical qubit can potentially contribute an exponential increase in computational space, so there is a trade-off between using qubits for error correction or using them as noisy qubits. In this work we look at the effects of using noisy qubits in conjunction with noiseless qubits (an idealized model for error-corrected qubits), which we call the \"clean and dirty\" setup. We employ analytical models and numerical simulations to characterize this setup. Numerically we show the appearance of Noise-Induced Barren Plateaus (NIBPs), i.e., an exponential concentration of observables caused by noise, in an Ising model Hamiltonian variational ansatz circuit. We observe this even if only a single qubit is noisy and given a deep enough circuit, suggesting that NIBPs cannot be fully overcome simply by error-correcting a subset of the qubits. On the positive side, we find that for every noiseless qubit in the circuit, there is an exponential suppression in concentration of gradient observables, showing the benefit of partial error correction. Finally, our analytical models corroborate these findings by showing that observables concentrate with a scaling in the exponent related to the ratio of dirty-to-total qubits.",
           4,
           "quantum"
          ],
          [
           "A quantum extension of SVM-perf for training nonlinear SVMs in almost linear time",
           "10.22331/q-2020-10-15-342",
           2020,
           "We propose a quantum algorithm for training nonlinear support vector machines (SVM) for feature space learning where classical input data is encoded in the amplitudes of quantum states. Based on the classical SVM-perf algorithm of Joachims \\cite{joachims2006training}, our algorithm has a running time which scales linearly in the number of training examplesm(up to polylogarithmic factors) and applies to the standard soft-marginℓ1-SVM model. In contrast, while classical SVM-perf has demonstrated impressive performance on both linear and nonlinear SVMs, its efficiency is guaranteed only in certain cases: it achieves linearmscaling only for linear SVMs, where classification is performed in the original input data space, or for the special cases of low-rank or shift-invariant kernels. Similarly, previously proposed quantum algorithms either have super-linear scaling inm, or else apply to different SVM models such as the hard-margin or least squaresℓ2-SVM which lack certain desirable properties of the soft-marginℓ1-SVM model. We classically simulate our algorithm and give evidence that it can perform well in practice, and not only for asymptotically large data sets.",
           5,
           "quantum"
          ],
          [
           "Probing the non-classicality of temporal correlations",
           "10.22331/q-2017-11-25-35",
           2017,
           "Correlations between spacelike separated measurements on entangled quantum systems are stronger than any classical correlations and are at the heart of numerous quantum technologies. In practice, however, spacelike separation is often not guaranteed and we typically face situations where measurements have an underlying time order. Here we aim to provide a fair comparison of classical and quantum models of temporal correlations on a single particle, as well as timelike-separated correlations on multiple particles. We use a causal modeling approach to show, in theory and experiment, that quantum correlations outperform their classical counterpart when allowed equal, but limited communication resources. This provides a clearer picture of the role of quantum correlations in timelike separated scenarios, which play an important role in foundational and practical aspects of quantum information processing.",
           13,
           "quantum"
          ],
          [
           "Time crystallinity in open quantum systems",
           "10.22331/q-2020-05-25-270",
           2020,
           "Time crystals are genuinely non-equilibrium quantum phases of matter that break time-translational symmetry. While in non-equilibrium closed systems time crystals have been experimentally realized, it remains an open question whether or not such a phase survives when systems are coupled to an environment. Although dissipation caused by the coupling to a bath may stabilize time crystals in some regimes, the introduction of incoherent noise may also destroy the time crystalline order. Therefore, the mechanisms that stabilize a time crystal in open and closed systems are not necessarily the same. Here, we propose a way to identify an open system time crystal based on a single object: the Floquet propagator. Armed with such a description we show time-crystalline behavior in an explicitly short-range interacting open system and demonstrate the crucial role of the nature of the decay processes.",
           26,
           "quantum"
          ],
          [
           "Hamiltonian variational ansatz without barren plateaus",
           "10.22331/q-2024-02-01-1239",
           2024,
           "Variational quantum algorithms, which combine highly expressive parameterized quantum circuits (PQCs) and optimization techniques in machine learning, are one of the most promising applications of a near-term quantum computer. Despite their huge potential, the utility of variational quantum algorithms beyond tens of qubits is still questioned. One of the central problems is the trainability of PQCs. The cost function landscape of a randomly initialized PQC is often too flat, asking for an exponential amount of quantum resources to find a solution. This problem, dubbed barren plateaus, has gained lots of attention recently, but a general solution is still not available. In this paper, we solve this problem for the Hamiltonian variational ansatz (HVA), which is widely studied for solving quantum many-body problems. After showing that a circuit described by a time-evolution operator generated by a local Hamiltonian does not have exponentially small gradients, we derive parameter conditions for which the HVA is well approximated by such an operator. Based on this result, we propose an initialization scheme for the variational quantum algorithms and a parameter-constrained ansatz free from barren plateaus.",
           0,
           "quantum"
          ],
          [
           "Error mitigation on a near-term quantum photonic device",
           "10.22331/q-2021-05-04-452",
           2021,
           "Photon loss is destructive to the performance of quantum photonic devices and therefore suppressing the effects of photon loss is paramount to photonic quantum technologies. We present two schemes to mitigate the effects of photon loss for a Gaussian Boson Sampling device, in particular, to improve the estimation of the sampling probabilities. Instead of using error correction codes which are expensive in terms of their hardware resource overhead, our schemes require only a small amount of hardware modifications or even no modification. Our loss-suppression techniques rely either on collecting additional measurement data or on classical post-processing once the measurement data is obtained. We show that with a moderate cost of classical post processing, the effects of photon loss can be significantly suppressed for a certain amount of loss. The proposed schemes are thus a key enabler for applications of near-term photonic quantum devices.",
           8,
           "quantum"
          ],
          [
           "General properties of fidelity in non-Hermitian quantum systems with PT symmetry",
           "10.22331/q-2023-03-23-960",
           2023,
           "The fidelity susceptibility is a tool for studying quantum phase transitions in the Hermitian condensed matter systems. Recently, it has been generalized with the biorthogonal basis for the non-Hermitian quantum systems. From the general perturbation description with the constraint of parity-time (PT) symmetry, we show that the fidelity F is always real for the PT-unbroken states. For the PT-broken states, the real part of the fidelity susceptibility Re[XF] is corresponding to considering both the PT partner states, and the negative infinity is explored by the perturbation theory when the parameter approaches the exceptional point (EP). Moreover, at the second-order EP, we prove that the real part of the fidelity between PT-unbroken and PT-broken states is ReF=12. Based on these general properties, we study the two-legged non-Hermitian Su-Schrieffer-Heeger (SSH) model and the non-Hermitian XXZ spin chain. We find that for both interacting and non-interacting systems, the real part of fidelity susceptibility density goes to negative infinity when the parameter approaches the EP, and verifies it is a second-order EP by ReF=12.",
           6,
           "quantum"
          ],
          [
           "Combining hard and soft decoders for hypergraph product codes",
           "10.22331/q-2021-04-15-432",
           2021,
           "Hypergraph product codes are a class of constant-rate quantum low-density parity-check (LDPC) codes equipped with a linear-time decoder called small-set-flip (SSF). This decoder displays sub-optimal performance in practice and requires very large error correcting codes to be effective. In this work, we present new hybrid decoders that combine the belief propagation (BP) algorithm with the SSF decoder. We present the results of numerical simulations when codes are subject to independent bit-flip and phase-flip errors. We provide evidence that the threshold of these codes is roughly 7.5% assuming an ideal syndrome extraction, and remains close to 3% in the presence of syndrome noise. This result subsumes and significantly improves upon an earlier work by Grospellier and Krishna (arXiv:1810.03681). The low-complexity high-performance of these heuristic decoders suggests that decoding should not be a substantial difficulty when moving from zero-rate surface codes to constant-rate LDPC codes and gives a further hint that such codes are well-worth investigating in the context of building large universal quantum computers.",
           20,
           "quantum"
          ],
          [
           "Quantum variational learning for quantum error-correcting codes",
           "10.22331/q-2022-10-06-828",
           2022,
           "Quantum error correction is believed to be a necessity for large-scale fault-tolerant quantum computation. In the past two decades, various constructions of quantum error-correcting codes (QECCs) have been developed, leading to many good code families. However, the majority of these codes are not suitable for near-term quantum devices. Here we present VarQEC, a noise-resilient variational quantum algorithm to search for quantum codes with a hardware-efficient encoding circuit. The cost functions are inspired by the most general and fundamental requirements of a QECC, the Knill-Laflamme conditions. Given the target noise channel (or the target code parameters) and the hardware connectivity graph, we optimize a shallow variational quantum circuit to prepare the basis states of an eligible code. In principle, VarQEC can find quantum codes for any error model, whether additive or non-additive, degenerate or non-degenerate, pure or impure. We have verified its effectiveness by (re)discovering some symmetric and asymmetric codes, e.g., ((n,2n&#x2212;6,3))2 for n from 7 to 14. We also found new ((6,2,3))2 and ((7,2,3))2 codes that are not equivalent to any stabilizer code, and extensive numerical evidence with VarQEC suggests that a ((7,3,3))2 code does not exist. Furthermore, we found many new channel-adaptive codes for error models involving nearest-neighbor correlated errors. Our work sheds new light on the understanding of QECC in general, which may also help to enhance near-term device performance with channel-adaptive error-correcting codes.",
           9,
           "quantum"
          ],
          [
           "Wigner function for SU(1,1)",
           "10.22331/q-2020-09-07-317",
           2020,
           "In spite of their potential usefulness, Wigner functions for systems with SU(1,1) symmetry have not been explored thus far. We address this problem from a physically-motivated perspective, with an eye towards applications in modern metrology. Starting from two independent modes, and after getting rid of the irrelevant degrees of freedom, we derive in a consistent way a Wigner distribution for SU(1,1). This distribution appears as the expectation value of the displaced parity operator, which suggests a direct way to experimentally sample it. We show how this formalism works in some relevant examples.Dedication: While this manuscript was under review, we learnt with great sadness of the untimely passing of our colleague and friend Jonathan Dowling. Through his outstanding scientific work, his kind attitude, and his inimitable humor, he leaves behind a rich legacy for all of us. Our work on SU(1,1) came as a result of long conversations during his frequent visits to Erlangen. We dedicate this paper to his memory.",
           16,
           "quantum"
          ],
          [
           "Universal MBQC with generalised parity-phase interactions and Pauli measurements",
           "10.22331/q-2019-04-26-134",
           2019,
           "We introduce a new family of models for measurement-based quantum computation which are deterministic and approximately universal. The resource states which play the role of graph states are prepared via 2-qubit gates of the form exp⁡(−iπ2nZ⊗Z). When n=2, these are equivalent, up to local Clifford unitaries, to graph states. However, when n>2, their behaviour diverges in two important ways. First, multiple applications of the entangling gate to a single pair of qubits produces non-trivial entanglement, and hence multiple parallel edges between nodes play an important role in these generalised graph states. Second, such a state can be used to realise deterministic, approximately universal computation using only Pauli Z and X measurements and feed-forward. Even though, for n>2, the relevant resource states are no longer stabiliser states, they admit a straightforward, graphical representation using the ZX-calculus. Using this representation, we are able to provide a simple, graphical proof of universality. We furthermore show that for every n>2 this family is capable of producing all Clifford gates and all diagonal gates in the n-th level of the Clifford hierarchy.",
           15,
           "quantum"
          ],
          [
           "Separability of diagonal symmetric states: a quadratic conic optimization problem",
           "10.22331/q-2018-01-12-45",
           2018,
           "We study the separability problem in mixtures of Dicke states i.e., the separability of the so-called Diagonal Symmetric (DS) states. First, we show that separability in the case of DS inCd⊗Cd(symmetric qudits) can be reformulated as a quadratic conic optimization problem. This connection allows us to exchange concepts and ideas between quantum information and this field of mathematics. For instance, copositive matrices can be understood as indecomposable entanglement witnesses for DS states. As a consequence, we show that positivity of the partial transposition (PPT) is sufficient and necessary for separability of DS states ford≤4. Furthermore, ford≥5, we provide analytic examples of PPT-entangled states. Second, we develop new sufficient separability conditions beyond the PPT criterion for bipartite DS states. Finally, we focus onN-partite DS qubits, where PPT is known to be necessary and sufficient for separability. In this case, we present a family of almost DS states that are PPT with respect to each partition but nevertheless entangled.",
           26,
           "quantum"
          ],
          [
           "Decomposable coherence and quantum fluctuation relations",
           "10.22331/q-2019-11-11-202",
           2019,
           "In Newtonian mechanics, any closed-system dynamics of a composite system in a microstate will leave all its individual subsystems in distinct microstates, however this fails dramatically in quantum mechanics due to the existence of quantum entanglement. Here we introduce the notion of a `coherent work process', and show that it is the direct extension of a work process in classical mechanics into quantum theory. This leads to the notion of `decomposable' and `non-decomposable' quantum coherence and gives a new perspective on recent results in the theory of asymmetry as well as early analysis in the theory of classical random variables. Within the context of recent fluctuation relations, originally framed in terms of quantum channels, we show that coherent work processes play the same role as their classical counterparts, and so provide a simple physical primitive for quantum coherence in such systems. We also introduce a pure state effective potential as a tool with which to analyze the coherent component of these fluctuation relations, and which leads to a notion of temperature-dependent mean coherence, provides connections with multi-partite entanglement, and gives a hierarchy of quantum corrections to the classical Crooks relation in powers of inverse temperature.",
           8,
           "quantum"
          ],
          [
           "Quantum reference frames: derivation of perspective-dependent descriptions via a perspective-neutral structure",
           "10.22331/q-2023-08-29-1098",
           2023,
           "In standard quantum mechanics, reference frames are treated as abstract entities. We can think of them as idealized, infinite-mass subsystems which decouple from the rest of the system. In nature, however, all reference frames are realized through finite-mass systems that are subject to the laws of quantum mechanics and must be included in the dynamical evolution. A fundamental physical theory should take this fact seriously. In this paper, we further develop a symmetry-inspired approach to describe physics from the perspective of quantum reference frames. We find a unifying framework allowing us to systematically derive a broad class of perspective dependent descriptions and the transformations between them. Working with a translational-invariant toy model of three free particles, we discover that the introduction of relative coordinates leads to a Hamiltonian structure with two non-commuting constraints. This structure can be said to contain all observer-perspectives at once, while the redundancies prevent an immediate operational interpretation. We show that the operationally meaningful perspective dependent descriptions are given by Darboux coordinates on the constraint surface and that reference frame transformations correspond to reparametrizations of the constraint surface. We conclude by constructing a quantum perspective neutral structure, via which we can derive and change perspective dependent descriptions without referring to the classical theory. In addition to the physical findings, this work illuminates the interrelation of first and second class constrained systems and their respective quantization procedures.",
           0,
           "quantum"
          ],
          [
           "On the complementary quantum capacity of the depolarizing channel",
           "10.22331/q-2017-09-19-28",
           2017,
           "The qubit depolarizing channel with noise parameter η transmits an input qubit perfectly with probability 1−η, and outputs the completely mixed state with probability η. We show that its complementary channel has positive quantum capacity for all η>0. Thus, we find that there exists a single parameter family of channels having the peculiar property of having positive quantum capacity even when the outputs of these channels approach a fixed state independent of the input. Comparisons with other related channels, and implications on the difficulty of studying the quantum capacity of the depolarizing channel are discussed.",
           12,
           "quantum"
          ],
          [
           "POVMs are equivalent to projections for perfect state exclusion of three pure states in three dimensions",
           "10.22331/q-2019-01-25-117",
           2019,
           "Performing perfect/conclusive quantum state exclusion means to be able to discard with certainty at least one out ofnpossible quantum state preparations by performing a measurement of the resulting state. This task of state exclusion has recently been studied at length in \\cite{bandyopadhyay2014conclusive}, and it is at the heart of the celebrated PBR thought experiment \\cite{pusey2012reality}. When all the preparations correspond to pure states and there are no more of them than their common dimension, it is an open problem whether POVMs give any additional power for this task with respect to projective measurements. This is the case even for the simple case of three states in three dimensions, which is mentioned in \\cite{caves2002conditions} as unsuccessfully tackled. In this paper, we give an analytical proof that in this case considering POVMs does indeed not give any additional power with respect to projective measurements. To do so, we first make without loss of generality some assumptions about the structure of an optimal POVM. The justification of these assumptions involves arguments based on convexity, rank and symmetry properties. We show then that any pure states perfectly excluded by such a POVM meet the conditions identified in \\cite{caves2002conditions} for perfect exclusion by a projective measurement of three pure states in three dimensions. We also discuss possible generalizations of our work, including an application of Quadratically Constrained Quadratic Programming that might be of special interest.",
           1,
           "quantum"
          ],
          [
           "Composite Quantum Simulations",
           "10.22331/q-2023-11-14-1181",
           2023,
           "In this paper we provide a framework for combining multiple quantum simulation methods, such as Trotter-Suzuki formulas and QDrift into a single Composite channel that builds upon older coalescing ideas for reducing gate counts. The central idea behind our approach is to use a partitioning scheme that allocates a Hamiltonian term to the Trotter or QDrift part of a channel within the simulation. This allows us to simulate small but numerous terms using QDrift while simulating the larger terms using a high-order Trotter-Suzuki formula. We prove rigorous bounds on the diamond distance between the Composite channel and the ideal simulation channel and show under what conditions the cost of implementing the Composite channel is asymptotically upper bounded by the methods that comprise it for both probabilistic partitioning of terms and deterministic partitioning. Finally, we discuss strategies for determining partitioning schemes as well as methods for incorporating different simulation methods within the same framework.",
           4,
           "quantum"
          ],
          [
           "Here comes the SU(N): multivariate quantum gates and gradients",
           "10.22331/q-2024-03-07-1275",
           2024,
           "Variational quantum algorithms use non-convex optimization methods to find the optimal parameters for a parametrized quantum circuit in order to solve a computational problem. The choice of the circuit ansatz, which consists of parameterized gates, is crucial to the success of these algorithms. Here, we propose a gate which fully parameterizes the special unitary group SU(N). This gate is generated by a sum of non-commuting operators, and we provide a method for calculating its gradient on quantum hardware. In addition, we provide a theorem for the computational complexity of calculating these gradients by using results from Lie algebra theory. In doing so, we further generalize previous parameter-shift methods. We show that the proposed gate and its optimization satisfy the quantum speed limit, resulting in geodesics on the unitary group. Finally, we give numerical evidence to support the feasibility of our approach and show the advantage of our gate over a standard gate decomposition scheme. In doing so, we show that not only the expressibility of an ansatz matters, but also how it's explicitly parameterized.",
           0,
           "quantum"
          ],
          [
           "Flow of time during energy measurements and the resulting time-energy uncertainty relations",
           "10.22331/q-2022-04-07-683",
           2022,
           "Uncertainty relations play a crucial role in quantum mechanics. Well-defined methods exist for the derivation of such uncertainties for pairs of observables. Other approaches also allow the formulation of time-energy uncertainty relations, even though time is not an operator in standard quantum mechanics. However, in these cases, different approaches are associated with different meanings and interpretations for these relations. The one of interest here revolves around the idea of whether quantum mechanics inherently imposes a fundamental minimum duration for energy measurements with a certain precision. In our study, we investigate within the Page and Wootters timeless framework how energy measurements modify the relative \"flow of time&apos;&apos; between internal and external clocks. This provides a unified framework for discussing the subject, allowing us to recover previous results and derive new ones. In particular, we show that the duration of an energy measurement carried out by an external system cannot be performed arbitrarily fast from the perspective of the internal clock. Moreover, we show that during any energy measurement the evolution given by the internal clock is non-unitary.",
           4,
           "quantum"
          ],
          [
           "Pauli channels can be estimated from syndrome measurements in quantum error correction",
           "10.22331/q-2022-09-19-809",
           2022,
           "The performance of quantum error correction can be significantly improved if detailed information about the noise is available, allowing to optimize both codes and decoders. It has been proposed to estimate error rates from the syndrome measurements done anyway during quantum error correction. While these measurements preserve the encoded quantum state, it is currently not clear how much information about the noise can be extracted in this way. So far, apart from the limit of vanishing error rates, rigorous results have only been established for some specific codes.\nIn this work, we rigorously resolve the question for arbitrary stabilizer codes. The main result is that a stabilizer code can be used to estimate Pauli channels with correlations across a number of qubits given by the pure distance. This result does not rely on the limit of vanishing error rates, and applies even if high weight errors occur frequently. Moreover, it also allows for measurement errors within the framework of quantum data-syndrome codes. Our proof combines Boolean Fourier analysis, combinatorics and elementary algebraic geometry. It is our hope that this work opens up interesting applications, such as the online adaptation of a decoder to time-varying noise.",
           2,
           "quantum"
          ],
          [
           "Gottesman-Kitaev-Preskill codes: A lattice perspective",
           "10.22331/q-2022-02-10-648",
           2022,
           "We examine general Gottesman-Kitaev-Preskill (GKP) codes for continuous-variable quantum error correction, including concatenated GKP codes, through the lens of lattice theory, in order to better understand the structure of this class of stabilizer codes. We derive formal bounds on code parameters, show how different decoding strategies are precisely related, propose new ways to obtain GKP codes by means of glued lattices and the tensor product of lattices and point to natural resource savings that have remained hidden in recent approaches. We present general results that we illustrate through examples taken from different classes of codes, including scaled self-dual GKP codes and the concatenated surface-GKP code.",
           12,
           "quantum"
          ],
          [
           "The classical-quantum divergence of complexity in modelling spin chains",
           "10.22331/q-2017-08-11-25",
           2017,
           "The minimal memory required to model a given stochastic process - known as the statistical complexity - is a widely adopted quantifier of structure in complexity science. Here, we ask if quantum mechanics can fundamentally change the qualitative behaviour of this measure. We study this question in the context of the classical Ising spin chain. In this system, the statistical complexity is known to grow monotonically with temperature. We evaluate the spin chain's quantum mechanical statistical complexity by explicitly constructing its provably simplest quantum model, and demonstrate that this measure exhibits drastically different behaviour: it rises to a maximum at some finite temperature then tends back towards zero for higher temperatures. This demonstrates how complexity, as captured by the amount of memory required to model a process, can exhibit radically different behaviour when quantum processing is allowed.",
           16,
           "quantum"
          ],
          [
           "Finite-density phase diagram of a<mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mml:mo stretchy=\"false\">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy=\"false\">)</mml:mo><mml:mo>−</mml:mo><mml:mi>d</mml:mi></mml:math>non-abelian lattice gauge theory with tensor networks",
           "10.22331/q-2017-04-25-9",
           2017,
           "We investigate the finite-density phase diagram of a non-abelianSU(2)lattice gauge theory in(1+1)-dimensions using tensor network methods. We numerically characterise the phase diagram as a function of the matter filling and of the matter-field coupling, identifying different phases, some of them appearing only at finite densities. For weak matter-field coupling we find a meson BCS liquid phase, which is confirmed by second-order analytical perturbation theory. At unit filling and for strong coupling, the system undergoes a phase transition to a charge density wave of single-site (spin-0) mesons via spontaneous chiral symmetry breaking. At finite densities, the chiral symmetry is restored almost everywhere, and the meson BCS liquid becomes a simple liquid at strong couplings, with the exception of filling two-thirds, where a charge density wave of mesons spreading over neighbouring sites appears. Finally, we identify two tri-critical points between the chiral and the two liquid phases which are compatible with aSU(2)2Wess-Zumino-Novikov-Witten model. Here we do not perform the continuum limit but we explicitly address the globalU(1)charge conservation symmetry.",
           44,
           "quantum"
          ],
          [
           "Information and disturbance in operational probabilistic theories",
           "10.22331/q-2020-11-16-363",
           2020,
           "Any measurement is intended to provide information on a system, namely knowledge about its state. However, we learn from quantum theory that it is generally impossible to extract information without disturbing the state of the system or its correlations with other systems. In this paper we address the issue of the interplay between information and disturbance for a general operational probabilistic theory. The traditional notion of disturbance considers the fate of the system state after the measurement. However, the fact that the system state is left untouched ensures that also correlations are preserved only in the presence of local discriminability. Here we provide the definition of disturbance that is appropriate for a general theory. Moreover, since in a theory without causality information can be gathered also on the effect, we generalise the notion of no-information test. We then prove an equivalent condition for no-information without disturbance---atomicity of the identity---namely the impossibility of achieving the trivial evolution---the identity---as the coarse-graining of a set of non trivial ones. We prove a general theorem showing that information that can be retrieved without disturbance corresponds to perfectly repeatable and discriminating tests. Based on this, we prove a structure theorem for operational probabilistic theories, showing that the set of states of any system decomposes as a direct sum of perfectly discriminable sets, and such decomposition is preserved under system composition. As a consequence, a theory is such that any information can be extracted without disturbance only if all its systems are classical. Finally, we show via concrete examples that no-information without disturbance is independent of both local discriminability and purification.",
           8,
           "quantum"
          ],
          [
           "A quantum algorithm for the direct estimation of the steady state of open quantum systems",
           "10.22331/q-2021-02-22-399",
           2021,
           "Simulating the dynamics and the non-equilibrium steady state of an open quantum system are hard computational tasks on conventional computers. For the simulation of the time evolution, several efficient quantum algorithms have recently been developed. However, computing the non-equilibrium steady state as the long-time limit of the system dynamics is often not a viable solution, because of exceedingly long transient features or strong quantum correlations in the dynamics. Here, we develop an efficient quantum algorithm for the direct estimation of averaged expectation values of observables on the non-equilibrium steady state, thus bypassing the time integration of the master equation. The algorithm encodes the vectorized representation of the density matrix on a quantum register, and makes use of quantum phase estimation to approximate the eigenvector associated to the zero eigenvalue of the generator of the system dynamics. We show that the output state of the algorithm allows to estimate expectation values of observables on the steady state. Away from critical points, where the Liouvillian gap scales as a power law of the system size, the quantum algorithm performs with exponential advantage compared to exact diagonalization.",
           7,
           "quantum"
          ],
          [
           "Autonomous Ticking Clocks from Axiomatic Principles",
           "10.22331/q-2021-01-17-381",
           2021,
           "There are many different types of time keeping devices. We use the phraseticking clockto describe those which – simply put – ``tick'' at approximately regular intervals. Various important results have been derived for ticking clocks, and more are in the pipeline. It is thus important to understand the underlying models on which these results are founded. The aim of this paper is to introduce a new ticking clock model from axiomatic principles that overcomes concerns in the community about the physicality of the assumptions made in previous models. The ticking clock model in \\cite{woods2018quantum} achieves high accuracy, yet lacks the autonomy of the less accurate model in \\cite{thermoClockErker}. Importantly, the model we introduce here achieves the best of both models: it retains the autonomy of \\cite{thermoClockErker} while allowing for the high accuracies of \\cite{woods2018quantum}. What is more, \\cite{thermoClockErker} is revealed to be a special case of the new ticking clock model.",
           13,
           "quantum"
          ],
          [
           "On safe post-selection for Bell tests with ideal detectors: Causal diagram approach",
           "10.22331/q-2021-11-11-575",
           2021,
           "Reasoning about Bell nonlocality from the correlations observed in post-selected data is always a matter of concern. This is because conditioning on the outcomes is a source of non-causal correlations, known as aselection bias, rising doubts whether the conclusion concerns the actual causal process or maybe it is just an effect of processing the data. Yet, even in the idealised case without detection inefficiencies, post-selection is an integral part of experimental designs, not least because it is a part of the entanglement generation process itself. In this paper we discuss a broad class of scenarios with post-selection on multiple spatially distributed outcomes. A simple criterion is worked out, called theall-but-oneprinciple, showing when the conclusions about nonlocality from breaking Bell inequalities with post-selected data remain in force. Generality of this result, attained by adopting the high-level diagrammatic tools of causal inference, provides safe grounds for systematic reasoning based on the standard form of multipartite Bell inequalities in a wide array of entanglement generation schemes, without worrying about the dangers of selection bias. In particular, it can be applied to post-selection defined by single-particle events in each detection chanel when the number of particles in the system is conserved.",
           9,
           "quantum"
          ],
          [
           "Statistical time-domain characterization of non-periodic optical clocks",
           "10.22331/q-2022-07-14-764",
           2022,
           "Measuring time means counting the occurrence of periodic phenomena. Over the past centuries a major effort was put to make stable and precise oscillators to be used as clock regulators. Here we consider a different class of clocks based on stochastic clicking processes. We provide a rigorous statistical framework to study the performances of such devices and apply our results to a single coherently driven two-level atom under photodetection as an extreme example of non-periodic clock. Quantum Jump MonteCarlo simulations and photon counting waiting time distribution will provide independent checks on the main results.",
           1,
           "quantum"
          ],
          [
           "Tight Cramér-Rao type bounds for multiparameter quantum metrology through conic programming",
           "10.22331/q-2023-08-29-1094",
           2023,
           "In the quest to unlock the maximum potential of quantum sensors, it is of paramount importance to have practical measurement strategies that can estimate incompatible parameters with best precisions possible. However, it is still not known how to find practical measurements with optimal precisions, even for uncorrelated measurements over probe states. Here, we give a concrete way to find uncorrelated measurement strategies with optimal precisions. We solve this fundamental problem by introducing a framework of conic programming that unifies the theory of precision bounds for multiparameter estimates for uncorrelated and correlated measurement strategies under a common umbrella. Namely, we give precision bounds that arise from linear programs on various cones defined on a tensor product space of matrices, including a particular cone of separable matrices. Subsequently, our theory allows us to develop an efficient algorithm that calculates both upper and lower bounds for the ultimate precision bound for uncorrelated measurement strategies, where these bounds can be tight. In particular, the uncorrelated measurement strategy that arises from our theory saturates the upper bound to the ultimate precision bound. Also, we show numerically that there is a strict gap between the previous efficiently computable bounds and the ultimate precision bound.",
           2,
           "quantum"
          ],
          [
           "Pipelined correlated minimum weight perfect matching of the surface code",
           "10.22331/q-2023-12-12-1205",
           2023,
           "We describe a pipeline approach to decoding the surface code using minimum weight perfect matching, including taking into account correlations between detection events. An independent no-communication parallelizable processing stage reweights the graph according to likely correlations, followed by another no-communication parallelizable stage for high confidence matching. A later general stage finishes the matching. This is a simplification of previous correlated matching techniques which required a complex interaction between general matching and re-weighting the graph. Despite this simplification, which gives correlated matching a better chance of achieving real-time processing, we find the logical error rate practically unchanged. We validate the new algorithm on the fully fault-tolerant toric, unrotated, and rotated surface codes, all with standard depolarizing noise. We expect these techniques to be applicable to a wide range of other decoders.",
           1,
           "quantum"
          ],
          [
           "Concatenation Schemes for Topological Fault-tolerant Quantum Error Correction",
           "10.22331/q-2023-08-22-1089",
           2023,
           "We investigate a family of fault-tolerant quantum error correction schemes based on the concatenation of small error detection or error correction codes with the three-dimensional cluster state. We propose fault-tolerant state preparation and decoding schemes that effectively convert every circuit-level error into an erasure error, leveraging the cluster state's high threshold against such errors. We find a set of codes for which such a conversion is possible, and study their performance against the standard circuit-level depolarizing model. Our best performing scheme, which is based on a concatenation with a classical code, improves the threshold by 16.5&#x0025; and decreases the spacetime overhead by 32&#x0025; compared to the scheme without concatenation, with each scheme subject to a physical error rate of 10&#x2212;3 and achieving a logical error rate of 10&#x2212;6.",
           0,
           "quantum"
          ],
          [
           "A coherence-witnessing game and applications to semi-device-independent quantum key distribution",
           "10.22331/q-2023-08-22-1090",
           2023,
           "Semi-device-independent quantum key distribution aims to achieve a balance between the highest level of security, device independence, and experimental feasibility. Semi-quantum key distribution presents an intriguing approach that seeks to minimize users&apos; reliance on quantum operations while maintaining security, thus enabling the development of simplified and hardware fault-tolerant quantum protocols. In this work, we introduce a coherence-based, semi-device-independent, semi-quantum key distribution protocol built upon a noise-robust version of a coherence equality game that witnesses various types of coherence. Security is proven in the bounded quantum storage model, requiring users to implement only classical operations, specifically fixed-basis detections.",
           0,
           "quantum"
          ],
          [
           "Robust Bell inequalities from communication complexity",
           "10.22331/q-2018-06-07-72",
           2018,
           "The question of how large Bell inequality violations can be, for quantum distributions, has been the object of much work in the past several years. We say that a Bell inequality is normalized if its absolute value does not exceed 1 for any classical (i.e. local) distribution. Upper and (almost) tight lower bounds have been given for the quantum violation of these Bell inequalities in terms of number of outputs of the distribution, number of inputs, and the dimension of the shared quantum states. In this work, we revisit normalized Bell inequalities together with another family: inefficiency-resistant Bell inequalities. To be inefficiency-resistant, the Bell value must not exceed 1 for any local distribution, including those that can abort. This makes the Bell inequality resistant to the detection loophole, while a normalized Bell inequality is resistant to general local noise. Both these families of Bell inequalities are closely related to communication complexity lower bounds. We show how to derive large violations from any gap between classical and quantum communication complexity, provided the lower bound on classical communication is proven using these lower bound techniques. This leads to inefficiency-resistant violations that can be exponential in the size of the inputs. Finally, we study resistance to noise and inefficiency for these Bell inequalities.",
           5,
           "quantum"
          ],
          [
           "Quantum algorithms and approximating polynomials for composed functions with shared inputs",
           "10.22331/q-2021-09-16-543",
           2021,
           "We give new quantum algorithms for evaluating composed functions whose inputs may be shared between bottom-level gates. Letfbe anm-bit Boolean function and consider ann-bit functionFobtained by applyingfto conjunctions of possibly overlapping subsets ofnvariables. Iffhas quantum query complexityQ(f), we give an algorithm for evaluatingFusingO~(Q(f)⋅n)quantum queries. This improves on the bound ofO(Q(f)⋅n)that follows by treating each conjunction independently, and our bound is tight for worst-case choices off. Using completely different techniques, we prove a similar tight composition theorem for the approximate degree off.By recursively applying our composition theorems, we obtain a nearly optimalO~(n1−2−d)upper bound on the quantum query complexity and approximate degree of linear-size depth-dAC0circuits. As a consequence, such circuits can be PAC learned in subexponential time, even in the challenging agnostic setting. Prior to our work, a subexponential-time algorithm was not known even for linear-size depth-3 AC0circuits.As an additional consequence, we show that AC0∘⊕circuits of depthd+1require sizeΩ~(n1/(1−2−d))≥ω(n1+2−d)to compute the Inner Product function even on average. The previous best size lower bound wasΩ(n1+4−(d+1))and only held in the worst case (Cheraghchi et al., JCSS 2018).",
           0,
           "quantum"
          ],
          [
           "Ergodicity probes: using time-fluctuations to measure the Hilbert space dimension",
           "10.22331/q-2019-12-02-207",
           2019,
           "Quantum devices, such as quantum simulators, quantum annealers, and quantum computers, may be exploited to solve problems beyond what is tractable with classical computers. This may be achieved as the Hilbert space available to perform such `calculations' is far larger than that which may be classically simulated. In practice, however, quantum devices have imperfections, which may limit the accessibility to the whole Hilbert space. We thus determine that the dimension of the space of quantum states that are available to a quantum device is a meaningful measure of its functionality, though unfortunately this quantity cannot be directly experimentally determined. Here we outline an experimentally realisable approach to obtaining the required Hilbert space dimension of such a device to compute its time evolution, by exploiting the thermalization dynamics of a probe qubit. This is achieved by obtaining a fluctuation-dissipation theorem for high-temperature chaotic quantum systems, which facilitates the extraction of information on the Hilbert space dimension via measurements of the decay rate, and time-fluctuations.",
           3,
           "quantum"
          ],
          [
           "Quantum repeaters based on individual electron spins and nuclear-spin-ensemble memories in quantum dots",
           "10.22331/q-2021-11-02-570",
           2021,
           "Inspired by recent developments in the control and manipulation of quantum dot nuclear spins, which allow for the transfer of an electron spin state to the surrounding nuclear-spin ensemble for storage, we propose a quantum repeater scheme that combines individual quantum dot electron spins and nuclear-spin ensembles, which serve as spin-photon interfaces and quantum memories respectively. We consider the use of low-strain quantum dots embedded in high-cooperativity optical microcavities. Quantum dot nuclear-spin ensembles allow for the long-term storage of entangled states, and heralded entanglement swapping is performed using cavity-assisted gates. We highlight the advances in quantum dot technologies required to realize our quantum repeater scheme which promises the establishment of high-fidelity entanglement over long distances with a distribution rate exceeding that of the direct transmission of photons.",
           3,
           "quantum"
          ],
          [
           "Circuit optimization of Hamiltonian simulation by simultaneous diagonalization of Pauli clusters",
           "10.22331/q-2020-09-12-322",
           2020,
           "Many applications of practical interest rely on time evolution of Hamiltonians that are given by a sum of Pauli operators. Quantum circuits for exact time evolution of single Pauli operators are well known, and can be extended trivially to sums of commuting Paulis by concatenating the circuits of individual terms. In this paper we reduce the circuit complexity of Hamiltonian simulation by partitioning the Pauli operators into mutually commuting clusters and exponentiating the elements within each cluster after applying simultaneous diagonalization. We provide a practical algorithm for partitioning sets of Paulis into commuting subsets, and show that the proposed approach can help to significantly reduce both the number ofCNOToperations and circuit depth for Hamiltonians arising in quantum chemistry. The algorithms for simultaneous diagonalization are also applicable in the context of stabilizer states; in particular we provide novel four- and five-stage representations, each containing only a single stage of conditional gates.",
           21,
           "quantum"
          ],
          [
           "Does violation of a Bell inequality always imply quantum advantage in a communication complexity problem?",
           "10.22331/q-2020-09-07-316",
           2020,
           "Quantum correlations which violate a Bell inequality are presumed to power better-than-classical protocols for solving communication complexity problems (CCPs). How general is this statement? We show that violations of correlation-type Bell inequalities allow advantages in CCPs, when communication protocols are tailored to emulate the Bell no-signaling constraint (by not communicating measurement settings). Abandonment of this restriction on classical models allows us to disprove the main result of, inter alia, \\cite{BZ02}; we show that quantum correlations obtained from these communication strategies assisted by a small quantum violation of the CGLMP Bell inequalities do not imply advantages in any CCP in the input/output scenario considered in the reference. More generally, we show that there exists quantum correlations, with nontrivial local marginal probabilities, which violate the I3322 Bell inequality, but do not enable a quantum advantange in any CCP, regardless of the communication strategy employed in the quantum protocol, for a scenario with a fixed number of inputs and outputs",
           12,
           "quantum"
          ],
          [
           "Sandwiched Rényi Convergence for Quantum Evolutions",
           "10.22331/q-2018-02-27-55",
           2018,
           "We study the speed of convergence of a primitive quantum time evolution towards its fixed point in the distance of sandwiched Rényi divergences. For each of these distance measures the convergence is typically exponentially fast and the best exponent is given by a constant (similar to a logarithmic Sobolev constant) depending only on the generator of the time evolution. We establish relations between these constants and the logarithmic Sobolev constants as well as the spectral gap. An important consequence of these relations is the derivation of mixing time bounds for time evolutions directly from logarithmic Sobolev inequalities without relying on notions like lp-regularity. We also derive strong converse bounds for the classical capacity of a quantum time evolution and apply these to obtain bounds on the classical capacity of some examples, including stabilizer Hamiltonians under thermal noise.",
           12,
           "quantum"
          ],
          [
           "Overview and Comparison of Gate Level Quantum Software Platforms",
           "10.22331/q-2019-03-25-130",
           2019,
           "Quantum computers are available to use over the cloud, but the recent explosion of quantum software platforms can be overwhelming for those deciding on which to use. In this paper, we provide a current picture of the rapidly evolving quantum computing landscape by comparing four software platforms - Forest (pyQuil), Qiskit, ProjectQ, and the Quantum Developer Kit (Q#) - that enable researchers to use real and simulated quantum devices. Our analysis covers requirements and installation, language syntax through example programs, library support, and quantum simulator capabilities for each platform. For platforms that have quantum computer support, we compare hardware, quantum assembly languages, and quantum compilers. We conclude by covering features of each and briefly mentioning other quantum computing software packages.",
           94,
           "quantum"
          ],
          [
           "Basic quantum subroutines: finding multiple marked elements and summing numbers",
           "10.22331/q-2024-03-14-1284",
           2024,
           "We show how to find all k marked elements in a list of size N using the optimal number O(Nk) of quantum queries and only a polylogarithmic overhead in the gate complexity, in the setting where one has a small quantum memory. Previous algorithms either incurred a factor k overhead in the gate complexity, or had an extra factor log&#x2061;(k) in the query complexity.We then consider the problem of finding a multiplicative &#x03B4;-approximation of s=&#x2211;i=1Nvi where v=(vi)&#x2208;[0,1]N, given quantum query access to a binary description of v. We give an algorithm that does so, with probability at least 1&#x2212;&#x03C1;, using O(Nlog&#x2061;(1/&#x03C1;)/&#x03B4;) quantum queries (under mild assumptions on &#x03C1;). This quadratically improves the dependence on 1/&#x03B4; and log&#x2061;(1/&#x03C1;) compared to a straightforward application of amplitude estimation. To obtain the improved log&#x2061;(1/&#x03C1;) dependence we use the first result.",
           0,
           "quantum"
          ],
          [
           "Quantum-assisted Monte Carlo algorithms for fermions",
           "10.22331/q-2023-08-03-1072",
           2023,
           "Quantum computing is a promising way to systematically solve the longstanding computational problem, the ground state of a many-body fermion system. Many efforts have been made to realise certain forms of quantum advantage in this problem, for instance, the development of variational quantum algorithms. A recent work by Huggins et al. [1] reports a novel candidate, i.e. a quantum-classical hybrid Monte Carlo algorithm with a reduced bias in comparison to its fully-classical counterpart. In this paper, we propose a family of scalable quantum-assisted Monte Carlo algorithms where the quantum computer is used at its minimal cost and still can reduce the bias. By incorporating a Bayesian inference approach, we can achieve this quantum-facilitated bias reduction with a much smaller quantum-computing cost than taking empirical mean in amplitude estimation. Besides, we show that the hybrid Monte Carlo framework is a general way to suppress errors in the ground state obtained from classical algorithms. Our work provides a Monte Carlo toolkit for achieving quantum-enhanced calculation of fermion systems on near-term quantum devices.",
           3,
           "quantum"
          ],
          [
           "Kitaev's quantum double model as an error correcting code",
           "10.22331/q-2020-09-24-331",
           2020,
           "Kitaev's quantum double models in 2D provide some of the most commonly studied examples of topological quantum order. In particular, the ground space is thought to yield a quantum error-correcting code. We offer an explicit proof that this is the case for arbitrary finite groups. Actually a stronger claim is shown: any two states with zero energy density in some contractible region must have the same reduced state in that region. Alternatively, the local properties of a gauge-invariant state are fully determined by specifying that its holonomies in the region are trivial. We contrast this result with the fact that local properties of gauge-invariant states are not generally determined by specifying all of their non-Abelian fluxes --- that is, the Wilson loops of lattice gauge theory do not form a complete commuting set of observables. We also note that the methods developed by P. Naaijkens (PhD thesis, 2012) under a different context can be adapted to provide another proof of the error correcting property of Kitaev's model. Finally, we compute the topological entanglement entropy in Kitaev's model, and show, contrary to previous claims in the literature, that it does not depend on whether the ``log dim R'' term is included in the definition of entanglement entropy.",
           10,
           "quantum"
          ],
          [
           "Integral formula for quantum relative entropy implies data processing inequality",
           "10.22331/q-2023-09-07-1102",
           2023,
           "Integral representations of quantum relative entropy, and of the directional second and higher order derivatives of von Neumann entropy, are established, and used to give simple proofs of fundamental, known data processing inequalities: the Holevo bound on the quantity of information transmitted by a quantum communication channel, and, much more generally, the monotonicity of quantum relative entropy under trace-preserving positive linear maps – complete positivity of the map need not be assumed. The latter result was first proved by Müller-Hermes and Reeb, based on work of Beigi. For a simple application of such monotonicities, we consider any `divergence&apos; that is non-increasing under quantum measurements, such as the concavity of von Neumann entropy, or various known quantum divergences. An elegant argument due to Hiai, Ohya, and Tsukada is used to show that the infimum of such a `divergence&apos; on pairs of quantum states with prescribed trace distance is the same as the corresponding infimum on pairs of binary classical states. Applications of the new integral formulae to the general probabilistic model of information theory, and a related integral formula for the classical Rényi divergence, are also discussed.",
           1,
           "quantum"
          ],
          [
           "In situ upgrade of quantum simulators to universal computers",
           "10.22331/q-2018-08-08-80",
           2018,
           "Quantum simulators, machines that can replicate the dynamics of quantum systems, are being built as useful devices and are seen as a stepping stone to universal quantum computers. A key difference between the two is that computers have the ability to perform the logic gates that make up algorithms. We propose a method for learning how to construct these gates efficiently by using the simulator to perform optimal control on itself. This bypasses two major problems of purely classical approaches to the control problem: the need to have an accurate model of the system, and a classical computer more powerful than the quantum one to carry out the required simulations. Strong evidence that the scheme scales polynomially in the number of qubits, for systems of up to 9 qubits with Ising interactions, is presented from numerical simulations carried out in different topologies. This suggests that this in situ approach is a practical way of upgrading quantum simulators to computers.",
           8,
           "quantum"
          ],
          [
           "Nonadaptive fault-tolerant verification of quantum supremacy with noise",
           "10.22331/q-2019-07-12-164",
           2019,
           "Quantum samplers are believed capable of sampling efficiently from distributions that are classically hard to sample from. We consider a sampler inspired by the classical Ising model. It is nonadaptive and therefore experimentally amenable. Under a plausible conjecture, classical sampling upto additive errors from this model is known to be hard. We present a trap-based verification scheme for quantum supremacy that only requires the verifier to prepare single-qubit states. The verification is done on the same model as the original sampler, a square lattice, with only a constant overhead. We next revamp our verification scheme in two distinct ways using fault tolerance that preserves the nonadaptivity. The first has a lower overhead based on error correction with the same threshold as universal quantum computation. The second has a higher overhead but an improved threshold (1.97%) based on error detection. We show that classically sampling upto additive errors is likely hard in both these schemes. Our results are applicable to other sampling problems such as the Instantaneous Quantum Polynomial-time (IQP) computation model. They should also assist near-term attempts at experimentally demonstrating quantum supremacy and guide long-term ones.",
           6,
           "quantum"
          ],
          [
           "A game of quantum advantage: linking verification and simulation",
           "10.22331/q-2022-06-30-753",
           2022,
           "We present a formalism that captures the process of proving quantum superiority to skeptics as an interactive game between two agents, supervised by a referee. Bob, is sampling from a classical distribution on a quantum device that is supposed to demonstrate a quantum advantage. The other player, the skeptical Alice, is then allowed to propose mock distributions supposed to reproduce Bob&apos;s device&apos;s statistics. He then needs to provide witness functions to prove that Alice&apos;s proposed mock distributions cannot properly approximate his device. Within this framework, we establish three results. First, for random quantum circuits, Bob being able to efficiently distinguish his distribution from Alice&apos;s implies efficient approximate simulation of the distribution. Secondly, finding a polynomial time function to distinguish the output of random circuits from the uniform distribution can also spoof the heavy output generation problem in polynomial time. This pinpoints that exponential resources may be unavoidable for even the most basic verification tasks in the setting of random quantum circuits. Beyond this setting, by employing strong data processing inequalities, our framework allows us to analyse the effect of noise on classical simulability and verification of more general near-term quantum advantage proposals.",
           1,
           "quantum"
          ],
          [
           "Graph Picture of Linear Quantum Networks and Entanglement",
           "10.22331/q-2021-12-23-611",
           2021,
           "The indistinguishability of quantum particles is widely used as a resource for the generation of entanglement. Linear quantum networks (LQNs), in which identical particles linearly evolve to arrive at multimode detectors, exploit the indistinguishability to generate various multipartite entangled states by the proper control of transformation operators. However, it is challenging to devise a suitable LQN that carries a specific entangled state or compute the possible entangled state in a given LQN as the particle and mode number increase. This research presents a mapping process of arbitrary LQNs to graphs, which provides a powerful tool for analyzing and designing LQNs to generate multipartite entanglement. We also introduce the perfect matching diagram (PM diagram), which is a refined directed graph that includes all the essential information on the entanglement generation by an LQN. The PM diagram furnishes rigorous criteria for the entanglement of an LQN and solid guidelines for designing suitable LQNs for the genuine entanglement. Based on the structure of PM diagrams, we compose LQNs for fundamental N-partite genuinely entangled states.",
           4,
           "quantum"
          ],
          [
           "Classical Simulations of Quantum Field Theory in Curved Spacetime I: Fermionic Hawking-Hartle Vacua from a Staggered Lattice Scheme",
           "10.22331/q-2020-10-28-351",
           2020,
           "We numerically compute renormalized expectation values of quadratic operators in a quantum field theory (QFT) of free Dirac fermions in curved two-dimensional (Lorentzian) spacetime. First, we use a staggered-fermion discretization to generate a sequence of lattice theories yielding the desired QFT in the continuum limit. Numerically-computed lattice correlators are then used to approximate, through extrapolation, those in the continuum. Finally, we use so-called point-splitting regularization and Hadamard renormalization to remove divergences, and thus obtain finite, renormalized expectation values of quadratic operators in the continuum. As illustrative applications, we show how to recover the Unruh effect in flat spacetime and how to compute renormalized expectation values in the Hawking-Hartle vacuum of a Schwarzschild black hole and in the Bunch-Davies vacuum of an expanding universe described by de Sitter spacetime. Although here we address a non-interacting QFT using free fermion techniques, the framework described in this paper lays the groundwork for a series of subsequent studies involving simulation of interacting QFTs in curved spacetime by tensor network techniques.",
           3,
           "quantum"
          ],
          [
           "Sequential optical response suppression for chemical mixture characterization",
           "10.22331/q-2022-01-20-626",
           2022,
           "The characterization of mixtures of non-interacting, spectroscopically similar quantum components has important applications in chemistry, biology, and materials science. We introduce an approach based on quantum tracking control that allows for determining the relative concentrations of constituents in a quantum mixture, using a single pulse which enhances the distinguishability of components of the mixture and has a length that scales linearly with the number of mixture constituents. To illustrate the method, we consider two very distinct model systems: mixtures of diatomic molecules in the gas phase, as well as solid-state materials composed of a mixture of components. A set of numerical analyses are presented, showing strong performance in both settings.",
           6,
           "quantum"
          ],
          [
           "Distinguishability times and asymmetry monotone-based quantum speed limits in the Bloch ball",
           "10.22331/q-2018-10-01-96",
           2018,
           "For both unitary and open qubit dynamics, we compare asymmetry monotone-based bounds on the minimal time required for an initial qubit state to evolve to a final qubit state from which it is probabilistically distinguishable with fixed minimal error probability (i.e., the minimal error distinguishability time). For the case of unitary dynamics generated by a time-independent Hamiltonian, we derive a necessary and sufficient condition on two asymmetry monotones that guarantees that an arbitrary state of a two-level quantum system or a separable state of N two-level quantum systems will unitarily evolve to another state from which it can be distinguished with a fixed minimal error probability δ∈[0,1/2]. This condition is used to order the set of qubit states based on their distinguishability time, and to derive an optimal release time for driven two-level systems such as those that occur, e.g., in the Landau-Zener problem. For the case of non-unitary dynamics, we compare three lower bounds to the distinguishability time, including a new type of lower bound which is formulated in terms of the asymmetry of the uniformly time-twirled initial system-plus-environment state with respect to the generator HSE of the Stinespring isometry corresponding to the dynamics, specifically, in terms of ‖[HSE,ρav(τ)]‖1, where ρav(τ):=1τ∫0τdte−iHSEtρ⊗|0⟩E⟨0|EeiHSEt.",
           5,
           "quantum"
          ],
          [
           "Any consistent coupling between classical gravity and quantum matter is fundamentally irreversible",
           "10.22331/q-2023-10-16-1142",
           2023,
           "When gravity is sourced by a quantum system, there is tension between its role as the mediator of a fundamental interaction, which is expected to acquire nonclassical features, and its role in determining the properties of spacetime, which is inherently classical. Fundamentally, this tension should result in breaking one of the fundamental principles of quantum theory or general relativity, but it is usually hard to assess which one without resorting to a specific model. Here, we answer this question in a theory-independent way using General Probabilistic Theories (GPTs). We consider the interactions of the gravitational field with a single matter system, and derive a no-go theorem showing that when gravity is classical at least one of the following assumptions needs to be violated: (i) Matter degrees of freedom are described by fully non-classical degrees of freedom; (ii) Interactions between matter degrees of freedom and the gravitational field are reversible; (iii) Matter degrees of freedom back-react on the gravitational field. We argue that this implies that theories of classical gravity and quantum matter must be fundamentally irreversible, as is the case in the recent model of Oppenheim et al. Conversely if we require that the interaction between quantum matter and the gravitational field is reversible, then the gravitational field must be non-classical.",
           2,
           "quantum"
          ],
          [
           "The quantum switch is uniquely defined by its action on unitary operations",
           "10.22331/q-2023-11-07-1169",
           2023,
           "The quantum switch is a quantum process that creates a coherent control between different unitary operations, which is often described as a quantum process which transforms a pair of unitary operations (U1,U2) into a controlled unitary operation that coherently applies them in different orders as |0&#x27E9;&#x27E8;0|&#x2297;U1U2+|1&#x27E9;&#x27E8;1|&#x2297;U2U1. This description, however, does not directly define its action on non-unitary operations. The action of the quantum switch on non-unitary operations is then chosen to be a ``natural'' extension of its action on unitary operations. In general, the action of a process on non-unitary operations is not uniquely determined by its action on unitary operations. It may be that there could be a set of inequivalent extensions of the quantum switch for non-unitary operations. We prove, however, that the natural extension is the only possibility for the quantum switch for the 2-slot case. In other words, contrary to the general case, the action of the quantum switch on non-unitary operations (as a linear and completely CP preserving supermap) is completely determined by its action on unitary operations. We also discuss the general problem of when the complete description of a quantum process is uniquely determined by its action on unitary operations and identify a set of single-slot processes which are completely defined by their action on unitary operations.",
           1,
           "quantum"
          ],
          [
           "<mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mml:mi>a</mml:mi><mml:mo>×</mml:mo><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi></mml:math> in <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:math>D TQFT",
           "10.22331/q-2021-06-04-468",
           2021,
           "We study the implications of the anyon fusion equation a×b=c on global properties of 2+1D topological quantum field theories (TQFTs). Here a and b are anyons that fuse together to give a unique anyon, c. As is well known, when at least one of a and b is abelian, such equations describe aspects of the one-form symmetry of the theory. When a and b are non-abelian, the most obvious way such fusions arise is when a TQFT can be resolved into a product of TQFTs with trivial mutual braiding, and a and b lie in separate factors. More generally, we argue that the appearance of such fusions for non-abelian a and b can also be an indication of zero-form symmetries in a TQFT, of what we term \"quasi-zero-form symmetries\" (as in the case of discrete gauge theories based on the largest Mathieu group, M24), or of the existence of non-modular fusion subcategories. We study these ideas in a variety of TQFT settings from (twisted and untwisted) discrete gauge theories to Chern-Simons theories based on continuous gauge groups and related cosets. Along the way, we prove various useful theorems.",
           4,
           "quantum"
          ],
          [
           "Optimizing sparse fermionic Hamiltonians",
           "10.22331/q-2023-08-10-1081",
           2023,
           "We consider the problem of approximating the ground state energy of a fermionic Hamiltonian using a Gaussian state. In sharp contrast to the dense case [1, 2], we prove that strictly q-local sparse fermionic Hamiltonians have a constant Gaussian approximation ratio; the result holds for any connectivity and interaction strengths. Sparsity means that each fermion participates in a bounded number of interactions, and strictly q-local means that each term involves exactly q fermionic (Majorana) operators. We extend our proof to give a constant Gaussian approximation ratio for sparse fermionic Hamiltonians with both quartic and quadratic terms. With additional work, we also prove a constant Gaussian approximation ratio for the so-called sparse SYK model with strictly 4-local interactions (sparse SYK-4 model). In each setting we show that the Gaussian state can be efficiently determined. Finally, we prove that the O(n&#x2212;1/2) Gaussian approximation ratio for the normal (dense) SYK-4 model extends to SYK-q for even q&#x003E;4, with an approximation ratio of O(n1/2&#x2013;q/4). Our results identify non-sparseness as the prime reason that the SYK-4 model can fail to have a constant approximation ratio [1, 2].",
           1,
           "quantum"
          ],
          [
           "Genuinely multipartite noncausality",
           "10.22331/q-2017-12-14-39",
           2017,
           "The study of correlations with no definite causal order has revealed a rich structure emerging when more than two parties are involved. This motivates the consideration of multipartite \"noncausal\" correlations that cannot be realised even if noncausal resources are made available to a smaller number of parties. Here we formalise this notion: genuinely N-partite noncausal correlations are those that cannot be produced by grouping N parties into two or more subsets, where a causal order between the subsets exists. We prove that such correlations can be characterised as lying outside a polytope, whose vertices correspond to deterministic strategies and whose facets define what we call \"2-causal\" inequalities. We show that genuinely multipartite noncausal correlations arise within the process matrix formalism, where quantum mechanics holds locally but no global causal structure is assumed, although for some inequalities no violation was found. We further introduce two refined definitions that allow one to quantify, in different ways, to what extent noncausal correlations correspond to a genuinely multipartite resource.",
           10,
           "quantum"
          ],
          [
           "Dissipation as a resource for Quantum Reservoir Computing",
           "10.22331/q-2024-03-20-1291",
           2024,
           "Dissipation induced by interactions with an external environment typically hinders the performance of quantum computation, but in some cases can be turned out as a useful resource. We show the potential enhancement induced by dissipation in the field of quantum reservoir computing introducing tunable local losses in spin network models. Our approach based on continuous dissipation is able not only to reproduce the dynamics of previous proposals of quantum reservoir computing, based on discontinuous erasing maps but also to enhance their performance. Control of the damping rates is shown to boost popular machine learning temporal tasks as the capability to linearly and non-linearly process the input history and to forecast chaotic series. Finally, we formally prove that, under non-restrictive conditions, our dissipative models form a universal class for reservoir computing. It means that considering our approach, it is possible to approximate any fading memory map with arbitrary precision.",
           0,
           "quantum"
          ],
          [
           "Emergent quantum state designs and biunitarity in dual-unitary circuit dynamics",
           "10.22331/q-2022-06-15-738",
           2022,
           "Recent works have investigated the emergence of a new kind of random matrix behaviour in unitary dynamics following a quantum quench. Starting from a time-evolved state, an ensemble of pure states supported on a small subsystem can be generated by performing projective measurements on the remainder of the system, leading to a projected ensemble. In chaotic quantum systems it was conjectured that such projected ensembles become indistinguishable from the uniform Haar-random ensemble and lead to a quantum state design. Exact results were recently presented by Ho and Choi [Phys. Rev. Lett. 128, 060601 (2022)] for the kicked Ising model at the self-dual point. We provide an alternative construction that can be extended to general chaotic dual-unitary circuits with solvable initial states and measurements, highlighting the role of the underlying dual-unitarity and further showing how dual-unitary circuit models exhibit both exact solvability and random matrix behaviour. Building on results from biunitary connections, we show how complex Hadamard matrices and unitary error bases both lead to solvable measurement schemes.",
           18,
           "quantum"
          ],
          [
           "Computationally Efficient Quantum Expectation with Extended Bell Measurements",
           "10.22331/q-2022-04-13-688",
           2022,
           "Evaluating an expectation value of an arbitrary observable A&#x2208;C2n&#x00D7;2n through naïve Pauli measurements requires a large number of terms to be evaluated. We approach this issue using a method based on Bell measurement, which we refer to as the extended Bell measurement method. This analytical method quickly assembles the 4n matrix elements into at most 2n+1 groups for simultaneous measurements in O(nd) time, where d is the number of non-zero elements of A. The number of groups is particularly small when A is a band matrix. When the bandwidth of A is k=O(nc), the number of groups for simultaneous measurement reduces to O(nc+1). In addition, when non-zero elements densely fill the band, the variance is O((nc+1/2n)tr(A2)), which is small compared with the variances of existing methods. The proposed method requires a few additional gates for each measurement, namely one Hadamard gate, one phase gate and at most n&#x2212;1 CNOT gates. Experimental results on an IBM-Q system show the computational efficiency and scalability of the proposed scheme, compared with existing state-of-the-art approaches. Code is available at https://github.com/ToyotaCRDL/extended-bell-measurements.",
           5,
           "quantum"
          ],
          [
           "Self-testing in parallel with CHSH",
           "10.22331/q-2017-04-25-1",
           2017,
           "Self-testing allows classical referees to verify the quantum behaviour of some untrusted devices. Recently we developed a framework for building large self-tests by repeating a smaller self-test many times in parallel. However, the framework did not apply to the CHSH test, which tests a maximally entangled pair of qubits. CHSH is the most well known and widely used test of this type. Here we extend the parallel self-testing framework to build parallel CHSH self-tests for any number of pairs of maximally entangled qubits. Our construction achieves an error bound which is polynomial in the number of tested qubit pairs.",
           17,
           "quantum"
          ],
          [
           "Scaling of variational quantum circuit depth for condensed matter systems",
           "10.22331/q-2020-05-28-272",
           2020,
           "We benchmark the accuracy of a variational quantum eigensolver based on a finite-depth quantum circuit encoding ground state of local Hamiltonians. We show that in gapped phases, the accuracy improves exponentially with the depth of the circuit. When trying to encode the ground state of conformally invariant Hamiltonians, we observe two regimes. A finite-depth regime, where the accuracy improves slowly with the number of layers, and a finite-size regime where it improves again exponentially. The cross-over between the two regimes happens at a critical number of layers whose value increases linearly with the size of the system. We discuss the implication of these observations in the context of comparing different variational ansatz and their effectiveness in describing critical ground states.",
           43,
           "quantum"
          ],
          [
           "State Preparation Boosters for Early Fault-Tolerant Quantum Computation",
           "10.22331/q-2022-10-06-829",
           2022,
           "Quantum computing is believed to be particularly useful for the simulation of chemistry and materials, among the various applications. In recent years, there have been significant advancements in the development of near-term quantum algorithms for quantum simulation, including VQE and many of its variants. However, for such algorithms to be useful, they need to overcome several critical barriers including the inability to prepare high-quality approximations of the ground state. Current challenges to state preparation, including barren plateaus and the high-dimensionality of the optimization landscape, make state preparation through ansatz optimization unreliable. In this work, we introduce the method of ground state boosting, which uses a limited-depth quantum circuit to reliably increase the overlap with the ground state. This circuit, which we call a booster, can be used to augment an ansatz from VQE or be used as a stand-alone state preparation method. The booster converts circuit depth into ground state overlap in a controllable manner. We numerically demonstrate the capabilities of boosters by simulating the performance of a particular type of booster, namely the Gaussian booster, for preparing the ground state of N2 molecular system. Beyond ground state preparation as a direct objective, many quantum algorithms, such as quantum phase estimation, rely on high-quality state preparation as a subroutine. Therefore, we foresee ground state boosting and similar methods as becoming essential algorithmic components as the field transitions into using early fault-tolerant quantum computers.",
           4,
           "quantum"
          ],
          [
           "Self-organized topological insulator due to cavity-mediated correlated tunneling",
           "10.22331/q-2021-07-13-501",
           2021,
           "Topological materials have potential applications for quantum technologies. Non-interacting topological materials, such as e.g., topological insulators and superconductors, are classified by means of fundamental symmetry classes. It is instead only partially understood how interactions affect topological properties. Here, we discuss a model where topology emerges from the quantum interference between single-particle dynamics and global interactions. The system is composed by soft-core bosons that interact via global correlated hopping in a one-dimensional lattice. The onset of quantum interference leads to spontaneous breaking of the lattice translational symmetry, the corresponding phase resembles nontrivial states of the celebrated Su-Schriefer-Heeger model. Like the fermionic Peierls instability, the emerging quantum phase is a topological insulator and is found at half fillings. Originating from quantum interference, this topological phase is found in \"exact\" density-matrix renormalization group calculations and is entirely absent in the mean-field approach. We argue that these dynamics can be realized in existing experimental platforms, such as cavity quantum electrodynamics setups, where the topological features can be revealed in the light emitted by the resonator.",
           15,
           "quantum"
          ],
          [
           "Topological Link Models of Multipartite Entanglement",
           "10.22331/q-2022-06-20-741",
           2022,
           "We introduce a novel model of multipartite entanglement based on topological links, generalizing the graph/hypergraph entropy cone program. We demonstrate that there exist link representations of entropy vectors which provably cannot be represented by graphs or hypergraphs. Furthermore, we show that the contraction map proof method generalizes to the topological setting, though now requiring oracular solutions to well-known but difficult problems in knot theory.",
           3,
           "quantum"
          ],
          [
           "Conjugates, Filters and Quantum Mechanics",
           "10.22331/q-2019-07-08-158",
           2019,
           "The Jordan structure of finite-dimensional quantum theory is derived, in a conspicuously easy way, from a few simple postulates concerning abstract probabilistic models (each defined by a set of basic measurements and a convex set of states). The key assumption is that each system A can be paired with an isomorphic conjugate system, A¯, by means of a non-signaling bipartite state ηA perfectly and uniformly correlating each basic measurement on A with its counterpart on A¯. In the case of a quantum-mechanical system associated with a complex Hilbert space H, the conjugate system is that associated with the conjugate Hilbert space H, and ηA corresponds to the standard maximally entangled EPR state on H⊗H¯. A second ingredient is the notion of a reversible filter, that is, a probabilistically reversible process that independently attenuates the sensitivity of detectors associated with a measurement. In addition to offering more flexibility than most existing reconstructions of finite-dimensional quantum theory, the approach taken here has the advantage of not relying on any form of the ``no restriction\" hypothesis. That is, it is not assumed that arbitrary effects are physically measurable, nor that arbitrary families of physically measurable effects summing to the unit effect, represent physically accessible observables. (An appendix shows how a version of Hardy's ``subpace axiom\" can replace several assumptions native to this paper, although at the cost of disallowing superselection rules.)",
           7,
           "quantum"
          ],
          [
           "Quantum Lazy Training",
           "10.22331/q-2023-04-27-989",
           2023,
           "In the training of over-parameterized model functions via gradient descent, sometimes the parameters do not change significantly and remain close to their initial values. This phenomenon is called lazy training and motivates consideration of the linear approximation of the model function around the initial parameters. In the lazy regime, this linear approximation imitates the behavior of the parameterized function whose associated kernel, called the tangent kernel, specifies the training performance of the model. Lazy training is known to occur in the case of (classical) neural networks with large widths. In this paper, we show that the training of geometrically local parameterized quantum circuits enters the lazy regime for large numbers of qubits. More precisely, we prove bounds on the rate of changes of the parameters of such a geometrically local parameterized quantum circuit in the training process, and on the precision of the linear approximation of the associated quantum model function; both of these bounds tend to zero as the number of qubits grows. We support our analytic results with numerical simulations.",
           1,
           "quantum"
          ],
          [
           "Determining quantum phase diagrams of topological Kitaev-inspired models on NISQ quantum hardware",
           "10.22331/q-2021-09-28-553",
           2021,
           "Topological protection is employed in fault-tolerant error correction and in developing quantum algorithms with topological qubits. But, topological protection intrinsic to models being simulated, also robustly protects calculations, even on NISQ hardware. We leverage it by simulating Kitaev-inspired models on IBM quantum computers and accurately determining their phase diagrams. This requires constructing conventional quantum circuits for Majorana braiding to prepare the ground states of Kitaev-inspired models. The entanglement entropy is then measured to calculate the quantum phase boundaries. We show how maintaining particle-hole symmetry when sampling through the Brillouin zone is critical to obtaining high accuracy. This work illustrates how topological protection intrinsic to a quantum model can be employed to perform robust calculations on NISQ hardware, when one measures the appropriate protected quantum properties. It opens the door for further simulation of topological quantum models on quantum hardware available today.",
           12,
           "quantum"
          ],
          [
           "Partitioning qubits in hypergraph product codes to implement logical gates",
           "10.22331/q-2023-10-24-1153",
           2023,
           "The promise of high-rate low-density parity check (LDPC) codes to substantially reduce the overhead of fault-tolerant quantum computation depends on constructing efficient, fault-tolerant implementations of logical gates on such codes. Transversal gates are the simplest type of fault-tolerant gate, but the potential of transversal gates on LDPC codes has hitherto been largely neglected. We investigate the transversal gates that can be implemented in hypergraph product codes, a class of LDPC codes. Our analysis is aided by the construction of a symplectic canonical basis for the logical operators of hypergraph product codes, a result that may be of independent interest. We show that in these codes transversal gates can implement Hadamard (up to logical SWAP gates) and control-Z on all logical qubits. Moreover, we show that sequences of transversal operations, interleaved with error correction, allow implementation of entangling gates between arbitrary pairs of logical qubits in the same code block. We thereby demonstrate that transversal gates can be used as the basis for universal quantum computing on LDPC codes, when supplemented with state injection.",
           2,
           "quantum"
          ],
          [
           "Entanglement-Free Parameter Estimation of Generalized Pauli Channels",
           "10.22331/q-2021-07-01-490",
           2021,
           "We propose a parameter estimation protocol for generalized Pauli channels acting on d-dimensional Hilbert space. The salient features of the proposed method include product probe states and measurements, the number of measurement configurations linear in d, minimal post-processing, and the scaling of the mean square error comparable to that of the entanglement-based parameter estimation scheme for generalized Pauli channels. We also show that while measuring generalized Pauli operators the errors caused by the Pauli noise can be modeled as measurement errors. This makes it possible to utilize the measurement error mitigation framework to mitigate the errors caused by the generalized Pauli channels. We use this result to mitigate noise on the probe states and recover the scaling of the noiseless probes, except with a noise strength-dependent constant factor. This method of modeling Pauli channel as measurement noise can also be of independent interest in other NISQ tasks, e.g., state tomography problems, variational quantum algorithms, and other channel estimation problems where Pauli measurements have the central role.",
           11,
           "quantum"
          ],
          [
           "Quantum Alphatron: quantum advantage for learning with kernels and noise",
           "10.22331/q-2023-11-08-1174",
           2023,
           "At the interface of machine learning and quantum computing, an important question is what distributions can be learned provably with optimal sample complexities and with quantum-accelerated time complexities. In the classical case, Klivans and Goel discussed the Alphatron, an algorithm to learn distributions related to kernelized regression, which they also applied to the learning of two-layer neural networks. In this work, we provide quantum versions of the Alphatron in the fault-tolerant setting. In a well-defined learning model, this quantum algorithm is able to provide a polynomial speedup for a large range of parameters of the underlying concept class. We discuss two types of speedups, one for evaluating the kernel matrix and one for evaluating the gradient in the stochastic gradient descent procedure. We also discuss the quantum advantage in the context of learning of two-layer neural networks. Our work contributes to the study of quantum learning with kernels and from samples.",
           0,
           "quantum"
          ],
          [
           "Enhanced Gravitational Entanglement via Modulated Optomechanics",
           "10.22331/q-2023-11-08-1177",
           2023,
           "The role of entanglement in determining the non-classicality of a given interaction has gained significant traction over the last few years. In particular, as the basis for new experimental proposals to test the quantum nature of the gravitational field. Here we show that the rate of gravity mediated entanglement between two otherwise isolated optomechanical systems can be significantly increased by modulating the optomechanical coupling. This is most pronounced for low mass, high frequency systems – convenient for reaching the quantum regime – and can lead to improvements of several orders of magnitude, as well as a broadening of the measurement window. Nevertheless, significant obstacles still remain. In particular, we find that modulations increase decoherence effects at the same rate as the entanglement improvements. This adds to the growing evidence that the constraint on noise (acting on the position d.o.f) depends only on the particle mass, separation, and temperature of the environment and cannot be improved by novel quantum control. Finally, we highlight the close connection between the observation of quantum correlations and the limits of measurement precision derived via the Cramér-Rao Bound. An immediate consequence is that probing superpositions of the gravitational field places similar demands on detector sensitivity as entanglement verification.",
           0,
           "quantum"
          ],
          [
           "Gauge invariant information concerning quantum channels",
           "10.22331/q-2018-04-11-60",
           2018,
           "Motivated by the gate set tomography we study quantum channels from the perspective of information which is invariant with respect to the gauge realized through similarity of matrices representing channel superoperators. We thus use the complex spectrum of the superoperator to provide necessary conditions relevant for complete positivity of qubit channels and to express various metrics such as average gate fidelity.",
           15,
           "quantum"
          ],
          [
           "A polar decomposition for quantum channels (with applications to bounding error propagation in quantum circuits)",
           "10.22331/q-2019-08-12-173",
           2019,
           "Inevitably, assessing the overall performance of a quantum computer must rely on characterizing some of its elementary constituents and, from this information, formulate a broader statement concerning more complex constructions thereof. However, given the vastitude of possible quantum errors as well as their coherent nature, accurately inferring the quality of composite operations is generally difficult. To navigate through this jumble, we introduce a non-physical simplification of quantum maps that we refer to as the leading Kraus (LK) approximation. The uncluttered parameterization of LK approximated maps naturally suggests the introduction of a unitary-decoherent polar factorization for quantum channels in any dimension. We then leverage this structural dichotomy to bound the evolution -- as circuits grow in depth -- of two of the most experimentally relevant figures of merit, namely the average process fidelity and the unitarity. We demonstrate that the leeway in the behavior of the process fidelity is essentially taken into account by physical unitary operations.",
           9,
           "quantum"
          ],
          [
           "Quantum Darwinism and the spreading of classical information in non-classical theories",
           "10.22331/q-2022-01-31-636",
           2022,
           "Quantum Darwinism posits that the emergence of a classical reality relies on the spreading of classical information from a quantum system to many parts of its environment. But what are the essential physical principles of quantum theory that make this mechanism possible? We address this question by formulating the simplest instance of Darwinism – CNOT-like fan-out interactions – in a class of probabilistic theories that contain classical and quantum theory as special cases. We determine necessary and sufficient conditions for any theory to admit such interactions. We find that every theory with non-classical features that admits this idealized spreading of classical information must have both entangled states and entangled measurements. Furthermore, we show that Spekkens' toy theory admits this form of Darwinism, and so do all probabilistic theories that satisfy principles like strong symmetry, or contain a certain type of decoherence processes. Our result suggests the counter-intuitive general principle that in the presence of local non-classicality, a classical world can only emerge if this non-classicality can be \"amplified\" to a form of entanglement.",
           1,
           "quantum"
          ],
          [
           "Quantum walking in curved spacetime: discrete metric",
           "10.22331/q-2018-08-22-84",
           2018,
           "A discrete-time quantum walk (QW) is essentially a unitary operator driving the evolution of a single particle on the lattice. Some QWs have familiar physics PDEs as their continuum limit. Some slight generalization of them (allowing for prior encoding and larger neighbourhoods) even have the curved spacetime Dirac equation, as their continuum limit. In the(1+1)−dimensional massless case, this equation decouples as scalar transport equations with tunable speeds. We characterise and construct all those QWs that lead to scalar transport with tunable speeds. The local coin operator dictates that speed; we provide concrete techniques to tune the speed of propagation, by making use only of a finite number of coin operators-differently from previous models, in which the speed of propagation depends upon a continuous parameter of the quantum coin. The interest of such a discretization is twofold : to allow for easier experimental implementations on the one hand, and to evaluate ways of quantizing the metric field, on the other.",
           8,
           "quantum"
          ],
          [
           "Time-local unraveling of non-Markovian stochastic Schrödinger  equations",
           "10.22331/q-2017-09-19-29",
           2017,
           "Non-Markovian stochastic Schrödinger equations (NMSSE) are important tools in quantum mechanics, from the theory of open systems to foundations. Yet, in general, they are but formal objects: their solution can be computed numerically only in some specific cases or perturbatively. This article is focused on the NMSSE themselves rather than on the open-system evolution they unravel and aims at making them less abstract. Namely, we propose to write the stochastic realizations of linear NMSSE as averages over the solutions of an auxiliary equation with an additional random field. Our method yields a non-perturbative numerical simulation algorithm for generic linear NMSSE that can be made arbitrarily accurate for reasonably short times. For isotropic complex noises, the method extends from linear to non-linear NMSSE and allows to sample the solutions of norm-preserving NMSSE directly.",
           5,
           "quantum"
          ],
          [
           "The meaning of redundancy and consensus in quantum objectivity",
           "10.22331/q-2023-08-03-1074",
           2023,
           "While the terms \"redundancy\" and \"consensus\" are often used as synonyms in the context of quantum objectivity, we show here that these should be understood as two related but distinct notions, that quantify different features of the quantum-to-classical transition. We show that the two main frameworks used to measure quantum objectivity, namely spectrum broadcast structure and quantum Darwinism, are best suited to quantify redundancy and consensus, respectively. Furthermore, by analyzing explicit examples of states with nonlocally encoded information, we highlight the potentially stark difference between the degrees of redundancy and consensus. In particular, this causes a break in the hierarchical relations between spectrum broadcast structure and quantum Darwinism. Our framework provides a new perspective to interpret known and future results in the context of quantum objectivity, paving the way for a deeper understanding of the emergence of classicality from the quantum realm.",
           1,
           "quantum"
          ],
          [
           "Hypergraph framework for irreducible noncontextuality inequalities from logical proofs of the Kochen-Specker theorem",
           "10.22331/q-2020-01-10-219",
           2020,
           "Kochen-Specker (KS) theorem reveals the inconsistency between quantum theory and any putative underlying model of it satisfying the constraint of KS-noncontextuality. A logical proof of the KS theorem is one that relies only on the compatibility relations amongst a set of projectors (a KS set) to witness this inconsistency. These compatibility relations can be represented by a hypergraph, referred to as a contextuality scenario. Here we consider contextuality scenarios that we term KS-uncolourable, e.g., those which appear in logical proofs of the KS theorem. We introduce a hypergraph framework to obtain noise-robust witnesses of contextuality from such scenarios.\nOur approach builds on the results of R. Kunjwal and R. W. Spekkens, Phys. Rev. Lett. 115, 110403 (2015), by providing new insights into the relationship between the structure of a contextuality scenario and the associated noise-robust noncontextuality inequalities that witness contextuality. The present work also forms a necessary counterpart to the framework presented in R. Kunjwal, Quantum 3, 184 (2019), which only applies to KS-colourable contextuality scenarios, i.e., those which do not admit logical proofs of the KS theorem but do admit statistical proofs.\nWe rely on a single hypergraph invariant, defined in R. Kunjwal, Quantum 3, 184 (2019), that appears in our contextuality witnesses, namely, the weighted max-predictability. The present work can also be viewed as a study of this invariant. Significantly, unlike the case of R. Kunjwal, Quantum 3, 184 (2019), none of the graph invariants from the graph-theoretic framework for KS-contextuality due to Cabello, Severini, and Winter (the ``CSW framework\", Phys. Rev. Lett. 112, 040401 (2014)) are relevant for our noise-robust noncontextuality inequalities.",
           8,
           "quantum"
          ],
          [
           "Measurement disturbance and conservation laws in quantum mechanics",
           "10.22331/q-2023-06-05-1033",
           2023,
           "Measurement error and disturbance, in the presence of conservation laws, are analysed in general operational terms. We provide novel quantitative bounds demonstrating necessary conditions under which accurate or non-disturbing measurements can be achieved, highlighting an interesting interplay between incompatibility, unsharpness, and coherence. From here we obtain a substantial generalisation of the Wigner-Araki-Yanase (WAY) theorem. Our findings are further refined through the analysis of the fixed-point set of the measurement channel, some extra structure of which is characterised here for the first time.",
           2,
           "quantum"
          ],
          [
           "Duality in Quantum Quenches and Classical Approximation Algorithms: Pretty Good or Very Bad",
           "10.22331/q-2019-11-11-201",
           2019,
           "We consider classical and quantum algorithms which have a duality property: roughly, either the algorithm provides some nontrivial improvement over random or there exist many solutions which are significantly worse than random. This enables one to give guarantees that the algorithm will find such a nontrivial improvement: if few solutions exist which are much worse than random, then a nontrivial improvement is guaranteed. The quantum algorithm is based on a sudden quench of a Hamiltonian; while the algorithm is general, we analyze it in the specific context of MAX-K-LIN2, for both even and odd K. The classical algorithm is a ``dequantization of this algorithm\", obtaining the same guarantee (indeed, some results which are only conjectured in the quantum case can be proven here); however, the quantum point of view helps in analyzing the performance of the classical algorithm and might in some cases perform better.",
           7,
           "quantum"
          ],
          [
           "Lightweight Detection of a Small Number of Large Errors in a Quantum Circuit",
           "10.22331/q-2021-04-20-436",
           2021,
           "Suppose we want to implement a unitary U, for instance a circuit for some quantum algorithm. Suppose our actual implementation is a unitary U~, which we can only apply as a black-box. In general it is an exponentially-hard task to decide whether U~ equals the intended U, or is significantly different in a worst-case norm. In this paper we consider two special cases where relatively efficient and lightweight procedures exist for this task.First, we give an efficient procedure under the assumption that U and U~ (both of which we can now apply as a black-box) are either equal, or differ significantly in only one k-qubit gate, where k=O(1) (the k qubits need not be contiguous). Second, we give an even more lightweight procedure under the assumption that U and U~ are Clifford circuits which are either equal, or different in arbitrary ways (the specification of U is now classically given while U~ can still only be applied as a black-box). Both procedures only need to run U~ a constant number of times to detect a constant error in a worst-case norm. We note that the Clifford result also follows from earlier work of Flammia and Liu, and da Silva, Landon-Cardinal, and Poulin.In the Clifford case, our error-detection procedure also allows us efficiently to learn (and hence correct) U~ if we have a small list of possible errors that could have happened to U; for example if we know that only O(1) of the gates of U~ are wrong, this list will be polynomially small and we can test each possible erroneous version of U for equality with U~.",
           3,
           "quantum"
          ],
          [
           "Number-phase uncertainty relations and bipartite entanglement detection in spin ensembles",
           "10.22331/q-2023-02-09-914",
           2023,
           "We present a method to detect bipartite entanglement based on number-phase-like uncertainty relations in split spin ensembles. First, we derive an uncertainty relation that plays the role of a number-phase uncertainty for spin systems. It is important that the relation is given with well-defined and easily measurable quantities, and that it does not need assuming infinite dimensional systems. Based on this uncertainty relation, we show how to detect bipartite entanglement in an unpolarized Dicke state of many spin-1/2 particles. The particles are split into two subensembles, then collective angular momentum measurements are carried out locally on the two parts. First, we present a bipartite Einstein-Podolsky-Rosen (EPR) steering criterion. Then, we present an entanglement condition that can detect bipartite entanglement in such systems. We demonstrate the utility of the criteria by applying them to a recent experiment given in K. Lange et al. [Science 360, 416 (2018)] realizing a Dicke state in a Bose-Einstein condensate of cold atoms, in which the two subensembles were spatially separated from each other. Our methods also work well if split spin-squeezed states are considered. We show in a comprehensive way how to handle experimental imperfections, such as the nonzero particle number variance including the partition noise, and the fact that, while ideally BECs occupy a single spatial mode, in practice the population of other spatial modes cannot be fully suppressed.",
           3,
           "quantum"
          ],
          [
           "On the Hardness of PAC-learning Stabilizer States with Noise",
           "10.22331/q-2022-02-02-640",
           2022,
           "We consider the problem of learning stabilizer states with noise in the Probably Approximately Correct (PAC) framework of Aaronson (2007) for learning quantum states. In the noiseless setting, an algorithm for this problem was recently given by Rocchetto (2018), but the noisy case was left open. Motivated by approaches to noise tolerance from classical learning theory, we introduce the Statistical Query (SQ) model for PAC-learning quantum states, and prove that algorithms in this model are indeed resilient to common forms of noise, including classification and depolarizing noise. We prove an exponential lower bound on learning stabilizer states in the SQ model. Even outside the SQ model, we prove that learning stabilizer states with noise is in general as hard as Learning Parity with Noise (LPN) using classical examples. Our results position the problem of learning stabilizer states as a natural quantum analogue of the classical problem of learning parities: easy in the noiseless setting, but seemingly intractable even with simple forms of noise.",
           5,
           "quantum"
          ],
          [
           "Adaptive surface code for quantum error correction in the presence of temporary or permanent defects",
           "10.22331/q-2023-07-25-1065",
           2023,
           "Whether it is at the fabrication stage or during the course of the quantum computation, e.g. because of high-energy events like cosmic rays, the qubits constituting an error correcting code may be rendered inoperable. Such defects may correspond to individual qubits or to clusters and could potentially disrupt the code sufficiently to generate logical errors. In this paper, we explore a novel adaptive approach for surface code quantum error correction on a defective lattice. We show that combining an appropriate defect detection algorithm and a quarantine of the identified zone allows one to preserve the advantage of quantum error correction at finite code sizes, at the cost of a qubit overhead that scales with the size of the defect. Our numerics indicate that the code's threshold need not be significantly affected; for example, for a certain scenario where small defects repeatedly arise in each logical qubit, the noise threshold is 2.7&#x0025; (versus the defect-free case of 2.9&#x0025;). These results pave the way to the experimental implementation of large-scale quantum computers where defects will be inevitable.",
           2,
           "quantum"
          ],
          [
           "Deviation bounds and concentration inequalities for quantum noises",
           "10.22331/q-2022-08-04-772",
           2022,
           "We provide a stochastic interpretation of non-commutative Dirichlet forms in the context of quantum filtering. For stochastic processes motivated by quantum optics experiments, we derive an optimal finite time deviation bound expressed in terms of the non-commutative Dirichlet form. Introducing and developing new non-commutative functional inequalities, we deduce concentration inequalities for these processes. Examples satisfying our bounds include tensor products of quantum Markov semigroups as well as Gibbs samplers above a threshold temperature.",
           4,
           "quantum"
          ],
          [
           "Efficient simulation of Gottesman-Kitaev-Preskill states with Gaussian circuits",
           "10.22331/q-2022-12-01-867",
           2022,
           "We study the classical simulatability of Gottesman-Kitaev-Preskill (GKP) states in combination with arbitrary displacements, a large set of symplectic operations and homodyne measurements. For these types of circuits, neither continuous-variable theorems based on the non-negativity of quasi-probability distributions nor discrete-variable theorems such as the Gottesman-Knill theorem can be employed to assess the simulatability. We first develop a method to evaluate the probability density function corresponding to measuring a single GKP state in the position basis following arbitrary squeezing and a large set of rotations. This method involves evaluating a transformed Jacobi theta function using techniques from analytic number theory. We then use this result to identify two large classes of multimode circuits which are classically efficiently simulatable and are not contained by the GKP encoded Clifford group. Our results extend the set of circuits previously known to be classically efficiently simulatable.",
           4,
           "quantum"
          ],
          [
           "The quartic Blochnium: an anharmonic quasicharge superconducting qubit",
           "10.22331/q-2023-12-04-1193",
           2023,
           "The quasicharge superconducting qubit realizes the dual of the transmon and shows strong robustness to flux and charge fluctuations thanks to a very large inductance closed on a Josephson junction. At the same time, a weak anharmonicity of the spectrum is inherited from the parent transmon, that introduces leakage errors and is prone to frequency crowding in multi-qubit setups. We propose a novel design that employs a quartic superinductor and confers a good degree of anharmonicity to the spectrum. The quartic regime is achieved through a properly designed chain of Josephson junction loops that shows minimal quantum fluctuations without introducing a severe dependence on the external fluxes.",
           0,
           "quantum"
          ],
          [
           "Faster quantum and classical SDP approximations for quadratic binary optimization",
           "10.22331/q-2022-01-20-625",
           2022,
           "We give a quantum speedup for solving the canonical semidefinite programming relaxation for binary quadratic optimization. This class of relaxations for combinatorial optimization has so far eluded quantum speedups. Our methods combine ideas from quantum Gibbs sampling and matrix exponent updates. A de-quantization of the algorithm also leads to a faster classical solver. For generic instances, our quantum solver gives a nearly quadratic speedup over state-of-the-art algorithms. Such instances include approximating the ground state of spin glasses and MaxCut on Erdös-Rényi graphs. We also provide an efficient randomized rounding procedure that converts approximately optimal SDP solutions into approximations of the original quadratic optimization problem.",
           8,
           "quantum"
          ],
          [
           "Parity Quantum Optimization: Benchmarks",
           "10.22331/q-2023-03-17-952",
           2023,
           "We present benchmarks of the parity transformation for the Quantum Approximate Optimization Algorithm (QAOA). We analyse the gate resources required to implement a single QAOA cycle for real-world scenarios. In particular, we consider random spin models with higher order terms, as well as the problems of predicting financial crashes and finding the ground states of electronic structure Hamiltonians. For the spin models studied our findings imply a significant advantage of the parity mapping compared to the standard gate model. In combination with full parallelizability of gates this has the potential to boost the race for demonstrating quantum advantage.",
           4,
           "quantum"
          ],
          [
           "Fast simulation of quantum algorithms using circuit optimization",
           "10.22331/q-2022-05-03-706",
           2022,
           "Classical simulators play a major role in the development and benchmark of quantum algorithms and practically any software framework for quantum computation provides the option of running the algorithms on simulators. However, the development of quantum simulators was substantially separated from the rest of the software frameworks which, instead, focus on usability and compilation. Here, we demonstrate the advantage of co-developing and integrating simulators and compilers by proposing a specialized compiler pass to reduce the simulation time for arbitrary circuits. While the concept is broadly applicable, we present a concrete implementation based on the Intel Quantum Simulator, a high-performance distributed simulator. As part of this work, we extend its implementation with additional functionalities related to the representation of quantum states. The communication overhead is reduced by changing the order in which state amplitudes are stored in the distributed memory, a concept analogous to the distinction between local and global qubits for distributed Schroedinger-type simulators. We then implement a compiler pass to exploit the novel functionalities by introducing special instructions governing data movement as part of the quantum circuit. Those instructions target unique capabilities of simulators and have no analogue in actual quantum devices. To quantify the advantage, we compare the time required to simulate random circuits with and without our optimization. The simulation time is typically halved.",
           4,
           "quantum"
          ],
          [
           "Sample-efficient verification of continuously-parameterized quantum gates for small quantum processors",
           "10.22331/q-2023-05-04-997",
           2023,
           "Most near-term quantum information processing devices will not be capable of implementing quantum error correction and the associated logical quantum gate set. Instead, quantum circuits will be implemented directly using the physical native gate set of the device. These native gates often have a parameterization (e.g., rotation angles) which provide the ability to perform a continuous range of operations. Verification of the correct operation of these gates across the allowable range of parameters is important for gaining confidence in the reliability of these devices. In this work, we demonstrate a procedure for sample-efficient verification of continuously-parameterized quantum gates for small quantum processors of up to approximately 10 qubits. This procedure involves generating random sequences of randomly-parameterized layers of gates chosen from the native gate set of the device, and then stochastically compiling an approximate inverse to this sequence such that executing the full sequence on the device should leave the system near its initial state. We show that fidelity estimates made via this technique have a lower variance than fidelity estimates made via cross-entropy benchmarking. This provides an experimentally-relevant advantage in sample efficiency when estimating the fidelity loss to some desired precision. We describe the experimental realization of this technique using continuously-parameterized quantum gate sets on a trapped-ion quantum processor from Sandia QSCOUT and a superconducting quantum processor from IBM Q, and we demonstrate the sample efficiency advantage of this technique both numerically and experimentally.",
           2,
           "quantum"
          ],
          [
           "Quantum algorithms and lower bounds for convex optimization",
           "10.22331/q-2020-01-13-221",
           2020,
           "While recent work suggests that quantum computers can speed up the solution of semidefinite programs, little is known about the quantum complexity of more general convex optimization. We present a quantum algorithm that can optimize a convex function over an n-dimensional convex body using O~(n) queries to oracles that evaluate the objective function and determine membership in the convex body. This represents a quadratic improvement over the best-known classical algorithm. We also study limitations on the power of quantum computers for general convex optimization, showing that it requires Ω~(n) evaluation queries and Ω(n) membership queries.",
           18,
           "quantum"
          ],
          [
           "Real Time Dynamics and Confinement in the <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mml:msub><mml:mrow class=\"MJX-TeXAtom-ORD\"><mml:mi mathvariant=\"double-struck\">Z</mml:mi></mml:mrow><mml:mrow class=\"MJX-TeXAtom-ORD\"><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math> Schwinger-Weyl lattice model for 1+1 QED",
           "10.22331/q-2020-06-15-281",
           2020,
           "We study the out-of-equilibrium properties of 1+1 dimensional quantum electrodynamics (QED), discretized via the staggered-fermion Schwinger model with an Abelian Zn gauge group. We look at two relevant phenomena: first, we analyze the stability of the Dirac vacuum with respect to particle/antiparticle pair production, both spontaneous and induced by an external electric field; then, we examine the string breaking mechanism. We observe a strong effect of confinement, which acts by suppressing both spontaneous pair production and string breaking into quark/antiquark pairs, indicating that the system dynamics displays a number of out-of-equilibrium features.",
           82,
           "quantum"
          ],
          [
           "Quantum walk-based portfolio optimisation",
           "10.22331/q-2021-07-28-513",
           2021,
           "This paper proposes a highly efficient quantum algorithm for portfolio optimisation targeted at near-term noisy intermediate-scale quantum computers. Recent work by Hodson et al. (2019) explored potential application of hybrid quantum-classical algorithms to the problem of financial portfolio rebalancing. In particular, they deal with the portfolio optimisation problem using the Quantum Approximate Optimisation Algorithm and the Quantum Alternating Operator Ansatz. In this paper, we demonstrate substantially better performance using a newly developed Quantum Walk Optimisation Algorithm in finding high-quality solutions to the portfolio optimisation problem.",
           21,
           "quantum"
          ],
          [
           "Avoiding symmetry roadblocks and minimizing the measurement overhead of adaptive variational quantum eigensolvers",
           "10.22331/q-2023-06-12-1040",
           2023,
           "Quantum simulation of strongly correlated systems is potentially the most feasible useful application of near-term quantum computers. Minimizing quantum computational resources is crucial to achieving this goal. A promising class of algorithms for this purpose consists of variational quantum eigensolvers (VQEs). Among these, problem-tailored versions such as ADAPT-VQE that build variational ansätze step by step from a predefined operator pool perform particularly well in terms of circuit depths and variational parameter counts. However, this improved performance comes at the expense of an additional measurement overhead compared to standard VQEs. Here, we show that this overhead can be reduced to an amount that grows only linearly with the number n of qubits, instead of quartically as in the original ADAPT-VQE. We do this by proving that operator pools of size 2n&#x2212;2 can represent any state in Hilbert space if chosen appropriately. We prove that this is the minimal size of such \"complete\" pools, discuss their algebraic properties, and present necessary and sufficient conditions for their completeness that allow us to find such pools efficiently. We further show that, if the simulated problem possesses symmetries, then complete pools can fail to yield convergent results, unless the pool is chosen to obey certain symmetry rules. We demonstrate the performance of such symmetry-adapted complete pools by using them in classical simulations of ADAPT-VQE for several strongly correlated molecules. Our findings are relevant for any VQE that uses an ansatz based on Pauli strings.",
           7,
           "quantum"
          ],
          [
           "Boosting device-independent cryptography with tripartite nonlocality",
           "10.22331/q-2023-04-13-980",
           2023,
           "Device-independent (DI) protocols, such as DI conference key agreement (DICKA) and DI randomness expansion (DIRE), certify private randomness by observing nonlocal correlations when two or more parties test a Bell inequality. While most DI protocols are restricted to bipartite Bell tests, harnessing multipartite nonlocal correlations may lead to better performance. Here, we consider tripartite DICKA and DIRE protocols based on testing multipartite Bell inequalities, specifically: the Mermin-Ardehali-Belinskii-Klyshko (MABK) inequality, and the Holz and the Parity-CHSH inequalities introduced in the context of DICKA protocols. We evaluate the asymptotic performance of the DICKA (DIRE) protocols in terms of their conference key rate (net randomness generation rate), by deriving lower bounds on the conditional von Neumann entropy of one party&apos;s outcome and two parties&apos; outcomes. For the Holz inequality, we prove a tight analytical lower bound on the one-outcome entropy and conjecture a tight lower bound on the two-outcome entropy. We additionally re-derive the analytical one-outcome entropy bound for the MABK inequality with a much simpler method and obtain a numerical lower bound on the two-outcome entropy for the Parity-CHSH inequality. Our simulations show that DICKA and DIRE protocols employing tripartite Bell inequalities can significantly outperform their bipartite counterparts. Moreover, we establish that genuine multipartite entanglement is not a precondition for multipartite DIRE while its necessity for DICKA remains an open question.",
           2,
           "quantum"
          ],
          [
           "On tests of the quantum nature of gravitational interactions in presence of non-linear corrections to quantum mechanics",
           "10.22331/q-2023-10-25-1157",
           2023,
           "When two particles interact primarily through gravity and follow the laws of quantum mechanics, the generation of entanglement is considered a hallmark of the quantum nature of the gravitational interaction. However, we demonstrate that entanglement dynamics can also occur in the presence of a weak quantum interaction and non-linear corrections to local quantum mechanics, even if the gravitational interaction is classical or absent at short distances. This highlights the importance of going beyond entanglement detection to conclusively test the quantum character of gravity, and it requires a thorough examination of the strength of other quantum forces and potential non-linear corrections to quantum mechanics in the realm of large masses.",
           1,
           "quantum"
          ],
          [
           "Photonic entanglement during a zero-g flight",
           "10.22331/q-2024-02-15-1256",
           2024,
           "Quantum technologies have matured to the point that we can test fundamental quantum phenomena under extreme conditions. Specifically, entanglement, a cornerstone of modern quantum information theory, can be robustly produced and verified in various adverse environments. We take these tests further and implement a high-quality Bell experiment during a parabolic flight, transitioning from microgravity to hypergravity of 1.8 g while continuously observing Bell violation, with Bell-CHSH parameters between S=&#x2212;2.6202 and &#x2212;2.7323, an average of S&#x00AF;=&#x2212;2.680, and average standard deviation of &#x0394;S&#x00AF;=0.014. This violation is unaffected both by uniform and non-uniform acceleration. This experiment demonstrates the stability of current quantum communication platforms for space-based applications and adds an important reference point for testing the interplay of non-inertial motion and quantum information.",
           0,
           "quantum"
          ],
          [
           "Simulating quantum circuits using tree tensor networks",
           "10.22331/q-2023-03-30-964",
           2023,
           "We develop and analyze a method for simulating quantum circuits on classical computers by representing quantum states as rooted tree tensor networks. Our algorithm first determines a suitable, fixed tree structure adapted to the expected entanglement generated by the quantum circuit. The gates are sequentially applied to the tree by absorbing single-qubit gates into leaf nodes, and splitting two-qubit gates via singular value decomposition and threading the resulting virtual bond through the tree. We theoretically analyze the applicability of the method as well as its computational cost and memory requirements, and identify advantageous scenarios in terms of required bond dimensions as compared to a matrix product state representation. The study is complemented by numerical experiments for different quantum circuit layouts up to 37 qubits.",
           2,
           "quantum"
          ],
          [
           "Direct detection of quantum non-Gaussian light from a dispersively coupled single atom",
           "10.22331/q-2022-02-24-660",
           2022,
           "Many applications in quantum communication, sensing and computation need provably quantum non-Gaussian light. Recently such light, witnessed by a negative Wigner function, has been estimated using homodyne tomography from a single atom dispersively coupled to a high-finesse cavity. This opens an investigation of quantum non-Gaussian light for many experiments with atoms and solid-state emitters. However, at their early stage, an atom or emitter in a cavity system with different channels to the environment and additional noise are insufficient to produce negative Wigner functions. Moreover, homodyne detection is frequently challenging for such experiments. We analyse these issues and prove that such cavities can be used to emit quantum non-Gaussian light employing single-photon detection in the Hanbury Brown and Twiss configuration and quantum non-Gaussianity criteria suitable for this measurement. We investigate in detail cases of considerable cavity leakage when the negativity of the Wigner function disappears completely. Advantageously, quantum non-Gaussian light can be still conclusively proven for a large set of the cavity parameters at the cost of overall measurement time, even if noise is present.",
           1,
           "quantum"
          ],
          [
           "Local Probabilistic Decoding of a Quantum Code",
           "10.22331/q-2023-08-29-1093",
           2023,
           "flip is an extremely simple and maximally local classical decoder which has been used to great effect in certain classes of classical codes. When applied to quantum codes there exist constant-weight errors (such as half of a stabiliser) which are uncorrectable for this decoder, so previous studies have considered modified versions of flip, sometimes in conjunction with other decoders. We argue that this may not always be necessary, and present numerical evidence for the existence of a threshold for flip when applied to the looplike syndromes of a three-dimensional toric code on a cubic lattice. This result can be attributed to the fact that the lowest-weight uncorrectable errors for this decoder are closer (in terms of Hamming distance) to correctable errors than to other uncorrectable errors, and so they are likely to become correctable in future code cycles after transformation by additional noise. Introducing randomness into the decoder can allow it to correct these \"uncorrectable\" errors with finite probability, and for a decoding strategy that uses a combination of belief propagation and probabilistic flip we observe a threshold of &#x223C;5.5&#x0025; under phenomenological noise. This is comparable to the best known threshold for this code (&#x223C;7.1&#x0025;) which was achieved using belief propagation and ordered statistics decoding [Higgott and Breuckmann, 2022], a strategy with a runtime of O(n3) as opposed to the O(n) (O(1) when parallelised) runtime of our local decoder. We expect that this strategy could be generalised to work well in other low-density parity check codes, and hope that these results will prompt investigation of other previously overlooked decoders.",
           2,
           "quantum"
          ],
          [
           "Emergent classicality in general multipartite states and channels",
           "10.22331/q-2021-09-28-555",
           2021,
           "In a quantum measurement process, classical information about the measured system spreads throughout the environment. Meanwhile, quantum information about the system becomes inaccessible to local observers. Here we prove a result about quantum channels indicating that an aspect of this phenomenon is completely general. We show that for any evolution of the system and environment, for everywhere in the environment excluding an O(1)-sized region we call the \"quantum Markov blanket,\" any locally accessible information about the system must be approximately classical, i.e. obtainable from some fixed measurement. The result strengthens the earlier result of  Brandão et al. (Nat. comm. 6:7908) in which the excluded region was allowed to grow with total environment size. It may also be seen as a new consequence of the principles of no-cloning or monogamy of entanglement. Our proof offers a constructive optimization procedure for determining the \"quantum Markov blanket\" region, as well as the effective measurement induced by the evolution. Alternatively, under channel-state duality, our result characterizes the marginals of multipartite states.",
           12,
           "quantum"
          ],
          [
           "Beyond the Cabello-Severini-Winter framework: Making sense of contextuality without sharpness of measurements",
           "10.22331/q-2019-09-09-184",
           2019,
           "We develop a hypergraph-theoretic framework for Spekkens contextuality applied to Kochen-Specker (KS) type scenarios that goes beyond the Cabello-Severini-Winter (CSW) framework. To do this, we add new hypergraph-theoretic ingredients to the CSW framework. We then obtain noise-robust noncontextuality inequalities in this generalized framework by applying the assumption of (Spekkens) noncontextuality to both preparations and measurements. The resulting framework goes beyond the CSW framework in both senses, conceptual and technical. On the conceptual level: 1) as in any treatment based on the generalized notion of noncontextuality à la Spekkens, we relax the assumption of outcome determinism inherent to the Kochen-Specker theorem but retain measurement noncontextuality, besides introducing preparation noncontextuality, 2) we do not require the exclusivity principle -- that pairwise exclusive measurement events must all be mutually exclusive -- as a fundamental constraint on measurement events of interest in an experimental test of contextuality, given that this property is not true of general quantum measurements, and 3) as a result, we do not need to presume that measurement events of interest are ``sharp\" (for any definition of sharpness), where this notion of sharpness is meant to imply the exclusivity principle. On the technical level, we go beyond the CSW framework in the following senses: 1) we introduce a source events hypergraph -- besides the measurement events hypergraph usually considered -- and define a new operational quantity Corr that appears in our inequalities, 2) we define a new hypergraph invariant -- the weightedmax-predictability -- that is necessary for our analysis and appears in our inequalities, and 3) our noise-robust noncontextuality inequalities quantify tradeoff relations between three operational quantities -- Corr, R, and p0 -- only one of which (namely, R) corresponds to the Bell-Kochen-Specker functionals appearing in the CSW framework; when Corr=1, the inequalities formally reduce to CSW type bounds on R. Along the way, we also consider in detail the scope of our framework vis-à-vis the CSW framework, particularly the role of Specker's principle in the CSW framework, i.e., what the principle means for an operational theory satisfying it and why we don't impose it in our framework.",
           15,
           "quantum"
          ],
          [
           "The type-independent resource theory of local operations and shared randomness",
           "10.22331/q-2020-04-30-262",
           2020,
           "In space-like separated experiments and other scenarios where multiple parties share a classical common cause but no cause-effect relations, quantum theory allows a variety of nonsignaling resources which are useful for distributed quantum information processing. These include quantum states, nonlocal boxes, steering assemblages, teleportages, channel steering assemblages, and so on. Such resources are often studied using nonlocal games, semiquantum games, entanglement-witnesses, teleportation experiments, and similar tasks. We introduce a unifying framework which subsumes the full range of nonsignaling resources, as well as the games and experiments which probe them, into a common resource theory: that of local operations and shared randomness (LOSR). Crucially, we allow these LOSR operations to locally change the type of a resource, so that players can convert resources of any type into resources of any other type, and in particular into strategies for the specific type of game they are playing. We then prove several theorems relating resources and games of different types. These theorems generalize a number of seminal results from the literature, and can be applied to lessen the assumptions needed to characterize the nonclassicality of resources. As just one example, we prove that semiquantum games are able to perfectly characterize the LOSR nonclassicality of every resource of any type (not just quantum states, as was previously shown). As a consequence, we show that any resource can be characterized in a measurement-device-independent manner.",
           37,
           "quantum"
          ],
          [
           "A relativistic discrete spacetime formulation of 3+1 QED",
           "10.22331/q-2023-11-08-1179",
           2023,
           "This work provides a relativistic, digital quantum simulation scheme for both 2+1 and 3+1 dimensional quantum electrodynamics (QED), based on a discrete spacetime formulation of theory. It takes the form of a quantum circuit, infinitely repeating across space and time, parametrised by the discretization step &#x0394;t=&#x0394;x. Strict causality at each step is ensured as circuit wires coincide with the lightlike worldlines of QED; simulation time under decoherence is optimized. The construction replays the logic that leads to the QED Lagrangian. Namely, it starts from the Dirac quantum walk, well-known to converge towards free relativistic fermions. It then extends the quantum walk into a multi-particle sector quantum cellular automata in a way which respects the fermionic anti-commutation relations and the discrete gauge invariance symmetry. Both requirements can only be achieved at cost of introducing the gauge field. Lastly the gauge field is given its own electromagnetic dynamics, which can be formulated as a quantum walk at each plaquette.",
           1,
           "quantum"
          ],
          [
           "Accessible coherence in open quantum system dynamics",
           "10.22331/q-2020-04-02-249",
           2020,
           "Quantum coherence generated in a physical process can only be cast as a potentially useful resource if its effects can be detected at a later time. Recently, the notion of non-coherence-generating-and-detecting (NCGD) dynamics has been introduced and related to the classicality of the statistics associated with sequential measurements at different times. However, in order for a dynamics to be NCGD, its propagators need to satisfy a given set of conditions foralltriples of consecutive times. We reduce this to a finite set ofd(d−1)conditions, wheredis the dimension of the quantum system, provided that the generator is time-independent. Further conditions are derived for the more general time-dependent case. The application of this result to the case of a qubit dynamics allows us to elucidate which kind of noise gives rise to non-coherence-generation-and-detection.",
           7,
           "quantum"
          ],
          [
           "Entangled subspaces and generic local state discrimination with pre-shared entanglement",
           "10.22331/q-2022-07-07-760",
           2022,
           "Walgate and Scott have determined the maximum number of generic pure quantum states that can be unambiguously discriminated by an LOCC measurement [Journal of Physics A: Mathematical and Theoretical, 41:375305, 08 2008]. In this work, we determine this number in a more general setting in which the local parties have access to pre-shared entanglement in the form of a resource state. We find that, for an arbitrary pure resource state, this number is equal to the Krull dimension of (the closure of) the set of pure states obtainable from the resource state by SLOCC. Surprisingly, a generic resource state maximizes this number.Local state discrimination is closely related to the topic of entangled subspaces, which we study in its own right. We introduce r-entangled subspaces, which naturally generalize previously studied spaces to higher multipartite entanglement. We use algebraic-geometric methods to determine the maximum dimension of an r-entangled subspace, and present novel explicit constructions of such spaces. We obtain similar results for symmetric and antisymmetric r-entangled subspaces, which correspond to entangled subspaces of bosonic and fermionic systems, respectively.",
           3,
           "quantum"
          ],
          [
           "The refined quantum extremal surface prescription from the asymptotic equipartition property",
           "10.22331/q-2022-02-16-655",
           2022,
           "Information-theoretic ideas have provided numerous insights in the progress of fundamental physics, especially in our pursuit of quantum gravity. In particular, the holographic entanglement entropy is a very useful tool in studying AdS/CFT, and its efficacy is manifested in the recent black hole page curve calculation. On the other hand, the one-shot information-theoretic entropies, such as the smooth min/max-entropies, are less discussed in AdS/CFT. They are however more fundamental entropy measures from the quantum information perspective and should also play pivotal roles in holography. We combine the technical methods from both quantum information and quantum gravity to put this idea on firm grounds. In particular, we study the quantum extremal surface (QES) prescription that was recently revised to highlight the significance of one-shot entropies in characterizing the QES phase transition. Motivated by the asymptotic equipartition property (AEP), we derive the refined quantum extremal surface prescription for fixed-area states via a novel AEP replica trick, demonstrating the synergy between quantum information and quantum gravity. We further prove that, when restricted to pure bulk marginal states, such corrections do not occur for the higher Rényi entropies of a boundary subregion in fixed-area states, meaning they always have sharp QES transitions. Our path integral derivation suggests that the refinement applies beyond AdS/CFT, and we confirm it in a black hole toy model by showing that the Page curve, for a black hole in a superposition of two radiation stages, receives a large correction that is consistent with the refined QES prescription.",
           4,
           "quantum"
          ],
          [
           "Volumetric Benchmarking of Error Mitigation with Qermit",
           "10.22331/q-2023-07-13-1059",
           2023,
           "The detrimental effect of noise accumulates as quantum computers grow in size. In the case where devices are too small or noisy to perform error correction, error mitigation may be used. Error mitigation does not increase the fidelity of quantum states, but instead aims to reduce the approximation error in quantities of concern, such as expectation values of observables. However, it is as yet unclear which circuit types, and devices of which characteristics, benefit most from the use of error mitigation. Here we develop a methodology to assess the performance of quantum error mitigation techniques. Our benchmarks are volumetric in design, and are performed on different superconducting hardware devices. Extensive classical simulations are also used for comparison. We use these benchmarks to identify disconnects between the predicted and practical performance of error mitigation protocols, and to identify the situations in which their use is beneficial. To perform these experiments, and for the benefit of the wider community, we introduceQermit– an open source python package for quantum error mitigation. Qermit supports a wide range of error mitigation methods, is easily extensible and has a modular graph-based software design that facilitates composition of error mitigation protocols and subroutines.",
           3,
           "quantum"
          ],
          [
           "How to make unforgeable money in generalised probabilistic theories",
           "10.22331/q-2018-11-02-103",
           2018,
           "We discuss the possibility of creating money that is physically impossible to counterfeit. Of course, \"physically impossible\" is dependent on the theory that is a faithful description of nature. Currently there are several proposals for quantum money which have their security based on the validity of quantum mechanics. In this work, we examine Wiesner's money scheme in the framework of generalised probabilistic theories. This framework is broad enough to allow for essentially any potential theory of nature, provided that it admits an operational description. We prove that under a quantifiable version of the no-cloning theorem, one can create physical money which has an exponentially small chance of being counterfeited. Our proof relies on cone programming, a natural generalisation of semidefinite programming. Moreover, we discuss some of the difficulties that arise when considering non-quantum theories.",
           16,
           "quantum"
          ],
          [
           "Analysing causal structures in generalised probabilistic theories",
           "10.22331/q-2020-02-27-236",
           2020,
           "Causal structures give us a way to understand the origin of observed correlations. These were developed for classical scenarios, but quantum mechanical experiments necessitate their generalisation. Here we study causal structures in a broad range of theories, which include both quantum and classical theory as special cases. We propose a method for analysing differences between such theories based on the so-called measurement entropy. We apply this method to several causal structures, deriving new relations that separate classical, quantum and more general theories within these causal structures. The constraints we derive for the most general theories are in a sense minimal requirements of any causal explanation in these scenarios. In addition, we make several technical contributions that give insight for the entropic analysis of quantum causal structures. In particular, we prove that for any causal structure and for any generalised probabilistic theory, the set of achievable entropy vectors form a convex cone.",
           9,
           "quantum"
          ],
          [
           "Depth-efficient proofs of quantumness",
           "10.22331/q-2022-09-19-807",
           2022,
           "A proof of quantumness is a type of challenge-response protocol in which a classical verifier can efficiently certify the quantum advantage of an untrusted prover. That is, a quantum prover can correctly answer the verifier's challenges and be accepted, while any polynomial-time classical prover will be rejected with high probability, based on plausible computational assumptions. To answer the verifier's challenges, existing proofs of quantumness typically require the quantum prover to perform a combination of polynomial-size quantum circuits and measurements. In this paper, we give two proof of quantumness constructions in which the prover need only perform constant-depth quantum circuits (and measurements) together with log-depth classical computation. Our first construction is a generic compiler that allows us to translate all existing proofs of quantumness into constant quantum depth versions. Our second construction is based around the learning with rounding problem, and yields circuits with shorter depth and requiring fewer qubits than the generic construction. In addition, the second construction also has some robustness against noise.",
           5,
           "quantum"
          ],
          [
           "Entanglement and squeezing in continuous-variable systems",
           "10.22331/q-2017-07-14-17",
           2017,
           "We introduce a multi-mode squeezing coefficient to characterize entanglement in N-partite continuous-variable systems. The coefficient relates to the squeezing of collective observables in the 2N-dimensional phase space and can be readily extracted from the covariance matrix. Simple extensions further permit to reveal entanglement within specific partitions of a multipartite system. Applications with nonlinear observables allow for the detection of non-Gaussian entanglement.",
           17,
           "quantum"
          ],
          [
           "Cutting multi-control quantum gates with ZX calculus",
           "10.22331/q-2023-10-23-1147",
           2023,
           "Circuit cutting, the decomposition of a quantum circuit into independent partitions, has become a promising avenue towards experiments with larger quantum circuits in the noisy-intermediate scale quantum (NISQ) era. While previous work focused on cutting qubit wires or two-qubit gates, in this work we introduce a method for cutting multi-controlled Z gates. We construct a decomposition and prove the upper bound O(62K) on the associated sampling overhead, where K is the number of cuts in the circuit. This bound is independent of the number of control qubits but can be further reduced to O(4.52K) for the special case of CCZ gates. Furthermore, we evaluate our proposal on IBM hardware and experimentally show noise resilience due to the strong reduction of CNOT gates in the cut circuits.",
           1,
           "quantum"
          ],
          [
           "Resource requirements for efficient quantum communication using all-photonic graph states generated from a few matter qubits",
           "10.22331/q-2021-02-15-397",
           2021,
           "Quantum communication technologies show great promise for applications ranging from the secure transmission of secret messages to distributed quantum computing. Due to fiber losses, long-distance quantum communication requires the use of quantum repeaters, for which there exist quantum memory-based schemes and all-photonic schemes. While all-photonic approaches based on graph states generated from linear optics avoid coherence time issues associated with memories, they outperform repeater-less protocols only at the expense of a prohibitively large overhead in resources. Here, we consider using matter qubits to produce the photonic graph states and analyze in detail the trade-off between resources and performance, as characterized by the achievable secret key rate per matter qubit. We show that fast two-qubit entangling gates between matter qubits and high photon collection and detection efficiencies are the main ingredients needed for the all-photonic protocol to outperform both repeater-less and memory-based schemes.",
           27,
           "quantum"
          ],
          [
           "A Threshold for Quantum Advantage in Derivative Pricing",
           "10.22331/q-2021-06-01-463",
           2021,
           "We give an upper bound on the resources required for valuable quantum advantage in pricing derivatives. To do so, we give the first complete resource estimates for useful quantum derivative pricing, using autocallable and Target Accrual Redemption Forward (TARF) derivatives as benchmark use cases. We uncover blocking challenges in known approaches and introduce a new method for quantum derivative pricing – there-parameterization method– that avoids them. This method combines pre-trained variational circuits with fault-tolerant quantum computing to dramatically reduce resource requirements. We find that the benchmark use cases we examine require 8k logical qubits and a T-depth of 54 million. We estimate that quantum advantage would require executing this program at the order of a second. While the resource requirements given here are out of reach of current systems, we hope they will provide a roadmap for further improvements in algorithms, implementations, and planned hardware architectures.",
           56,
           "quantum"
          ],
          [
           "Improved quantum algorithms for linear and nonlinear differential equations",
           "10.22331/q-2023-02-02-913",
           2023,
           "We present substantially generalized and improved quantum algorithms over prior work for inhomogeneous linear and nonlinear ordinary differential equations (ODE). Specifically, we show how the norm of the matrix exponential characterizes the run time of quantum algorithms for linear ODEs opening the door to an application to a wider class of linear and nonlinear ODEs. In \\cite{BCOW17}, a quantum algorithm for a certain class of linear ODEs is given, where the matrix involved needs to be diagonalizable. The quantum algorithm for linear ODEs presented here extends to many classes of non-diagonalizable matrices including singular matrices. The algorithm here is also exponentially faster than the bounds derived in \\cite{BCOW17} for certain classes of diagonalizable matrices.\n\nOur linear ODE algorithm is then applied to nonlinear differential equations using Carleman linearization (an approach taken recently by us in \\cite{Liue2026805118}). The improvement over that result is two-fold. First, we obtain an exponentially better dependence on error. This kind of logarithmic dependence on error has also been achieved by \\cite{Xue_2021}, but only for homogeneous nonlinear equations. Second, the present algorithm can handle any sparse matrix (that models dissipation) if it has a negative log-norm (including non-diagonalizable matrices), whereas \\cite{Liue2026805118} and \\cite{Xue_2021} additionally require normality.",
           11,
           "quantum"
          ],
          [
           "Ancilla-free continuous-variable SWAP test",
           "10.22331/q-2022-09-08-800",
           2022,
           "We propose a continuous-variable (CV) SWAP test that requires no ancilla register, thereby generalizing the ancilla-free SWAP test for qubits. In this ancilla-free CV SWAP test, the computational basis measurement is replaced by photon number-resolving measurement, and we calculate an upper bound on the error of the overlap estimate obtained from a finite Fock cutoff in the detector. As an example, we show that estimation of the overlap of pure, centered, single-mode Gaussian states of energyEand squeezed in opposite quadratures can be obtained to error&#x03F5;using photon statistics below a Fock basis cutoffO(Eln&#x2061;&#x03F5;&#x2212;1). This cutoff is greatly reduced toE+O(Eln&#x2061;&#x03F5;&#x2212;1)when the states have rapidly decaying Fock tails, such as coherent states. We show how the ancilla-free CV SWAP test can be extended to many modes and applied to quantum algorithms such as variational compiling and entanglement spectroscopy in the CV setting. For the latter we also provide a new algorithm which does not have an analog in qubit systems. The ancilla-free CV SWAP test is implemented on Xanadu's 8-mode photonic processor in order to estimate the vacuum probability of a two-mode squeezed state.",
           4,
           "quantum"
          ],
          [
           "Thermodynamics of Minimal Coupling Quantum Heat Engines",
           "10.22331/q-2020-12-23-375",
           2020,
           "The minimal-coupling quantum heat engine is a thermal machine consisting of an explicit energy storage system, heat baths, and a working body, which alternatively couples to subsystems through discrete strokes --- energy-conserving two-body quantum operations. Within this paradigm, we present a general framework of quantum thermodynamics, where a work extraction process is fundamentally limited by a flow of non-passive energy (ergotropy), while energy dissipation is expressed through a flow of passive energy. It turns out that small dimensionality of the working body and a restriction only to two-body operations make the engine fundamentally irreversible. Our main result is finding the optimal efficiency and work production per cycle within the whole class of irreversible minimal-coupling engines composed of three strokes and with the two-level working body, where we take into account all possible quantum correlations between the working body and the battery. One of the key new tools is the introduced ``control-marginal state\" --- one which acts only on a working body Hilbert space, but encapsulates all features regarding work extraction of the total working body-battery system. In addition, we propose a generalization of the many-stroke engine, and we analyze efficiency vs extracted work trade-offs, as well as work fluctuations after many cycles of the running of the engine.",
           12,
           "quantum"
          ],
          [
           "Quantum Circuits for Sparse Isometries",
           "10.22331/q-2021-03-15-412",
           2021,
           "We consider the task of breaking down a quantum computation given as an isometry into C-NOTs and single-qubit gates, while keeping the number of C-NOT gates small. Although several decompositions are known for general isometries, here we focus on a method based on Householder reflections that adapts well in the case of sparse isometries. We show how to use this method to decompose an arbitrary isometry before illustrating that the method can lead to significant improvements in the case of sparse isometries. We also discuss the classical complexity of this method and illustrate its effectiveness in the case of sparse state preparation by applying it to randomly chosen sparse states.",
           15,
           "quantum"
          ],
          [
           "Analyticity constraints bound the decay of the spectral form factor",
           "10.22331/q-2022-11-03-852",
           2022,
           "Quantum chaos cannot develop faster than &#x03BB;&#x2264;2&#x03C0;/(&#x210F;&#x03B2;) for systems in thermal equilibrium [Maldacena, Shenker & Stanford, JHEP (2016)]. This `MSS bound' on the Lyapunov exponent &#x03BB; is set by the width of the strip on which the regularized out-of-time-order correlator is analytic. We show that similar constraints also bound the decay of the spectral form factor (SFF), that measures spectral correlation and is defined from the Fourier transform of the two-level correlation function. Specifically, the inflection exponent&#x03B7;, that we introduce to characterize the early-time decay of the SFF, is bounded as &#x03B7;&#x2264;&#x03C0;/(2&#x210F;&#x03B2;). This bound is universal and exists outside of the chaotic regime. The results are illustrated in systems with regular, chaotic, and tunable dynamics, namely the single-particle harmonic oscillator, the many-particle Calogero-Sutherland model, an ensemble from random matrix theory, and the quantum kicked top. The relation of the derived bound with other known bounds, including quantum speed limits, is discussed.",
           1,
           "quantum"
          ],
          [
           "Receiver-Device-Independent Quantum Key Distribution",
           "10.22331/q-2022-05-24-718",
           2022,
           "We present protocols for quantum key distribution in a prepare-and-measure setup with an asymmetric level of trust. While the device of the sender (Alice) is partially characterized, the receiver&apos;s (Bob&apos;s) device is treated as a black-box. The security of the protocols is based on the assumption that Alice&apos;s prepared states have limited overlaps, but no explicit bound on the Hilbert space dimension is required. The protocols are immune to attacks on the receiver&apos;s device, such as blinding attacks. The users can establish a secret key while continuously monitoring the correct functioning of their devices through observed statistics. We report a proof-of-principle demonstration, involving mostly off-the-shelf equipment, as well as a high-efficiency superconducting nanowire detector. A positive key rate is demonstrated over a 4.8 km low-loss optical fiber with finite-key analysis. The prospects of implementing these protocols over longer distances is discussed.",
           2,
           "quantum"
          ],
          [
           "One-Shot Hybrid State Redistribution",
           "10.22331/q-2022-05-30-724",
           2022,
           "We consider state redistribution of a \"hybrid\" information source that has both classical and quantum components. The sender transmits classical and quantum information at the same time to the receiver, in the presence of classical and quantum side information both at the sender and at the decoder. The available resources are shared entanglement, and noiseless classical and quantum communication channels. We derive one-shot direct and converse bounds for these three resources, represented in terms of the smooth conditional entropies of the source state. Various coding theorems for two-party source coding problems are systematically obtained by reduction from our results, including the ones that have not been addressed in previous literature.",
           4,
           "quantum"
          ],
          [
           "Almost Markovian processes from closed dynamics",
           "10.22331/q-2019-04-30-136",
           2019,
           "It is common, when dealing with quantum processes involving a subsystem of a much larger composite closed system, to treat them as effectively memory-less (Markovian). While open systems theory tells us that non-Markovian processes should be the norm, the ubiquity of Markovian processes is undeniable. Here, without resorting to the Born-Markov assumption of weak coupling or making any approximations, we formally prove that processes are close to Markovian ones, when the subsystem is sufficiently small compared to the remainder of the composite, with a probability that tends to unity exponentially in the size of the latter. We also show that, for a fixed global system size, it may not be possible to neglect non-Markovian effects when the process is allowed to continue for long enough. However, detecting non-Markovianity for such processes would usually require non-trivial entangling resources. Our results have foundational importance, as they give birth to almost Markovian processes from composite closed dynamics, and to obtain them we introduce a new notion of equilibration that is far stronger than the conventional one and show that this stronger equilibration is attained.",
           23,
           "quantum"
          ],
          [
           "A review and reformulation of macroscopic realism: resolving its deficiencies using the framework of generalized probabilistic theories",
           "10.22331/q-2024-01-03-1217",
           2024,
           "The notion of macrorealism was introduced by Leggett and Garg in an attempt to capture our intuitive conception of the macroscopic world, which seems difficult to reconcile with our knowledge of quantum physics. By now, numerous experimental witnesses have been proposed as methods of falsifying macrorealism. In this work, I critically review and analyze both the definition of macrorealism and the various proposed tests thereof, identifying a number of problems with these (and revisiting key criticisms raised by other authors). I then show that all these problems can be resolved by reformulating macrorealism within the framework of generalized probabilistic theories. In particular, I argue that a theory should be considered to be macrorealist if and only if it describes every macroscopic system by a strictly classical (i.e., simplicial) generalized probabilistic theory. This approach brings significant clarity and precision to our understanding of macrorealism, and provides us with a host of new tools – both conceptual and technical – for studying macrorealism. I leverage this approach i) to clarify in what sense macrorealism is a notion of classicality, ii) to propose a new test of macrorealism that is maximally informative and theory-independent (unlike all prior tests of macrorealism), and iii) to show that every proof of generalized contextuality on a macroscopic system implies the failure of macrorealism.",
           1,
           "quantum"
          ],
          [
           "Robust measurement of wave function topology on NISQ quantum computers",
           "10.22331/q-2023-04-27-987",
           2023,
           "Topological quantum phases of quantum materials are defined through their topological invariants. These topological invariants are quantities that characterize the global geometrical properties of the quantum wave functions and thus are immune to local noise. Here, we present a strategy to measure topological invariants on quantum computers. We show that our strategy can be easily integrated with the variational quantum eigensolver (VQE) so that the topological properties of generic quantum many-body states can be characterized on current quantum hardware. We demonstrate the robust nature of the method by measuring topological invariants for both non-interacting and interacting models, and map out interacting quantum phase diagrams on quantum simulators and IBM quantum hardware.",
           1,
           "quantum"
          ],
          [
           "The Multi-round Process Matrix",
           "10.22331/q-2021-01-20-384",
           2021,
           "We develop an extension of the process matrix (PM) framework for correlations between quantum operations with no causal order that allows multiple rounds of information exchange for each party compatibly with the assumption of well-defined causal order of events locally. We characterise the higher-order process describing such correlations, which we name the multi-round process matrix (MPM), and formulate a notion of causal nonseparability for it that extends the one for standard PMs. We show that in the multi-round case there are novel manifestations of causal nonseparability that are not captured by a naive application of the standard PM formalism: we exhibit an instance of an operator that is both a valid PM and a valid MPM, but is causally separable in the first case and can violate causal inequalities in the second case due to the possibility of using a side channel.",
           2,
           "quantum"
          ],
          [
           "Switching Quantum Reference Frames for Quantum Measurement",
           "10.22331/q-2020-06-18-283",
           2020,
           "Physical observation is made relative to a reference frame. A reference frame is essentially a quantum system given the universal validity of quantum mechanics. Thus, a quantum system must be described relative to a quantum reference frame (QRF). Further requirements on QRF include using only relational observables and not assuming the existence of external reference frame. To address these requirements, two approaches are proposed in the literature. The first one is an operational approach (F. Giacomini, et al, Nat. Comm. 10:494, 2019) which focuses on the quantization of transformation between QRFs. The second approach attempts to derive the quantum transformation between QRFs from first principles (A. Vanrietvelde, et al,Quantum4:225, 2020). Such first principle approach describes physical systems as symmetry induced constrained Hamiltonian systems. The Dirac quantization of such systems before removing redundancy is interpreted as perspective-neutral description. Then, a systematic redundancy reduction procedure is introduced to derive description from perspective of a QRF. The first principle approach recovers some of the results from the operational approach, but not yet include an important part of a quantum theory - the measurement theory. This paper is intended to bridge the gap. We show that the von Neumann quantum measurement theory can be embedded into the perspective-neutral framework. This allows us to successfully recover the results found in the operational approach, with the advantage that the transformation operator can be derived from the first principle. In addition, the formulation presented here reveals several interesting conceptual insights. For instance, the projection operation in measurement needs to be performed after redundancy reduction, and the projection operator must be transformed accordingly when switching QRFs. These results represent one step forward in understanding how quantum measurement should be formulated when the reference frame is also a quantum system.",
           15,
           "quantum"
          ],
          [
           "Encoding strongly-correlated many-boson wavefunctions on a photonic quantum computer: application to the attractive Bose-Hubbard model",
           "10.22331/q-2021-11-08-572",
           2021,
           "Variational quantum algorithms (VQA) are considered as some of the most promising methods to determine the properties of complex strongly correlated quantum many-body systems, especially from the perspective of devices available in the near term. In this context, the development of efficient quantum circuit ansatze to encode a many-body wavefunction is one of the keys for the success of a VQA. Great efforts have been invested to study the potential of current quantum devices to encode the eigenstates of fermionic systems, but little is known about the encoding of bosonic systems. In this work, we investigate the encoding of the ground state of the (simple but rich) attractive Bose-Hubbard model using a Continuous-Variable (CV) photonic-based quantum circuit. We introduce two different ansatz architectures and demonstrate that the proposed continuous variable quantum circuits can efficiently encode (with a fidelity higher than 99%) the strongly correlated many-boson wavefunction with just a few layers, in all many-body regimes and for different number of bosons and initial states. Beyond the study of the suitability of the ansatz to approximate the ground states of many-boson systems, we also perform initial evaluations of the use of the ansatz in a variational quantum eigensolver algorithm to find it through energy minimization. To this end we also introduce a scheme to measure the Hamiltonian energy in an experimental system, and study the effect of sampling noise.",
           4,
           "quantum"
          ],
          [
           "Towards Quantum Gravity in the Lab on Quantum Processors",
           "10.22331/q-2023-10-12-1138",
           2023,
           "The holographic principle and its realization in the AdS/CFT correspondence led to unexpected connections between general relativity and quantum information. This set the stage for studying aspects of quantum gravity models, which are otherwise difficult to access, in table-top quantum-computational experiments. Recent works have designed a special teleportation protocol that realizes a surprising communication phenomenon most naturally explained by the physics of a traversable wormhole. In this work, we have carried out quantum experiments based on this protocol on state-of-the-art quantum computers. The target quantum processing units (QPUs) included the Quantinuum's trapped-ion System Model H1-1 and five IBM superconducting QPUs of various architectures, with public and premium user access. We report the observed teleportation signals from these QPUs with the best one reaching 80% of theoretical predictions. We outline the experimental challenges we have faced in the course of implementation, as well as the new theoretical insights into quantum dynamics the work has led to. We also developed QGLab – an open-source end-to-end software solution that facilitates conducting the wormhole-inspired teleportation experiments on state-of-the-art and emergent generations of QPUs supported by the Qiskit and tket SDKs. We consider our study and deliverables as an early practical step towards the realization of more complex experiments for the indirect probing of quantum gravity in the lab.",
           1,
           "quantum"
          ],
          [
           "Generation of highly retrievable atom photon entanglement with a millisecond lifetime via a spatially multiplexed cavity",
           "10.22331/q-2023-01-19-903",
           2023,
           "Qubit memory that is entangled with photonic qubit is the building block for long distance quantum repeaters. Cavity enhanced and long lived spin wave photon entanglement has been demonstrated by applying dual laser beams onto optical-lattice atoms. However, owing to cross readouts by two beams, retrieval efficiency of spin wave qubit is decreased by one quarter compared to that of single mode spin wave at all storage times. Here, by coupling cold atoms to two modes of a polarization interferometer based cavity, we achieve perfect qubit retrieval in cavity enhanced and long lived atom photon entanglement. A write laser beam is applied onto cold atoms, we then create a magnetic field insensitive spin wave qubit that is entangled with the photonic qubit encoded onto two arms of the interferometer. The spin wave qubit is retrieved by a read beam, which avoids the cross readouts. Our experiment demonstrates 540&#x03BC;s storage time at 50% intrinsic qubit retrieval efficiency, which is 13.5 times longer than the best reported result.",
           4,
           "quantum"
          ],
          [
           "Fast quantum transfer mediated by topological domain walls",
           "10.22331/q-2023-06-22-1043",
           2023,
           "The duration of bidirectional transfer protocols in 1D topological models usually scales exponentially with distance. In this work, we propose transfer protocols in multidomain SSH chains and Creutz ladders that lose the exponential dependence, greatly speeding up the process with respect to their single-domain counterparts, reducing the accumulation of errors and drastically increasing their performance, even in the presence of symmetry-breaking disorder. We also investigate how to harness the localization properties of the Creutz ladder---with two localized modes per domain wall---to choose the two states along the ladder that will be swapped during the transfer protocol, without disturbing the states located in the intermediate walls between them. This provides a 1D network with all-to-all connectivity that can be helpful for quantum information purposes.",
           4,
           "quantum"
          ],
          [
           "A change of perspective: switching quantum reference frames via a perspective-neutral framework",
           "10.22331/q-2020-01-27-225",
           2020,
           "Treating reference frames fundamentally as quantum systems is inevitable in quantum gravity and also in quantum foundations once considering laboratories as physical systems. Both fields thereby face the question of how to describe physics relative to quantum reference systems and how the descriptions relative to different such choices are related. Here, we exploit a fruitful interplay of ideas from both fields to begin developing a unifying approach to transformations among quantum reference systems that ultimately aims at encompassing both quantum and gravitational physics. In particular, using a gravity inspired symmetry principle, which enforces physical observables to be relational and leads to an inherent redundancy in the description, we develop a perspective-neutral structure, which contains all frame perspectives at once and via which they are changed. We show that taking the perspective of a specific frame amounts to a fixing of the symmetry related redundancies in both the classical and quantum theory and that changing perspective corresponds to a symmetry transformation. We implement this using the language of constrained systems, which naturally encodes symmetries. Within a simple one-dimensional model, we recover some of the quantum frame transformations of \\cite{Giacomini:2017zju}, embedding them in a perspective-neutral framework. Using them, we illustrate how entanglement and classicality of an observed system depend on the quantum frame perspective. Our operational language also inspires a new interpretation of Dirac and reduced quantized theories within our model as perspective-neutral and perspectival quantum theories, respectively, and reveals the explicit link between them. In this light, we suggest a new take on the relation between a `quantum general covariance' and the diffeomorphism symmetry in quantum gravity.",
           77,
           "quantum"
          ],
          [
           "Effective versus Floquet theory for the Kerr parametric oscillator",
           "10.22331/q-2024-03-25-1298",
           2024,
           "Parametric gates and processes engineered from the perspective of the static effective Hamiltonian of a driven system are central to quantum technology. However, the perturbative expansions used to derive static effective models may not be able to efficiently capture all the relevant physics of the original system. In this work, we investigate the conditions for the validity of the usual low-order static effective Hamiltonian used to describe a Kerr oscillator under a squeezing drive. This system is of fundamental and technological interest. In particular, it has been used to stabilize Schrödinger cat states, which have applications for quantum computing. We compare the states and energies of the effective static Hamiltonian with the exact Floquet states and quasi-energies of the driven system and determine the parameter regime where the two descriptions agree. Our work brings to light the physics that is left out by ordinary static effective treatments and that can be explored by state-of-the-art experiments.",
           0,
           "quantum"
          ],
          [
           "Option Pricing using Quantum Computers",
           "10.22331/q-2020-07-06-291",
           2020,
           "We present a methodology to price options and portfolios of options on a gate-based quantum computer using amplitude estimation, an algorithm which provides a quadratic speedup compared to classical Monte Carlo methods. The options that we cover include vanilla options, multi-asset options and path-dependent options such as barrier options. We put an emphasis on the implementation of the quantum circuits required to build the input states and operators needed by amplitude estimation to price the different option types. Additionally, we show simulation results to highlight how the circuits that we implement price the different option contracts. Finally, we examine the performance of option pricing circuits on quantum hardware using the IBM Q Tokyo quantum device. We employ a simple, yet effective, error mitigation scheme that allows us to significantly reduce the errors arising from noisy two-qubit gates.",
           112,
           "quantum"
          ],
          [
           "Device-independent quantum key distribution with single-photon sources",
           "10.22331/q-2020-04-30-260",
           2020,
           "Device-independent quantum key distribution protocols allow two honest users to establish a secret key with minimal levels of trust on the provider, as security is proven without any assumption on the inner working of the devices used for the distribution. Unfortunately, the implementation of these protocols is challenging, as it requires the observation of a large Bell-inequality violation between the two distant users. Here, we introduce novel photonic protocols for device-independent quantum key distribution exploiting single-photon sources and heralding-type architectures. The heralding process is designed so that transmission losses become irrelevant for security. We then show how the use of single-photon sources for entanglement distribution in these architectures, instead of standard entangled-pair generation schemes, provides significant improvements on the attainable key rates and distances over previous proposals. Given the current progress in single-photon sources, our work opens up a promising avenue for device-independent quantum key distribution implementations.",
           34,
           "quantum"
          ],
          [
           "Nonlinear extension of the quantum dynamical semigroup",
           "10.22331/q-2021-03-23-420",
           2021,
           "In this paper we consider deterministic nonlinear time evolutions satisfying so called convex quasi-linearity condition. Such evolutions preserve the equivalence of ensembles and therefore are free from problems with signaling. We show that if family of linear non-trace-preserving maps satisfies the semigroup property then the generated family of convex quasi-linear operations also possesses the semigroup property. Next we generalize the Gorini-Kossakowski-Sudarshan-Lindblad type equation for the considered evolution. As examples we discuss the general qubit evolution in our model as well as an extension of the Jaynes-Cummings model. We apply our formalism to spin density matrix of a charged particle moving in the electromagnetic field as well as to flavor evolution of solar neutrinos.",
           8,
           "quantum"
          ],
          [
           "Entanglement Spectroscopy and probing the Li-Haldane Conjecture in Topological Quantum Matter",
           "10.22331/q-2022-04-27-702",
           2022,
           "Topological phases are characterized by their entanglement properties, which is manifest in a direct relation between entanglement spectra and edge states discovered by Li and Haldane. We propose to leverage the power of synthetic quantum systems for measuring entanglement via the Entanglement Hamiltonian to probe this relationship experimentally. This is made possible by exploiting the quasi-local structure of Entanglement Hamiltonians. The feasibility of this proposal is illustrated for two paradigmatic examples realizable with current technology, an integer quantum Hall state of non-interacting fermions on a 2D lattice and a symmetry protected topological state of interacting fermions on a 1D chain. Our results pave the road towards an experimental identification of topological order in strongly correlated quantum many-body systems.",
           7,
           "quantum"
          ],
          [
           "Flag fault-tolerant error correction with arbitrary distance codes",
           "10.22331/q-2018-02-08-53",
           2018,
           "In this paper we introduce a general fault-tolerant quantum error correction protocol using flag circuits for measuring stabilizers of arbitrary distance codes. In addition to extending flag error correction beyond distance-three codes for the first time, our protocol also applies to a broader class of distance-three codes than was previously known. Flag circuits use extra ancilla qubits to signal when errors resulting fromvfaults in the circuit have weight greater thanv. The flag error correction protocol is applicable to stabilizer codes of arbitrary distance which satisfy a set of conditions and uses fewer qubits than other schemes such as Shor, Steane and Knill error correction. We give examples of infinite code families which satisfy these conditions and analyze the behaviour of distance-three and -five examples numerically. Requiring fewer resources than Shor error correction, flag error correction could potentially be used in low-overhead fault-tolerant error correction protocols using low density parity check quantum codes of large code length.",
           79,
           "quantum"
          ],
          [
           "Efficient classical simulation of noisy random quantum circuits in one dimension",
           "10.22331/q-2020-09-11-318",
           2020,
           "Understanding the computational power of noisy intermediate-scale quantum (NISQ) devices is of both fundamental and practical importance to quantum information science. Here, we address the question of whether error-uncorrected noisy quantum computers can provide computational advantage over classical computers. Specifically, we study noisy random circuit sampling in one dimension (or 1D noisy RCS) as a simple model for exploring the effects of noise on the computational power of a noisy quantum device. In particular, we simulate the real-time dynamics of 1D noisy random quantum circuits via matrix product operators (MPOs) and characterize the computational power of the 1D noisy quantum system by using a metric we call MPO entanglement entropy. The latter metric is chosen because it determines the cost of classical MPO simulation. We numerically demonstrate that for the two-qubit gate error rates we considered, there exists a characteristic system size above which adding more qubits does not bring about an exponential growth of the cost of classical MPO simulation of 1D noisy systems. Specifically, we show that above the characteristic system size, there is an optimal circuit depth, independent of the system size, where the MPO entanglement entropy is maximized. Most importantly, the maximum achievable MPO entanglement entropy is bounded by a constant that depends only on the gate error rate, not on the system size. We also provide a heuristic analysis to get the scaling of the maximum achievable MPO entanglement entropy as a function of the gate error rate. The obtained scaling suggests that although the cost of MPO simulation does not increase exponentially in the system size above a certain characteristic system size, it does increase exponentially as the gate error rate decreases, possibly making classical simulation practically not feasible even with state-of-the-art supercomputers.",
           48,
           "quantum"
          ],
          [
           "Modeling and mitigation of cross-talk effects in readout noise with applications to the Quantum Approximate Optimization Algorithm",
           "10.22331/q-2021-06-01-464",
           2021,
           "Measurement noise is one of the main sources of errors in currently available quantum devices based on superconducting qubits. At the same time, the complexity of its characterization and mitigation often exhibits exponential scaling with the system size. In this work, we introduce a correlated measurement noise model that can be efficiently described and characterized, and which admits effective noise-mitigation on the level of marginal probability distributions. Noise mitigation can be performed up to some error for which we derive upper bounds. Characterization of the model is done efficiently using Diagonal Detector Overlapping Tomography – a generalization of the recently introduced Quantum Overlapping Tomography to the problem of reconstruction of readout noise with restricted locality. The procedure allows to characterizek-local measurement cross-talk onN-qubit device usingO(k2klog(N))circuits containing random combinations of X and identity gates. We perform experiments on 15 (23) qubits using IBM's (Rigetti's) devices to test both the noise model and the error-mitigation scheme, and obtain an average reduction of errors by a factor>22(>5.5) compared to no mitigation. Interestingly, we find that correlations in the measurement noise do not correspond to the physical layout of the device. Furthermore, we study numerically the effects of readout noise on the performance of the Quantum Approximate Optimization Algorithm (QAOA). We observe in simulations that for numerous objective Hamiltonians, including random MAX-2-SAT instances and the Sherrington-Kirkpatrick model, the noise-mitigation improves the quality of the optimization. Finally, we provide arguments why in the course of QAOA optimization the estimates of the local energy (or cost) terms often behave like uncorrelated variables, which greatly reduces sampling complexity of the energy estimation compared to the pessimistic error analysis. We also show that similar effects are expected for Haar-random quantum states and states generated by shallow-depth random circuits.",
           21,
           "quantum"
          ],
          [
           "Semi-device-independent framework based on natural physical assumptions",
           "10.22331/q-2017-11-18-33",
           2017,
           "The semi-device-independent approach provides a framework for prepare-and-measure quantum protocols using devices whose behavior must not be characterized nor trusted, except for a single assumption on the dimension of the Hilbert space characterizing the quantum carriers. Here, we propose instead to constrain the quantum carriers through a bound on the mean value of a well-chosen observable. This modified assumption is physically better motivated than a dimension bound and closer to the description of actual experiments. In particular, we consider quantum optical schemes where the source emits quantum states described in an infinite-dimensional Fock space and model our assumption as an upper bound on the average photon number in the emitted states. We characterize the set of correlations that may be exhibited in the simplest possible scenario compatible with our new framework, based on two energy-constrained state preparations and a two-outcome measurement. Interestingly, we uncover the existence of quantum correlations exceeding the set of classical correlations that can be produced by devices behaving in a purely pre-determined fashion (possibly including shared randomness). This feature suggests immediate applications to certified randomness generation. Along this line, we analyze the achievable correlations in several prepare-and-measure optical schemes with a mean photon number constraint and demonstrate that they allow for the generation of certified randomness. Our simplest optical scheme works by the on-off keying of an attenuated laser source followed by photocounting. It opens the path to more sophisticated energy-constrained semi-device-independent quantum cryptography protocols, such as quantum key distribution.",
           57,
           "quantum"
          ],
          [
           "There and back again: A circuit extraction tale",
           "10.22331/q-2021-03-25-421",
           2021,
           "Translations between the quantum circuit model and the measurement-based one-way model are useful for verification and optimisation of quantum computations. They make crucial use of a property known as gflow. While gflow is defined for one-way computations allowing measurements in three different planes of the Bloch sphere, most research so far has focused on computations containing only measurements in the XY-plane. Here, we give the first circuit-extraction algorithm to work for one-way computations containing measurements in all three planes and having gflow. The algorithm is efficient and the resulting circuits do not contain ancillae. One-way computations are represented using the ZX-calculus, hence the algorithm also represents the most general known procedure for extracting circuits from ZX-diagrams. In developing this algorithm, we generalise several concepts and results previously known for computations containing only XY-plane measurements. We bring together several known rewrite rules for measurement patterns and formalise them in a unified notation using the ZX-calculus. These rules are used to simplify measurement patterns by reducing the number of qubits while preserving both the semantics and the existence of gflow. The results can be applied to circuit optimisation by translating circuits to patterns and back again.",
           27,
           "quantum"
          ],
          [
           "The Synthetic Hilbert Space of Laser-Driven Free-Electrons",
           "10.22331/q-2023-01-03-888",
           2023,
           "Recent advances in laser interactions with coherent free electrons have enabled to shape the electron&apos;s quantum state. Each electron becomes a superposition of energy levels on an infinite quantized ladder, shown to contain up to thousands of energy levels. We propose to utilize the quantum nature of such laser-driven free electrons as a \"synthetic Hilbert space\" in which we construct and control qudits (quantum digits). The question that motivates our work is what qudit states can be accessed using electron-laser interactions, and whether it is possible to implement any arbitrary quantum gate. We find how to encode and manipulate free-electron qudit states, focusing on dimensions which are powers of 2, where the qudit represents multiple qubits implemented on the same single electron – algebraically separated, but physically joined. As an example, we prove the possibility to fully control a 4-dimenisonal qudit, and reveal the steps required for full control over any arbitrary dimension. Our work enriches the range of applications of free electrons in microscopy and spectroscopy, offering a new platform for continuous-variable quantum information.",
           2,
           "quantum"
          ],
          [
           "Classical zero-knowledge arguments for quantum computations",
           "10.22331/q-2020-05-14-266",
           2020,
           "We show that every language in QMA admits a classical-verifier, quantum-prover zero-knowledge argument system which is sound against quantum polynomial-time provers and zero-knowledge for classical (and quantum) polynomial-time verifiers. The protocol builds upon two recent results: a computational zero-knowledge proof system for languages in QMA, with a quantum verifier, introduced by Broadbent et al. (FOCS 2016), and an argument system for languages in QMA, with a classical verifier, introduced by Mahadev (FOCS 2018).",
           8,
           "quantum"
          ],
          [
           "Dynamical many-body delocalization transition of a Tonks gas in a quasi-periodic driving potential",
           "10.22331/q-2023-02-09-917",
           2023,
           "The quantum kicked rotor is well-known for displaying dynamical (Anderson) localization. It has recently been shown that a periodically kicked Tonks gas will always localize and converge to a finite energy steady-state. This steady-state has been described as being effectively thermal with an effective temperature that depends on the parameters of the kick. Here we study a generalization to a quasi-periodic driving with three frequencies which, without interactions, has a metal-insulator Anderson transition. We show that a quasi-periodically kicked Tonks gas goes through a dynamical many-body delocalization transition when the kick strength is increased. The localized phase is still described by a low effective temperature, while the delocalized phase corresponds to an infinite-temperature phase, with the temperature increasing linearly in time. At the critical point, the momentum distribution of the Tonks gas displays different scaling at small and large momenta (contrary to the non-interacting case), signaling a breakdown of the one-parameter scaling theory of localization.",
           2,
           "quantum"
          ],
          [
           "Pulse-efficient quantum machine learning",
           "10.22331/q-2023-10-09-1130",
           2023,
           "Quantum machine learning algorithms based on parameterized quantum circuits are promising candidates for near-term quantum advantage. Although these algorithms are compatible with the current generation of quantum processors, device noise limits their performance, for example by inducing an exponential flattening of loss landscapes. Error suppression schemes such as dynamical decoupling and Pauli twirling alleviate this issue by reducing noise at the hardware level. A recent addition to this toolbox of techniques is pulse-efficient transpilation, which reduces circuit schedule duration by exploiting hardware-native cross-resonance interaction. In this work, we investigate the impact of pulse-efficient circuits on near-term algorithms for quantum machine learning. We report results for two standard experiments: binary classification on a synthetic dataset with quantum neural networks and handwritten digit recognition with quantum kernel estimation. In both cases, we find that pulse-efficient transpilation vastly reduces average circuit durations and, as a result, significantly improves classification accuracy. We conclude by applying pulse-efficient transpilation to the Hamiltonian Variational Ansatz and show that it delays the onset of noise-induced barren plateaus.",
           2,
           "quantum"
          ],
          [
           "Quantum Methods for Neural Networks and Application to Medical Image Classification",
           "10.22331/q-2022-12-22-881",
           2022,
           "Quantum machine learning techniques have been proposed as a way to potentially enhance performance in machine learning applications.\nIn this paper, we introduce two new quantum methods for neural networks. The first one is a quantum orthogonal neural network, which is based on a quantum pyramidal circuit as the building block for implementing orthogonal matrix multiplication. We provide an efficient way for training such orthogonal neural networks; novel algorithms are detailed for both classical and quantum hardware, where both are proven to scale asymptotically better than previously known training algorithms.\nThe second method is quantum-assisted neural networks, where a quantum computer is used to perform inner product estimation for inference and training of classical neural networks.\nWe then present extensive experiments applied to medical image classification tasks using current state of the art quantum hardware, where we compare different quantum methods with classical ones, on both real quantum hardware and simulators. Our results show that quantum and classical neural networks generates similar level of accuracy, supporting the promise that quantum methods can be useful in solving visual tasks, given the advent of better quantum hardware.",
           11,
           "quantum"
          ],
          [
           "An efficient high dimensional quantum Schur transform",
           "10.22331/q-2019-02-14-122",
           2019,
           "The Schur transform is a unitary operator that block diagonalizes the action of the symmetric and unitary groups on an n fold tensor product V⊗n of a vector space V of dimension d. Bacon, Chuang and Harrow [5] gave a quantum algorithm for this transform that is polynomial in n, d and log⁡ϵ−1, where ϵ is the precision. In a footnote in Harrow's thesis [18], a brief description of how to make the algorithm of [5] polynomial in log⁡d is given using the unitary group representation theory (however, this has not been explained in detail anywhere). In this article, we present a quantum algorithm for the Schur transform that is polynomial in n, log⁡d and log⁡ϵ−1 using a different approach. Specifically, we build this transform using the representation theory of the symmetric group and in this sense our technique can be considered a ''dual\" algorithm to [5]. A novel feature of our algorithm is that we construct the quantum Fourier transform over the so called permutation modules, which could have other applications.",
           18,
           "quantum"
          ],
          [
           "Distributing Multipartite Entanglement over Noisy Quantum Networks",
           "10.22331/q-2023-02-09-920",
           2023,
           "A quantum internet aims at harnessing networked quantum technologies, namely by distributing bipartite entanglement between distant nodes. However, multipartite entanglement between the nodes may empower the quantum internet for additional or better applications for communications, sensing, and computation. In this work, we present an algorithm for generating multipartite entanglement between different nodes of a quantum network with noisy quantum repeaters and imperfect quantum memories, where the links are entangled pairs. Our algorithm is optimal for GHZ states with 3 qubits, maximising simultaneously the final state fidelity and the rate of entanglement distribution. Furthermore, we determine the conditions yielding this simultaneous optimality for GHZ states with a higher number of qubits, and for other types of multipartite entanglement. Our algorithm is general also in the sense that it can optimise simultaneously arbitrary parameters. This work opens the way to optimally generate multipartite quantum correlations over noisy quantum networks, an important resource for distributed quantum technologies.",
           16,
           "quantum"
          ],
          [
           "The Fermionic Quantum Emulator",
           "10.22331/q-2021-10-27-568",
           2021,
           "The fermionic quantum emulator (FQE) is a collection of protocols for emulating quantum dynamics of fermions efficiently taking advantage of common symmetries present in chemical, materials, and condensed-matter systems. The library is fully integrated with the OpenFermion software package and serves as the simulation backend. The FQE reduces memory footprint by exploiting number and spin symmetry along with custom evolution routines for sparse and dense Hamiltonians, allowing us to study significantly larger quantum circuits at modest computational cost when compared against qubit state vector simulators. This release paper outlines the technical details of the simulation methods and key advantages.",
           10,
           "quantum"
          ],
          [
           "Experimental entanglement of temporal order",
           "10.22331/q-2022-01-11-621",
           2022,
           "The study of causal relations has recently been applied to the quantum realm, leading to the discovery that not all physical processes have a definite causal structure. While indefinite causal processes have previously been experimentally shown, these proofs relied on the quantum description of the experiments. Yet, the same experimental data could also be compatible with definite causal structures within different descriptions. Here, we present the first demonstration of indefinite temporal order outside of quantum formalism. We show that our experimental outcomes are incompatible with a class of generalised probabilistic theories satisfying the assumptions of locality and definite temporal order. To this end, we derive physical constraints (in the form of a Bell-like inequality) on experimental outcomes within such a class of theories. We then experimentally invalidate these theories by violating the inequality using entangled temporal order. This provides experimental evidence that there exist correlations in nature which are incompatible with the assumptions of locality and definite temporal order.",
           25,
           "quantum"
          ],
          [
           "Compiling Quantum Circuits for Dynamically Field-Programmable Neutral Atoms Array Processors",
           "10.22331/q-2024-03-14-1281",
           2024,
           "Dynamically field-programmable qubit arrays (DPQA) have recently emerged as a promising platform for quantum information processing. In DPQA, atomic qubits are selectively loaded into arrays of optical traps that can be reconfigured during the computation itself. Leveraging qubit transport and parallel, entangling quantum operations, different pairs of qubits, even those initially far away, can be entangled at different stages of the quantum program execution. Such reconfigurability and non-local connectivity present new challenges for compilation, especially in the layout synthesis step which places and routes the qubits and schedules the gates. In this paper, we consider a DPQA architecture that contains multiple arrays and supports 2D array movements, representing cutting-edge experimental platforms. Within this architecture, we discretize the state space and formulate layout synthesis as a satisfiability modulo theories problem, which can be solved by existing solvers optimally in terms of circuit depth. For a set of benchmark circuits generated by random graphs with complex connectivities, our compiler OLSQ-DPQA reduces the number of two-qubit entangling gates on small problem instances by 1.7x compared to optimal compilation results on a fixed planar architecture. To further improve scalability and practicality of the method, we introduce a greedy heuristic inspired by the iterative peeling approach in classical integrated circuit routing. Using a hybrid approach that combined the greedy and optimal methods, we demonstrate that our DPQA-based compiled circuits feature reduced scaling overhead compared to a grid fixed architecture, resulting in 5.1X less two-qubit gates for 90 qubit quantum circuits. These methods enable programmable, complex quantum circuits with neutral atom quantum computers, as well as informing both future compilers and future hardware choices.",
           1,
           "quantum"
          ],
          [
           "By-passing fluctuation theorems",
           "10.22331/q-2020-02-20-231",
           2020,
           "Fluctuation theorems impose constraints on possible work extraction probabilities in thermodynamical processes. These constraints are stronger than the usual second law, which is concerned only with average values. Here, we show that such constraints, expressed in the form of the Jarzysnki equality, can be by-passed if one allows for the use of catalysts---additional degrees of freedom that may become correlated with the system from which work is extracted, but whose reduced state remains unchanged so that they can be re-used. This violation can be achieved both for small systems but also for macroscopic many-body systems, and leads to positive work extraction per particle with finite probability from macroscopic states in equilibrium. In addition to studying such violations for a single system, we also discuss the scenario in which many parties use the same catalyst to induce local transitions. We show that there exist catalytic processes that lead to highly correlated work distributions, expected to have implications for stochastic and quantum thermodynamics.",
           12,
           "quantum"
          ],
          [
           "Modeling noise and error correction for Majorana-based quantum computing",
           "10.22331/q-2018-09-03-88",
           2018,
           "Majorana-based quantum computing seeks to use the non-local nature of Majorana zero modes to store and manipulate quantum information in a topologically protected way. While noise is anticipated to be significantly suppressed in such systems, finite temperature and system size result in residual errors. In this work, we connect the underlying physical error processes in Majorana-based systems to the noise models used in a fault tolerance analysis. Standard qubit-based noise models built from Pauli operators do not capture leading order noise processes arising from quasiparticle poisoning events, thus it is not obviousa priorithat such noise models can be usefully applied to a Majorana-based system. We develop stochastic Majorana noise models that are generalizations of the standard qubit-based models and connect the error probabilities defining these models to parameters of the physical system. Using these models, we compute pseudo-thresholds for thed=5Bacon-Shor subsystem code. Our results emphasize the importance of correlated errors induced in multi-qubit measurements. Moreover, we find that for sufficiently fast quasiparticle relaxation the errors are well described by Pauli operators. This work bridges the divide between physical errors in Majorana-based quantum computing architectures and the significance of these errors in a quantum error correcting code.",
           16,
           "quantum"
          ],
          [
           "The Power of Adiabatic Quantum Computation with No Sign Problem",
           "10.22331/q-2021-12-06-597",
           2021,
           "We show a superpolynomial oracle separation between the power of adiabatic quantum computation with no sign problem and the power of classical computation.",
           14,
           "quantum"
          ],
          [
           "The first law of general quantum resource theories",
           "10.22331/q-2020-04-30-259",
           2020,
           "We extend the tools of quantum resource theories to scenarios in which multiple quantities (or resources) are present, and their interplay governs the evolution of physical systems. We derive conditions for the interconversion of these resources, which generalise the first law of thermodynamics. We study reversibility conditions for multi-resource theories, and find that the relative entropy distances from the invariant sets of the theory play a fundamental role in the quantification of the resources. The first law for general multi-resource theories is a single relation which links the change in the properties of the system during a state transformation and the weighted sum of the resources exchanged. In fact, this law can be seen as relating the change in the relative entropy from different sets of states. In contrast to typical single-resource theories, the notion of free states and invariant sets of states become distinct in light of multiple constraints. Additionally, generalisations of the Helmholtz free energy, and of adiabatic and isothermal transformations, emerge. We thus have a set of laws for general quantum resource theories, which generalise the laws of thermodynamics. We first test this approach on thermodynamics with multiple conservation laws, and then apply it to the theory of local operations under energetic restrictions.",
           24,
           "quantum"
          ],
          [
           "Efficient solution of the non-unitary time-dependent Schrodinger equation on a quantum computer with complex absorbing potential",
           "10.22331/q-2024-04-08-1311",
           2024,
           "We explore the possibility of adding complex absorbing potential at the boundaries when solving the one-dimensional real-time Schrödinger evolution on a grid using a quantum computer with a fully quantum algorithm described on a n qubit register. Due to the complex potential, the evolution mixes real- and imaginary-time propagation and the wave function can potentially be continuously absorbed during the time propagation. We use the dilation quantum algorithm to treat the imaginary-time evolution in parallel to the real-time propagation. This method has the advantage of using only one reservoir qubit at a time, that is measured with a certain success probability to implement the desired imaginary-time evolution. We propose a specific prescription for the dilation method where the success probability is directly linked to the physical norm of the continuously absorbed state evolving on the mesh. We expect that the proposed prescription will have the advantage of keeping a high probability of success in most physical situations. Applications of the method are made on one-dimensional wave functions evolving on a mesh. Results obtained on a quantum computer identify with those obtained on a classical computer. We finally give a detailed discussion on the complexity of implementing the dilation matrix. Due to the local nature of the potential, for n qubits, the dilation matrix only requires 2n CNOT and 2n unitary rotation for each time step, whereas it would require of the order of 4n+1 C-NOT gates to implement it using the best-known algorithm for general unitary matrices.",
           0,
           "quantum"
          ],
          [
           "Causal structure in the presence of sectorial constraints, with application to the quantum switch",
           "10.22331/q-2023-06-01-1028",
           2023,
           "Existing work on quantum causal structure assumes that one can perform arbitrary operations on the systems of interest. But this condition is often not met. Here, we extend the framework for quantum causal modelling to situations where a system can suffer sectorial constraints, that is, restrictions on the orthogonal subspaces of its Hilbert space that may be mapped to one another. Our framework (a) proves that a number of different intuitions about causal relations turn out to be equivalent; (b) shows that quantum causal structures in the presence of sectorial constraints can be represented with a directed graph; and (c) defines a fine-graining of the causal structure in which the individual sectors of a system bear causal relations. As an example, we apply our framework to purported photonic implementations of the quantum switch to show that while their coarse-grained causal structure is cyclic, their fine-grained causal structure is acyclic. We therefore conclude that these experiments realize indefinite causal order only in a weak sense. Notably, this is the first argument to this effect that is not rooted in the assumption that the causal relata must be localized in spacetime.",
           5,
           "quantum"
          ],
          [
           "The arrow of time in operational formulations of quantum theory",
           "10.22331/q-2021-08-09-520",
           2021,
           "The operational formulations of quantum theory are drastically time oriented. However, to the best of our knowledge, microscopic physics is time-symmetric. We address this tension by showing that the asymmetry of the operational formulations does not reflect a fundamental time-orientation of physics. Instead, it stems from built-in assumptions about the users of the theory. In particular, these formalisms are designed for predicting the future based on information about the past, and the main mathematical objects contain implicit assumption about the past, but not about the future. The main asymmetry in quantum theory is the difference between knowns and unknowns.",
           15,
           "quantum"
          ],
          [
           "Exact and efficient Lanczos method on a quantum computer",
           "10.22331/q-2023-05-23-1018",
           2023,
           "We present an algorithm that uses block encoding on a quantum computer to exactly construct a Krylov space, which can be used as the basis for the Lanczos method to estimate extremal eigenvalues of Hamiltonians. While the classical Lanczos method has exponential cost in the system size to represent the Krylov states for quantum systems, our efficient quantum algorithm achieves this in polynomial time and memory. The construction presented is exact in the sense that the resulting Krylov space is identical to that of the Lanczos method, so the only approximation with respect to the exact method is due to finite sample noise. This is possible because, unlike previous quantum Krylov methods, our algorithm does not require simulating real or imaginary time evolution. We provide an explicit error bound for the resulting ground state energy estimate in the presence of noise. For our method to be successful efficiently, the only requirement on the input problem is that the overlap of the initial state with the true ground state must be &#x03A9;(1/poly(n)) for n qubits.",
           9,
           "quantum"
          ],
          [
           "Error mitigation with Clifford quantum-circuit data",
           "10.22331/q-2021-11-26-592",
           2021,
           "Achieving near-term quantum advantage will require accurate estimation of quantum observables despite significant hardware noise. For this purpose, we propose a novel, scalable error-mitigation method that applies to gate-based quantum computers. The method generates training data {Xinoisy,Xiexact} via quantum circuits composed largely of Clifford gates, which can be efficiently simulated classically, where Xinoisy and Xiexact are noisy and noiseless observables respectively. Fitting a linear ansatz to this data then allows for the prediction of noise-free observables for arbitrary circuits. We analyze the performance of our method versus the number of qubits, circuit depth, and number of non-Clifford gates. We obtain an order-of-magnitude error reduction for a ground-state energy problem on 16 qubits in an IBMQ quantum computer and on a 64-qubit noisy simulator.",
           100,
           "quantum"
          ],
          [
           "Classical shadows based on locally-entangled measurements",
           "10.22331/q-2024-03-21-1293",
           2024,
           "We study classical shadows protocols based on randomized measurements in n-qubit entangled bases, generalizing the random Pauli measurement protocol (n=1). We show that entangled measurements (n&#x2265;2) enable nontrivial and potentially advantageous trade-offs in the sample complexity of learning Pauli expectation values. This is sharply illustrated by shadows based on two-qubit Bell measurements: the scaling of sample complexity with Pauli weight k improves quadratically (from &#x223C;3k down to &#x223C;3k/2) for many operators, while others become impossible to learn. Tuning the amount of entanglement in the measurement bases defines a family of protocols that interpolate between Pauli and Bell shadows, retaining some of the benefits of both. For large n, we show that randomized measurements in n-qubit GHZ bases further improve the best scaling to &#x223C;(3/2)k, albeit on an increasingly restricted set of operators. Despite their simplicity and lower hardware requirements, these protocols can match or outperform recently-introduced \"shallow shadows\" in some practically-relevant Pauli estimation tasks.",
           1,
           "quantum"
          ],
          [
           "Transformations of Stabilizer States in Quantum Networks",
           "10.22331/q-2022-10-25-846",
           2022,
           "Stabilizer states and graph states find application in quantum error correction, measurement-based quantum computation and various other concepts in quantum information theory. In this work, we study party-local Clifford (PLC) transformations among stabilizer states. These transformations arise as a physically motivated extension of local operations in quantum networks with access to bipartite entanglement between some of the nodes of the network. First, we show that PLC transformations among graph states are equivalent to a generalization of the well-known local complementation, which describes local Clifford transformations among graph states. Then, we introduce a mathematical framework to study PLC equivalence of stabilizer states, relating it to the classification of tuples of bilinear forms. This framework allows us to study decompositions of stabilizer states into tensor products of indecomposable ones, that is, decompositions into states from the entanglement generating set (EGS). While the EGS is finite up to 3 parties [Bravyi et al., J. Math. Phys. 47, 062106 (2006)], we show that for 4 and more parties it is an infinite set, even when considering party-local unitary transformations. Moreover, we explicitly compute the EGS for 4 parties up to 10 qubits. Finally, we generalize the framework to qudit stabilizer states in prime dimensions not equal to 2, which allows us to show that the decomposition of qudit stabilizer states into states from the EGS is unique.",
           3,
           "quantum"
          ],
          [
           "Driven-dissipative topological phases in parametric resonator arrays",
           "10.22331/q-2023-05-23-1016",
           2023,
           "We study the phenomena of topological amplification in arrays of parametric oscillators. We find two phases of topological amplification, both with directional transport and exponential gain with the number of sites, and one of them featuring squeezing. We also find a topologically trivial phase with zero-energy modes which produces amplification but lacks the robust topological protection of the others. We characterize the resilience to disorder of the different phases and their stability, gain, and noise-to-signal ratio. Finally, we discuss their experimental implementation with state-of-the-art techniques.",
           4,
           "quantum"
          ],
          [
           "Fault-tolerant quantum computation of molecular observables",
           "10.22331/q-2023-11-06-1164",
           2023,
           "Over the past three decades significant reductions have been made to the cost of estimating ground-state energies of molecular Hamiltonians with quantum computers. However, comparatively little attention has been paid to estimating the expectation values of other observables with respect to said ground states, which is important for many industrial applications. In this work we present a novel expectation value estimation (EVE) quantum algorithm which can be applied to estimate the expectation values of arbitrary observables with respect to any of the system&apos;s eigenstates. In particular, we consider two variants of EVE: std-EVE, based on standard quantum phase estimation, and QSP-EVE, which utilizes quantum signal processing (QSP) techniques. We provide rigorous error analysis for both both variants and minimize the number of individual phase factors for QSPEVE. These error analyses enable us to produce constant-factor quantum resource estimates for both std-EVE and QSP-EVE across a variety of molecular systems and observables. For the systems considered, we show that QSP-EVE reduces (Toffoli) gate counts by up to three orders of magnitude and reduces qubit width by up to 25% compared to std-EVE. While estimated resource counts remain far too high for the first generations of fault-tolerant quantum computers, our estimates mark a first of their kind for both the application of expectation value estimation and modern QSP-based techniques.",
           3,
           "quantum"
          ],
          [
           "Adaptive Quantum State Tomography with Active Learning",
           "10.22331/q-2023-10-09-1129",
           2023,
           "Recently, tremendous progress has been made in the field of quantum science and technologies: different platforms for quantum simulation as well as quantum computing, ranging from superconducting qubits to neutral atoms, are starting to reach unprecedentedly large systems. In order to benchmark these systems and gain physical insights, the need for efficient tools to characterize quantum states arises. The exponential growth of the Hilbert space with system size renders a full reconstruction of the quantum state prohibitively demanding in terms of the number of necessary measurements. Here we propose and implement an efficient scheme for quantum state tomography using active learning. Based on a few initial measurements, the active learning protocol proposes the next measurement basis, designed to yield the maximum information gain. We apply the active learning quantum state tomography scheme to reconstruct different multi-qubit states with varying degree of entanglement as well as to ground states of the XXZ model in 1D and a kinetically constrained spin chain. In all cases, we obtain a significantly improved reconstruction as compared to a reconstruction based on the exact same number of measurements and measurement configurations, but with randomly chosen basis configurations. Our scheme is highly relevant to gain physical insights in quantum many-body systems as well as for benchmarking and characterizing quantum devices, e.g. for quantum simulation, and paves the way for scalable adaptive protocols to probe, prepare, and manipulate quantum systems.",
           2,
           "quantum"
          ],
          [
           "Gate Set Tomography",
           "10.22331/q-2021-10-05-557",
           2021,
           "Gate set tomography (GST) is a protocol for detailed, predictive characterization of logic operations (gates) on quantum computing processors. Early versions of GST emerged around 2012-13, and since then it has been refined, demonstrated, and used in a large number of experiments. This paper presents the foundations of GST in comprehensive detail. The most important feature of GST, compared to older state and process tomography protocols, is that it is calibration-free. GST does not rely on pre-calibrated state preparations and measurements. Instead, it characterizes all the operations in a gate set simultaneously and self-consistently, relative to each other. Long sequence GST can estimate gates with very high precision and efficiency, achieving Heisenberg scaling in regimes of practical interest. In this paper, we cover GST's intellectual history, the techniques and experiments used to achieve its intended purpose, data analysis, gauge freedom and fixing, error bars, and the interpretation of gauge-fixed estimates of gate sets. Our focus is fundamental mathematical aspects of GST, rather than implementation details, but we touch on some of the foundational algorithmic tricks used in the pyGSTi implementation.",
           83,
           "quantum"
          ]
         ],
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "Tamanho do Abstract=%{x}<br>title=%{customdata[0]}<br>doi=%{customdata[1]}<br>year=%{customdata[2]}<br>abstract=%{customdata[3]}<br>is_referenced_by_count=%{customdata[4]}<br>journal=%{customdata[5]}<extra></extra>",
         "jitter": 0,
         "legendgroup": "",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#636efa",
          "symbol": "line-ns-open"
         },
         "name": "",
         "offsetgroup": "",
         "showlegend": false,
         "type": "box",
         "x": [
          1165,
          1151,
          1532,
          1402,
          1395,
          1458,
          1800,
          1463,
          2486,
          1164,
          1268,
          1814,
          1199,
          1403,
          847,
          1006,
          768,
          1831,
          1347,
          1186,
          1673,
          1203,
          1725,
          1509,
          1072,
          1322,
          1364,
          1765,
          1457,
          1648,
          1099,
          1183,
          724,
          1422,
          866,
          1689,
          1045,
          1551,
          1492,
          966,
          813,
          1294,
          1189,
          729,
          1787,
          1073,
          1471,
          1507,
          1281,
          1118,
          1326,
          577,
          1100,
          1462,
          1568,
          1615,
          1360,
          1379,
          1040,
          1598,
          1751,
          1134,
          1130,
          1608,
          993,
          1012,
          1518,
          1379,
          1793,
          1398,
          1487,
          1788,
          1912,
          1646,
          2191,
          1179,
          1760,
          1056,
          1288,
          1873,
          1171,
          1193,
          1361,
          1168,
          1072,
          1631,
          1258,
          1698,
          1167,
          1475,
          1169,
          1409,
          1164,
          1449,
          1409,
          696,
          1222,
          1393,
          1258,
          1164,
          1844,
          1377,
          1404,
          1197,
          1288,
          1423,
          851,
          77,
          1886,
          1272,
          1258,
          1422,
          1353,
          1631,
          1140,
          1024,
          1493,
          1647,
          1347,
          1308,
          1904,
          1341,
          1060,
          1640,
          1433,
          1561,
          1435,
          1638,
          1267,
          948,
          1435,
          1443,
          1764,
          84,
          2068,
          1618,
          1635,
          1698,
          1354,
          1392,
          596,
          1418,
          1156,
          1636,
          1790,
          1062,
          1374,
          1134,
          145,
          1049,
          1310,
          1537,
          1673,
          1461,
          1462,
          1388,
          984,
          1503,
          1130,
          79,
          1372,
          1432,
          1370,
          1773,
          1480,
          1316,
          1798,
          1478,
          1908,
          1276,
          1468,
          2148,
          1866,
          1333,
          1304,
          1439,
          1745,
          705,
          50,
          1339,
          1148,
          1248,
          172,
          33,
          1259,
          1079,
          1185,
          131,
          1251,
          1666,
          1298,
          1415,
          1519,
          1051,
          1517,
          1408,
          1291,
          1315,
          1405,
          1751,
          1667,
          1174,
          1321,
          2085,
          1151,
          1163,
          1306,
          1402,
          1374,
          1107,
          2013,
          1671,
          1430,
          1491,
          1046,
          1561,
          1837,
          1439,
          1595,
          2047,
          1470,
          1886,
          2080,
          1906,
          1332,
          1532,
          1333,
          1882,
          1588,
          1489,
          1418,
          1366,
          1197,
          1161,
          1256,
          1966,
          2332,
          1648,
          1332,
          1267,
          265,
          1406,
          1259,
          1281,
          1533,
          1193,
          1281,
          1601,
          1668,
          1127,
          1353,
          1298,
          1353,
          1460,
          1103,
          1356,
          1569,
          1395,
          1741,
          1534,
          2015,
          2232,
          1466,
          1668,
          1483,
          1444,
          1459,
          1036,
          1512,
          1477,
          1949,
          1327,
          1437,
          1549,
          1907,
          2079,
          2445,
          1424,
          1952,
          1501,
          1729,
          1283,
          1376,
          2840,
          1692,
          1422,
          1936,
          1421,
          885,
          1060,
          11,
          569,
          11,
          586,
          538,
          344,
          445,
          1061,
          1479,
          837,
          596,
          1060,
          795,
          571,
          506,
          1470,
          537,
          665,
          1068,
          1116,
          948,
          855,
          1139,
          937,
          1365,
          1477,
          988,
          661,
          969,
          1208,
          1649,
          708,
          1025,
          1324,
          924,
          1412,
          1266,
          464,
          545,
          794,
          1134,
          694,
          1262,
          1141,
          868,
          593,
          897,
          1114,
          604,
          1296,
          1465,
          524,
          450,
          700,
          656,
          1142,
          1384,
          403,
          907,
          1011,
          1142,
          1210,
          902,
          746,
          1187,
          1382,
          989,
          534,
          1453,
          822,
          800,
          566,
          761,
          1340,
          1481,
          956,
          958,
          965,
          496,
          866,
          1057,
          328,
          11,
          1191,
          677,
          933,
          1144,
          937,
          796,
          1851,
          1098,
          898,
          420,
          359,
          765,
          1089,
          396,
          1391,
          994,
          795,
          951,
          928,
          849,
          561,
          994,
          1006,
          852,
          927,
          1299,
          579,
          1267,
          1060,
          307,
          897,
          652,
          985,
          794,
          1426,
          851,
          547,
          572,
          1405,
          798,
          1504,
          1446,
          982,
          1167,
          955,
          990,
          1169,
          567,
          607,
          1008,
          1091,
          1495,
          1190,
          1268,
          807,
          1328,
          1462,
          613,
          1328,
          591,
          1408,
          300,
          929,
          1379,
          1323,
          914,
          977,
          1105,
          1370,
          1272,
          598,
          1058,
          1468,
          1068,
          1048,
          375,
          1526,
          1275,
          987,
          793,
          1450,
          1012,
          977,
          909,
          1083,
          1455,
          1232,
          1032,
          632,
          1707,
          1372,
          940,
          812,
          1372,
          937,
          1255,
          1450,
          786,
          994,
          1235,
          508,
          1097,
          1781,
          423,
          588,
          1247,
          1138,
          1533,
          1375,
          314,
          1066,
          893,
          1338,
          1768,
          646,
          525,
          714,
          1518,
          1248,
          2124,
          1765,
          1304,
          1303,
          959,
          369,
          1535,
          1105,
          1299,
          2300,
          1376,
          1746,
          1437,
          1330,
          720,
          1283,
          596,
          1252,
          453,
          1915,
          2461,
          1854,
          1068,
          1291,
          470,
          863,
          1627,
          1894,
          911,
          545,
          984,
          925,
          735,
          1400,
          498,
          913,
          975,
          1484,
          2036,
          933,
          1229,
          829,
          499,
          1234,
          995,
          1138,
          1771,
          885,
          246,
          1780,
          1311,
          1277,
          686,
          1303,
          1057,
          1416,
          1286,
          1166,
          949,
          2015,
          448,
          972,
          946,
          1440,
          1361,
          1461,
          1622,
          624,
          1096,
          1228,
          1710,
          637,
          1260,
          1585,
          661,
          665,
          739,
          1485,
          1786,
          815,
          989,
          584,
          1272,
          904,
          1600,
          58,
          640,
          1225,
          1416,
          1084,
          1470,
          1265,
          961,
          1049,
          821,
          1098,
          229,
          269,
          1522,
          698,
          832,
          1365,
          659,
          1577,
          759,
          1742,
          1252,
          187,
          1283,
          1094,
          857,
          1167,
          1118,
          833,
          1126,
          1349,
          1047,
          944,
          763,
          1137,
          1396,
          992,
          1593,
          1845,
          1223,
          1407,
          1571,
          1551,
          1657,
          863,
          1666,
          855,
          1466,
          1158,
          1057,
          1466,
          869,
          373,
          1493,
          1056,
          856,
          1658,
          382,
          554,
          888,
          1189,
          1360,
          1092,
          924,
          1234,
          1790,
          1145,
          979,
          1235,
          501,
          1254,
          1128,
          631,
          1272,
          1389,
          944,
          979,
          1546,
          1125,
          1128,
          1334,
          1075,
          829,
          1206,
          1246,
          1419,
          1074,
          1602,
          1354,
          1530,
          889,
          470,
          1301,
          655,
          1507,
          1013,
          1641,
          1342,
          2915,
          1554,
          848,
          1621,
          1589,
          1240,
          1159,
          903,
          1045,
          654,
          1293,
          444,
          1346,
          805,
          1199,
          1445,
          650,
          1565,
          1547,
          996,
          1161,
          867,
          709,
          1167,
          1203,
          1426,
          965,
          591,
          1742,
          1120,
          1333,
          1169,
          1384,
          1463,
          1336,
          354,
          1205,
          1418,
          1307,
          703,
          1369,
          539,
          470,
          2147,
          1353,
          582,
          1242,
          1621,
          1090,
          669,
          1117,
          1816,
          626,
          1422,
          1040,
          415,
          1729,
          908,
          686,
          914,
          1682,
          1535,
          871,
          1322,
          1159,
          921,
          983,
          619,
          622,
          1010,
          642,
          1053,
          1672,
          1035,
          511,
          1198,
          580,
          1087,
          998,
          1079,
          336,
          586,
          1641,
          940,
          373,
          1263,
          1058,
          1073,
          1075,
          1753,
          1266,
          1346,
          1039,
          996,
          1337,
          776,
          469,
          846,
          311,
          774,
          2518,
          599,
          1438,
          1053,
          1154,
          1088,
          998,
          720,
          616,
          1324,
          1278,
          1718,
          1754,
          1829,
          1271,
          1233,
          1876,
          1227,
          1493,
          1182,
          1066,
          985,
          816,
          1067,
          1018,
          1158,
          1114,
          754,
          381,
          1414,
          1211,
          1409,
          935,
          1048,
          772,
          1364,
          908,
          1058,
          624,
          1301,
          1427,
          1190,
          447,
          1040,
          659,
          522,
          1479,
          1314,
          1279,
          707,
          1096,
          496,
          1248,
          763,
          1301,
          390,
          725,
          1163,
          1044,
          1128,
          661,
          879,
          665,
          1166,
          1472,
          1249,
          922,
          877,
          555,
          616,
          1447,
          904,
          916,
          308,
          959,
          1155,
          1041,
          1179,
          726,
          1165,
          2516,
          766,
          1003,
          1143,
          689,
          688,
          636,
          353,
          540,
          1419,
          1576,
          1003,
          1391,
          1113,
          464,
          1420,
          1014,
          874,
          771,
          929,
          1173,
          635,
          1741,
          850,
          1047,
          1174,
          1596,
          1040,
          1391,
          1201,
          1627,
          1548,
          853,
          1001,
          1592,
          1471,
          1118,
          818,
          1207,
          1164,
          1208,
          1642,
          1677,
          979,
          716,
          893,
          941,
          1163,
          1291,
          1413,
          1163,
          1023,
          553,
          1118,
          1178,
          1098,
          831,
          1746,
          880,
          847,
          1701,
          1232,
          1202,
          1439,
          930,
          709,
          413,
          719,
          707,
          912,
          820,
          1455,
          1182,
          1065,
          1291,
          984,
          548,
          1601,
          599,
          835,
          1222,
          1477,
          1642,
          1090,
          1087,
          1258,
          742,
          1814,
          951,
          949,
          850,
          1082,
          1841,
          1104,
          1207,
          433,
          682,
          743,
          1011,
          1017,
          975,
          1009,
          991,
          1173,
          813,
          793,
          411,
          758,
          757,
          278,
          543,
          1239,
          957,
          1557,
          1730,
          912,
          241,
          1422,
          1922,
          1648,
          1703,
          1288,
          878,
          1632,
          1279,
          555,
          1247,
          1146,
          1470,
          335,
          1091,
          1038,
          1223,
          1184,
          1425,
          1061,
          1916,
          1929,
          1758,
          1236,
          1487,
          1462,
          1859,
          1799,
          1524,
          1166,
          825,
          898,
          1237,
          1296,
          1515,
          1052,
          1364,
          1022,
          1134,
          1342,
          1122,
          1101,
          1224,
          1408,
          1079,
          597,
          811,
          1902,
          589,
          830,
          1757,
          1049,
          1921,
          1181,
          1093,
          847,
          995,
          1112,
          1046,
          1599,
          856,
          1041,
          456,
          1346,
          1889,
          1892,
          1182,
          1333,
          1271,
          1165,
          890,
          1109,
          1147,
          748,
          1003,
          1365,
          1801,
          749,
          1312,
          1570,
          1238,
          2566,
          1255,
          1218,
          888,
          588,
          1364,
          993,
          1543,
          1237,
          643,
          1199,
          832,
          1368,
          1136,
          1640,
          780,
          1229,
          855,
          1677,
          1674,
          890,
          1079,
          2009,
          1441,
          1391,
          1428,
          947,
          969,
          1023,
          1626,
          983,
          986,
          1191,
          1430,
          1190,
          998,
          1243,
          918,
          906,
          1567,
          1791,
          1228,
          853,
          1664,
          1309,
          1105,
          1358,
          661,
          1080,
          1323,
          875,
          1409,
          1218,
          965,
          958,
          1291,
          930,
          1313,
          1471,
          206,
          1065,
          1080,
          686,
          1942,
          1121,
          979,
          730,
          1896,
          1051,
          846,
          1241,
          1618,
          1075,
          1328,
          1486,
          1538,
          1137,
          1143,
          868,
          1326,
          971,
          699,
          1026,
          870,
          1196,
          1819,
          996,
          1811,
          1863,
          899,
          876,
          1082,
          790,
          1731,
          2014,
          1379,
          1758,
          1091,
          577,
          961,
          1097,
          938,
          1081,
          1114,
          963,
          812,
          1110,
          951,
          1425,
          1769,
          1785,
          1104,
          1594,
          1205,
          1236,
          1099,
          1636,
          1559,
          1126,
          1111,
          1387,
          1377,
          1205,
          2282,
          1185,
          1516,
          1062,
          1088,
          1640,
          1040,
          834,
          1394,
          1638,
          1419,
          1081,
          1454,
          1141,
          1926,
          1469,
          1094,
          1854,
          549,
          1346,
          1973,
          1666,
          1462,
          798,
          1106,
          913,
          1087,
          1507,
          1047,
          1148,
          2285,
          1925,
          793,
          1252,
          1291,
          862,
          1425,
          1586,
          1110,
          1653,
          1328,
          1186,
          1231,
          1157,
          2001,
          1497,
          1416,
          1108,
          1602,
          1183,
          1653,
          990,
          994,
          889,
          1917,
          1736,
          1199,
          1307,
          1116,
          1741,
          1223,
          1279,
          806,
          1647,
          756,
          1252,
          1195,
          644,
          807,
          1205,
          1470,
          1929,
          1868,
          1208,
          1334,
          1400,
          1182,
          1773,
          891,
          1391,
          502,
          896,
          850,
          1422,
          868,
          1429,
          1477,
          1041,
          1520,
          1419,
          1370,
          1279,
          1509,
          841,
          1395,
          1174,
          1070,
          1196,
          1150,
          900,
          1247,
          1376,
          1190,
          982,
          954,
          1405,
          1698,
          1065,
          1242,
          871,
          1403,
          1827,
          935,
          1077,
          920,
          1073,
          1954,
          1590,
          1344,
          861,
          2747,
          1939,
          1298,
          724,
          1449,
          1554,
          1218,
          990,
          1444,
          1547,
          1256,
          1156,
          900,
          2033,
          1024,
          1690,
          1220,
          1773,
          1294,
          1741,
          1776,
          1527,
          1681,
          1024,
          947,
          1499,
          1211,
          2074,
          1058,
          1141,
          1530,
          1102,
          1007,
          1515,
          1138,
          2029,
          1374,
          1233,
          1099,
          1269,
          1387,
          1237,
          856,
          1365,
          1295,
          1535,
          938,
          1176,
          819,
          882,
          1746,
          930,
          951,
          1239,
          1515,
          895,
          1868,
          2052,
          1820,
          998,
          1615,
          1045,
          1217,
          2019,
          2924,
          1863,
          1300,
          1007,
          1417,
          2232,
          1269,
          1814,
          990,
          1526,
          2559,
          288,
          1608,
          1652,
          1784,
          833,
          633,
          1414,
          772,
          1574,
          1367,
          2248,
          2488,
          2652,
          1710,
          2226,
          1707,
          2955,
          2196,
          1452,
          2203,
          826,
          1972,
          786,
          1675,
          551,
          1197,
          1301,
          2696,
          2170,
          2403,
          2903,
          1516,
          2684,
          2903,
          2601,
          2193,
          1544,
          1713,
          1898,
          2389,
          243,
          1747,
          1458,
          871,
          1528,
          691,
          2497,
          262,
          1826,
          1992,
          1750,
          2560,
          1760,
          2235,
          2083,
          2263,
          1992,
          1312,
          1880,
          1395,
          705,
          1684,
          1932,
          2152,
          2067,
          1536,
          1076,
          1477,
          1976,
          1803,
          2043,
          1379,
          1337,
          1677,
          2014,
          2068,
          1605,
          1975,
          1360,
          1396,
          1293,
          838,
          2551,
          1768,
          1649,
          2596,
          998,
          1615,
          1045,
          1217,
          2019,
          2924,
          1863,
          1300,
          1007,
          1417,
          2232,
          1269,
          1814,
          990,
          1526,
          2559,
          288,
          1608,
          1652,
          1784,
          833,
          633,
          1414,
          772,
          1574,
          1367,
          2248,
          2488,
          2652,
          1710,
          2226,
          1707,
          2955,
          2196,
          1452,
          2203,
          826,
          1972,
          786,
          1675,
          551,
          1197,
          1301,
          2696,
          2170,
          2403,
          2903,
          1516,
          2684,
          2903,
          2601,
          2193,
          1544,
          1713,
          1898,
          2389,
          243,
          1747,
          1458,
          871,
          1528,
          691,
          2497,
          262,
          1826,
          1992,
          1750,
          2560,
          1760,
          2235,
          2083,
          2263,
          1992,
          1312,
          1880,
          1395,
          705,
          1684,
          1932,
          2152,
          2067,
          1536,
          1076,
          1477,
          1976,
          1803,
          2043,
          1379,
          1337,
          1677,
          2014,
          2068,
          1605,
          1975,
          1360,
          1396,
          1293,
          838,
          2551,
          1768,
          1649,
          2596,
          1920,
          2894,
          2192,
          2199,
          1640,
          1932,
          2355,
          1616,
          1348,
          919,
          892,
          974,
          1317,
          2014,
          2820,
          2858,
          1908,
          2714,
          2385,
          2023,
          2881,
          2930,
          1986,
          1519,
          2222,
          2535,
          2362,
          2343,
          1835,
          2275,
          2311,
          2047,
          2575,
          2625,
          2523,
          2532,
          1778,
          1797,
          2666,
          1355,
          144,
          2450,
          2574,
          2125,
          1525,
          2932,
          976,
          429,
          642,
          489,
          534,
          784,
          991,
          814,
          466,
          425,
          1086,
          658,
          2994,
          483,
          903,
          600,
          1215,
          626,
          897,
          2477,
          1132,
          1705,
          1077,
          1918,
          1102,
          1236,
          1221,
          1245,
          769,
          1897,
          1071,
          1075,
          1161,
          999,
          666,
          783,
          1947,
          886,
          782,
          1625,
          1755,
          1807,
          946,
          928,
          1685,
          1042,
          1622,
          1150,
          1425,
          1178,
          912,
          901,
          1220,
          952,
          1142,
          1133,
          1566,
          1025,
          1181,
          1058,
          1287,
          1653,
          627,
          1544,
          1031,
          1128,
          1211,
          1254,
          724,
          928,
          1179,
          1810,
          1247,
          1002,
          1343,
          624,
          1364,
          963,
          884,
          777,
          1381,
          1315,
          1129,
          922,
          1042,
          1104,
          909,
          832,
          963,
          1141,
          1285,
          1240,
          986,
          1259,
          1349,
          1160,
          1197,
          768,
          1366,
          1383,
          1428,
          1090,
          1224,
          1132,
          1003,
          1132,
          1199,
          624,
          802,
          1614,
          1292,
          466,
          1514,
          1133,
          1045,
          1170,
          1136,
          998,
          1382,
          419,
          1084,
          1172,
          1036,
          892,
          994,
          1797,
          615,
          925,
          1549,
          1491,
          1062,
          1134,
          554,
          1021,
          700,
          764,
          662,
          1535,
          1666,
          650,
          664,
          665,
          1601,
          1576,
          747,
          943,
          851,
          1222,
          1707,
          1154,
          2354,
          1573,
          1061,
          874,
          1195,
          1678,
          1320,
          916,
          1025,
          1160,
          479,
          794,
          1033,
          1006,
          1429,
          1226,
          1398,
          690,
          1111,
          992,
          751,
          1192,
          1432,
          789,
          884,
          2032,
          1490,
          1505,
          1045,
          870,
          1868,
          1025,
          917,
          1092,
          796,
          847,
          1068,
          1920,
          2068,
          1754,
          1353,
          1170,
          525,
          1092,
          1286,
          1268,
          1023,
          1125,
          709,
          1119,
          1903,
          1077,
          1384,
          155,
          1362,
          1595,
          1200,
          672,
          1077,
          875,
          1123,
          1492,
          616,
          1466,
          1579,
          1230
         ],
         "xaxis": "x2",
         "yaxis": "y2"
        }
       ],
       "layout": {
        "bargap": 0.2,
        "barmode": "relative",
        "height": 600,
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribuição do Tamanho dos Abstracts"
        },
        "width": 1600,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Tamanho do Abstract"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          1
         ],
         "matches": "x",
         "showgrid": true,
         "showticklabels": false
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          0.8316
         ],
         "title": {
          "text": "Número de Artigos"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.8416,
          1
         ],
         "matches": "y2",
         "showgrid": false,
         "showline": false,
         "showticklabels": false,
         "ticks": ""
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter the DataFrame for abstract lengths less than 3000\n",
    "filtered_data = df_all_articles[df_all_articles['abstract_length'] < 3000]\n",
    "\n",
    "# Create the histogram using Plotly Express\n",
    "fig = px.histogram(filtered_data, x='abstract_length',\n",
    "                   nbins=50,  # Number of bins\n",
    "                   title='Distribuição do Tamanho dos Abstracts',\n",
    "                   labels={'abstract_length': 'Tamanho do Abstract'},  # Label for the x-axis\n",
    "                   marginal='rug',  \n",
    "                   hover_data=filtered_data.columns)\n",
    "\n",
    "# Update layout and axis labels\n",
    "fig.update_layout(\n",
    "    xaxis_title='Tamanho do Abstract',\n",
    "    yaxis_title='Número de Artigos',\n",
    "    bargap=0.2,  # Gap between bars of adjacent location coordinates\n",
    "    height=600,  # height of the plot in pixels\n",
    "    width=1600   # width of the plot in pixels\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover abstracts com menos de 100 caracteres\n",
    "df_all_articles = df_all_articles[df_all_articles['abstract_length'] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "df_all_articles.to_csv('all_articles.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all articles\n",
    "df_all_articles = pd.read_csv('all_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1ae61abd4d476bafc4e7439f84d4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding abstracts:   0%|          | 0/1831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "def encode_abstracts(abstracts, model, tokenizer):\n",
    "    embeddings = []\n",
    "    \n",
    "    # Wrap abstracts with tqdm for a progress bar\n",
    "    for abstract in tqdm(abstracts, desc='Encoding abstracts'):\n",
    "        inputs = tokenizer(abstract, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        hidden_states = outputs.hidden_states\n",
    "        last_layer_hidden_states = hidden_states[-1]\n",
    "        abstract_embeddings = last_layer_hidden_states.mean(dim=1)\n",
    "        embeddings.append(abstract_embeddings.cpu())  # Call `.cpu()` to move tensors back to CPU if using GPU\n",
    "\n",
    "    # Stack all embeddings into a single tensor\n",
    "    return torch.stack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SciBERT model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased', output_hidden_states=True)\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "# Assume 'df_all_articles_raw' is your DataFrame and it has an 'abstract' column\n",
    "# Apply the function to all abstracts\n",
    "abstract_embeddings = encode_abstracts(df_all_articles['abstract'].tolist(), model, tokenizer)\n",
    "torch.save(abstract_embeddings, 'abstract_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.22431481, -0.25318727,  0.11014143, ..., -0.28336376,\n",
       "          0.21446137, -0.5627571 ]],\n",
       "\n",
       "       [[ 0.39153066, -0.4899138 ,  0.14547488, ..., -0.35935095,\n",
       "          0.25185725, -0.48777324]],\n",
       "\n",
       "       [[ 0.24591634, -0.42300424,  0.1559297 , ..., -0.30734563,\n",
       "          0.13219088, -0.87109137]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.47076297, -0.3863434 ,  0.22683762, ..., -0.0600824 ,\n",
       "          0.37944347, -0.586188  ]],\n",
       "\n",
       "       [[ 0.32036796, -0.35674062,  0.2171505 , ..., -0.10391582,\n",
       "          0.48318368, -0.9345723 ]],\n",
       "\n",
       "       [[ 0.26914433, -0.6028914 ,  0.08458277, ..., -0.16385165,\n",
       "          0.2666776 , -0.6494315 ]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_embeddings_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1831, 1, 768])\n",
      "torch.Size([1831, 768])\n"
     ]
    }
   ],
   "source": [
    "print(abstract_embeddings.shape)\n",
    "abstract_embeddings_mean = abstract_embeddings.mean(dim=1)\n",
    "print(abstract_embeddings_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "journal=apl_machine_learning<br>tsne_x=%{x}<br>tsne_y=%{y}<extra></extra>",
         "legendgroup": "apl_machine_learning",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "apl_machine_learning",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -6.343194484710693,
          -2.160090446472168,
          4.064725875854492,
          -33.44277572631836,
          7.835247039794922,
          5.489220142364502,
          9.92919635772705,
          8.460881233215332,
          -2.792727470397949,
          -6.723811149597168,
          -8.528579711914062,
          -8.217708587646484,
          2.2432804107666016,
          -14.738675117492676,
          -20.95488166809082,
          -11.373109817504883,
          5.78753137588501,
          7.596825122833252,
          -1.294327974319458,
          5.211813449859619,
          -0.1977752149105072,
          7.301643371582031,
          -9.163969039916992,
          -5.308599948883057,
          9.000186920166016,
          -6.516477108001709,
          1.2127496004104614,
          -7.439972400665283,
          12.28808307647705,
          -5.83867073059082,
          -15.509223937988281,
          1.294935703277588,
          -8.088921546936035,
          -8.71000862121582,
          -8.200900077819824,
          -4.897927284240723,
          9.964020729064941,
          -10.741445541381836,
          1.7599881887435913,
          -7.28756046295166,
          4.60412073135376,
          2.563716411590576,
          -4.360947132110596,
          4.821362495422363,
          -0.2241237312555313,
          -3.301076650619507,
          -6.78668212890625,
          -8.690308570861816,
          4.687097549438477,
          -5.506216049194336,
          -0.881959855556488,
          -18.574819564819336,
          3.6757400035858154,
          -5.004453182220459,
          -3.846843719482422,
          3.800872325897217,
          8.609265327453613,
          -11.120210647583008,
          -9.659577369689941,
          1.0919110774993896,
          -15.970256805419922,
          1.8641756772994995,
          -0.038015786558389664,
          5.5495758056640625,
          -5.130194187164307,
          4.869932651519775,
          -1.6115193367004395,
          -2.0785093307495117,
          1.638715386390686,
          -7.7309956550598145,
          -4.385622501373291,
          -2.4252567291259766,
          -4.211452484130859,
          1.8270822763442993,
          2.5509188175201416,
          1.359413504600525,
          1.4542878866195679,
          -0.983538806438446,
          -0.8601800203323364,
          3.40964412689209,
          12.81364917755127,
          0.40212196111679077,
          -4.136012554168701,
          14.164831161499023,
          -21.705242156982422,
          1.8003486394882202,
          -4.2329630851745605,
          3.198831081390381,
          -2.794816732406616,
          -13.764161109924316,
          -2.7836496829986572,
          -1.3525272607803345,
          -1.3173061609268188,
          -8.496622085571289,
          -3.1942343711853027,
          -18.031049728393555,
          -20.818098068237305,
          0.8370939493179321,
          -8.95307731628418,
          4.5566325187683105,
          4.251800060272217,
          8.741077423095703,
          -9.780000686645508,
          8.693537712097168,
          6.01172399520874
         ],
         "xaxis": "x",
         "y": [
          -5.166877746582031,
          -8.492290496826172,
          -9.087244033813477,
          -1.1293580532073975,
          -4.410611629486084,
          -1.9673360586166382,
          -13.984858512878418,
          -6.103018760681152,
          1.4433903694152832,
          -3.5363192558288574,
          1.559791088104248,
          9.55832290649414,
          4.693049430847168,
          -12.055830001831055,
          -6.7837815284729,
          -5.1492156982421875,
          7.102747917175293,
          -14.05754280090332,
          -7.073698997497559,
          -2.7800865173339844,
          -22.95880889892578,
          -4.663167953491211,
          -15.157435417175293,
          -11.963094711303711,
          -2.905221462249756,
          -5.071499347686768,
          3.080401659011841,
          -9.990185737609863,
          0.31154289841651917,
          -8.878589630126953,
          -11.95749568939209,
          3.3979737758636475,
          -6.722873687744141,
          -5.095412254333496,
          -3.429821252822876,
          -6.153789520263672,
          -4.751712799072266,
          5.0006208419799805,
          -6.3903422355651855,
          9.336719512939453,
          5.559573650360107,
          3.2395238876342773,
          -8.720887184143066,
          -6.757992267608643,
          -14.798552513122559,
          -7.337717056274414,
          -12.643142700195312,
          -10.696634292602539,
          -8.285801887512207,
          6.412374496459961,
          -0.15698087215423584,
          -13.868227005004883,
          -4.499438285827637,
          -3.794618844985962,
          -4.954614162445068,
          -15.23751449584961,
          -2.6019864082336426,
          -12.414032936096191,
          -7.158718585968018,
          -10.507434844970703,
          -15.982428550720215,
          5.502608299255371,
          6.371668338775635,
          -1.4720185995101929,
          -12.728128433227539,
          -3.4415225982666016,
          4.748688697814941,
          -0.5253425240516663,
          -9.016829490661621,
          -17.54694938659668,
          -13.629378318786621,
          -9.029738426208496,
          -0.9579015970230103,
          -1.320717692375183,
          -11.544774055480957,
          4.725571632385254,
          -13.0817289352417,
          -6.1862688064575195,
          4.629648685455322,
          -17.800060272216797,
          2.333695650100708,
          -8.055302619934082,
          -16.749088287353516,
          0.23549513518810272,
          -8.989726066589355,
          -6.387789726257324,
          -10.892043113708496,
          -19.747312545776367,
          -1.4457398653030396,
          -14.886436462402344,
          -7.781693458557129,
          -10.304943084716797,
          -9.26822566986084,
          -10.09560489654541,
          -5.580386638641357,
          -10.59421443939209,
          -6.572352409362793,
          -11.722892761230469,
          -3.3936586380004883,
          5.344836235046387,
          -12.854248046875,
          -4.543065071105957,
          5.853749752044678,
          -2.29744029045105,
          -0.7446392774581909
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "journal=biology<br>tsne_x=%{x}<br>tsne_y=%{y}<extra></extra>",
         "legendgroup": "biology",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "biology",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          31.67534637451172,
          25.356861114501953,
          34.02822494506836,
          27.843273162841797,
          28.99118995666504,
          32.963050842285156,
          33.574951171875,
          44.27025604248047,
          32.82217788696289,
          19.23518180847168,
          38.548728942871094,
          29.03099822998047,
          32.397396087646484,
          27.060911178588867,
          26.319555282592773,
          43.927513122558594,
          22.940231323242188,
          34.7725944519043,
          34.34680938720703,
          32.545284271240234,
          36.159027099609375,
          36.70998001098633,
          42.612205505371094,
          29.21514320373535,
          28.30723762512207,
          29.61256980895996,
          32.19282531738281,
          40.195899963378906,
          39.99029541015625,
          33.34302520751953,
          -24.706741333007812,
          40.114051818847656,
          -18.802379608154297,
          39.78495788574219,
          37.88307189941406,
          45.8527717590332,
          23.619970321655273,
          37.73394012451172,
          17.819358825683594,
          41.7125129699707,
          -12.092652320861816,
          -0.8966104984283447,
          24.02512550354004,
          37.912872314453125,
          36.675567626953125,
          32.67831039428711,
          27.747060775756836,
          39.0261344909668,
          19.35020637512207,
          25.80975914001465,
          19.70282745361328,
          14.730525970458984,
          32.9384651184082,
          25.8787899017334,
          23.1049861907959,
          36.15999984741211,
          28.052209854125977,
          42.67612075805664,
          40.17912292480469,
          26.26059913635254,
          21.181827545166016,
          26.782920837402344,
          28.272703170776367,
          36.52751159667969,
          33.8521614074707,
          23.976076126098633,
          22.416730880737305,
          1.5567668676376343,
          31.94042205810547,
          43.28695297241211,
          26.865610122680664,
          16.933849334716797,
          26.569955825805664,
          11.138550758361816,
          27.06684112548828,
          24.126567840576172,
          35.87156677246094,
          -1.7650792598724365,
          28.378585815429688,
          31.417287826538086,
          14.262332916259766,
          33.73474884033203,
          28.872373580932617,
          25.311994552612305,
          26.197521209716797,
          33.48385238647461,
          35.97066879272461,
          43.97307586669922,
          32.18965148925781,
          36.38419723510742,
          23.05049705505371,
          44.05424499511719,
          32.66164016723633,
          42.77570343017578,
          17.61732292175293,
          20.367267608642578,
          34.05693054199219,
          42.59225082397461,
          21.647104263305664,
          34.997562408447266,
          20.579849243164062,
          22.09922218322754,
          36.79084777832031,
          37.729156494140625,
          39.1451416015625,
          15.342070579528809,
          34.231689453125,
          27.94021987915039,
          40.32563400268555,
          41.90581512451172,
          27.13495445251465,
          22.286888122558594,
          27.39549446105957,
          30.050506591796875,
          41.55988693237305,
          19.664119720458984,
          35.41199493408203,
          28.573511123657227,
          24.32766342163086,
          42.28548812866211,
          32.24859619140625,
          33.688865661621094,
          30.881494522094727,
          19.42420768737793,
          40.6912841796875,
          28.20853042602539,
          33.01164245605469,
          29.062360763549805,
          32.15895462036133,
          45.850555419921875,
          -1.3225677013397217,
          36.88444137573242,
          41.012046813964844,
          36.530853271484375,
          32.69722366333008,
          34.90849304199219,
          -3.053807020187378,
          27.421497344970703,
          23.964994430541992,
          20.744680404663086,
          24.80526351928711,
          38.550559997558594,
          28.20509147644043,
          30.906343460083008,
          29.857450485229492,
          33.713958740234375,
          25.318836212158203,
          36.389156341552734,
          30.94892692565918,
          25.31175422668457,
          29.92789649963379,
          38.79471969604492,
          32.9437141418457,
          25.63681411743164,
          23.71657943725586,
          32.20488739013672,
          19.36058807373047,
          30.83379364013672,
          36.61326217651367,
          28.831140518188477,
          34.01834487915039,
          34.661834716796875,
          38.079261779785156,
          32.55562210083008,
          25.288747787475586,
          35.94936752319336,
          40.06983947753906,
          43.23222351074219,
          28.994937896728516,
          34.61942672729492,
          25.322452545166016,
          24.237606048583984,
          28.199420928955078,
          34.170196533203125,
          34.80123519897461,
          37.27163314819336,
          28.74013328552246,
          34.190696716308594,
          37.82490539550781
         ],
         "xaxis": "x",
         "y": [
          -23.005176544189453,
          8.363438606262207,
          -19.680601119995117,
          0.39795151352882385,
          -14.904282569885254,
          -20.445600509643555,
          -21.938459396362305,
          -2.6710143089294434,
          -1.1759006977081299,
          -8.23680591583252,
          -11.515115737915039,
          -6.9620232582092285,
          -21.66728401184082,
          -8.124730110168457,
          -14.604588508605957,
          -3.632720470428467,
          -9.21032428741455,
          -23.75528907775879,
          -18.476911544799805,
          -8.361611366271973,
          -16.92583656311035,
          -21.06285285949707,
          -1.8736294507980347,
          -3.973475456237793,
          -11.49576187133789,
          -5.111820697784424,
          -1.078784704208374,
          -2.0787036418914795,
          -6.01340913772583,
          -3.3084421157836914,
          21.848901748657227,
          -4.558318614959717,
          12.390389442443848,
          -6.720283508300781,
          -8.302420616149902,
          -0.9338572025299072,
          -7.904000282287598,
          -0.9516364336013794,
          -1.409483551979065,
          -3.9076733589172363,
          15.039214134216309,
          31.242321014404297,
          -4.048747539520264,
          3.788149356842041,
          -20.78522491455078,
          -3.565650224685669,
          1.0332274436950684,
          -3.3746461868286133,
          -11.689962387084961,
          -6.217450141906738,
          -6.35037899017334,
          -5.488246917724609,
          -22.060150146484375,
          -15.86829662322998,
          -11.7317476272583,
          -18.876815795898438,
          -3.9894142150878906,
          -1.3851866722106934,
          -4.451620101928711,
          -9.345860481262207,
          -7.518014907836914,
          -10.565442085266113,
          -9.225910186767578,
          -8.649065017700195,
          -7.75746488571167,
          -17.784448623657227,
          -5.338340759277344,
          -16.070709228515625,
          -22.449331283569336,
          -7.422546863555908,
          -16.729816436767578,
          7.369383335113525,
          -6.500840187072754,
          8.247804641723633,
          1.446563482284546,
          -9.641142845153809,
          -5.097560405731201,
          31.204097747802734,
          -6.194962501525879,
          -6.454433441162109,
          -21.731884002685547,
          -5.595281600952148,
          -1.171624779701233,
          -11.185062408447266,
          -8.662622451782227,
          -16.864532470703125,
          -4.461927890777588,
          -4.612037658691406,
          -13.248383522033691,
          -21.34035301208496,
          -11.568344116210938,
          -1.2288411855697632,
          -6.310511112213135,
          -4.510958671569824,
          4.176095962524414,
          0.9853801131248474,
          -14.822175025939941,
          -0.1413644254207611,
          3.2066752910614014,
          -2.5826683044433594,
          -7.764819145202637,
          -2.5358128547668457,
          -8.587383270263672,
          1.766435146331787,
          5.871934413909912,
          -11.930581092834473,
          1.6965895891189575,
          -6.053921699523926,
          -2.1578471660614014,
          -6.377472877502441,
          -4.773314476013184,
          -6.156105995178223,
          -10.171773910522461,
          -10.275733947753906,
          -4.944158554077148,
          -8.866059303283691,
          -17.184635162353516,
          -9.815763473510742,
          -17.63269805908203,
          -6.77773380279541,
          -3.7058115005493164,
          -11.4790678024292,
          -5.078949451446533,
          -5.960453033447266,
          2.142169237136841,
          -11.269997596740723,
          -17.942779541015625,
          -8.643401145935059,
          -5.984715938568115,
          -0.9798504710197449,
          30.47809410095215,
          -16.94291114807129,
          -6.093632221221924,
          -5.966830253601074,
          -1.2059495449066162,
          -24.783275604248047,
          -16.4862060546875,
          3.9585354328155518,
          0.7924133539199829,
          -10.55009651184082,
          -3.20342755317688,
          -11.525412559509277,
          -22.915273666381836,
          -11.136455535888672,
          -12.550725936889648,
          -1.1041821241378784,
          -16.353288650512695,
          -1.8737515211105347,
          -19.44634246826172,
          -12.048972129821777,
          -8.659571647644043,
          3.6574199199676514,
          -20.33212661743164,
          -8.261662483215332,
          -7.845661163330078,
          -8.543007850646973,
          -8.487411499023438,
          -18.568416595458984,
          -6.051024913787842,
          -14.128312110900879,
          -15.518680572509766,
          -18.498693466186523,
          -3.1589646339416504,
          -21.318132400512695,
          -9.067529678344727,
          -22.171092987060547,
          -0.2572351396083832,
          -4.540467262268066,
          -15.297384262084961,
          -7.9868292808532715,
          -4.073828220367432,
          -6.546401023864746,
          -4.4386420249938965,
          -8.828994750976562,
          -7.615893840789795,
          -3.953809976577759,
          -0.370483934879303,
          2.34706711769104,
          1.7273201942443848
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "journal=chemistryopen<br>tsne_x=%{x}<br>tsne_y=%{y}<extra></extra>",
         "legendgroup": "chemistryopen",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "chemistryopen",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          38.03064727783203,
          22.814613342285156,
          4.7653117179870605,
          3.869612693786621,
          40.43938064575195,
          17.894865036010742,
          5.52228307723999,
          26.57326316833496,
          38.08922576904297,
          19.63158416748047,
          18.423770904541016,
          36.698734283447266,
          14.335280418395996,
          24.20784568786621,
          39.5252685546875,
          25.345428466796875,
          18.190710067749023,
          21.87689781188965,
          24.836566925048828,
          37.659217834472656,
          21.633787155151367,
          6.387808799743652,
          16.827877044677734,
          21.76307487487793,
          24.6176815032959,
          28.4019832611084,
          20.26591682434082,
          7.663635730743408,
          24.709070205688477,
          27.69301986694336,
          25.11591911315918,
          16.55668067932129,
          38.870765686035156,
          36.76408004760742,
          23.30345916748047,
          25.24057388305664,
          32.82350158691406,
          19.26150894165039,
          22.827157974243164,
          6.414698123931885,
          29.83290672302246,
          19.359437942504883,
          21.244007110595703,
          21.54806137084961,
          20.777114868164062,
          15.127995491027832,
          23.398242950439453,
          14.243897438049316,
          26.727481842041016,
          26.934022903442383,
          36.447105407714844,
          18.893709182739258,
          5.999515533447266,
          32.55170440673828,
          21.989015579223633,
          6.740431308746338,
          26.826126098632812,
          5.171016216278076,
          18.513803482055664,
          31.172094345092773,
          28.950214385986328,
          30.65019416809082,
          24.50315284729004,
          22.980091094970703,
          32.65317916870117,
          32.67884063720703,
          18.27788543701172,
          20.16583251953125,
          38.18007278442383,
          39.328128814697266,
          17.95770835876465,
          36.508975982666016,
          25.860708236694336,
          33.197715759277344,
          27.468669891357422,
          20.228872299194336,
          28.428075790405273,
          34.17935562133789,
          15.933991432189941,
          19.61228370666504,
          21.78265953063965,
          9.682281494140625,
          37.31476974487305,
          28.116291046142578,
          13.67096996307373,
          -14.072452545166016,
          38.514137268066406,
          20.29148292541504,
          9.682228088378906,
          14.616151809692383,
          22.81248664855957,
          23.332529067993164,
          5.408488750457764,
          20.14979362487793,
          28.087661743164062,
          20.945955276489258,
          26.37193489074707,
          13.474058151245117,
          18.36420440673828,
          18.441974639892578,
          29.42483139038086,
          7.832869052886963,
          6.034439563751221,
          26.12294578552246,
          23.016870498657227,
          20.732820510864258,
          11.791678428649902,
          35.62464141845703,
          5.746822357177734,
          34.9527587890625,
          30.590787887573242,
          22.197057723999023,
          22.3629150390625,
          15.326456069946289,
          38.01254653930664,
          23.991052627563477,
          8.069781303405762,
          36.73470687866211,
          4.549592971801758,
          20.425642013549805,
          16.10903549194336,
          15.154666900634766,
          21.767436981201172,
          34.10147476196289,
          23.392377853393555,
          38.40299987792969,
          16.602371215820312,
          23.527219772338867,
          31.87387466430664,
          17.103395462036133,
          18.446613311767578,
          8.347878456115723,
          21.60064125061035
         ],
         "xaxis": "x",
         "y": [
          30.40631675720215,
          29.11306381225586,
          26.43146514892578,
          27.212539672851562,
          16.44306182861328,
          26.88335418701172,
          29.143352508544922,
          15.71358585357666,
          20.383943557739258,
          29.77287483215332,
          31.78884506225586,
          28.0423526763916,
          6.669059753417969,
          19.281150817871094,
          10.426065444946289,
          1.8368339538574219,
          23.581418991088867,
          16.478544235229492,
          27.71713638305664,
          30.312753677368164,
          28.36427879333496,
          26.648609161376953,
          16.58354377746582,
          16.798423767089844,
          2.5420706272125244,
          22.93465232849121,
          29.68570899963379,
          27.615224838256836,
          29.623998641967773,
          -2.540999174118042,
          4.663674831390381,
          18.061506271362305,
          16.79037094116211,
          29.787029266357422,
          24.957250595092773,
          3.1384172439575195,
          27.91283416748047,
          33.23008728027344,
          18.417924880981445,
          26.879608154296875,
          8.03390121459961,
          28.728153228759766,
          31.420080184936523,
          22.27071189880371,
          21.89035415649414,
          20.068655014038086,
          5.601147174835205,
          1.466842532157898,
          33.17652130126953,
          26.270864486694336,
          6.609278678894043,
          30.2111873626709,
          27.88440704345703,
          12.037879943847656,
          30.478078842163086,
          25.43607521057129,
          27.722742080688477,
          27.471948623657227,
          28.38158416748047,
          13.022581100463867,
          11.345053672790527,
          35.5290412902832,
          21.637840270996094,
          30.674747467041016,
          34.00239944458008,
          24.414051055908203,
          11.574695587158203,
          18.280132293701172,
          29.374774932861328,
          16.460168838500977,
          8.958956718444824,
          26.121496200561523,
          15.211090087890625,
          33.1751823425293,
          23.64088249206543,
          30.422216415405273,
          29.490219116210938,
          18.13041114807129,
          29.20330047607422,
          11.897748947143555,
          31.362529754638672,
          18.507326126098633,
          29.16838836669922,
          29.76342010498047,
          16.553922653198242,
          6.321386814117432,
          20.07659149169922,
          27.6923770904541,
          13.373174667358398,
          17.431074142456055,
          18.461284637451172,
          17.08791732788086,
          28.170000076293945,
          31.683225631713867,
          12.594480514526367,
          19.389427185058594,
          27.35724639892578,
          17.854158401489258,
          29.990562438964844,
          15.760157585144043,
          15.160212516784668,
          28.281591415405273,
          28.759681701660156,
          29.115741729736328,
          23.460559844970703,
          29.895803451538086,
          16.962432861328125,
          27.80099105834961,
          27.518985748291016,
          16.533893585205078,
          15.041247367858887,
          14.648575782775879,
          20.998294830322266,
          3.520716905593872,
          12.58827018737793,
          28.393903732299805,
          -9.79413890838623,
          28.551694869995117,
          27.20802879333496,
          33.10611343383789,
          15.403761863708496,
          17.926563262939453,
          11.716654777526855,
          6.8856892585754395,
          4.838877201080322,
          17.002058029174805,
          29.217098236083984,
          7.9637346267700195,
          8.597753524780273,
          21.596603393554688,
          25.107147216796875,
          15.23703384399414,
          22.50963592529297
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "journal=chemistry<br>tsne_x=%{x}<br>tsne_y=%{y}<extra></extra>",
         "legendgroup": "chemistry",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "chemistry",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          35.45489501953125,
          38.70467758178711,
          33.82267379760742,
          21.450605392456055,
          26.171506881713867,
          31.068634033203125,
          23.60909080505371,
          30.621774673461914,
          11.464710235595703,
          28.29448127746582,
          1.3952009677886963,
          13.492828369140625,
          23.5093994140625,
          28.72834587097168,
          24.38007164001465,
          32.16449737548828,
          29.679574966430664,
          23.436616897583008,
          32.8246955871582,
          35.743560791015625,
          34.495277404785156,
          34.842124938964844,
          25.849395751953125,
          27.733243942260742,
          14.414231300354004,
          31.97439193725586,
          36.4212760925293,
          11.091219902038574,
          32.8605842590332,
          35.12105941772461,
          26.565053939819336,
          28.394128799438477,
          11.370924949645996,
          25.828020095825195,
          32.84584426879883,
          36.53168869018555,
          19.421966552734375,
          19.071531295776367,
          33.84669876098633,
          31.22063446044922,
          19.03536605834961,
          19.346172332763672,
          25.985872268676758,
          0.9064592719078064,
          30.6672306060791,
          33.039581298828125,
          35.20026779174805,
          21.301952362060547,
          27.383581161499023,
          14.53854751586914,
          26.997188568115234,
          26.0971622467041,
          25.118940353393555,
          26.668041229248047,
          24.636920928955078,
          34.20061111450195,
          30.423431396484375,
          16.029897689819336,
          -0.9192484021186829,
          9.152525901794434,
          31.947704315185547,
          29.0655574798584,
          33.06142807006836,
          21.98851203918457,
          15.18616771697998,
          19.629194259643555,
          40.77750015258789,
          35.67885208129883,
          30.1929931640625,
          37.12324523925781,
          38.678096771240234,
          38.13506317138672,
          33.16896438598633,
          6.920018196105957,
          15.660204887390137,
          21.028976440429688,
          38.3499870300293,
          40.82705307006836,
          16.504058837890625,
          34.33869171142578,
          -0.6280743479728699,
          34.828372955322266,
          22.183156967163086,
          28.513036727905273,
          1.3760191202163696,
          27.52556800842285,
          1.33206307888031,
          41.1345100402832,
          29.632314682006836,
          33.795894622802734,
          30.965003967285156,
          21.8904972076416,
          1.311010479927063,
          35.08803939819336,
          17.295249938964844,
          28.60515594482422,
          17.691482543945312,
          14.868738174438477,
          34.75889205932617,
          20.10810089111328,
          32.358062744140625,
          38.09926223754883,
          25.067529678344727,
          19.197233200073242,
          28.384443283081055,
          33.59429931640625,
          34.76877975463867,
          19.115148544311523,
          32.41758346557617,
          18.454919815063477,
          21.801986694335938,
          21.19713592529297,
          35.758705139160156,
          14.256295204162598,
          30.504514694213867,
          29.212034225463867,
          -1.3473354578018188,
          36.01667404174805,
          20.620378494262695,
          11.33754825592041,
          21.053865432739258,
          32.71773910522461,
          30.04497718811035,
          26.248746871948242,
          34.08621597290039,
          13.82236099243164,
          13.966720581054688,
          28.52401351928711,
          24.929039001464844,
          18.446388244628906,
          37.02735137939453,
          35.08814239501953,
          19.98603630065918,
          26.233196258544922,
          27.776134490966797,
          16.411460876464844,
          30.610578536987305,
          33.251094818115234,
          26.970081329345703,
          17.870941162109375,
          28.127193450927734,
          25.61170196533203,
          22.241687774658203,
          20.54437828063965,
          31.987613677978516,
          29.02960968017578,
          33.39036178588867,
          2.0595531463623047,
          24.24696922302246,
          14.726961135864258,
          12.334382057189941,
          31.14369773864746,
          28.669692993164062,
          -0.36030328273773193,
          34.770931243896484,
          32.31330490112305,
          35.253170013427734,
          34.181793212890625,
          44.03719711303711,
          28.632984161376953,
          32.89158248901367,
          14.694863319396973,
          43.99037170410156,
          0.05003967508673668,
          1.0483545064926147,
          36.01576232910156,
          14.725584983825684,
          29.698713302612305,
          15.366447448730469,
          34.79713439941406,
          36.242027282714844,
          32.00994110107422,
          37.973655700683594,
          23.478416442871094,
          -1.462786078453064,
          24.41059112548828,
          24.98274040222168,
          34.88982009887695,
          28.32303810119629,
          35.45966720581055,
          39.415061950683594,
          24.840129852294922,
          32.85919189453125,
          31.269851684570312,
          30.68299102783203,
          34.17795181274414,
          27.459932327270508,
          35.04072570800781,
          31.046430587768555,
          33.711265563964844,
          35.965293884277344,
          27.389188766479492,
          37.19828796386719,
          16.79414176940918,
          35.350521087646484,
          35.0302848815918,
          19.912694931030273,
          36.3271598815918,
          20.47612190246582
         ],
         "xaxis": "x",
         "y": [
          29.953662872314453,
          27.099876403808594,
          30.962726593017578,
          24.841346740722656,
          23.459352493286133,
          29.79117202758789,
          33.78139877319336,
          17.80188751220703,
          16.24292755126953,
          24.545804977416992,
          31.140581130981445,
          2.594111680984497,
          3.675187349319458,
          13.230490684509277,
          32.47308349609375,
          26.084728240966797,
          26.173398971557617,
          21.642858505249023,
          14.476836204528809,
          10.358515739440918,
          13.873953819274902,
          11.764458656311035,
          19.3439998626709,
          15.080450057983398,
          23.58094596862793,
          21.131317138671875,
          22.758068084716797,
          18.03749656677246,
          27.237232208251953,
          23.772207260131836,
          24.687803268432617,
          6.383676052093506,
          18.124977111816406,
          20.45989990234375,
          20.969083786010742,
          6.720038414001465,
          6.121938705444336,
          18.73503303527832,
          4.398798942565918,
          17.20930290222168,
          18.867687225341797,
          31.697362899780273,
          32.50898361206055,
          9.194201469421387,
          24.30765724182129,
          15.418874740600586,
          8.23690128326416,
          -0.17130322754383087,
          7.8677520751953125,
          23.821447372436523,
          11.729266166687012,
          0.4777883291244507,
          33.899044036865234,
          12.224359512329102,
          3.8734889030456543,
          10.703300476074219,
          20.524517059326172,
          3.231506824493408,
          28.82533836364746,
          14.54852294921875,
          15.902583122253418,
          7.644387722015381,
          16.22342872619629,
          35.22613525390625,
          4.187209606170654,
          14.720100402832031,
          2.196521759033203,
          27.33502197265625,
          22.282861709594727,
          4.558905124664307,
          27.262317657470703,
          10.87047004699707,
          13.675177574157715,
          12.72181510925293,
          1.703148603439331,
          16.45369529724121,
          9.574095726013184,
          1.0582048892974854,
          4.1155195236206055,
          4.192476272583008,
          7.588843822479248,
          28.04817771911621,
          32.82585525512695,
          7.49673318862915,
          10.106976509094238,
          21.716529846191406,
          31.19976043701172,
          0.5959528684616089,
          21.84229850769043,
          29.9550724029541,
          16.608491897583008,
          11.722625732421875,
          10.577670097351074,
          30.88742446899414,
          15.182016372680664,
          9.189299583435059,
          15.549324989318848,
          28.77899742126465,
          28.653955459594727,
          24.997282028198242,
          17.592573165893555,
          10.241655349731445,
          23.95393943786621,
          6.036850929260254,
          26.180309295654297,
          17.357297897338867,
          21.367050170898438,
          19.773059844970703,
          27.54891586303711,
          17.758241653442383,
          33.123619079589844,
          9.976454734802246,
          29.319320678710938,
          10.747970581054688,
          24.37081527709961,
          27.377113342285156,
          28.080371856689453,
          20.475025177001953,
          1.190573811531067,
          20.659645080566406,
          25.6076717376709,
          20.58222770690918,
          7.2721357345581055,
          2.336996555328369,
          6.839881896972656,
          19.12005615234375,
          19.81336212158203,
          24.74273681640625,
          14.884913444519043,
          21.167068481445312,
          31.150728225708008,
          11.899935722351074,
          6.195743560791016,
          16.55763053894043,
          19.749618530273438,
          7.592002868652344,
          27.160240173339844,
          29.41155433654785,
          31.513225555419922,
          24.905288696289062,
          12.389250755310059,
          0.5326343774795532,
          27.048608779907227,
          7.132420063018799,
          32.29652786254883,
          1.1459572315216064,
          4.98344087600708,
          55.72200012207031,
          21.73467445373535,
          10.943818092346191,
          21.48578453063965,
          31.282211303710938,
          22.044780731201172,
          47.43853759765625,
          25.467802047729492,
          9.590347290039062,
          3.3186874389648438,
          29.195480346679688,
          2.8677008152008057,
          16.4261474609375,
          12.600406646728516,
          10.74128532409668,
          2.828775644302368,
          30.634550094604492,
          33.755821228027344,
          21.07579231262207,
          25.018373489379883,
          28.529489517211914,
          2.082918405532837,
          26.61667251586914,
          30.836910247802734,
          25.99420166015625,
          11.159339904785156,
          32.156368255615234,
          27.935420989990234,
          25.63935661315918,
          32.57701873779297,
          32.9715461730957,
          32.68758010864258,
          32.13283157348633,
          19.101957321166992,
          25.886655807495117,
          16.715579986572266,
          27.58738136291504,
          32.350582122802734,
          27.391441345214844,
          27.316364288330078,
          3.459282398223877,
          29.877605438232422,
          16.480546951293945,
          15.120869636535645,
          7.273140907287598,
          4.532211780548096,
          1.8551899194717407,
          24.640771865844727,
          14.929072380065918,
          23.01105308532715,
          4.761474132537842,
          28.677627563476562
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "journal=complexity<br>tsne_x=%{x}<br>tsne_y=%{y}<extra></extra>",
         "legendgroup": "complexity",
         "marker": {
          "color": "#FFA15A",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "complexity",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -10.646219253540039,
          -5.324985980987549,
          -13.471480369567871,
          -4.6679911613464355,
          -32.80727767944336,
          -19.329641342163086,
          -4.716978073120117,
          -17.24553680419922,
          -7.280576705932617,
          6.036147594451904,
          -21.327680587768555,
          -19.241363525390625,
          -8.066205978393555,
          -22.627971649169922,
          -6.958287239074707,
          -7.995750904083252,
          -14.618528366088867,
          -11.63950252532959,
          -14.569914817810059,
          -13.156749725341797,
          -3.0001065731048584,
          -6.496549129486084,
          -35.43193054199219,
          -13.12224292755127,
          -10.698236465454102,
          -27.1554012298584,
          -16.981273651123047,
          -15.671758651733398,
          -4.337756633758545,
          -9.957633972167969,
          -4.127233982086182,
          -22.117809295654297,
          -20.786211013793945,
          -18.239078521728516,
          -10.576370239257812,
          -16.50183868408203,
          -2.8589894771575928,
          -23.853816986083984,
          -10.709309577941895,
          -23.866918563842773,
          -22.77115821838379,
          -19.19462776184082,
          8.017364501953125,
          -9.375911712646484,
          -16.806201934814453,
          -8.110429763793945,
          -11.362444877624512,
          -13.72524642944336,
          -13.47721004486084,
          -17.94607162475586,
          -13.060704231262207,
          -5.034491539001465,
          -3.4642691612243652,
          -16.47141456604004,
          -22.89732551574707,
          -5.373332500457764,
          8.707003593444824,
          -11.18264102935791,
          -11.738502502441406,
          -20.36783218383789,
          -17.752912521362305,
          -2.6270244121551514,
          -20.797964096069336,
          -14.167962074279785,
          -15.548935890197754,
          -17.273527145385742,
          -8.981481552124023,
          -16.078819274902344,
          -11.216712951660156,
          -15.233846664428711,
          -18.73572540283203,
          -11.611370086669922,
          -18.436800003051758,
          -12.622333526611328,
          -8.327948570251465,
          1.4009575843811035,
          -6.815187454223633,
          -11.550037384033203,
          -14.482484817504883,
          -24.05601692199707,
          -20.70878791809082,
          -17.71774673461914,
          -14.447751998901367,
          -8.39232063293457,
          -6.127702713012695,
          -5.774838447570801,
          -34.320980072021484,
          -21.733440399169922,
          -7.7996506690979,
          -11.720174789428711,
          -14.769639015197754,
          -19.58098602294922,
          -10.082369804382324,
          -21.6168212890625,
          -25.284870147705078,
          -8.808035850524902,
          -21.867835998535156,
          -9.956029891967773,
          -21.26739501953125,
          -14.070937156677246,
          -15.90080451965332,
          -6.902595520019531,
          -18.495906829833984,
          -16.471738815307617,
          -10.455780982971191,
          -11.24468994140625,
          -25.656545639038086,
          -17.24777603149414,
          -20.358421325683594,
          -7.342133522033691,
          -6.446641445159912,
          -9.459097862243652,
          -17.02648162841797,
          -5.307255744934082,
          -13.174447059631348,
          -22.201065063476562,
          -12.561729431152344,
          -6.124300956726074,
          -12.263886451721191,
          -18.246627807617188,
          -18.883380889892578,
          -19.919963836669922,
          -13.649197578430176,
          -25.8958683013916,
          -18.09037971496582,
          -19.912670135498047,
          -8.496710777282715,
          -18.047733306884766,
          -23.619014739990234,
          13.959622383117676,
          -3.3419806957244873,
          -50.91047286987305,
          -10.468241691589355,
          -36.54890823364258,
          -15.357860565185547,
          1.1087355613708496,
          -5.44805383682251,
          -19.015695571899414,
          -12.955032348632812,
          -14.873342514038086,
          -16.678905487060547,
          -6.5637526512146,
          17.307764053344727,
          -8.486799240112305,
          -11.97677993774414,
          -16.45089340209961,
          -15.471077919006348,
          -16.480186462402344,
          -16.226835250854492,
          -19.0808048248291,
          -12.147499084472656,
          -7.288081169128418,
          -7.507400035858154,
          -9.160945892333984,
          -12.00144100189209,
          -18.700937271118164,
          -6.352173328399658,
          -18.785505294799805,
          -9.080377578735352,
          -19.069318771362305,
          -10.293959617614746,
          7.880956172943115,
          0.7960858345031738,
          1.4067071676254272,
          -2.265530586242676,
          -19.712133407592773,
          11.825408935546875,
          -14.495543479919434,
          -20.243093490600586,
          -51.65056228637695
         ],
         "xaxis": "x",
         "y": [
          -29.65337371826172,
          -36.44607162475586,
          -42.01782989501953,
          -32.07893753051758,
          26.16110610961914,
          -37.675716400146484,
          -31.402517318725586,
          53.305233001708984,
          -33.66706466674805,
          -10.914525032043457,
          -38.80489730834961,
          -37.37934112548828,
          -31.797903060913086,
          -24.242422103881836,
          -33.24267578125,
          -32.78208541870117,
          -41.34699249267578,
          -34.803138732910156,
          -34.202999114990234,
          -40.40290832519531,
          -21.922449111938477,
          -27.973464965820312,
          -22.05258560180664,
          -32.231117248535156,
          -23.526100158691406,
          8.041605949401855,
          -32.65153121948242,
          -35.79853057861328,
          -15.21412467956543,
          -24.52581214904785,
          -37.13920974731445,
          -25.31824493408203,
          -23.519365310668945,
          15.147017478942871,
          -31.194442749023438,
          -34.351585388183594,
          -27.061323165893555,
          -26.356340408325195,
          -27.836183547973633,
          29.36757469177246,
          -23.49896812438965,
          21.636028289794922,
          -12.695695877075195,
          -33.989990234375,
          -38.159915924072266,
          -36.31715393066406,
          -39.152679443359375,
          -24.061689376831055,
          -39.23351287841797,
          20.566471099853516,
          -30.931493759155273,
          -31.61211395263672,
          -27.904701232910156,
          -40.67504119873047,
          -21.9995059967041,
          -31.523422241210938,
          -12.062764167785645,
          -34.38736343383789,
          -40.42081069946289,
          -22.6195068359375,
          -40.88663101196289,
          -24.907794952392578,
          -32.22791290283203,
          -39.93818283081055,
          -40.484519958496094,
          -32.05604553222656,
          -29.771806716918945,
          -39.73435592651367,
          -30.048463821411133,
          -36.17996597290039,
          -33.250099182128906,
          -32.992740631103516,
          -40.310882568359375,
          -28.8070011138916,
          -26.655649185180664,
          14.263359069824219,
          -34.86760711669922,
          -34.29349136352539,
          -27.69607162475586,
          -23.583740234375,
          -24.885225296020508,
          -32.08721160888672,
          -33.92549514770508,
          -37.24540710449219,
          -36.11582565307617,
          -34.8729248046875,
          -22.732677459716797,
          -25.91509246826172,
          -35.36929702758789,
          -30.180810928344727,
          -38.115692138671875,
          55.78704833984375,
          18.834741592407227,
          -38.76117706298828,
          -24.549436569213867,
          -35.83736801147461,
          -27.174673080444336,
          -38.311058044433594,
          18.298791885375977,
          -31.173723220825195,
          -29.01673126220703,
          -31.001474380493164,
          22.92184066772461,
          -41.06212615966797,
          -30.757856369018555,
          -40.465232849121094,
          10.906789779663086,
          13.056221961975098,
          9.92410659790039,
          -24.81336212158203,
          19.806745529174805,
          -36.26171112060547,
          -25.460294723510742,
          -17.25507354736328,
          -39.89848327636719,
          -26.340572357177734,
          -36.46444320678711,
          -8.015449523925781,
          -27.34807777404785,
          -35.94395065307617,
          -31.475126266479492,
          -25.78115463256836,
          -39.70956039428711,
          8.441239356994629,
          -34.109291076660156,
          -35.34151077270508,
          -26.787696838378906,
          -23.56831169128418,
          18.895118713378906,
          -9.038738250732422,
          -22.113910675048828,
          -11.5159912109375,
          -23.682985305786133,
          -21.423831939697266,
          -29.578866958618164,
          14.746793746948242,
          -30.764644622802734,
          -34.82669448852539,
          -38.41055679321289,
          -39.64335250854492,
          -25.857301712036133,
          -28.222509384155273,
          -38.82937240600586,
          18.98587989807129,
          -37.60868453979492,
          -35.00816345214844,
          -38.94242477416992,
          -22.698226928710938,
          -31.19658088684082,
          -39.152740478515625,
          -27.4633731842041,
          -35.92759323120117,
          -38.369205474853516,
          13.911639213562012,
          -39.5238037109375,
          -34.67211151123047,
          -36.35344314575195,
          -32.11775588989258,
          19.14081573486328,
          11.036921501159668,
          -27.489377975463867,
          -12.176267623901367,
          -25.390886306762695,
          -17.954490661621094,
          -24.326894760131836,
          55.30555725097656,
          -0.28408101201057434,
          14.195591926574707,
          -24.673574447631836,
          -5.322547435760498
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "journal=culture_&_psychology<br>tsne_x=%{x}<br>tsne_y=%{y}<extra></extra>",
         "legendgroup": "culture_&_psychology",
         "marker": {
          "color": "#19d3f3",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "culture_&_psychology",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -4.22247838973999,
          -4.343812465667725,
          -3.2693233489990234,
          0.5600826740264893,
          -7.383007526397705,
          -5.7185893058776855,
          -8.090415000915527,
          -12.704292297363281,
          -10.764244079589844,
          -6.4971604347229,
          -7.40761137008667,
          -2.7288553714752197,
          -4.2640228271484375,
          -3.0969371795654297,
          -8.904149055480957,
          -0.6508238911628723,
          -7.056090354919434,
          0.317918986082077,
          -12.97347640991211,
          -4.655930519104004,
          -11.127190589904785,
          -8.819629669189453,
          -14.673103332519531,
          0.8227081894874573,
          -8.219416618347168,
          -8.79958724975586,
          2.069481134414673,
          -15.424776077270508,
          -2.485018491744995,
          -6.739083766937256,
          -0.08251850306987762,
          -11.20859432220459,
          -0.33472710847854614,
          -12.120115280151367,
          -1.1964691877365112,
          -16.436662673950195,
          -12.71578311920166,
          -7.921483516693115,
          -9.82426643371582,
          -8.900067329406738,
          -12.524683952331543,
          -0.8320604562759399,
          -2.4763097763061523,
          -4.375674247741699,
          -4.22761344909668,
          -8.84964370727539,
          -6.435445785522461,
          -9.050851821899414,
          -9.701308250427246,
          1.2531558275222778,
          -5.150252342224121,
          -3.6782989501953125,
          -7.826546669006348,
          -3.1953065395355225,
          2.11380934715271,
          -10.104460716247559,
          -6.650999546051025,
          -1.369866132736206,
          -10.51307487487793,
          -6.23132848739624,
          -11.248323440551758,
          -13.480317115783691,
          -11.003466606140137,
          -7.123680114746094,
          -8.539716720581055,
          -2.395984411239624,
          -12.576105117797852,
          -0.423954576253891,
          2.819183588027954,
          -4.72877311706543,
          -4.0477213859558105,
          -8.204361915588379,
          0.8315331935882568,
          -12.225212097167969,
          -2.324018955230713,
          -11.304586410522461,
          -9.441215515136719,
          -6.995628833770752,
          -8.38952922821045,
          -5.2337493896484375,
          -11.106526374816895,
          -6.784816741943359,
          -7.466545104980469,
          -10.298579216003418,
          -7.072988033294678,
          -5.95096492767334,
          -2.338366985321045,
          -4.560492038726807,
          -12.920656204223633,
          -10.658360481262207,
          -12.915773391723633,
          -9.728456497192383,
          -7.018550872802734,
          -12.44495677947998,
          -2.3395204544067383,
          -6.560431003570557,
          -5.982447624206543,
          -9.991739273071289,
          -10.611199378967285,
          -14.578766822814941,
          -4.459702968597412,
          -13.551335334777832,
          -9.492116928100586,
          -4.028480052947998,
          -15.042609214782715,
          0.5032273530960083,
          -9.405780792236328,
          -11.689169883728027,
          -11.217659950256348,
          -14.140247344970703,
          -16.79530143737793,
          -0.4772167503833771,
          -6.803321838378906,
          -2.4714887142181396,
          -3.945425033569336,
          -13.329339027404785,
          -12.816116333007812,
          -6.117774963378906,
          -4.114417552947998,
          1.4245854616165161,
          -1.6105451583862305,
          -6.47110652923584,
          -17.261390686035156,
          -2.833061933517456,
          -17.542652130126953,
          0.02974424697458744,
          -12.662782669067383,
          1.9093512296676636,
          -0.6586569547653198,
          -4.927897930145264,
          -5.643331050872803,
          -3.323382616043091,
          -9.876091957092285,
          -7.478922367095947,
          0.9249267578125,
          -17.202680587768555,
          -4.673043251037598,
          -3.6226162910461426,
          -4.92598295211792,
          1.0974647998809814,
          0.11781273782253265,
          -11.510915756225586,
          -16.71350860595703,
          -2.7925968170166016,
          -3.454432487487793,
          -7.564888000488281,
          -5.3820905685424805,
          -13.071075439453125,
          -4.9380340576171875,
          -1.0577608346939087,
          -14.983357429504395,
          -9.295665740966797,
          -13.901163101196289,
          -2.6407666206359863,
          -5.156855583190918,
          -7.8156418800354,
          -3.1870038509368896,
          -5.9760847091674805,
          -2.2052724361419678,
          -5.204607963562012,
          -18.58843231201172,
          -9.898418426513672,
          -0.8393921256065369,
          -2.125645160675049,
          -5.630844593048096,
          -11.550930976867676,
          -0.23135878145694733,
          3.604099988937378
         ],
         "xaxis": "x",
         "y": [
          59.88496398925781,
          54.76417541503906,
          65.5133285522461,
          55.67109298706055,
          49.180484771728516,
          56.47548294067383,
          53.684043884277344,
          60.896644592285156,
          54.1585693359375,
          63.06791305541992,
          64.60875701904297,
          55.016666412353516,
          59.336021423339844,
          56.895599365234375,
          60.32598876953125,
          61.024940490722656,
          51.167137145996094,
          52.39037322998047,
          50.83428192138672,
          49.13705062866211,
          50.4149055480957,
          64.66478729248047,
          61.23812484741211,
          51.23707580566406,
          56.590877532958984,
          59.0053825378418,
          52.61317443847656,
          58.85612869262695,
          48.89316940307617,
          66.2883071899414,
          50.150779724121094,
          49.4610710144043,
          25.26811408996582,
          53.439056396484375,
          50.791969299316406,
          59.91830062866211,
          64.5044174194336,
          57.905723571777344,
          51.76416015625,
          50.14080810546875,
          60.53440856933594,
          54.15299606323242,
          48.856361389160156,
          61.09315490722656,
          53.379459381103516,
          50.8009033203125,
          53.22670364379883,
          56.353759765625,
          55.01988983154297,
          53.396636962890625,
          47.813751220703125,
          52.53016662597656,
          54.95014190673828,
          53.71078109741211,
          50.9095344543457,
          62.97957992553711,
          61.29681396484375,
          56.27726364135742,
          47.13788986206055,
          55.28403091430664,
          52.276119232177734,
          49.71975326538086,
          60.429725646972656,
          55.668540954589844,
          65.24431610107422,
          61.04127502441406,
          58.36581039428711,
          61.972957611083984,
          53.812618255615234,
          44.6600227355957,
          51.14292526245117,
          62.80059814453125,
          55.47541427612305,
          52.737449645996094,
          58.6829719543457,
          55.652626037597656,
          53.238739013671875,
          57.012325286865234,
          52.09449768066406,
          48.32622146606445,
          56.387393951416016,
          65.60646057128906,
          48.16640853881836,
          60.1058464050293,
          52.36697006225586,
          54.33454513549805,
          56.30207443237305,
          58.952735900878906,
          52.8413200378418,
          57.766815185546875,
          54.33076095581055,
          57.98003005981445,
          58.472572326660156,
          56.6855354309082,
          59.69240188598633,
          58.927303314208984,
          59.288902282714844,
          56.37809753417969,
          64.70401763916016,
          53.82265090942383,
          51.749961853027344,
          56.369049072265625,
          46.339752197265625,
          54.04894256591797,
          55.706817626953125,
          60.05984115600586,
          61.89463806152344,
          57.137630462646484,
          59.60603332519531,
          58.30667495727539,
          56.529510498046875,
          58.565826416015625,
          61.502750396728516,
          62.368892669677734,
          56.118873596191406,
          53.79986572265625,
          61.975826263427734,
          66.02584838867188,
          57.83789825439453,
          55.57062530517578,
          58.0937385559082,
          52.430484771728516,
          58.37797927856445,
          54.785945892333984,
          57.569454193115234,
          52.4411735534668,
          63.48469161987305,
          59.97163009643555,
          63.29600143432617,
          63.55379104614258,
          60.70821762084961,
          60.31758499145508,
          61.47108840942383,
          53.00674057006836,
          58.508750915527344,
          56.84409713745117,
          56.61760711669922,
          62.11293029785156,
          55.65467071533203,
          61.461151123046875,
          56.869869232177734,
          62.26970291137695,
          58.50218200683594,
          58.395633697509766,
          65.48221588134766,
          49.290565490722656,
          57.919368743896484,
          55.04317092895508,
          58.673160552978516,
          60.216922760009766,
          57.67304992675781,
          63.06829071044922,
          59.00288009643555,
          50.98564529418945,
          54.137691497802734,
          61.63607406616211,
          46.37055587768555,
          50.457759857177734,
          52.883880615234375,
          52.723148345947266,
          57.90645980834961,
          62.5609016418457,
          60.04405975341797,
          51.834957122802734,
          51.479122161865234,
          58.95832824707031,
          53.419960021972656,
          57.16295623779297
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "journal=journal_of_physics_complexity<br>tsne_x=%{x}<br>tsne_y=%{y}<extra></extra>",
         "legendgroup": "journal_of_physics_complexity",
         "marker": {
          "color": "#FF6692",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "journal_of_physics_complexity",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -37.22529220581055,
          -8.612394332885742,
          -33.220802307128906,
          -28.755056381225586,
          -29.921045303344727,
          -9.918326377868652,
          -18.756174087524414,
          -30.65104866027832,
          -19.871686935424805,
          2.5174849033355713,
          -19.79704475402832,
          -46.762638092041016,
          -14.711923599243164,
          -23.490041732788086,
          -6.003836631774902,
          -50.64487075805664,
          -25.686424255371094,
          -31.513872146606445,
          -35.79548263549805,
          -29.841604232788086,
          -34.231605529785156,
          -33.03593063354492,
          -5.7436957359313965,
          -29.765535354614258,
          -14.659029960632324,
          -9.001310348510742,
          -27.432567596435547,
          -21.282852172851562,
          -21.130701065063477,
          -31.097129821777344,
          -18.188684463500977,
          -23.836484909057617,
          -26.427770614624023,
          -15.67447280883789,
          -33.14259719848633,
          -27.80132293701172,
          -20.634607315063477,
          -22.033430099487305,
          -27.338464736938477,
          -32.400146484375,
          -26.525449752807617,
          -26.56544303894043,
          -15.226654052734375,
          -11.22441577911377,
          -25.37590789794922,
          -23.319250106811523,
          -15.00318431854248,
          -30.241018295288086,
          -29.382946014404297,
          -32.000640869140625,
          -20.86668586730957,
          -21.249114990234375,
          -22.161197662353516,
          -2.6289594173431396,
          -7.105274677276611,
          -9.569169044494629,
          -19.1236572265625,
          -38.0805778503418,
          -15.746827125549316,
          -21.02834129333496,
          -21.979272842407227,
          -14.19820785522461,
          -25.659469604492188,
          -27.422988891601562,
          -37.24891662597656,
          -32.22844314575195,
          -26.366365432739258,
          -29.221267700195312,
          -29.180700302124023,
          -25.776641845703125,
          -25.60930061340332,
          -37.258033752441406,
          -25.77794647216797,
          -8.227317810058594,
          -19.365713119506836,
          -20.361543655395508,
          -34.175010681152344,
          -23.25431251525879,
          -28.532772064208984,
          -35.20258712768555,
          4.245162010192871,
          -21.41506004333496,
          -15.141276359558105,
          -32.88374328613281,
          -16.589874267578125,
          -18.65943145751953,
          -6.892611980438232,
          -20.852569580078125,
          -20.48693084716797,
          -32.558963775634766,
          22.23904800415039,
          -30.70855140686035,
          -24.129444122314453,
          -32.92658233642578,
          -32.44824981689453,
          -29.833154678344727,
          -32.83540725708008,
          -26.158700942993164,
          -41.76948165893555,
          -38.407920837402344,
          -28.74834632873535,
          -26.90591812133789,
          -35.40391159057617,
          -37.08451843261719,
          -7.537934303283691,
          -26.901391983032227,
          -27.132423400878906,
          -36.71419906616211,
          -21.515430450439453,
          -20.27881622314453,
          -3.615335702896118,
          -20.759899139404297,
          -31.80240821838379,
          -13.210522651672363,
          -25.513288497924805,
          -23.32969093322754,
          -27.715835571289062,
          -14.659502029418945,
          -30.306278228759766,
          -20.364734649658203,
          -16.486957550048828,
          -16.784589767456055,
          -35.40639114379883,
          -22.585914611816406,
          -22.156829833984375,
          -25.196889877319336,
          -14.58533000946045,
          -13.951947212219238,
          -5.684536457061768,
          -20.284866333007812,
          -41.70145034790039,
          -27.162744522094727,
          -30.495967864990234,
          -8.116745948791504,
          -35.19938278198242,
          -24.32654571533203,
          -19.582279205322266,
          -37.916866302490234,
          -6.296115398406982,
          -29.217702865600586,
          -14.828948974609375,
          -24.23798942565918,
          -35.445919036865234,
          -34.09074401855469,
          -27.63703155517578,
          -31.93239402770996,
          -21.699913024902344,
          -26.925100326538086,
          -19.38092041015625,
          3.070427179336548,
          -25.659391403198242,
          -34.053955078125,
          -6.879811763763428,
          -8.872056007385254,
          -15.672977447509766,
          -14.026063919067383,
          -37.918643951416016,
          -22.563650131225586,
          -37.30726623535156,
          -31.816308975219727,
          -22.699277877807617,
          -22.89712142944336,
          -28.764619827270508,
          -15.731355667114258,
          -27.647613525390625,
          -20.079267501831055,
          -26.387508392333984,
          -7.2400383949279785,
          -32.92983627319336,
          -27.17557144165039,
          -25.244037628173828,
          -6.088906764984131,
          -21.401504516601562,
          -29.798439025878906,
          -36.64924621582031,
          -27.859729766845703,
          -24.324024200439453,
          -21.414371490478516,
          -29.126699447631836,
          -31.883373260498047,
          -30.88869285583496,
          -22.52992057800293,
          -32.52252960205078,
          -22.760746002197266,
          -2.7437591552734375,
          -32.47068786621094,
          -22.680343627929688,
          -24.571470260620117,
          -24.47711181640625,
          -11.19445514678955,
          -27.845998764038086,
          -34.664833068847656,
          -15.883259773254395,
          -15.646645545959473,
          -9.30681324005127,
          1.3518941402435303,
          -31.761474609375,
          -29.932680130004883,
          -32.016334533691406
         ],
         "xaxis": "x",
         "y": [
          15.953594207763672,
          11.888311386108398,
          27.08660316467285,
          22.489532470703125,
          24.839174270629883,
          7.359997272491455,
          14.927833557128906,
          16.09857749938965,
          30.328182220458984,
          30.907529830932617,
          25.9627742767334,
          -6.457664489746094,
          -23.70507049560547,
          17.679691314697266,
          -14.458638191223145,
          4.775634765625,
          20.656211853027344,
          18.415653228759766,
          23.762697219848633,
          19.85552406311035,
          17.466745376586914,
          6.535327434539795,
          16.530426025390625,
          25.38992691040039,
          17.65409278869629,
          10.76590347290039,
          20.972702026367188,
          11.64159870147705,
          11.659975051879883,
          17.528257369995117,
          18.35683822631836,
          22.770597457885742,
          24.715282440185547,
          9.755145072937012,
          19.840892791748047,
          17.363496780395508,
          24.319705963134766,
          26.223907470703125,
          16.328815460205078,
          18.530054092407227,
          21.25245475769043,
          14.225752830505371,
          -23.622827529907227,
          9.332813262939453,
          13.420671463012695,
          13.547969818115234,
          14.374402046203613,
          13.564468383789062,
          10.550559043884277,
          9.81401538848877,
          21.913219451904297,
          12.771825790405273,
          26.15394401550293,
          11.13345718383789,
          15.6445894241333,
          15.688684463500977,
          19.39473533630371,
          12.79525089263916,
          11.217390060424805,
          15.210599899291992,
          11.450448036193848,
          -8.646135330200195,
          15.68127155303955,
          17.043912887573242,
          15.031368255615234,
          26.265989303588867,
          24.525150299072266,
          17.19619369506836,
          16.058135986328125,
          28.663740158081055,
          12.540325164794922,
          24.137531280517578,
          18.48656463623047,
          12.929622650146484,
          13.264060020446777,
          20.02577018737793,
          20.634729385375977,
          9.969057083129883,
          12.768177032470703,
          14.533597946166992,
          -11.40576457977295,
          7.469286918640137,
          -21.094301223754883,
          25.292720794677734,
          8.64865493774414,
          18.61525535583496,
          14.051775932312012,
          24.665176391601562,
          26.252727508544922,
          14.860013008117676,
          -15.643835067749023,
          9.842214584350586,
          18.054580688476562,
          20.839948654174805,
          9.602350234985352,
          19.87592315673828,
          6.381748676300049,
          17.278362274169922,
          10.50247859954834,
          12.199899673461914,
          14.935136795043945,
          25.8057861328125,
          12.217663764953613,
          8.300819396972656,
          13.701573371887207,
          1.7394688129425049,
          13.702900886535645,
          23.895347595214844,
          16.111814498901367,
          13.191594123840332,
          7.5067315101623535,
          -10.254505157470703,
          16.049877166748047,
          12.13525390625,
          29.057634353637695,
          9.81410026550293,
          18.225324630737305,
          20.879749298095703,
          24.643672943115234,
          22.7574520111084,
          14.167206764221191,
          -8.354101181030273,
          16.478363037109375,
          15.667407989501953,
          20.099515914916992,
          24.500858306884766,
          9.3273344039917,
          24.967992782592773,
          17.58839988708496,
          22.13541030883789,
          10.61410140991211,
          19.26286506652832,
          22.185331344604492,
          13.591517448425293,
          19.9930419921875,
          15.605485916137695,
          -21.517000198364258,
          14.715950012207031,
          -14.633736610412598,
          12.167013168334961,
          21.407958984375,
          20.748729705810547,
          19.244537353515625,
          13.263993263244629,
          15.35996150970459,
          13.968831062316895,
          12.397937774658203,
          19.3438720703125,
          17.183744430541992,
          30.693078994750977,
          1.200545072555542,
          16.12241554260254,
          40.69767761230469,
          45.540523529052734,
          -22.216053009033203,
          24.6574764251709,
          17.33526039123535,
          22.52310562133789,
          16.70953941345215,
          11.99367618560791,
          12.554359436035156,
          13.468463897705078,
          18.20764923095703,
          16.960351943969727,
          27.658918380737305,
          21.932857513427734,
          27.883031845092773,
          45.52427673339844,
          11.788057327270508,
          11.62154769897461,
          5.015092849731445,
          10.929122924804688,
          6.731038570404053,
          21.107982635498047,
          16.50598907470703,
          10.644181251525879,
          13.326322555541992,
          16.294483184814453,
          14.360123634338379,
          22.493968963623047,
          22.340267181396484,
          18.98423957824707,
          20.733482360839844,
          19.37030029296875,
          -13.169485092163086,
          15.587071418762207,
          -22.808589935302734,
          15.808382034301758,
          12.250016212463379,
          14.402165412902832,
          23.106542587280273,
          14.268661499023438,
          23.41290283203125,
          17.06513786315918,
          10.152297973632812,
          -4.493961811065674,
          11.903824806213379,
          27.050270080566406,
          15.941804885864258
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "journal=machine_learning_science_and_technology<br>tsne_x=%{x}<br>tsne_y=%{y}<extra></extra>",
         "legendgroup": "machine_learning_science_and_technology",
         "marker": {
          "color": "#B6E880",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "machine_learning_science_and_technology",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -8.103204727172852,
          -4.81805419921875,
          7.6662468910217285,
          -0.7410105466842651,
          -13.330289840698242,
          -14.15009593963623,
          -30.93202781677246,
          4.828559875488281,
          -10.151617050170898,
          -13.034337043762207,
          -14.91755485534668,
          -3.9041147232055664,
          -11.464306831359863,
          1.6279560327529907,
          1.970145583152771,
          -17.444225311279297,
          -9.42595386505127,
          -12.422937393188477,
          -14.575217247009277,
          -29.655588150024414,
          -1.3738527297973633,
          -16.914628982543945,
          -13.794957160949707,
          -15.37944221496582,
          -8.385433197021484,
          -39.7093620300293,
          -3.824805974960327,
          -5.313425064086914,
          8.156046867370605,
          -7.809112548828125,
          -13.35824966430664,
          -0.738737940788269,
          -17.422658920288086,
          -18.945053100585938,
          9.085909843444824,
          4.578324794769287,
          -14.01209831237793,
          5.065478801727295,
          -6.950003147125244,
          -23.637971878051758,
          -7.911769390106201,
          -6.308270454406738,
          -22.611438751220703,
          -4.001978397369385,
          -9.184405326843262,
          -2.6632134914398193,
          -1.2996599674224854,
          -24.862829208374023,
          -16.30746078491211,
          -7.334970474243164,
          -6.119879245758057,
          -12.61384105682373,
          -18.13680076599121,
          -7.297177791595459,
          -16.457246780395508,
          -22.830514907836914,
          -9.483139038085938,
          -0.7739542722702026,
          5.230560779571533,
          -10.791329383850098,
          -5.48576545715332,
          -22.774795532226562,
          -1.5743902921676636,
          -17.074995040893555,
          -3.540513277053833,
          -12.197733879089355,
          -7.68560791015625,
          -12.112404823303223,
          0.6567000150680542,
          2.4569144248962402,
          -9.522976875305176,
          -13.542317390441895,
          -10.26190185546875,
          -44.914466857910156,
          -7.497351169586182,
          0.7438682317733765,
          -33.108436584472656,
          -11.241201400756836,
          -16.814210891723633,
          -9.531123161315918,
          -14.035375595092773,
          -17.373245239257812,
          -19.878223419189453,
          -4.138018608093262,
          -4.456370830535889,
          -12.748653411865234,
          2.5170819759368896,
          -20.963016510009766,
          -12.928139686584473,
          -4.400575637817383,
          -45.7979736328125,
          -7.795814037322998,
          -9.528694152832031,
          -10.986857414245605,
          -5.471426486968994,
          -2.0316162109375,
          -25.530946731567383,
          0.4670591652393341,
          -10.888738632202148,
          -1.618647575378418,
          -34.77455520629883,
          -11.665019035339355,
          -11.134875297546387,
          -1.830445647239685,
          -12.291003227233887,
          -15.106765747070312,
          -6.404616832733154,
          -15.48434829711914,
          -19.347511291503906,
          -17.728633880615234,
          -7.9391398429870605,
          14.211409568786621,
          -17.820011138916016,
          -9.825715065002441,
          -12.881033897399902,
          -7.34390115737915,
          -15.186345100402832,
          -18.58149528503418,
          2.226940393447876,
          -9.057012557983398,
          0.7246189117431641,
          -32.63154220581055,
          -7.514724254608154,
          -11.60204792022705,
          -5.477462291717529,
          -15.319689750671387,
          -3.449620246887207,
          -2.5778191089630127,
          -8.751481056213379,
          -7.715973377227783,
          0.20274949073791504,
          -0.26192227005958557,
          -15.600301742553711,
          -15.959741592407227,
          9.208582878112793,
          9.000494003295898,
          -4.046420574188232,
          -26.363203048706055,
          -3.5567901134490967,
          -12.756380081176758,
          -45.77729034423828,
          -2.56587815284729,
          -11.674277305603027,
          -15.149521827697754,
          -13.569439888000488,
          -17.81749725341797,
          -21.195070266723633,
          -5.116474151611328,
          -12.383050918579102,
          -8.380646705627441,
          -1.8952302932739258,
          -24.690998077392578,
          -4.0627288818359375,
          -4.200746536254883,
          -13.069523811340332,
          -9.4869384765625,
          21.051897048950195,
          -9.993416786193848,
          -19.242202758789062,
          -0.9224460124969482,
          -2.7718002796173096,
          2.5053184032440186,
          -31.57530403137207,
          -6.5572357177734375,
          -15.40608024597168,
          6.146698474884033,
          -12.985086441040039,
          -12.800105094909668,
          -12.20233154296875,
          -3.136545419692993,
          -17.538684844970703,
          -2.2728214263916016,
          -14.952290534973145,
          -14.752874374389648,
          -6.2960028648376465,
          -0.632361888885498,
          -30.28803062438965,
          -32.26088333129883,
          -11.364289283752441,
          -15.273906707763672,
          -21.02724838256836,
          -3.6178650856018066,
          -22.21947479248047,
          -5.782278537750244,
          -14.671854972839355,
          -11.075470924377441,
          -34.16755676269531,
          -5.063780784606934,
          0.4332714378833771,
          -45.735286712646484,
          -46.9228401184082,
          6.3723015785217285,
          -13.489733695983887
         ],
         "xaxis": "x",
         "y": [
          5.3766655921936035,
          -0.7202081084251404,
          14.668715476989746,
          -16.288516998291016,
          -2.2441065311431885,
          -4.487937927246094,
          -2.0459115505218506,
          -11.175780296325684,
          -14.239456176757812,
          -1.763183355331421,
          -2.6332249641418457,
          0.8243447542190552,
          -9.440593719482422,
          1.1033321619033813,
          -21.732357025146484,
          -4.843425273895264,
          -2.6647889614105225,
          3.285727024078369,
          -1.6930063962936401,
          9.752553939819336,
          -3.13975191116333,
          2.3507590293884277,
          -4.103787422180176,
          -14.392464637756348,
          -8.423324584960938,
          1.3085849285125732,
          2.7059719562530518,
          14.197617530822754,
          -14.532007217407227,
          -15.683394432067871,
          5.186081886291504,
          -16.250415802001953,
          -2.8221466541290283,
          -4.885224342346191,
          -20.816020965576172,
          -9.290037155151367,
          -13.373382568359375,
          1.100758671760559,
          -6.215725421905518,
          -8.22022819519043,
          2.3686962127685547,
          0.3268001973628998,
          1.3491359949111938,
          -15.327374458312988,
          5.493107318878174,
          0.7587723135948181,
          -3.1618969440460205,
          -2.818782091140747,
          1.8856480121612549,
          3.564262628555298,
          -1.8183245658874512,
          -3.985806465148926,
          -0.6943072080612183,
          -9.619571685791016,
          0.5267220735549927,
          -8.704282760620117,
          1.5542882680892944,
          -24.284542083740234,
          -19.122499465942383,
          1.4412569999694824,
          -0.5660429000854492,
          1.4490606784820557,
          -18.874536514282227,
          0.3786788582801819,
          2.5229804515838623,
          -0.8444576859474182,
          1.173265814781189,
          -0.9912114143371582,
          -10.466174125671387,
          -13.253728866577148,
          -16.992515563964844,
          24.797931671142578,
          -6.567827224731445,
          -8.760907173156738,
          -4.235987186431885,
          -4.166852951049805,
          -11.85362434387207,
          -12.626574516296387,
          -0.9159833192825317,
          -5.587517261505127,
          -13.969141960144043,
          -6.6483869552612305,
          0.5878753066062927,
          -19.270219802856445,
          -21.08134651184082,
          -11.302414894104004,
          -18.34593963623047,
          -11.80323600769043,
          0.2009190320968628,
          -1.4225380420684814,
          6.520320415496826,
          6.263878345489502,
          0.06963063776493073,
          -2.957615375518799,
          3.7613577842712402,
          -10.488936424255371,
          1.237297534942627,
          -21.08392333984375,
          -8.773762702941895,
          -11.9702787399292,
          -7.503228664398193,
          -5.957238674163818,
          -10.249085426330566,
          -14.01999568939209,
          -17.970712661743164,
          0.10808882117271423,
          -1.0200655460357666,
          -5.54176664352417,
          -8.371038436889648,
          -11.751984596252441,
          0.05390496924519539,
          17.00296401977539,
          0.8210940361022949,
          -3.2898166179656982,
          -7.2725114822387695,
          -21.680831909179688,
          -6.107967853546143,
          2.396745443344116,
          -3.096496343612671,
          -2.079939365386963,
          -4.136587619781494,
          -16.39746856689453,
          -0.9293478727340698,
          1.470259189605713,
          5.564945220947266,
          2.6928648948669434,
          -3.8215386867523193,
          5.24477481842041,
          3.0100979804992676,
          -5.0855488777160645,
          2.0916903018951416,
          -10.729604721069336,
          -7.504909038543701,
          -10.617866516113281,
          -14.210338592529297,
          -16.468185424804688,
          -4.966053485870361,
          2.0836825370788574,
          -14.073147773742676,
          -15.476849555969238,
          6.7195024490356445,
          -2.1027095317840576,
          5.547894477844238,
          4.261733531951904,
          5.672912120819092,
          -5.0283942222595215,
          -5.550017356872559,
          -25.84699249267578,
          -4.045131206512451,
          -11.6500244140625,
          -6.815053939819336,
          -4.736973762512207,
          -7.3619608879089355,
          -11.361230850219727,
          -8.986711502075195,
          -14.804891586303711,
          -25.023672103881836,
          1.2662065029144287,
          -1.1738004684448242,
          -14.081965446472168,
          -14.844315528869629,
          -18.372133255004883,
          -4.527737140655518,
          2.3756484985351562,
          -6.96843147277832,
          -15.205903053283691,
          -6.896363258361816,
          -2.920583724975586,
          -8.60072135925293,
          0.4712684452533722,
          5.93548059463501,
          2.1253552436828613,
          -11.41113567352295,
          -10.266645431518555,
          -20.74225616455078,
          2.339581251144409,
          -2.1963300704956055,
          -6.463389873504639,
          3.5411248207092285,
          -16.013830184936523,
          -11.284692764282227,
          -21.41045379638672,
          -3.1548242568969727,
          12.514270782470703,
          2.3791306018829346,
          -11.084142684936523,
          14.148721694946289,
          1.3950114250183105,
          -1.8387548923492432,
          7.564369201660156,
          4.131234645843506,
          -15.052186012268066,
          -9.899395942687988
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "journal=medical_physics<br>tsne_x=%{x}<br>tsne_y=%{y}<extra></extra>",
         "legendgroup": "medical_physics",
         "marker": {
          "color": "#FF97FF",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "medical_physics",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          11.509984970092773,
          16.29595375061035,
          30.87487030029297,
          16.620803833007812,
          24.024667739868164,
          28.7855224609375,
          37.28183364868164,
          18.66626739501953,
          19.37200164794922,
          15.615992546081543,
          15.509568214416504,
          30.788326263427734,
          35.47108459472656,
          15.959689140319824,
          17.21637725830078,
          6.669355869293213,
          14.524619102478027,
          22.116193771362305,
          28.01627540588379,
          2.828970432281494,
          26.68596839904785,
          12.338260650634766,
          15.016603469848633,
          14.203215599060059,
          17.68388557434082,
          17.80181312561035,
          11.932662963867188,
          25.50458335876465,
          23.184139251708984,
          18.1591854095459,
          28.53073501586914,
          30.758163452148438,
          25.498916625976562,
          25.078338623046875,
          21.181425094604492,
          20.567453384399414,
          37.808189392089844,
          17.431716918945312,
          20.92699432373047,
          10.154706954956055,
          29.27843475341797,
          22.488252639770508,
          11.226441383361816,
          18.176681518554688,
          20.804960250854492,
          19.264806747436523,
          26.761533737182617,
          24.156944274902344,
          26.951738357543945,
          4.01934814453125,
          14.70152473449707,
          17.736312866210938,
          31.684112548828125,
          31.078397750854492,
          27.9148006439209,
          23.106945037841797,
          30.49815559387207,
          8.074762344360352,
          24.59364128112793,
          11.37951946258545,
          14.968266487121582,
          20.564016342163086,
          5.871007442474365,
          33.25272750854492,
          25.203481674194336,
          12.940423011779785,
          20.454708099365234,
          15.183963775634766,
          27.706384658813477,
          17.301774978637695,
          21.14336585998535,
          21.922300338745117,
          24.77631187438965,
          21.125865936279297,
          9.900639533996582,
          19.176368713378906,
          27.169376373291016,
          18.728511810302734,
          23.767900466918945,
          6.58274507522583,
          13.812675476074219,
          22.364076614379883,
          35.63396453857422,
          33.28842544555664,
          31.436189651489258,
          28.38115692138672,
          9.103476524353027,
          17.637224197387695,
          17.900516510009766,
          34.56388473510742,
          30.00924301147461,
          26.715423583984375,
          21.656753540039062,
          16.37192153930664,
          24.856887817382812,
          28.27510643005371,
          31.238529205322266,
          12.874650001525879,
          14.698277473449707,
          13.088565826416016,
          8.712674140930176,
          23.082538604736328,
          20.724178314208984,
          34.75394058227539,
          4.453465461730957,
          12.08534049987793,
          33.1828498840332,
          11.509984970092773,
          16.29595375061035,
          30.87487030029297,
          16.620573043823242,
          24.02483367919922,
          28.786865234375,
          37.28160095214844,
          18.666122436523438,
          19.37191390991211,
          15.615992546081543,
          15.509526252746582,
          30.788049697875977,
          35.47108459472656,
          15.959689140319824,
          17.21588134765625,
          6.669355869293213,
          14.524628639221191,
          22.11576271057129,
          28.01627540588379,
          2.828970432281494,
          26.68659210205078,
          12.338276863098145,
          15.016603469848633,
          14.203215599060059,
          17.68388557434082,
          17.80181312561035,
          11.932662963867188,
          25.50447654724121,
          23.184139251708984,
          18.1591854095459,
          28.53073501586914,
          30.756498336791992,
          25.498916625976562,
          25.078338623046875,
          21.18130874633789,
          20.568925857543945,
          37.807350158691406,
          17.431716918945312,
          20.92699432373047,
          10.154706954956055,
          29.278623580932617,
          22.488252639770508,
          11.225540161132812,
          18.176681518554688,
          20.804960250854492,
          19.264806747436523,
          26.761533737182617,
          24.156944274902344,
          26.951339721679688,
          4.01934814453125,
          14.700716018676758,
          17.736215591430664,
          31.684112548828125,
          31.078399658203125,
          27.91484260559082,
          23.106945037841797,
          30.49815559387207,
          8.074762344360352,
          24.593652725219727,
          11.37951946258545,
          14.968266487121582,
          20.565547943115234,
          5.870972156524658,
          33.25272750854492,
          25.203460693359375,
          12.940423011779785,
          20.455541610717773,
          15.183963775634766,
          27.705739974975586,
          17.301895141601562,
          21.142606735229492,
          21.92255210876465,
          24.776124954223633,
          21.125865936279297,
          9.90084457397461,
          19.176368713378906,
          27.169376373291016,
          18.728456497192383,
          23.768198013305664,
          6.58236837387085,
          13.812675476074219,
          22.364076614379883,
          35.63396453857422,
          33.28842544555664,
          31.436189651489258,
          28.379453659057617,
          9.103476524353027,
          17.637224197387695,
          17.900999069213867,
          34.564022064208984,
          30.00924301147461,
          26.715423583984375,
          21.65637969970703,
          16.37192153930664,
          24.856887817382812,
          28.275554656982422,
          31.238529205322266,
          12.875260353088379,
          14.698277473449707,
          13.088550567626953,
          8.712674140930176,
          23.082538604736328,
          20.724178314208984,
          34.75394058227539,
          4.453465461730957,
          12.085185050964355,
          33.18288040161133,
          12.000530242919922,
          33.75693893432617,
          28.471315383911133,
          26.583736419677734,
          11.964388847351074,
          12.544209480285645,
          29.34663963317871,
          23.930009841918945,
          26.53339195251465,
          31.79189109802246,
          29.125896453857422,
          15.276300430297852,
          11.742300987243652,
          12.290107727050781,
          16.163658142089844,
          18.78487777709961,
          19.66019630432129,
          1.5947608947753906,
          20.59541893005371,
          22.801048278808594,
          24.595746994018555,
          2.6394240856170654,
          23.199188232421875,
          35.81344223022461,
          25.70952606201172,
          30.068828582763672,
          19.79768180847168,
          17.742801666259766,
          24.46260643005371,
          33.0042724609375,
          24.123323440551758,
          24.89775848388672,
          20.024635314941406,
          22.313621520996094,
          23.144094467163086,
          20.04413604736328,
          29.82495880126953,
          21.20838737487793,
          25.802711486816406,
          21.483402252197266,
          32.416831970214844,
          29.459949493408203,
          31.1844482421875,
          30.06026840209961,
          24.932024002075195,
          23.42548942565918,
          25.824085235595703,
          27.638032913208008,
          12.793728828430176,
          0.8135446906089783,
          20.203311920166016,
          26.522659301757812,
          14.384481430053711,
          31.77581024169922,
          20.546592712402344,
          12.800159454345703,
          33.326473236083984,
          19.099164962768555,
          18.64082908630371,
          14.525821685791016,
          27.77203941345215,
          10.336639404296875,
          13.987163543701172,
          10.471284866333008,
          16.35683822631836,
          7.979425430297852,
          31.054607391357422,
          3.265592098236084,
          8.441679954528809,
          18.500280380249023,
          14.791340827941895
         ],
         "xaxis": "x",
         "y": [
          -31.438013076782227,
          -27.28215217590332,
          -40.235111236572266,
          -54.94722366333008,
          -50.03681182861328,
          -42.7677116394043,
          -37.08702850341797,
          -44.158843994140625,
          -49.33576583862305,
          -51.934696197509766,
          -43.708396911621094,
          -35.95341110229492,
          -39.798805236816406,
          -57.84589385986328,
          -45.55228042602539,
          -48.77452850341797,
          -38.44318771362305,
          -35.693115234375,
          -33.71259689331055,
          21.88471031188965,
          -43.45766830444336,
          -44.742496490478516,
          -41.25553894042969,
          -50.21717834472656,
          -60.6434326171875,
          -36.29375076293945,
          -50.3062858581543,
          -45.207645416259766,
          -44.09135437011719,
          -39.33012771606445,
          -37.74553298950195,
          -42.62563705444336,
          -47.197383880615234,
          -42.61345672607422,
          -48.26567077636719,
          -29.44211196899414,
          -42.263187408447266,
          -52.48782730102539,
          -41.47224807739258,
          -53.03812026977539,
          -30.053651809692383,
          -55.35724639892578,
          -23.959102630615234,
          -20.759750366210938,
          -53.24924850463867,
          -54.858062744140625,
          -36.10403823852539,
          -31.999343872070312,
          -29.5622501373291,
          -22.633258819580078,
          -32.43501281738281,
          -24.927871704101562,
          -37.015071868896484,
          -44.2892951965332,
          -46.27815628051758,
          -46.936336517333984,
          -47.19367599487305,
          -28.94407844543457,
          -24.76202392578125,
          -58.16091537475586,
          -29.757614135742188,
          -46.233211517333984,
          -36.11302185058594,
          -42.9986686706543,
          -40.55856704711914,
          -52.963890075683594,
          -38.59950637817383,
          -17.100969314575195,
          -49.65471267700195,
          -32.85781478881836,
          -43.875457763671875,
          -32.71526336669922,
          -35.02571105957031,
          -26.219722747802734,
          -39.550750732421875,
          -27.79947853088379,
          -40.71927261352539,
          -47.2519645690918,
          -38.17018127441406,
          -32.59398651123047,
          -56.73323440551758,
          -39.90496826171875,
          -34.57350158691406,
          -33.99147033691406,
          -28.37261390686035,
          -39.408565521240234,
          -34.68855667114258,
          -49.44542694091797,
          -42.153587341308594,
          -30.22165298461914,
          -50.778099060058594,
          -25.545745849609375,
          -50.2659797668457,
          -47.92000198364258,
          -53.891292572021484,
          -27.160968780517578,
          -33.31690216064453,
          -47.39540100097656,
          -46.04930114746094,
          -34.172828674316406,
          -46.19497299194336,
          -52.22383499145508,
          -58.237831115722656,
          -37.480491638183594,
          -24.671382904052734,
          -28.17007064819336,
          -38.16086959838867,
          -31.438013076782227,
          -27.28215217590332,
          -40.235111236572266,
          -54.946495056152344,
          -50.03582763671875,
          -42.7672004699707,
          -37.087196350097656,
          -44.16115188598633,
          -49.33580017089844,
          -51.934696197509766,
          -43.708343505859375,
          -35.953365325927734,
          -39.798805236816406,
          -57.84589385986328,
          -45.55229949951172,
          -48.77452850341797,
          -38.44317626953125,
          -35.693817138671875,
          -33.71259689331055,
          21.88471031188965,
          -43.45707321166992,
          -44.74251174926758,
          -41.25553894042969,
          -50.21717834472656,
          -60.6434326171875,
          -36.29375076293945,
          -50.3062858581543,
          -45.20711135864258,
          -44.09135437011719,
          -39.32988357543945,
          -37.74553298950195,
          -42.62481689453125,
          -47.197383880615234,
          -42.61345672607422,
          -48.26594161987305,
          -29.442564010620117,
          -42.26325988769531,
          -52.48782730102539,
          -41.47224807739258,
          -53.03812026977539,
          -30.053924560546875,
          -55.35724639892578,
          -23.960773468017578,
          -20.759750366210938,
          -53.24924850463867,
          -54.858062744140625,
          -36.10403823852539,
          -31.999343872070312,
          -29.562347412109375,
          -22.633258819580078,
          -32.43482971191406,
          -24.928239822387695,
          -37.015071868896484,
          -44.289310455322266,
          -46.27816390991211,
          -46.936336517333984,
          -47.19367599487305,
          -28.94407844543457,
          -24.761932373046875,
          -58.16091537475586,
          -29.757614135742188,
          -46.2334098815918,
          -36.1131706237793,
          -42.9986686706543,
          -40.55865478515625,
          -52.963890075683594,
          -38.599971771240234,
          -17.100969314575195,
          -49.65497589111328,
          -32.85776901245117,
          -43.87457275390625,
          -32.715049743652344,
          -35.02576446533203,
          -26.219722747802734,
          -39.55121994018555,
          -27.79947853088379,
          -40.71927261352539,
          -47.2518424987793,
          -38.17040252685547,
          -32.5936279296875,
          -56.73323440551758,
          -39.90496826171875,
          -34.57350158691406,
          -33.99147033691406,
          -28.37261390686035,
          -39.408363342285156,
          -34.68855667114258,
          -49.44542694091797,
          -42.15400695800781,
          -30.22187614440918,
          -50.778099060058594,
          -25.545745849609375,
          -50.26462936401367,
          -47.92000198364258,
          -53.891292572021484,
          -27.161823272705078,
          -33.31690216064453,
          -47.3952522277832,
          -46.04930114746094,
          -34.17285919189453,
          -46.19497299194336,
          -52.22383499145508,
          -58.237831115722656,
          -37.480491638183594,
          -24.671382904052734,
          -28.16950225830078,
          -38.16084289550781,
          -43.45652389526367,
          -39.11613845825195,
          19.655567169189453,
          -32.67109298706055,
          -43.13720703125,
          -27.19636344909668,
          -40.537296295166016,
          -29.655065536499023,
          -32.784698486328125,
          -32.62367630004883,
          -36.145381927490234,
          -42.19061279296875,
          -47.92874526977539,
          -22.41654396057129,
          -53.4895133972168,
          -52.166297912597656,
          -35.8768196105957,
          -23.810474395751953,
          -40.17586898803711,
          -33.134037017822266,
          -30.201967239379883,
          -23.6050968170166,
          -35.03126525878906,
          -22.81265640258789,
          -31.21658706665039,
          -39.580238342285156,
          -33.87826919555664,
          -30.150733947753906,
          -37.136444091796875,
          -41.50934982299805,
          -28.017162322998047,
          -30.851131439208984,
          -33.941280364990234,
          -29.192852020263672,
          -42.536808013916016,
          -16.77468490600586,
          -37.59077072143555,
          -37.8278923034668,
          -36.97347640991211,
          -28.695817947387695,
          -41.47904586791992,
          -44.59798812866211,
          -38.992210388183594,
          -35.3672981262207,
          -27.760805130004883,
          -42.01868438720703,
          -38.73414993286133,
          -36.62813949584961,
          -57.84151840209961,
          -24.00368309020996,
          -31.65947914123535,
          -38.154422760009766,
          -28.89642333984375,
          -40.189170837402344,
          -50.945823669433594,
          -55.03721618652344,
          -46.46414566040039,
          -57.154296875,
          -56.7919807434082,
          -54.775665283203125,
          -41.5612678527832,
          -52.20205307006836,
          -52.59903335571289,
          -54.24354553222656,
          -50.466590881347656,
          -54.3082389831543,
          -41.50535202026367,
          -24.761276245117188,
          -52.27599334716797,
          -50.47657012939453,
          -49.28514099121094
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "journal=quantum<br>tsne_x=%{x}<br>tsne_y=%{y}<extra></extra>",
         "legendgroup": "quantum",
         "marker": {
          "color": "#FECB52",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "quantum",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -47.650814056396484,
          -43.799842834472656,
          -45.076148986816406,
          -47.40019226074219,
          -46.61075973510742,
          -36.026588439941406,
          -43.555450439453125,
          -44.28569412231445,
          -32.88043975830078,
          -41.28056335449219,
          -41.173587799072266,
          -48.722572326660156,
          -35.16876220703125,
          -43.1295166015625,
          -39.896507263183594,
          -37.65045928955078,
          -45.065853118896484,
          -45.609458923339844,
          -44.407264709472656,
          -48.02341842651367,
          -29.001907348632812,
          -50.09883499145508,
          -48.960052490234375,
          -44.652408599853516,
          -37.201541900634766,
          -40.14495849609375,
          -43.38462829589844,
          -41.495975494384766,
          -35.713897705078125,
          -40.73475646972656,
          -50.45637893676758,
          -34.62838363647461,
          -35.511661529541016,
          -32.70037841796875,
          -45.3947639465332,
          -39.80287170410156,
          -37.151615142822266,
          -32.83372497558594,
          -54.231903076171875,
          -38.8600959777832,
          -38.187381744384766,
          -52.64684295654297,
          -46.980098724365234,
          -44.96759796142578,
          -46.35063171386719,
          -51.114768981933594,
          -43.210880279541016,
          -50.77922821044922,
          -32.26244354248047,
          -34.626014709472656,
          -49.59602355957031,
          -38.812294006347656,
          -40.53087615966797,
          -35.972957611083984,
          -40.70371627807617,
          -50.15031051635742,
          -36.90040969848633,
          -27.73385238647461,
          -44.605186462402344,
          -29.282127380371094,
          -43.49372100830078,
          -28.052276611328125,
          -38.08213806152344,
          -35.6834716796875,
          -43.097347259521484,
          -41.90028381347656,
          -37.013145446777344,
          -34.77153778076172,
          -33.018733978271484,
          -41.42702865600586,
          -48.47921371459961,
          -26.633472442626953,
          -40.57075119018555,
          -31.55304718017578,
          -44.90780258178711,
          -48.68806076049805,
          -27.474220275878906,
          -42.73686218261719,
          -44.460655212402344,
          -32.351722717285156,
          -43.68369674682617,
          -23.518762588500977,
          -46.274436950683594,
          -47.55509567260742,
          -47.102176666259766,
          -45.584774017333984,
          -39.65701675415039,
          -48.225990295410156,
          -29.706375122070312,
          -41.30200958251953,
          -38.858280181884766,
          -39.40141677856445,
          -35.605167388916016,
          -29.691022872924805,
          -39.88378143310547,
          -41.87858963012695,
          -49.15912628173828,
          -31.224748611450195,
          -35.21876907348633,
          -39.226890563964844,
          -37.573387145996094,
          -32.439449310302734,
          -40.04701232910156,
          -38.06140899658203,
          -39.26533508300781,
          -47.472938537597656,
          -43.521305084228516,
          -41.503089904785156,
          -50.473793029785156,
          -51.184078216552734,
          -37.02950668334961,
          -42.34126663208008,
          -41.128761291503906,
          -43.52047348022461,
          -41.82695007324219,
          -35.08650207519531,
          -49.152767181396484,
          -41.59381103515625,
          -31.00040626525879,
          -35.044132232666016,
          -28.385433197021484,
          -28.246309280395508,
          -29.597692489624023,
          -34.71908187866211,
          -40.88544845581055,
          -27.607797622680664,
          -36.828819274902344,
          -45.193241119384766,
          -47.011905670166016,
          -37.97703170776367,
          -29.2434024810791,
          -38.95268630981445,
          -39.025001525878906,
          -44.83266067504883,
          -51.248592376708984,
          -46.60955047607422,
          -43.423545837402344,
          -43.49662780761719,
          -44.73484802246094,
          -53.63846969604492,
          -28.218286514282227,
          -47.454856872558594,
          -49.127357482910156,
          -43.7264518737793,
          -36.98465347290039,
          -31.98960304260254,
          -34.90183639526367,
          -29.8563232421875,
          -36.33584213256836,
          -38.964813232421875,
          -43.10641098022461,
          -34.076168060302734,
          -39.51431655883789,
          -36.55564498901367,
          -39.56377410888672,
          -41.692138671875,
          -51.808929443359375,
          -35.27669906616211,
          -47.963130950927734,
          -51.22712707519531,
          -32.79773712158203,
          -37.40045166015625,
          -34.0827522277832,
          -31.73792266845703,
          -51.105472564697266,
          -37.75864791870117,
          -29.325963973999023,
          -35.612789154052734,
          -42.35954284667969,
          -36.12993240356445,
          -39.79087448120117,
          -36.62648010253906,
          -36.621803283691406,
          -38.33517074584961,
          -47.4120979309082,
          -35.43571472167969,
          -43.988346099853516,
          -39.708763122558594,
          -31.024930953979492,
          -24.98163414001465,
          -41.42905044555664,
          -35.91075134277344,
          -27.857704162597656,
          -48.82264709472656,
          -31.280118942260742,
          -43.35115432739258,
          -34.02023696899414,
          -36.357669830322266,
          -49.11799621582031,
          -34.74712371826172,
          -48.56937026977539,
          -50.74738311767578,
          -34.63319778442383,
          -32.31254959106445,
          -37.98585891723633,
          -44.97272491455078,
          -32.369266510009766,
          -35.74238967895508,
          -33.35309600830078,
          -28.222549438476562
         ],
         "xaxis": "x",
         "y": [
          0.3930927515029907,
          -3.863835096359253,
          -3.9766671657562256,
          -8.378948211669922,
          -3.2482452392578125,
          -11.832992553710938,
          -7.634802341461182,
          -12.486230850219727,
          -9.187995910644531,
          0.3602902591228485,
          -2.109254837036133,
          -6.610631942749023,
          -16.425861358642578,
          -6.298306465148926,
          -1.741430401802063,
          -4.814197540283203,
          -4.9742817878723145,
          -0.565040647983551,
          -16.048364639282227,
          -13.327164649963379,
          -7.890902519226074,
          7.357810020446777,
          2.883112907409668,
          -8.335592269897461,
          -9.813138961791992,
          -14.63085651397705,
          -1.914242148399353,
          -4.784602165222168,
          -9.348048210144043,
          4.926779747009277,
          -4.012500762939453,
          -1.9520678520202637,
          -5.933454513549805,
          -14.126691818237305,
          2.453900098800659,
          6.628376483917236,
          -10.936860084533691,
          -4.227540969848633,
          -1.0513428449630737,
          -8.772418975830078,
          -10.45832347869873,
          -3.869537115097046,
          -3.5173285007476807,
          -6.589544773101807,
          0.4794805645942688,
          0.5344576835632324,
          -2.164687156677246,
          -5.229672908782959,
          -9.978922843933105,
          -10.640432357788086,
          2.28064227104187,
          -5.205677509307861,
          -7.7961554527282715,
          10.531999588012695,
          8.160733222961426,
          -3.5623133182525635,
          7.464400291442871,
          -14.323371887207031,
          0.7248923182487488,
          1.2999567985534668,
          -9.761385917663574,
          -11.44327163696289,
          -8.35476016998291,
          -3.4272265434265137,
          -10.553536415100098,
          -14.268697738647461,
          0.575537383556366,
          -0.20423980057239532,
          -10.370803833007812,
          -1.739275574684143,
          -13.097589492797852,
          -7.217400074005127,
          -14.693063735961914,
          -2.6517298221588135,
          -2.4335744380950928,
          -12.125388145446777,
          -5.804349899291992,
          -12.314044952392578,
          -12.69744873046875,
          0.05419566482305527,
          5.867525577545166,
          2.228360176086426,
          -8.332304000854492,
          1.1195111274719238,
          -9.534106254577637,
          -2.3580005168914795,
          -11.760289192199707,
          -2.8333024978637695,
          1.847275733947754,
          -3.6024856567382812,
          -11.75689697265625,
          -6.000678539276123,
          6.189065933227539,
          -9.164993286132812,
          7.005805015563965,
          -8.292587280273438,
          -4.764655590057373,
          -13.700078010559082,
          2.314647912979126,
          -7.917130470275879,
          -6.149750709533691,
          -14.06824779510498,
          -0.8826038837432861,
          3.4295835494995117,
          1.4282070398330688,
          0.49830904603004456,
          4.26875638961792,
          1.6111304759979248,
          4.390309810638428,
          -7.670802116394043,
          20.768712997436523,
          -0.4896499812602997,
          -10.71989631652832,
          -5.1364312171936035,
          -12.250823020935059,
          -5.608513355255127,
          -13.64230728149414,
          -4.334804534912109,
          3.02427077293396,
          -16.211666107177734,
          -2.2062456607818604,
          -6.392423629760742,
          -8.765778541564941,
          -15.068411827087402,
          7.288404941558838,
          -1.5411738157272339,
          -10.132709503173828,
          -11.78299331665039,
          2.224297285079956,
          -13.98098087310791,
          -2.796048402786255,
          -0.8222799301147461,
          -9.222892761230469,
          -1.4139842987060547,
          -7.763091087341309,
          -5.520384311676025,
          4.1751322746276855,
          -0.5013520121574402,
          -5.4891767501831055,
          -1.1076732873916626,
          -7.42710542678833,
          -0.6754660606384277,
          0.21671217679977417,
          -13.321920394897461,
          3.4170589447021484,
          -7.988050937652588,
          -2.235964775085449,
          -6.009521961212158,
          -12.260327339172363,
          -12.928230285644531,
          3.3493614196777344,
          -11.346277236938477,
          -14.323713302612305,
          -3.074761152267456,
          -3.8339781761169434,
          0.6090760231018066,
          -7.3881096839904785,
          2.5627739429473877,
          -1.6211267709732056,
          -0.037606120109558105,
          -2.2633426189422607,
          -1.3459677696228027,
          0.23270128667354584,
          2.9298856258392334,
          0.6256629228591919,
          6.071812152862549,
          -5.307880401611328,
          -2.736294746398926,
          -3.8399605751037598,
          3.180081605911255,
          -9.118755340576172,
          -8.72172737121582,
          -6.515646934509277,
          -2.4175970554351807,
          -4.416889190673828,
          -0.2995627224445343,
          -14.001843452453613,
          7.860493183135986,
          -5.900040626525879,
          -4.857137203216553,
          -6.362746715545654,
          -1.3748536109924316,
          -3.5662169456481934,
          -0.8909278512001038,
          -7.255566120147705,
          1.0582363605499268,
          -5.29966402053833,
          -17.313796997070312,
          0.6405061483383179,
          -7.829110145568848,
          -1.3187272548675537,
          2.5776588916778564,
          -8.76073932647705,
          -6.405184745788574,
          -13.119821548461914,
          -6.1087822914123535,
          3.5710346698760986,
          -9.833110809326172,
          -2.3304712772369385,
          -8.35881519317627
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "journal"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "t-SNE of Abstract Embeddings"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "tsne_x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "tsne_y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "abstract_embeddings_np = abstract_embeddings_mean.detach().cpu().numpy()\n",
    "\n",
    "tsne2d = TSNE(n_components=2, random_state=42)\n",
    "tsne3d = TSNE(n_components=3, random_state=42)\n",
    "\n",
    "embeddings_2d = tsne2d.fit_transform(abstract_embeddings_np)\n",
    "embeddings_3d = tsne3d.fit_transform(abstract_embeddings_np)\n",
    "\n",
    "df_all_articles['tsne_x_2d'] = embeddings_2d[:, 0]\n",
    "df_all_articles['tsne_y_2d'] = embeddings_2d[:, 1]\n",
    "\n",
    "df_all_articles['tsne_x_3d'] = embeddings_3d[:, 0]\n",
    "df_all_articles['tsne_y_3d'] = embeddings_3d[:, 1]\n",
    "df_all_articles['tsne_z_3d'] = embeddings_3d[:, 2]\n",
    "\n",
    "fig = px.scatter(df_all_articles, x='tsne_x', y='tsne_y', color='journal',\n",
    "                 title='t-SNE of Abstract Embeddings')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df_all_articles, x='tsne_x_3d', y='tsne_y', z_ color='journal',\n",
    "                 title='t-SNE of Abstract Embeddings')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
