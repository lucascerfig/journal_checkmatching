[
    {
        "title": "Towards automating structural discovery in scanning transmission electron microscopy\n                  <sup>*</sup>",
        "doi": "10.1088/2632-2153/ac3844",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Scanning transmission electron microscopy is now the primary tool for exploring functional materials on the atomic level. Often, features of interest are highly localized in specific regions in the material, such as ferroelectric domain walls, extended defects, or second phase inclusions. Selecting regions to image for structural and chemical discovery via atomically resolved imaging has traditionally proceeded via human operators making semi-informed judgements on sampling locations and parameters. Recent efforts at automation for structural and physical discovery have pointed towards the use of \u2018active learning\u2019 methods that utilize Bayesian optimization with surrogate models to quickly find relevant regions of interest. Yet despite the potential importance of this direction, there is a general lack of certainty in selecting relevant control algorithms and how to balance <jats:italic>a priori</jats:italic> knowledge of the material system with knowledge derived during experimentation. Here we address this gap by developing the automated experiment workflows with several combinations to both illustrate the effects of these choices and demonstrate the tradeoffs associated with each in terms of accuracy, robustness, and susceptibility to hyperparameters for structural discovery. We discuss possible methods to build descriptors using the raw image data and deep learning based semantic segmentation, as well as the implementation of variational autoencoder based representation. Furthermore, each workflow is applied to a range of feature sizes including NiO pillars within a La:SrMnO<jats:sub>3</jats:sub> matrix, ferroelectric domains in BiFeO<jats:sub>3</jats:sub>, and topological defects in graphene. The code developed in this manuscript is open sourced and will be released at <jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/nccreang/AE_Workflows\" xlink:type=\"simple\">github.com/nccreang/AE_Workflows</jats:ext-link>.</jats:p>",
        "is_referenced_by_count": 11
    },
    {
        "title": "SMILES-X: autonomous molecular compounds characterization for small datasets without descriptors",
        "doi": "10.1088/2632-2153/ab57f3",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>There is more and more evidence that machine learning can be successfully applied in materials science and related fields. However, datasets in these fields are often quite small (from tens to several thousands of samples). This means the most advanced machine learning techniques remain neglected, as they are considered to be applicable to big data only. Moreover, materials informatics methods often rely on human-engineered descriptors, that should be carefully chosen, or even created, to fit the physicochemical property that one intends to predict. In this article, we propose a new method that tackles both the issue of small datasets and the difficulty of developing task-specific descriptors. The SMILES-X is an autonomous pipeline for molecular compounds characterisation based on a {Embed-Encode-Attend-Predict} neural architecture with a data-specific Bayesian hyper-parameters optimisation. The only input to the architecture\u2014the SMILES strings\u2014are de-canonicalised in order to efficiently augment the data. One of the key features of the architecture is the attention mechanism, which enables the interpretation of output predictions without extra computational cost. The SMILES-X achieves state-of-the-art results in the inference of aqueous solubility (<jats:inline-formula>\n                     <jats:tex-math>\n<?CDATA ${\\overline{{RMSE}}}_{{\\rm{test}}}\\simeq 0.57\\pm 0.07$?>\n</jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:msub>\n                           <mml:mrow>\n                              <mml:mover accent=\"true\">\n                                 <mml:mrow>\n                                    <mml:mi mathvariant=\"italic\">RMSE</mml:mi>\n                                 </mml:mrow>\n                                 <mml:mrow>\n                                    <mml:mo stretchy=\"true\">\u00af</mml:mo>\n                                 </mml:mrow>\n                              </mml:mover>\n                           </mml:mrow>\n                           <mml:mrow>\n                              <mml:mi mathvariant=\"normal\">test</mml:mi>\n                           </mml:mrow>\n                        </mml:msub>\n                        <mml:mo>\u2243</mml:mo>\n                        <mml:mn>0.57</mml:mn>\n                        <mml:mo>\u00b1</mml:mo>\n                        <mml:mn>0.07</mml:mn>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstab57f3ieqn1.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> mols/L), hydration free energy (<jats:inline-formula>\n                     <jats:tex-math>\n<?CDATA ${\\overline{{RMSE}}}_{{\\rm{test}}}\\simeq 0.81\\pm 0.22$?>\n</jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:msub>\n                           <mml:mrow>\n                              <mml:mover accent=\"true\">\n                                 <mml:mrow>\n                                    <mml:mi mathvariant=\"italic\">RMSE</mml:mi>\n                                 </mml:mrow>\n                                 <mml:mrow>\n                                    <mml:mo stretchy=\"true\">\u00af</mml:mo>\n                                 </mml:mrow>\n                              </mml:mover>\n                           </mml:mrow>\n                           <mml:mrow>\n                              <mml:mi mathvariant=\"normal\">test</mml:mi>\n                           </mml:mrow>\n                        </mml:msub>\n                        <mml:mo>\u2243</mml:mo>\n                        <mml:mn>0.81</mml:mn>\n                        <mml:mo>\u00b1</mml:mo>\n                        <mml:mn>0.22</mml:mn>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstab57f3ieqn2.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> kcal/mol, which is \u223c24.5% better than molecular dynamics simulations), and octanol/water distribution coefficient (<jats:inline-formula>\n                     <jats:tex-math>\n<?CDATA ${\\overline{{RMSE}}}_{{\\rm{test}}}\\simeq 0.59\\pm 0.02$?>\n</jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:msub>\n                           <mml:mrow>\n                              <mml:mover accent=\"true\">\n                                 <mml:mrow>\n                                    <mml:mi mathvariant=\"italic\">RMSE</mml:mi>\n                                 </mml:mrow>\n                                 <mml:mrow>\n                                    <mml:mo stretchy=\"true\">\u00af</mml:mo>\n                                 </mml:mrow>\n                              </mml:mover>\n                           </mml:mrow>\n                           <mml:mrow>\n                              <mml:mi mathvariant=\"normal\">test</mml:mi>\n                           </mml:mrow>\n                        </mml:msub>\n                        <mml:mo>\u2243</mml:mo>\n                        <mml:mn>0.59</mml:mn>\n                        <mml:mo>\u00b1</mml:mo>\n                        <mml:mn>0.02</mml:mn>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstab57f3ieqn3.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> for LogD at pH 7.4) of molecular compounds. The SMILES-X is intended to become an important asset in the toolkit of materials scientists and chemists. The source code for the SMILES-X is available at <jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"http://github.com/GLambard/SMILES-X\" xlink:type=\"simple\">github.com/GLambard/SMILES-X</jats:ext-link>.</jats:p>",
        "is_referenced_by_count": 10
    },
    {
        "title": "Confined hydrogen atom: endohedrals H@C<sub>36</sub> and H@C<sub>60</sub>",
        "doi": "10.1088/2632-2153/acb901",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>In this work, for the lowest states with angular momentum, <jats:inline-formula>\n                     <jats:tex-math><?CDATA $l = 0,1,2$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mi>l</mml:mi>\n                        <mml:mo>=</mml:mo>\n                        <mml:mn>0</mml:mn>\n                        <mml:mo>,</mml:mo>\n                        <mml:mn>1</mml:mn>\n                        <mml:mo>,</mml:mo>\n                        <mml:mn>2</mml:mn>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstacb901ieqn1.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> the energies and eigenfunctions of the endohedrals H@C<jats:sub>36</jats:sub> and H@C<jats:sub>60</jats:sub> are presented. The confining spherically-symmetric barrier was modeled by an inverted Gaussian function of depth <jats:italic>\u03c9</jats:italic>\n                  <jats:sub>0</jats:sub>, width <jats:italic>\u03c3</jats:italic> and centered at <jats:italic>r</jats:italic>\n                  <jats:sub>\n                     <jats:italic>c</jats:italic>\n                  </jats:sub>, <jats:inline-formula>\n                     <jats:tex-math><?CDATA $w(r) = -\\,\\omega_0\\, \\textrm{exp}[-(r-r_c)^2/\\sigma^2]$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mi>w</mml:mi>\n                        <mml:mo stretchy=\"false\">(</mml:mo>\n                        <mml:mi>r</mml:mi>\n                        <mml:mo stretchy=\"false\">)</mml:mo>\n                        <mml:mo>=</mml:mo>\n                        <mml:mo>\u2212</mml:mo>\n                        <mml:msub>\n                           <mml:mi>\u03c9</mml:mi>\n                           <mml:mn>0</mml:mn>\n                        </mml:msub>\n                        <mml:mrow>\n                           <mml:mtext>exp</mml:mtext>\n                        </mml:mrow>\n                        <mml:mo stretchy=\"false\">[</mml:mo>\n                        <mml:mo>\u2212</mml:mo>\n                        <mml:mo stretchy=\"false\">(</mml:mo>\n                        <mml:mi>r</mml:mi>\n                        <mml:mo>\u2212</mml:mo>\n                        <mml:msub>\n                           <mml:mi>r</mml:mi>\n                           <mml:mi>c</mml:mi>\n                        </mml:msub>\n                        <mml:mrow>\n                           <mml:msup>\n                              <mml:mo stretchy=\"false\">)</mml:mo>\n                              <mml:mn>2</mml:mn>\n                           </mml:msup>\n                        </mml:mrow>\n                        <mml:mrow>\n                           <mml:mo>/</mml:mo>\n                        </mml:mrow>\n                        <mml:msup>\n                           <mml:mi>\u03c3</mml:mi>\n                           <mml:mn>2</mml:mn>\n                        </mml:msup>\n                        <mml:mo stretchy=\"false\">]</mml:mo>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstacb901ieqn2.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>. The spectra of the system as a function of the parameters (<jats:inline-formula>\n                     <jats:tex-math><?CDATA $\\omega_0,\\sigma,r_c$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:msub>\n                           <mml:mi>\u03c9</mml:mi>\n                           <mml:mn>0</mml:mn>\n                        </mml:msub>\n                        <mml:mo>,</mml:mo>\n                        <mml:mi>\u03c3</mml:mi>\n                        <mml:mo>,</mml:mo>\n                        <mml:msub>\n                           <mml:mi>r</mml:mi>\n                           <mml:mi>c</mml:mi>\n                        </mml:msub>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstacb901ieqn3.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>) is calculated using three distinct numerical methods: (<jats:italic>i</jats:italic>) Lagrange-mesh method, (<jats:italic>ii</jats:italic>) fourth order finite differences and (<jats:italic>iii</jats:italic>) the finite element method. Concrete results with not less than 11 significant figures are displayed. Also, within the Lagrange-mesh approach the corresponding eigenfunctions and the expectation value of <jats:italic>r</jats:italic> for the first six states of <jats:inline-formula>\n                     <jats:tex-math><?CDATA $s, p$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mi>s</mml:mi>\n                        <mml:mo>,</mml:mo>\n                        <mml:mi>p</mml:mi>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstacb901ieqn4.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>, and <jats:italic>d</jats:italic> symmetries, respectively, are presented as well. Our accurate energies are taken as initial data to train an artificial neural network that generates faster and efficient numerical interpolation. The present numerical results improve and extend those reported in the literature.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "A filter-based feature selection approach in multilabel classification",
        "doi": "10.1088/2632-2153/ad035d",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Multi-label classification is a fast-growing field of machine learning. Recent developments have shown several applications, including social media, healthcare, bio-molecular analysis, scene, and music classification associated with the multilabel classification. In classification problems, multiple labels (multilabel or more than one class label) are assigned to an unseen record instead of a single-label class assignment. Feature selection is a preprocessing phase used to identify the most relevant features that could improve the accuracy of the multilabel classifiers. The focus of this study is the feature selection method in multilabel classification. The study used a feature selection filter method involving the Fisher score, analysis of variance test, mutual information, Chi-Square, and ensembles of these statistical methods. An extensive range of machine learning algorithms is applied in the modelling phase of a multilabel classification model that includes binary relevance, classifier chain, label powerset, binary relevance KNN, multi-label twin support vector machine, multi-label KNN. Besides, label space partitioning and majority voting of ensemble methods are used and Random Forest is the base learner. The experiments are carried out over five different multilabel benchmarking datasets. The evaluation of the classification model is measured using accuracy, precision, recall, F1 score, and hamming loss. The study demonstrated that the filter methods (i.e. mutual information) having top weighted <jats:inline-formula>\n                     <jats:tex-math><?CDATA $80\\%$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mn>80</mml:mn>\n                        <mml:mi mathvariant=\"normal\">%</mml:mi>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstad035dieqn1.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> to <jats:inline-formula>\n                     <jats:tex-math><?CDATA $20\\%$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mn>20</mml:mn>\n                        <mml:mi mathvariant=\"normal\">%</mml:mi>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstad035dieqn2.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> features provided significant outcomes.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "Improving parametric neural networks for high-energy physics (and beyond)",
        "doi": "10.1088/2632-2153/ac917c",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Signal-background classification is a central problem in high-energy physics, that plays a major role for the discovery of new fundamental particles. A recent method\u2014the parametric neural network (pNN)\u2014leverages multiple signal mass hypotheses as an additional input feature to effectively replace a whole set of individual classifiers, each providing (in principle) the best response for the corresponding mass hypothesis. In this work we aim at deepening the understanding of pNNs in light of real-world usage. We discovered several peculiarities of parametric networks, providing intuition, metrics, and guidelines to them. We further propose an alternative parametrization scheme, resulting in a new parametrized neural network architecture: the AffinePNN; along with many other generally applicable improvements, like the <jats:italic>balanced training</jats:italic> procedure. Finally, we extensively and empirically evaluate our models on the <jats:monospace>HEPMASS</jats:monospace> dataset, along its <jats:italic>imbalanced</jats:italic> version (called <jats:monospace>HEPMASS-IMB</jats:monospace>) we provide here for the first time, to further validate our approach. Provided results are in terms of the impact of the proposed design decisions, classification performance, and interpolation capability, as well.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Learning to discover: expressive Gaussian mixture models for multi-dimensional simulation and parameter inference in the physical sciences",
        "doi": "10.1088/2632-2153/ac4a3b",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We show that density models describing multiple observables with (1) hard boundaries and (2) dependence on external parameters may be created using an auto-regressive Gaussian mixture model. The model is designed to capture how observable spectra are deformed by hypothesis variations, and is made more expressive by projecting data onto a configurable latent space. It may be used as a statistical model for scientific discovery in interpreting experimental observations, for example when constraining the parameters of a physical model or tuning simulation parameters according to calibration data. The model may also be sampled for use within a Monte Carlo simulation chain, or used to estimate likelihood ratios for event classification. The method is demonstrated on simulated high-energy particle physics data considering the anomalous electroweak production of a <jats:italic>Z</jats:italic> boson in association with a dijet system at the Large Hadron Collider, and the accuracy of inference is tested using a realistic toy example. The developed methods are domain agnostic; they may be used within any field to perform simulation or inference where a dataset consisting of many real-valued observables has conditional dependence on external parameters.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "Towards a variational Jordan\u2013Lee\u2013Preskill quantum algorithm",
        "doi": "10.1088/2632-2153/aca06b",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Rapid developments of quantum information technology show promising opportunities for simulating quantum field theory in near-term quantum devices. In this work, we formulate the theory of (time-dependent) variational quantum simulation of the <jats:inline-formula>\n                     <jats:tex-math><?CDATA $1+1$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mn>1</mml:mn>\n                        <mml:mo>+</mml:mo>\n                        <mml:mn>1</mml:mn>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstaca06bieqn1.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> dimensional <jats:inline-formula>\n                     <jats:tex-math><?CDATA $\\lambda \\phi^4$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mi>\u03bb</mml:mi>\n                        <mml:msup>\n                           <mml:mi>\u03d5</mml:mi>\n                           <mml:mn>4</mml:mn>\n                        </mml:msup>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstaca06bieqn2.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> quantum field theory including encoding, state preparation, and time evolution, with several numerical simulation results. These algorithms could be understood as near-term variational quantum circuit (quantum neural network) analogs of the Jordan\u2013Lee\u2013Preskill algorithm, the basic algorithm for simulating quantum field theory using universal quantum devices. Besides, we highlight the advantages of encoding with harmonic oscillator basis based on the Lehmann\u2014Symanzik\u2014Zimmermann reduction formula and several computational efficiency such as when implementing a bosonic version of the unitary coupled cluster ansatz to prepare initial states. We also discuss how to circumvent the \u2018spectral crowding\u2019 problem in the quantum field theory simulation and appraise our algorithm by both state and subspace fidelities.</jats:p>",
        "is_referenced_by_count": 6
    },
    {
        "title": "A multi-stage machine learning algorithm for estimating personal dose equivalent using thermoluminescent dosimeter",
        "doi": "10.1088/2632-2153/ad1c31",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>In the present age, marked by data-driven advancements in various fields, the importance of machine learning (ML) holds a prominent position. The ability of ML algorithms to resolve complex patterns and extract insights from large datasets has solidified its transformative potential in various scientific domains. This paper introduces an innovative application of ML techniques in the domain of radiation dosimetry. Specifically, it shows the applicability of ML in estimating the radiation dose received by occupational workers. This estimation is expressed in terms of personal dose equivalent, and it involves the utilization of thermoluminescence signals emitted by CaSO<jats:sub>4</jats:sub>:Dy-based personnel monitoring badges. To estimate personal dose equivalent, three-stage algorithm driven by ML models is proposed. This algorithm systematically identifies the photon energy ranges, calculates the average photon energy, and determines personal dose equivalent. By implementing this approach to the conventional three-element dosimeter, the study overcomes existing limitations and enhances accuracy in dose estimation. The algorithm demonstrates 97.8% classification accuracy in discerning photon energy ranges and achieves a coefficient of determination of 0.988 for estimating average photon energy. Importantly, it also reduces the coefficient of variation of relative deviations by up to 6% for estimated personal dose equivalent, compared to existing algorithms. The study improves accuracy and establishes a new methodology for evaluating radiation exposure to occupational workers using conventional thermoluminescent dosimeter badge.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Semi-equivariant conditional normalizing flows, with applications to target-aware molecule generation",
        "doi": "10.1088/2632-2153/ace58c",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Learning over the domain of 3D graphs has applications in a number of scientific and engineering disciplines, including molecular chemistry, high energy physics, and computer vision. We consider a specific problem in this domain, namely: given one such 3D graph, dubbed the base graph, our goal is to learn a conditional distribution over another such graph, dubbed the complement graph. Due to the three-dimensional nature of the graphs in question, there are certain natural invariances such a distribution should satisfy: it should be invariant to rigid body transformations that act jointly on the base graph and the complement graph, and it should also be invariant to permutations of the vertices of either graph. We propose a general method for learning the conditional probabilistic model, the central part of which is a continuous normalizing flow. We establish semi-equivariance conditions on the flow which guarantee the aforementioned invariance conditions on the conditional distribution. Additionally, we propose a graph neural network architecture which implements this flow, and which is designed to learn effectively despite the typical differences in size between the base graph and the complement graph. We demonstrate the utility of our technique in the molecular setting by training a conditional generative model which, given a receptor, can generate ligands which may successfully bind to that receptor. The resulting model, which has potential applications in drug design, displays high quality performance in the key \u0394Binding metric.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "ELUQuant: event-level uncertainty quantification in deep inelastic scattering",
        "doi": "10.1088/2632-2153/ad2098",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We introduce a physics-informed Bayesian neural network with flow-approximated posteriors using multiplicative normalizing flows for detailed uncertainty quantification (UQ) at the physics event-level. Our method is capable of identifying both heteroskedastic aleatoric and epistemic uncertainties, providing granular physical insights. Applied to deep inelastic scattering (DIS) events, our model effectively extracts the kinematic variables <jats:italic>x</jats:italic>, <jats:italic>Q</jats:italic>\n                  <jats:sup>2</jats:sup>, and <jats:italic>y</jats:italic>, matching the performance of recent deep learning regression techniques but with the critical enhancement of event-level UQ. This detailed description of the underlying uncertainty proves invaluable for decision-making, especially in tasks like event filtering. It also allows for the reduction of true inaccuracies without directly accessing the ground truth. A thorough DIS simulation using the H1 detector at HERA indicates possible applications for the future electron\u2013ion collider. Additionally, this paves the way for related tasks such as data quality monitoring and anomaly detection. Remarkably, our approach effectively processes large samples at high rates.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Source-Agnostic Gravitational-Wave Detection with Recurrent Autoencoders",
        "doi": "10.1088/2632-2153/ac5385",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We present an application of anomaly detection techniques based on deep recurrent autoencoders to the problem of detecting gravitational wave signals in laser interferometers. Trained on noise data, this class of algorithms could detect signals using an unsupervised strategy, i.e., without targeting a speci\ufb01c kind of source. We develop a custom architecture to analyze the data from two interferometers. We compare the obtained performance to that obtained with other autoencoder architectures and with a convolutional classi\ufb01er. The unsupervised nature of the proposed strategy comes with a cost in terms of accuracy, when compared to more traditional supervised techniques. On the other hand, there is a qualitative gain in generalizing the experimental sensitivity beyond the ensemble of pre-computed signal templates. The recurrent autoencoder outperforms other autoencoders based on di\ufb00erent architectures. The class of recurrent autoencoders presented in this paper could complement the search strategy employed for gravitational wave detection and extend the reach of the ongoing detection campaigns. </jats:p>",
        "is_referenced_by_count": 2
    },
    {
        "title": "NeuralNEB\u2014neural networks can find reaction paths fast",
        "doi": "10.1088/2632-2153/aca23e",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title><jats:p>Quantum mechanical methods like density functional theory (DFT) are used with great success alongside efficient search algorithms for studying kinetics of reactive systems. However, DFT is prohibitively expensive for large scale exploration. Machine learning (ML) models have turned out to be excellent emulators of small molecule DFT calculations and could possibly replace DFT in such tasks. For kinetics, success relies primarily on the models\u2019 capability to accurately predict the potential energy surface around transition-states and minimal energy paths. Previously this has not been possible due to scarcity of relevant data in the literature. In this paper we train equivariant graph neural network-based models on data from 10 000 elementary reactions from the recently published Transition1x dataset. We apply the models as potentials for the nudged elastic band algorithm and achieve a mean average error of 0.23\u2009eV and root mean squared error of 0.52\u2009eV on barrier energies on unseen reactions. We compare the results against equivalent models trained on QM9x and ANI1x. We also compare with and outperform Density Functional based Tight Binding on both accuracy and required computational resources. The implication is that ML models are now at a level where they can be applied to studying chemical reaction kinetics given a sufficient amount of data relevant to this task.</jats:p>",
        "is_referenced_by_count": 10
    },
    {
        "title": "Deep kernel methods learn better: from cards to process optimization",
        "doi": "10.1088/2632-2153/ad1a4f",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>The ability of deep learning methods to perform classification and regression tasks relies heavily on their capacity to uncover manifolds in high-dimensional data spaces and project them into low-dimensional representation spaces. In this study, we investigate the structure and character of the manifolds generated by classical variational autoencoder (VAE) approaches and deep kernel learning (DKL). In the former case, the structure of the latent space is determined by the properties of the input data alone, while in the latter, the latent manifold forms as a result of an active learning process that balances the data distribution and target functionalities. We show that DKL with active learning can produce a more compact and smooth latent space which is more conducive to optimization compared to previously reported methods, such as the VAE. We demonstrate this behavior using a simple cards dataset and extend it to the optimization of domain-generated trajectories in physical systems. Our findings suggest that latent manifolds constructed through active learning have a more beneficial structure for optimization problems, especially in feature-rich target-poor scenarios that are common in domain sciences, such as materials synthesis, energy storage, and molecular discovery. The Jupyter Notebooks that encapsulate the complete analysis accompany the article.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Graph machine learning framework for depicting wavefunction on interface",
        "doi": "10.1088/2632-2153/ad0937",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>The wavefunction, as the basic hypothesis of quantum mechanics, describes the motion of particles and plays a pivotal role in determining physical properties at the atomic scale. However, its conventional acquisition method, such as density functional theory, requires a considerable amount of calculation, which brings numerous problems to wide application. Here, we propose an algorithmic framework based on graph neural network to machine-learn the wavefunction of electrons. This framework primarily generates atomic features containing information about chemical environment and geometric structure and subsequently constructs a scalable distribution map. For the first time, the visualization of wavefunction of interface is realized by machine learning methods, bypassing complex calculation and obscure comprehension. In this way, we vividly illustrate quantum mechanics, which can inspire theoretical exploration. As an intriguing case to verify the ability of our method, a novel quantum confinement phenomenon on interfaces based on graphene nanoribbon is uncovered. We believe that the versatility of this framework paves the way for swiftly linking quantum physics and atom-level structures.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Stochastic gradient descent with random label noises: doubly stochastic models and inference stabilizer",
        "doi": "10.1088/2632-2153/ad13ba",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Random label noise (or observational noise) widely exists in practical machine learning settings. While previous studies primarily focused on the effects of label noise to the performance of learning, our work intends to investigate the implicit regularization effects of label noise, under mini-batch sampling settings of stochastic gradient descent (SGD), with the assumption that label noise is unbiased. Specifically, we analyze the learning dynamics of SGD over the quadratic loss with unbiased label noise (ULN), where we model the dynamics of SGD as a stochastic differentiable equation with two diffusion terms (namely a doubly stochastic model). While the first diffusion term is caused by mini-batch sampling over the (label-noiseless) loss gradients, as in many other works on SGD (Zhu <jats:italic>et al</jats:italic> 2019 <jats:italic>ICML</jats:italic> 7654\u201363; Wu <jats:italic>et al</jats:italic> 2020 <jats:italic>Int. Conf. on Machine Learning</jats:italic> (PMLR) pp 10367\u201376), our model investigates the second noise term of SGD dynamics, which is caused by mini-batch sampling over the label noise, as an implicit regularizer. Our theoretical analysis finds such an implicit regularizer would favor some convergence points that could stabilize model outputs against perturbations of parameters (namely <jats:italic>inference stability</jats:italic>). Though similar phenomenon have been investigated by Blanc <jats:italic>et al</jats:italic> (2020 <jats:italic>Conf. on Learning Theory</jats:italic> (PMLR) pp 483\u2013513), our work does not assume SGD as an Ornstein\u2013Uhlenbeck-like process and achieves a more generalizable result with convergence of the approximation proved. To validate our analysis, we design two sets of empirical studies to analyze the implicit regularizer of SGD with unbiased random label noise for deep neural network training and linear regression. Our first experiment studies the noisy self-distillation tricks for deep learning, where student networks are trained using the outputs from well-trained teachers with additive unbiased random label noise. Our experiment shows that the implicit regularizer caused by the label noise tends to select models with improved inference stability. We also carry out experiments on SGD-based linear regression with ULN, where we plot the trajectories of parameters learned in every step and visualize the effects of implicit regularization. The results back up our theoretical findings.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Efficient hyperparameter tuning for kernel ridge regression with Bayesian optimization",
        "doi": "10.1088/2632-2153/abee59",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Machine learning methods usually depend on internal parameters\u2014so called hyperparameters\u2014that need to be optimized for best performance. Such optimization poses a burden on machine learning practitioners, requiring expert knowledge, intuition or computationally demanding brute-force parameter searches. We here assess three different hyperparameter selection methods: grid search, random search and an efficient automated optimization technique based on Bayesian optimization (BO). We apply these methods to a machine learning problem based on kernel ridge regression in computational chemistry. Two different descriptors are employed to represent the atomic structure of organic molecules, one of which introduces its own set of hyperparameters to the method. We identify optimal hyperparameter configurations and infer entire prediction error landscapes in hyperparameter space that serve as visual guides for the hyperparameter performance. We further demonstrate that for an increasing number of hyperparameters, BO and random search become significantly more efficient in computational time than an exhaustive grid search, while delivering an equivalent or even better accuracy.</jats:p>",
        "is_referenced_by_count": 28
    },
    {
        "title": "Transfer learning application of self-supervised learning in ARPES",
        "doi": "10.1088/2632-2153/aced7d",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>There is a growing recognition that electronic band structure is a local property of materials and devices, and there is steep growth in capabilities to collect the relevant data. New photon sources, from small-laboratory-based lasers to free electron lasers, together with focusing beam optics and advanced electron spectrometers, are beginning to enable angle-resolved photoemission spectroscopy (ARPES) in scanning mode with a spatial resolution of near to and below microns, two- to three orders of magnitude smaller than what has been typical for ARPES hitherto. The results are vast data sets inhabiting a five-dimensional subspace of the ten-dimensional space spanned by two scanning dimensions of real space, three of reciprocal space, three of spin-space, time, and energy. In this work, we demonstrate that recent developments in representational learning (self-supervised learning) combined with <jats:italic>k</jats:italic>-means clustering can help automate the labeling and spatial mapping of dispersion cuts, thus saving precious time relative to manual analysis, albeit with low performance. Finally, we introduce a few-shot learning (<jats:italic>k</jats:italic>-nearest neighbor) in representational space where we selectively choose one (<jats:italic>k</jats:italic> = 1) image reference for each known label and subsequently label the rest of the data with respect to the nearest reference image. This last approach demonstrates the strength of self-supervised learning to automate image analysis in ARPES in particular and can be generalized to any scientific image analysis.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Machine-learning Kohn\u2013Sham potential from dynamics in time-dependent Kohn\u2013Sham systems",
        "doi": "10.1088/2632-2153/ace8f0",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>The construction of a better exchange-correlation potential in time-dependent density functional theory (TDDFT) can improve the accuracy of TDDFT calculations and provide more accurate predictions of the properties of many-electron systems. Here, we propose a machine learning method to develop the energy functional and the Kohn\u2013Sham potential of a time-dependent Kohn\u2013Sham (TDKS) system is proposed. The method is based on the dynamics of the Kohn\u2013Sham system and does not require any data on the exact Kohn\u2013Sham potential for training the model. We demonstrate the results of our method with a 1D harmonic oscillator example and a 1D two-electron example. We show that the machine-learned Kohn\u2013Sham potential matches the exact Kohn\u2013Sham potential in the absence of memory effect. Our method can still capture the dynamics of the Kohn\u2013Sham system in the presence of memory effects. The machine learning method developed in this article provides insight into making better approximations of the energy functional and the Kohn\u2013Sham potential in the TDKS system.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Defence against adversarial attacks using classical and quantum-enhanced Boltzmann machines\n                  <sup>\u2020</sup>",
        "doi": "10.1088/2632-2153/abf834",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We provide a robust defence to adversarial attacks on discriminative algorithms. Neural networks are naturally vulnerable to small, tailored perturbations in the input data that lead to wrong predictions. On the contrary, generative models attempt to learn the distribution underlying a dataset, making them inherently more robust to small perturbations. We use Boltzmann machines for discrimination purposes as attack-resistant classifiers, and compare them against standard state-of-the-art adversarial defences. We find improvements ranging from 5% to 72% against attacks with Boltzmann machines on the MNIST dataset. We furthermore complement the training with quantum-enhanced sampling from the D-Wave 2000Q annealer, finding results comparable with classical techniques and with marginal improvements in some cases. These results underline the relevance of probabilistic methods in constructing neural networks and highlight a novel scenario of practical relevance where quantum computers, even with limited hardware capabilities, could provide advantages over classical computers.</jats:p>",
        "is_referenced_by_count": 3
    },
    {
        "title": "How isotropic kernels perform on simple invariants",
        "doi": "10.1088/2632-2153/abd485",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We investigate how the training curve of isotropic kernel methods depends on the symmetry of the task to be learned, in several settings. (i) We consider a regression task, where the target function is a Gaussian random field that depends only on <jats:inline-formula>\n                     <jats:tex-math><?CDATA $d_\\parallel$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:msub>\n                           <mml:mi>d</mml:mi>\n                           <mml:mo>\u2225</mml:mo>\n                        </mml:msub>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstabd485ieqn1.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> variables, fewer than the input dimension <jats:italic>d</jats:italic>. We compute the expected test error <jats:italic>\u03f5</jats:italic> that follows <jats:inline-formula>\n                     <jats:tex-math><?CDATA $\\epsilon\\sim p^{-\\beta}$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mi>\u03f5</mml:mi>\n                        <mml:mo>\u223c</mml:mo>\n                        <mml:msup>\n                           <mml:mi>p</mml:mi>\n                           <mml:mrow>\n                              <mml:mo>\u2212</mml:mo>\n                              <mml:mi>\u03b2</mml:mi>\n                           </mml:mrow>\n                        </mml:msup>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstabd485ieqn2.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> where <jats:italic>p</jats:italic> is the size of the training set. We find that <jats:italic>\u03b2</jats:italic>\u2009\u223c\u20091/<jats:italic>d</jats:italic> independently of <jats:inline-formula>\n                     <jats:tex-math><?CDATA $d_\\parallel$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:msub>\n                           <mml:mi>d</mml:mi>\n                           <mml:mo>\u2225</mml:mo>\n                        </mml:msub>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstabd485ieqn3.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>, supporting previous findings that the presence of invariants does not resolve the curse of dimensionality for kernel regression. (ii) Next we consider support-vector binary classification and introduce the <jats:italic>stripe model</jats:italic>, where the data label depends on a single coordinate <jats:inline-formula>\n                     <jats:tex-math><?CDATA $y(\\underline x) = y(x_1)$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mi>y</mml:mi>\n                        <mml:mo stretchy=\"false\">(</mml:mo>\n                        <mml:munder>\n                           <mml:mi>x</mml:mi>\n                           <mml:mo accent=\"true\" stretchy=\"true\">_</mml:mo>\n                        </mml:munder>\n                        <mml:mo stretchy=\"false\">)</mml:mo>\n                        <mml:mo>=</mml:mo>\n                        <mml:mi>y</mml:mi>\n                        <mml:mo stretchy=\"false\">(</mml:mo>\n                        <mml:msub>\n                           <mml:mi>x</mml:mi>\n                           <mml:mn>1</mml:mn>\n                        </mml:msub>\n                        <mml:mo stretchy=\"false\">)</mml:mo>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstabd485ieqn4.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>, corresponding to parallel decision boundaries separating labels of different signs, and consider that there is no margin at these interfaces. We argue and confirm numerically that, for large bandwidth, <jats:inline-formula>\n                     <jats:tex-math><?CDATA $\\beta = \\frac{d-1+\\xi}{3d-3+\\xi}$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mi>\u03b2</mml:mi>\n                        <mml:mo>=</mml:mo>\n                        <mml:mfrac>\n                           <mml:mrow>\n                              <mml:mi>d</mml:mi>\n                              <mml:mo>\u2212</mml:mo>\n                              <mml:mn>1</mml:mn>\n                              <mml:mo>+</mml:mo>\n                              <mml:mi>\u03be</mml:mi>\n                           </mml:mrow>\n                           <mml:mrow>\n                              <mml:mn>3</mml:mn>\n                              <mml:mi>d</mml:mi>\n                              <mml:mo>\u2212</mml:mo>\n                              <mml:mn>3</mml:mn>\n                              <mml:mo>+</mml:mo>\n                              <mml:mi>\u03be</mml:mi>\n                           </mml:mrow>\n                        </mml:mfrac>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstabd485ieqn5.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>, where <jats:italic>\u03be</jats:italic>\u2009\u2208\u2009(0,\u20092) is the exponent characterizing the singularity of the kernel at the origin. This estimation improves classical bounds obtainable from Rademacher complexity. In this setting there is no curse of dimensionality since <jats:inline-formula>\n                     <jats:tex-math><?CDATA $\\beta\\rightarrow 1/3$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mi>\u03b2</mml:mi>\n                        <mml:mo stretchy=\"false\">\u2192</mml:mo>\n                        <mml:mn>1</mml:mn>\n                        <mml:mrow>\n                           <mml:mo>/</mml:mo>\n                        </mml:mrow>\n                        <mml:mn>3</mml:mn>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstabd485ieqn6.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> as <jats:inline-formula>\n                     <jats:tex-math><?CDATA $d\\rightarrow\\infty$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mi>d</mml:mi>\n                        <mml:mo stretchy=\"false\">\u2192</mml:mo>\n                        <mml:mi mathvariant=\"normal\">\u221e</mml:mi>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstabd485ieqn7.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>. (iii) We confirm these findings for the <jats:italic>spherical model</jats:italic>, for which <jats:inline-formula>\n                     <jats:tex-math><?CDATA $y(\\underline x) = y(||\\underline x||)$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mi>y</mml:mi>\n                        <mml:mo stretchy=\"false\">(</mml:mo>\n                        <mml:munder>\n                           <mml:mi>x</mml:mi>\n                           <mml:mo accent=\"true\" stretchy=\"true\">_</mml:mo>\n                        </mml:munder>\n                        <mml:mo stretchy=\"false\">)</mml:mo>\n                        <mml:mo>=</mml:mo>\n                        <mml:mi>y</mml:mi>\n                        <mml:mo stretchy=\"false\">(</mml:mo>\n                        <mml:mrow>\n                           <mml:mo>|</mml:mo>\n                        </mml:mrow>\n                        <mml:mrow>\n                           <mml:mo>|</mml:mo>\n                        </mml:mrow>\n                        <mml:munder>\n                           <mml:mi>x</mml:mi>\n                           <mml:mo accent=\"true\" stretchy=\"true\">_</mml:mo>\n                        </mml:munder>\n                        <mml:mrow>\n                           <mml:mo>|</mml:mo>\n                        </mml:mrow>\n                        <mml:mrow>\n                           <mml:mo>|</mml:mo>\n                        </mml:mrow>\n                        <mml:mo stretchy=\"false\">)</mml:mo>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstabd485ieqn8.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>. (iv) In the stripe model, we show that, if the data are compressed along their invariants by some factor <jats:italic>\u03bb</jats:italic> (an operation believed to take place in deep networks), the test error is reduced by a factor <jats:inline-formula>\n                     <jats:tex-math><?CDATA $\\lambda^{-\\frac{2(d-1)}{3d-3+\\xi}}$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:msup>\n                           <mml:mi>\u03bb</mml:mi>\n                           <mml:mrow>\n                              <mml:mo>\u2212</mml:mo>\n                              <mml:mfrac>\n                                 <mml:mrow>\n                                    <mml:mn>2</mml:mn>\n                                    <mml:mo stretchy=\"false\">(</mml:mo>\n                                    <mml:mi>d</mml:mi>\n                                    <mml:mo>\u2212</mml:mo>\n                                    <mml:mn>1</mml:mn>\n                                    <mml:mo stretchy=\"false\">)</mml:mo>\n                                 </mml:mrow>\n                                 <mml:mrow>\n                                    <mml:mn>3</mml:mn>\n                                    <mml:mi>d</mml:mi>\n                                    <mml:mo>\u2212</mml:mo>\n                                    <mml:mn>3</mml:mn>\n                                    <mml:mo>+</mml:mo>\n                                    <mml:mi>\u03be</mml:mi>\n                                 </mml:mrow>\n                              </mml:mfrac>\n                           </mml:mrow>\n                        </mml:msup>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstabd485ieqn9.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>.</jats:p>",
        "is_referenced_by_count": 4
    },
    {
        "title": "Machine learning for neutron scattering at ORNL<sup>*</sup>",
        "doi": "10.1088/2632-2153/abcf88",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Machine learning (ML) offers exciting new opportunities to extract more information from scattering data. At neutron scattering user facilities, ML has the potential to help accelerate scientific productivity by empowering facility users with insight into their data which has traditionally been supplied by scattering experts. Such support can help in both speeding up common modeling problems for users, as well as help solve harder problems that are normally time consuming and difficult to address with standard methods. This article explores the recent ML work undertaken at Oak Ridge National Laboratory involving neutron scattering data. We cover materials structure modeling for diffuse scattering, powder diffraction, and small-angle scattering. We also discuss how ML can help to model the response of the instrument more precisely, as well as enable quick extraction of information from neutron data. The application of super-resolution techniques to small-angle scattering and peak extraction for diffraction will be discussed.</jats:p>",
        "is_referenced_by_count": 9
    },
    {
        "title": "Deep learning neural network for approaching Schr\u00f6dinger problems with arbitrary two-dimensional confinement",
        "doi": "10.1088/2632-2153/acf55b",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>This article presents an approach to the two-dimensional Schr\u00f6dinger equation based on automatic learning methods with neural networks. It is intended to determine the ground state of a particle confined in any two-dimensional potential, starting from the knowledge of the solutions to a large number of arbitrary sample problems. A network architecture with two hidden layers is proposed to predict the wave function and energy of the ground state. Several accuracy indicators are proposed for validating the estimates provided by the neural network. The testing of the trained network is done by applying it to a large set of confinement potentials different from those used in the learning process. Some particular cases with symmetrical potentials are solved as concrete examples, and a good network prediction accuracy is found.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "\u2018Flux+Mutability\u2019: a conditional generative approach to one-class classification and anomaly detection",
        "doi": "10.1088/2632-2153/ac9bcb",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Anomaly Detection is becoming increasingly popular within the experimental physics community. At experiments such as the Large Hadron Collider, anomaly detection is growing in interest for finding new physics beyond the Standard Model. This paper details the implementation of a novel Machine Learning architecture, called Flux+Mutability, which combines cutting-edge conditional generative models with clustering algorithms. In the \u2018flux\u2019 stage we learn the distribution of a reference class. The \u2018mutability\u2019 stage at inference addresses if data significantly deviates from the reference class. We demonstrate the validity of our approach and its connection to multiple problems spanning from one-class classification to anomaly detection. In particular, we apply our method to the isolation of neutral showers in an electromagnetic calorimeter and show its performance in detecting anomalous dijets events from standard QCD background. This approach limits assumptions on the reference sample and remains agnostic to the complementary class of objects of a given problem. We describe the possibility of dynamically generating a reference population and defining selection criteria via quantile cuts. Remarkably this flexible architecture can be deployed for a wide range of problems, and applications like multi-class classification or data quality control are left for further exploration.</jats:p>",
        "is_referenced_by_count": 7
    },
    {
        "title": "GRINN: a physics-informed neural network for solving hydrodynamic systems in the presence of self-gravity",
        "doi": "10.1088/2632-2153/ad3a32",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Modeling self-gravitating gas flows is essential to answering many fundamental questions in astrophysics. This spans many topics including planet-forming disks, star-forming clouds, galaxy formation, and the development of large-scale structures in the Universe. However, the nonlinear interaction between gravity and fluid dynamics offers a formidable challenge to solving the resulting time-dependent partial differential equations (PDEs) in three dimensions (3D). By leveraging the universal approximation capabilities of a neural network within a mesh-free framework, physics informed neural networks (PINNs) offer a new way of addressing this challenge. We introduce the gravity-informed neural network (GRINN), a PINN-based code, to simulate 3D self-gravitating hydrodynamic systems. Here, we specifically study gravitational instability and wave propagation in an isothermal gas. Our results match a linear analytic solution to within 1% in the linear regime and a conventional grid code solution to within 5% as the disturbance grows into the nonlinear regime. We find that the computation time of the GRINN does not scale with the number of dimensions. This is in contrast to the scaling of the grid-based code for the hydrodynamic and self-gravity calculations as the number of dimensions is increased. Our results show that the GRINN computation time is longer than the grid code in one- and two- dimensional calculations but is an order of magnitude lesser than the grid code in 3D with similar accuracy. Physics-informed neural networks like GRINN thus show promise for advancing our ability to model 3D astrophysical flows.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Evaluation of synthetic and experimental training data in supervised machine learning applied to charge-state detection of quantum dots",
        "doi": "10.1088/2632-2153/ac104c",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Automated tuning of gate-defined quantum dots is a requirement for large-scale semiconductor-based qubit initialisation. An essential step of these tuning procedures is charge-state detection based on charge stability diagrams. Using supervised machine learning to perform this task requires a large dataset for models to train on. In order to avoid hand labelling experimental data, synthetic data has been explored as an alternative. While providing a significant increase in the size of the training dataset compared to using experimental data, using synthetic data means that classifiers are trained on data sourced from a different distribution than the experimental data that is part of the tuning process. Here we evaluate the prediction accuracy of a range of machine learning models trained on simulated and experimental data, and their ability to generalise to experimental charge stability diagrams in two-dimensional electron gas and nanowire devices. We find that classifiers perform best on either purely experimental or a combination of synthetic and experimental training data, and that adding common experimental noise signatures to the synthetic data does not dramatically improve the classification accuracy. These results suggest that experimental training data as well as realistic quantum dot simulations and noise models are essential in charge-state detection using supervised machine learning.</jats:p>",
        "is_referenced_by_count": 9
    },
    {
        "title": "Reinforcement learning decoders for fault-tolerant quantum computation",
        "doi": "10.1088/2632-2153/abc609",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Topological error correcting codes, and particularly the surface code, currently provide the most feasible road-map towards large-scale fault-tolerant quantum computation. As such, obtaining fast and flexible decoding algorithms for these codes, within the experimentally realistic and challenging context of faulty syndrome measurements, without requiring any final read-out of the physical qubits, is of critical importance. In this work, we show that the problem of decoding such codes can be naturally reformulated as a process of repeated interactions between a decoding agent and a code environment, to which the machinery of reinforcement learning can be applied to obtain decoding agents. While in principle this framework can be instantiated with environments modelling circuit level noise, we take a first step towards this goal by using deepQ learning to obtain decoding agents for a variety of simplified phenomenological noise models, which yield faulty syndrome measurements without including the propagation of errors which arise in full circuit level noise models.</jats:p>",
        "is_referenced_by_count": 30
    },
    {
        "title": "Transferring predictions of formation energy across lattices of increasing size*",
        "doi": "10.1088/2632-2153/ad3d2c",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>In this study, we show the transferability of graph convolutional neural network (GCNN) predictions of the formation energy of the nickel-platinum solid solution alloy across atomic structures of increasing sizes. The original dataset was generated with the large-scale atomic/molecular massively parallel simulator using the second nearest-neighbor modified embedded-atom method empirical interatomic potential. Geometry optimization was performed on the initially randomly generated face centered cubic crystal structures and the formation energy has been calculated at each step of the geometry optimization, with configurations spanning the whole compositional range. Using data from various steps of the geometry optimization, we first trained our open-source, scalable implementation of GCNN called HydraGNN on a lattice of 256 atoms, which accounts well for the short-range interactions. Using this data, we predicted the formation energy for lattices of 864 atoms and 2048 atoms, which resulted in lower-than-expected accuracy due to the long-range interactions present in these larger lattices. We accounted for the long-range interactions by including a small amount of training data representative for those two larger sizes, whereupon the predictions of HydraGNN scaled linearly with the size of the lattice. Therefore, our strategy ensured scalability while reducing significantly the computational cost of training on larger lattice sizes.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Quantum machine learning and quantum biomimetics: A perspective",
        "doi": "10.1088/2632-2153/ab9803",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title><jats:p>Quantum machine learning has emerged as an exciting and promising paradigm inside quantum technologies. It may permit, on the one hand, to carry out more efficient machine learning calculations by means of quantum devices, while, on the other hand, to employ machine learning techniques to better control quantum systems. Inside quantum machine learning, quantum reinforcement learning aims at developing \u2018intelligent\u2019 quantum agents that may interact with the outer world and adapt to it, with the strategy of achieving some final goal. Another paradigm inside quantum machine learning is that of quantum autoencoders, which may allow one for employing fewer resources in a quantum device via a training process. Moreover, the field of quantum biomimetics aims at establishing analogies between biological and quantum systems, to look for previously inadvertent connections that may enable useful applications. Two recent examples are the concepts of quantum artificial life, as well as of quantum memristors. In this Perspective, we give an overview of these topics, describing the related research carried out by the scientific community.</jats:p>",
        "is_referenced_by_count": 41
    },
    {
        "title": "ML-based regionalization of climate variables to forecast seasonal precipitation for water resources management",
        "doi": "10.1088/2632-2153/ad1d04",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Numerous dams and reservoirs have been constructed in South Korea, considering the distribution of seasonal precipitation which highly deviates from the actual one with high precipitation amount in summer and very low amount in other seasons. These water-related structures should be properly managed in order to meet seasonal demands of water resources wherein the forecasting of seasonal precipitation plays a critical role. However, owing to the impact of diverse complex weather systems, seasonal precipitation forecasting has been a challenging task. The current study proposes a novel procedure for forecasting seasonal precipitation by: (1) regionalizing the influential climate variables to the seasonal precipitation with <jats:italic>k</jats:italic>-means clustering; (2) extracting the features from the regionalized climate variables with machine learning-based algorithms such as principal component analysis (PCA), independent component analysis (ICA), and Autoencoder; and (3) finally regressing the extracted features with one linear model of generalized linear model (GLM) and another nonlinear model of support vector machine (SVM). Two globally gridded climate variables-mean sea level pressure (MSLP) and sea surface temperature (SST)-were teleconnected with the seasonal precipitation of South Korea, denoted as accumulated seasonal precipitation (ASP). Results indicated that <jats:italic>k</jats:italic>-means clustering successfully regionalized the highly correlated climate variables with the ASP, and all three extraction algorithms-PCA, ICA, and Autoencoder-combined with the GLM and SVM models presented their superiority in different seasons. In particular, the PCA combined with the linear GLM model performed better, and the Autoencoder combined with the nonlinear SVM model did better. It can be concluded that the proposed forecasting procedure of the seasonal precipitation, combined with several ML-based algorithms, can be a good alternative.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "The effects of topological features on convolutional neural networks\u2014an explanatory analysis via Grad-CAM",
        "doi": "10.1088/2632-2153/ace6f3",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Topological data analysis (TDA) characterizes the global structure of data based on topological invariants such as persistent homology, whereas convolutional neural networks (CNNs) are capable of characterizing local features in the global structure of the data. In contrast, a combined model of TDA and CNN, a family of multimodal networks, simultaneously takes the image and the corresponding topological features as the input to the network for classification, thereby significantly improving the performance of a single CNN. This innovative approach has been recently successful in various applications. However, there is a lack of explanation regarding how and why topological signatures, when combined with a CNN, improve discriminative power. In this paper, we use persistent homology to compute topological features and subsequently demonstrate both qualitatively and quantitatively the effects of topological signatures on a CNN model, for which the Grad-CAM analysis of multimodal networks and topological inverse image map are proposed and appropriately utilized. For experimental validation, we utilize two famous datasets: the transient versus bogus image dataset and the HAM10000 dataset. Using Grad-CAM analysis of multimodal networks, we demonstrate that topological features enforce the image network of a CNN to focus more on significant and meaningful regions across images rather than task-irrelevant artifacts such as background noise and texture.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Machine learning inference of molecular dipole moment in liquid water",
        "doi": "10.1088/2632-2153/ac0123",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Molecular dipole moment in liquid water is an intriguing property, partly due to the fact that there is no unique way to partition the total electron density into individual molecular contributions. The prevailing method to circumvent this problem is to use maximally localized Wannier functions, which perform a unitary transformation of the occupied molecular orbitals by minimizing the spread function of Boys. Here we revisit this problem using a data-driven approach satisfying two physical constraints, namely: (a) The displacement of the atomic charges is proportional to the Berry phase polarization; (b) Each water molecule has a formal charge of zero. It turns out that the distribution of molecular dipole moments in liquid water inferred from latent variables is surprisingly similar to that obtained from maximally localized Wannier functions. Apart from putting a maximum-likelihood footnote to the established method, this work highlights the capability of graph convolution based charge models and the importance of physical constraints on improving the model interpretability.</jats:p>",
        "is_referenced_by_count": 4
    },
    {
        "title": "Novel heuristic-based hybrid ResNeXt with recurrent neural network to handle multi class classification of sentiment analysis",
        "doi": "10.1088/2632-2153/acc0d5",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Present-day, interdisciplinary research is increasing in social network-related applications, and it is a daily routine activity in every human life. So, sentiment analysis (SA) based on opinion mining is the most sophisticated concept in the well-known social network environment. Different machine learning methods were implemented to extract different text label features in SA, and all of those methods can detect whether a given text is positive or negative based on the text features. Analysis of sentiment has been suffering from inaccuracies while using machine learning and sentiment-based lexical methods dependent on domain-specific problems. Multi-class SA is an expensive task where memory, label samples, and other parameters are insufficient. So, we propose and implement a novel hybrid model which is a combination of ResNeXt and recurrent neural framework (NH-ResNeXt-RNF) to explore multi-class sentiment from textual features. This framework investigates the polarity of words connected to a specific domain across the entire dataset and eliminates noisy data in an unsupervised manner using pre-processing. Optimization is required to perform efficient multi-class classification to reduce the effort associated with annotation for multi-class SA via unsupervised learning. The proposed model performance is evaluated on two data sets namely: Amazon and Twitter. We increase the accuracy of the sentiment of polarity on each sentence present in the data set. Experimental results of the proposed approach give better and more efficient multi-class (<jats:bold>positive, negative, very positive, neutral and highly negative)</jats:bold> domain-specific sentiment than traditional approaches related to supervised, semi-supervised, and unsupervised domains. The proposed hybrid model accuracy is 96.5% and 95.37% for Amazon and Twitter datasets respectively.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Online accelerator optimization with a machine learning-based stochastic algorithm",
        "doi": "10.1088/2632-2153/abc81e",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Online optimization is critical for realizing the design performance of accelerators. Highly efficient stochastic optimization algorithms are needed for many online accelerator optimization problems in order to find the global optimum in the non-linear, coupled parameter space. In this study, we propose to use the multi-generation Gaussian process optimizer for online accelerator optimization and demonstrate that the algorithm is significantly more efficient than other stochastic algorithms that are commonly used in the accelerator community.</jats:p>",
        "is_referenced_by_count": 4
    },
    {
        "title": "Supplementing recurrent neural networks with annealing to solve combinatorial optimization problems",
        "doi": "10.1088/2632-2153/acb895",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Combinatorial optimization problems can be solved by heuristic algorithms such as simulated annealing (SA) which aims to find the optimal solution within a large search space through thermal fluctuations. This algorithm generates new solutions through Markov-chain Monte Carlo techniques which can result in severe limitations, such as slow convergence and a tendency to stay within the same local search space at small temperatures. To overcome these shortcomings, we use the variational classical annealing (VCA) framework that combines autoregressive recurrent neural networks (RNNs) with traditional annealing to sample solutions that are uncorrelated. In this paper, we demonstrate the potential of using VCA as an approach to solving real-world optimization problems. We explore VCA\u2019s performance in comparison with SA at solving three popular optimization problems: the maximum cut problem (Max-Cut), the nurse scheduling problem (NSP), and the traveling salesman problem (TSP). For all three problems, we find that VCA outperforms SA on average in the asymptotic limit by one or more orders of magnitude in terms of relative error. Interestingly, we reach large system sizes of up to 256 cities for the TSP. We also conclude that in the best case scenario, VCA can serve as a great alternative when SA fails to find the optimal solution.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "Using positional tracking to improve abdominal ultrasound machine learning classification",
        "doi": "10.1088/2632-2153/ad379d",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Diagnostic abdominal ultrasound screening and monitoring protocols are based around gathering a set of standard cross sectional images that ensure the coverage of relevant anatomical structures during the collection procedure. This allows clinicians to make diagnostic decisions with the best picture available from that modality. Currently, there is very little assistance provided to sonographers to ensure adherence to collection protocols, with previous studies suggesting that traditional image only machine learning classification can provide only limited assistance in supporting this task, for example it can be difficult to differentiate between multiple liver cross sections or those of the left and right kidney from image post collection. In this proof of concept, positional tracking information was added to the image input of a neural network to provide the additional context required to recognize six otherwise difficult to identify edge cases. In this paper optical and sensor based infrared tracking (IR) was used to track the position of an ultrasound probe during the collection of clinical cross sections on an abdominal phantom. Convolutional neural networks were then trained using both image-only and image with positional data, the classification accuracy results were then compared. The addition of positional information significantly improved average classification results from \u223c90% for image-only to 95% for optical IR position tracking and 93% for Sensor-based IR in common abdominal cross sections. While there is further work to be done, the addition of low-cost positional tracking to machine learning ultrasound classification will allow for significantly increased accuracy for identifying important diagnostic cross sections, with the potential to not only provide validation of adherence to protocol but also could provide navigation prompts to assist in user training and in ensuring adherence in capturing cross sections in future.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Machine learning-based signal quality assessment for cardiac volume monitoring in electrical impedance tomography",
        "doi": "10.1088/2632-2153/acc637",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Owing to recent advances in thoracic electrical impedance tomography (EIT), a patient\u2019s hemodynamic function can be noninvasively and continuously estimated in real-time by surveilling a cardiac volume signal (CVS) associated with stroke volume and cardiac output. In clinical applications, however, a CVS is often of low quality, mainly because of the patient\u2019s deliberate movements or inevitable motions during clinical interventions. This study aims to develop a signal quality indexing method that assesses the influence of motion artifacts on transient CVSs. The assessment is performed on each cardiac cycle to take advantage of the periodicity and regularity in cardiac volume changes. Time intervals are identified using the synchronized electrocardiography system. We apply divergent machine-learning methods, which can be sorted into discriminative-model and manifold-learning approaches. The use of machine-learning could be suitable for our real-time monitoring application that requires fast inference and automation as well as high accuracy. In the clinical environment, the proposed method can be utilized to provide immediate warnings so that clinicians can minimize confusion regarding patients\u2019 conditions, reduce clinical resource utilization, and improve the confidence level of the monitoring system. Numerous experiments using actual EIT data validate the capability of CVSs degraded by motion artifacts to be accurately and automatically assessed in real-time by machine learning. The best model achieved an accuracy of 0.95, positive and negative predictive values of 0.96 and 0.86, sensitivity of 0.98, specificity of 0.77, and AUC of 0.96.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "Near-optimal control of dynamical systems with neural ordinary differential equations",
        "doi": "10.1088/2632-2153/ac92c3",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Optimal control problems naturally arise in many scientific applications where one wishes to steer a dynamical system from an initial state <jats:bold>x</jats:bold>\n                  <jats:sub>0</jats:sub> to a desired target state <jats:inline-formula>\n                     <jats:tex-math><?CDATA $\\mathbf{x}^*$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:msup>\n                           <mml:mrow>\n                              <mml:mi mathvariant=\"bold\">x</mml:mi>\n                           </mml:mrow>\n                           <mml:mo>\u2217</mml:mo>\n                        </mml:msup>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstac92c3ieqn1.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> in finite time <jats:italic>T</jats:italic>. Recent advances in deep learning and neural network\u2013based optimization have contributed to the development of numerical methods that can help solve control problems involving high-dimensional dynamical systems. In particular, the framework of neural ordinary differential equations (neural ODEs) provides an efficient means to iteratively approximate continuous-time control functions associated with analytically intractable and computationally demanding control tasks. Although neural ODE controllers have shown great potential in solving complex control problems, the understanding of the effects of hyperparameters such as network structure and optimizers on learning performance is still very limited. Our work aims at addressing some of these knowledge gaps to conduct efficient hyperparameter optimization. To this end, we first analyze how truncated and non-truncated backpropagation through time affect both runtime performance and the ability of neural networks to learn optimal control functions. Using analytical and numerical methods, we then study the role of parameter initializations, optimizers, and neural-network architecture. Finally, we connect our results to the ability of neural ODE controllers to implicitly regularize control energy.</jats:p>",
        "is_referenced_by_count": 3
    },
    {
        "title": "Machine learning based quantification of synchrotron radiation-induced x-ray fluorescence measurements\u2014a case study",
        "doi": "10.1088/2632-2153/abc9fb",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>In this work, we describe the use of artificial neural networks (ANNs) for the quantification of x-ray fluorescence measurements. The training data were generated using Monte Carlo simulation, which avoided the use of adapted reference materials. The extension of the available dataset by means of an ANN to generate additional data was demonstrated. Particular emphasis was put on the comparability of simulated and experimental data and how the influence of deviations can be reduced. The search for the optimal hyperparameter, manual and automatic, is also described. For the presented case, we were able to train a network with a mean absolute error of 0.1 weight percent for the synthetic data and 0.7 weight percent for a set of experimental data obtained with certified reference materials.</jats:p>",
        "is_referenced_by_count": 5
    },
    {
        "title": "Machine learning for analyzing and characterizing InAsSb-based nBn photodetectors",
        "doi": "10.1088/2632-2153/abcf89",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>This paper discusses two cases of applying artificial neural networks to the capacitance\u2013voltage characteristics of InAsSb-based barrier infrared detectors. In the first case, we discuss a methodology for training a fully-connected feedforward network to predict the capacitance of the device as a function of the absorber, barrier, and contact doping densities, the barrier thickness, and the applied voltage. We verify the model\u2019s performance with physics-based justification of trends observed in single parameter sweeps, partial dependence plots, and two examples of gradient-based sensitivity analysis. The second case focuses on the development of a convolutional neural network that addresses the inverse problem, where a capacitance\u2013voltage profile is used to predict the architectural properties of the device. The advantage of this approach is a more comprehensive characterization of a device by capacitance\u2013voltage profiling than may be possible with other techniques. Finally, both approaches are material and device agnostic, and can be applied to other semiconductor device characteristics.</jats:p>",
        "is_referenced_by_count": 2
    },
    {
        "title": "A recipe for cracking the quantum scaling limit with machine learned electron densities",
        "doi": "10.1088/2632-2153/acb314",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title><jats:p>A long-standing goal of science is to accurately simulate large molecular systems using quantum mechanics. The poor scaling of current quantum chemistry algorithms on classical computers, however, imposes an effective limit of about a few dozen atoms on traditional electronic structure calculations. We present a machine learning (ML) method to break through this scaling limit for electron densities. We show that Euclidean neural networks can be trained to predict molecular electron densities from limited data. By learning the electron density, the model can be trained on small systems and make accurate predictions on large ones. In the context of water clusters, we show that an ML model trained on clusters of just 12 molecules contains all the information needed to make accurate electron density predictions on cluster sizes of 50 or more, beyond the scaling limit of current quantum chemistry methods.</jats:p>",
        "is_referenced_by_count": 10
    },
    {
        "title": "Enabling robust offline active learning for machine learning potentials using simple physics-based priors",
        "doi": "10.1088/2632-2153/abcc44",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Machine learning surrogate models for quantum mechanical simulations have enabled the field to efficiently and accurately study material and molecular systems. Developed models typically rely on a substantial amount of data to make reliable predictions of the potential energy landscape or careful active learning (AL) and uncertainty estimates. When starting with small datasets, convergence of AL approaches is a major outstanding challenge which has limited most demonstrations to online AL. In this work we demonstrate a \u0394-machine learning (ML) approach that enables stable convergence in offline AL strategies by avoiding unphysical configurations with initial datasets as little as a single data point. We demonstrate our framework\u2019s capabilities on a structural relaxation, transition state calculation, and molecular dynamics simulation, with the number of first principle calculations being cut down anywhere from 70%\u201390%. The approach is incorporated and developed alongside AMP<jats:italic>torch</jats:italic>, an open-source ML potential package, along with interactive Google Colab notebook examples.</jats:p>",
        "is_referenced_by_count": 19
    },
    {
        "title": "Prediction of chemical reaction yields using deep learning",
        "doi": "10.1088/2632-2153/abc81d",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Artificial intelligence is driving one of the most important revolutions in organic chemistry. Multiple platforms, including tools for reaction prediction and synthesis planning based on machine learning, have successfully become part of the organic chemists\u2019 daily laboratory, assisting in domain-specific synthetic problems. Unlike reaction prediction and retrosynthetic models, the prediction of reaction yields has received less attention in spite of the enormous potential of accurately predicting reaction conversion rates. Reaction yields models, describing the percentage of the reactants converted to the desired products, could guide chemists and help them select high-yielding reactions and score synthesis routes, reducing the number of attempts. So far, yield predictions have been predominantly performed for high-throughput experiments using a categorical (one-hot) encoding of reactants, concatenated molecular fingerprints, or computed chemical descriptors. Here, we extend the application of natural language processing architectures to predict reaction properties given a text-based representation of the reaction, using an encoder transformer model combined with a regression layer. We demonstrate outstanding prediction performance on two high-throughput experiment reactions sets. An analysis of the yields reported in the open-source USPTO data set shows that their distribution differs depending on the mass scale, limiting the data set applicability in reaction yields predictions.</jats:p>",
        "is_referenced_by_count": 103
    },
    {
        "title": "Vortex detection in atomic Bose\u2013Einstein condensates using neural networks trained on synthetic images",
        "doi": "10.1088/2632-2153/ad03ad",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Quantum vortices in atomic Bose\u2013Einstein condensates (BECs) are topological defects characterized by quantized circulation of particles around them. In experimental studies, vortices are commonly detected by time-of-flight imaging, where their density-depleted cores are enlarged. In this work, we describe a machine learning-based method for detecting vortices in experimental BEC images, particularly focusing on turbulent condensates containing irregularly distributed vortices. Our approach employs a convolutional neural network (CNN) trained solely on synthetic simulated images, eliminating the need for manual labeling of the vortex positions as ground truth. We find that the CNN achieves accurate vortex detection in real experimental images, thereby facilitating analysis of large experimental datasets without being constrained by specific experimental conditions. This novel approach represents a significant advancement in studying quantum vortex dynamics and streamlines the analysis process in the investigation of turbulent BECs.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Feature space reduction method for ultrahigh-dimensional, multiclass data: random forest-based multiround screening (RFMS)",
        "doi": "10.1088/2632-2153/ad020e",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>In recent years, several screening methods have been published for ultrahigh-dimensional data that contain hundreds of thousands of features, many of which are irrelevant or redundant. However, most of these methods cannot handle data with thousands of classes. Prediction models built to authenticate users based on multichannel biometric data result in this type of problem. In this study, we present a novel method known as <jats:italic>random forest-based multiround screening (RFMS)</jats:italic> that can be effectively applied under such circumstances. The proposed algorithm divides the feature space into small subsets and executes a series of partial model builds. These partial models are used to implement tournament-based sorting and the selection of features based on their importance. This algorithm successfully filters irrelevant features and also discovers binary and higher-order feature interactions. To benchmark RFMS, a synthetic biometric feature space generator known as <jats:italic>BiometricBlender</jats:italic> is employed. Based on the results, the RFMS is on par with industry-standard feature screening methods, while simultaneously possessing many advantages over them.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Finding simplicity: unsupervised discovery of features, patterns, and order parameters via shift-invariant variational autoencoders\n                  <sup>*</sup>",
        "doi": "10.1088/2632-2153/ad073b",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Recent advances in scanning tunneling and transmission electron microscopies (STM and STEM) have allowed routine generation of large volumes of imaging data containing information on the structure and functionality of materials. The experimental data sets contain signatures of long-range phenomena such as physical order parameter fields, polarization, and strain gradients in STEM, or standing electronic waves and carrier-mediated exchange interactions in STM, all superimposed onto scanning system distortions and gradual changes of contrast due to drift and/or mis-tilt effects. Correspondingly, while the human eye can readily identify certain patterns in the images such as lattice periodicities, repeating structural elements, or microstructures, their automatic extraction and classification are highly non-trivial and universal pathways to accomplish such analyses are absent. We pose that the most distinctive elements of the patterns observed in STM and (S)TEM images are similarity and (almost-) periodicity, behaviors stemming directly from the parsimony of elementary atomic structures, superimposed on the gradual changes reflective of order parameter distributions. However, the discovery of these elements via global Fourier methods is non-trivial due to variability and lack of ideal discrete translation symmetry. To address this problem, we explore the shift-invariant variational autoencoders (shift-VAEs) that allow disentangling characteristic repeating features in the images, their variations, and shifts that inevitably occur when randomly sampling the image space. Shift-VAEs balance the uncertainty in the position of the object of interest with the uncertainty in shape reconstruction. This approach is illustrated for model 1D data, and further extended to synthetic and experimental STM and STEM 2D data. We further introduce an approach for training shift-VAEs that allows finding the latent variables that comport to known physical behavior. In this specific case, the condition is that the latent variable maps should be smooth on the length scale of the atomic lattice (as expected for physical order parameters), but other conditions can be imposed. The opportunities and limitations of the shift VAE analysis for pattern discovery are elucidated.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Bridging the gap between high-level quantum chemical methods and deep learning models",
        "doi": "10.1088/2632-2153/ad27e1",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Supervised deep learning (DL) models are becoming ubiquitous in computational chemistry because they can efficiently learn complex input-output relationships and predict chemical properties at a cost significantly lower than methods based on quantum mechanics. The central challenge in many DL applications is the need to invest considerable computational resources in generating large (<jats:inline-formula>\n                     <jats:tex-math><?CDATA $N \\gt 1 \\times 10^5$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mi>N</mml:mi>\n                        <mml:mo>&gt;</mml:mo>\n                        <mml:mn>1</mml:mn>\n                        <mml:mo>\u00d7</mml:mo>\n                        <mml:msup>\n                           <mml:mn>10</mml:mn>\n                           <mml:mn>5</mml:mn>\n                        </mml:msup>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstad27e1ieqn1.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>) training sets such that the resulting DL model can be generalized reliably to unseen systems. The lack of better alternatives has encouraged the use of low-cost and relatively inaccurate density-functional theory (DFT) methods to generate training data, leading to DL models that lack accuracy and reliability. In this article, we describe a robust and easily implemented approach based on property-specific atom-centered potentials (ACPs) that resolves this central challenge in DL model development. ACPs are one-electron potentials that are applied in combination with a computationally inexpensive but inaccurate quantum mechanical method (e.g. double-<jats:italic>\u03b6</jats:italic> DFT) and fitted against relatively few high-level data (<jats:inline-formula>\n                     <jats:tex-math><?CDATA $N \\approx 1\\times 10^{3}$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mi>N</mml:mi>\n                        <mml:mo>\u2248</mml:mo>\n                        <mml:mn>1</mml:mn>\n                        <mml:mo>\u00d7</mml:mo>\n                        <mml:msup>\n                           <mml:mn>10</mml:mn>\n                           <mml:mrow>\n                              <mml:mn>3</mml:mn>\n                           </mml:mrow>\n                        </mml:msup>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstad27e1ieqn2.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>\u2013<jats:inline-formula>\n                     <jats:tex-math><?CDATA $1\\times 10^{4}$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mn>1</mml:mn>\n                        <mml:mo>\u00d7</mml:mo>\n                        <mml:msup>\n                           <mml:mn>10</mml:mn>\n                           <mml:mrow>\n                              <mml:mn>4</mml:mn>\n                           </mml:mrow>\n                        </mml:msup>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstad27e1ieqn3.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>), possibly obtained from the literature. The resulting ACP-corrected methods retain the low cost of the double-<jats:italic>\u03b6</jats:italic> DFT approach, while generating high-level-quality data in unseen systems for the specific property for which they were designed. With this approach, we demonstrate that ACPs can be used as an intermediate method between high-level approaches and DL model development, enabling the calculation of large and accurate DL training sets for the chemical property of interest. We demonstrate the effectiveness of the proposed approach by predicting bond dissociation enthalpies, reaction barrier heights, and reaction energies with chemical accuracy at a computational cost lower than the DFT methods routinely used for DL training data set generation.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Outlook for artificial intelligence and machine learning at the NSLS-II",
        "doi": "10.1088/2632-2153/abbd4e",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title><jats:p>We describe the current and future plans for using artificial intelligence and machine learning (AI/ML) methods at the National Synchrotron Light Source II (NSLS-II), a scientific user facility at the Brookhaven National Laboratory. We discuss the opportunity for using the AI/ML tools and techniques developed in the data and computational science areas to greatly improve the scientific output of large scale experimental user facilities. We describe our current and future plans in areas including from detecting and recovering from faults, optimizing the source and instrument configurations, streamlining the pipeline from measurement to insight, through data acquisition, processing, analysis. The overall strategy and direction of the NSLS-II facility in relation to AI/ML is presented.</jats:p>",
        "is_referenced_by_count": 12
    },
    {
        "title": "Attention-based quantum tomography",
        "doi": "10.1088/2632-2153/ac362b",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>With rapid progress across platforms for quantum systems, the problem of many-body quantum state reconstruction for noisy quantum states becomes an important challenge. There has been a growing interest in approaching the problem of quantum state reconstruction using generative neural network models. Here we propose the \u2018attention-based quantum tomography\u2019 (AQT), a quantum state reconstruction using an attention mechanism-based generative network that learns the mixed state density matrix of a noisy quantum state. AQT is based on the model proposed in \u2018Attention is all you need\u2019 by Vaswani <jats:italic>et al</jats:italic> (2017 <jats:italic>NIPS</jats:italic>) that is designed to learn long-range correlations in natural language sentences and thereby outperform previous natural language processing (NLP) models. We demonstrate not only that AQT outperforms earlier neural-network-based quantum state reconstruction on identical tasks but that AQT can accurately reconstruct the density matrix associated with a noisy quantum state experimentally realized in an IBMQ quantum computer. We speculate the success of the AQT stems from its ability to model quantum entanglement across the entire quantum system much as the attention model for NLP captures the correlations among words in a sentence.</jats:p>",
        "is_referenced_by_count": 22
    },
    {
        "title": "Gaussian-process-regression-based method for the localization of exceptional points in complex resonance spectra",
        "doi": "10.1088/2632-2153/ad2e16",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Resonances in open quantum systems depending on at least two controllable parameters can show the phenomenon of exceptional points (EPs), where not only the eigenvalues but also the eigenvectors of two or more resonances coalesce. Their exact localization in the parameter space is challenging, in particular in systems, where the computation of the quantum spectra and resonances is numerically very expensive. We introduce an efficient machine learning algorithm to find EPs based on Gaussian process regression (GPR). The GPR-model is trained with an initial set of eigenvalue pairs belonging to an EP and used for a first estimation of the EP position via a numerically cheap root search. The estimate is then improved iteratively by adding selected exact eigenvalue pairs as training points to the GPR-model. The GPR-based method is developed and tested on a simple low-dimensional matrix model and then applied to a challenging real physical system, viz., the localization of EPs in the resonance spectra of excitons in cuprous oxide in external electric and magnetic fields. The precise computation of EPs, by taking into account the complete valence band structure and central-cell corrections of the crystal, can be the basis for the experimental observation of EPs in this system.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Optimal data generation for machine learned interatomic potentials",
        "doi": "10.1088/2632-2153/ac9ae7",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Machine learning interatomic potentials (MLIPs) are routinely used atomic simulations, but generating databases of atomic configurations used in fitting these models is a laborious process, requiring significant computational and human effort. A computationally efficient method is presented to generate databases of atomic configurations that contain optimal information on the small-displacement regime of the potential energy surface of bulk crystalline matter. Utilising non-diagonal supercell (Lloyd-Williams and Monserrat 2015 <jats:italic>Phys. Rev.</jats:italic> B <jats:bold>92</jats:bold> 184301), an automatic process is suggested for <jats:italic>ab initio</jats:italic> data generation. MLIPs were fitted for Al, W, Mg and Si, which very closely reproduce the <jats:italic>ab initio</jats:italic> phonon and elastic properties. The protocol can be easily adapted to other materials and can be inserted in the workflow of any flavour of MLIP generation.</jats:p>",
        "is_referenced_by_count": 3
    },
    {
        "title": "Molecular machine learning with conformer ensembles",
        "doi": "10.1088/2632-2153/acefa7",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Virtual screening can accelerate drug discovery by identifying promising candidates for experimental evaluation. Machine learning is a powerful method for screening, as it can learn complex structure\u2013property relationships from experimental data and make rapid predictions over virtual libraries. Molecules inherently exist as a three-dimensional ensemble and their biological action typically occurs through supramolecular recognition. However, most deep learning approaches to molecular property prediction use a 2D graph representation as input, and in some cases a single 3D conformation. Here we investigate how the 3D information of multiple conformers, traditionally known as 4D information in the cheminformatics community, can improve molecular property prediction in deep learning models. We introduce multiple deep learning models that expand upon key architectures such as ChemProp and SchNet, adding elements such as multiple-conformer inputs and conformer attention. We then benchmark the performance trade-offs of these models on 2D, 3D and 4D representations in the prediction of drug activity using a large training set of geometrically resolved molecules. The new architectures perform significantly better than 2D models, but their performance is often just as strong with a single conformer as with many. We also find that 4D deep learning models learn interpretable attention weights for each conformer.</jats:p>",
        "is_referenced_by_count": 7
    },
    {
        "title": "GWAK: Gravitational-Wave Anomalous Knowledge with Recurrent Autoencoders",
        "doi": "10.1088/2632-2153/ad3a31",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Matched-filtering detection techniques for gravitational-wave (GW) signals in ground-based interferometers rely on having well-modeled templates of the GW emission. Such techniques have been traditionally used in searches for compact binary coalescences (CBCs), and have been employed in all known GW detections so far. However, interesting science cases aside from compact mergers do not yet have accurate enough modeling to make matched filtering possible, including core-collapse supernovae and sources where stochasticity may be involved. Therefore the development of techniques to identify sources of these types is of significant interest. In this paper, we present a method of anomaly detection based on deep recurrent autoencoders to enhance the search region to unmodeled transients. We use a semi-supervised strategy that we name \u201cGravitational Wave Anomalous Knowledge\u201d (GWAK). While the semi-supervised nature of the problem comes with a cost in terms of accuracy as compared to supervised techniques, there is a qualitative advantage in generalizing experimental sensitivity beyond pre-computed signal templates. We construct a low-dimensional embedded space using the GWAK method, capturing the physical signatures of distinct signals on each axis of the space. By introducing signal priors that capture some of the salient features of GW signals, we allow for the recovery of sensitivity even when an unmodeled anomaly is encountered. We show that regions of the GWAK space can identify CBCs, detector glitches and also a variety of unmodeled astrophysical sources.&amp;#xD;</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Noise enhanced neural networks for analytic continuation",
        "doi": "10.1088/2632-2153/ac6f44",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Analytic continuation maps imaginary-time Green\u2019s functions obtained by various theoretical/numerical methods to real-time response functions that can be directly compared with experiments. Analytic continuation is an important bridge between many-body theories and experiments but is also a challenging problem because such mappings are ill-conditioned. In this work, we develop a neural network (NN)-based method for this problem. The training data is generated either using synthetic Gaussian-type spectral functions or from exactly solvable models where the analytic continuation can be obtained analytically. Then, we applied the trained NN to the testing data, either with synthetic noise or intrinsic noise in Monte Carlo simulations. We conclude that the best performance is always achieved when a proper amount of noise is added to the training data. Moreover, our method can successfully capture multi-peak structure in the resulting response function for the cases with the best performance. The method can be combined with Monte Carlo simulations to compare with experiments on real-time dynamics.</jats:p>",
        "is_referenced_by_count": 2
    },
    {
        "title": "Role of multifidelity data in sequential active learning materials discovery campaigns: case study of electronic bandgap",
        "doi": "10.1088/2632-2153/ad1627",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Materials discovery and design typically proceeds through iterative evaluation (both experimental and computational) to obtain data, generally targeting improvement of one or more properties under one or more constraints (e.g. time or budget). However, there can be great variation in the quality and cost of different data, and when they are mixed together in what we here call multifidelity data, the optimal approaches to their utilization are not established. It is therefore important to develop strategies to acquire and use multifidelity data to realize the most efficient iterative materials exploration. In this work, we assess the impact of using multifidelity data through mock demonstration of designing solar cell materials, using the electronic bandgap as the target property. We propose a new approach of using multifidelity data through leveraging machine learning models of both low- and high-fidelity data, where using predicted low-fidelity data as an input feature in the high-fidelity model can improve the impact of a multifidelity data approach. We show how tradeoffs of low- versus high-fidelity measurement cost and acquisition can impact the materials discovery process. We find that the use of multifidelity data has maximal impact on the materials discovery campaign when approximately five low-fidelity measurements per high-fidelity measurement are performed, and when the cost of low-fidelity measurements is approximately 5% or less than that of high-fidelity measurements. This work provides practical guidance and useful qualitative measures for improving materials discovery campaigns that involve multifidelity data.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Mapping confinement potentials and charge densities of interacting quantum systems using conditional generative adversarial networks",
        "doi": "10.1088/2632-2153/acd6d8",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Accurate and efficient tools for calculating the ground state properties of interacting quantum systems are essential in the design of nanoelectronic devices. The exact diagonalization method fully accounts for the Coulomb interaction beyond mean field approximations and it is regarded as the gold-standard for few electron systems. However, by increasing the number of instances to be solved, the computational costs become prohibitive and new approaches based on machine learning techniques can provide a significant reduction in computational time and resources, maintaining a reasonable accuracy. Here, we employ <jats:monospace>pix2pix</jats:monospace>, a general-purpose image-to-image translation method based on conditional generative adversarial network (cGAN), for predicting ground state densities from randomly generated confinement potentials. Other mappings were also investigated, like potentials to non-interacting densities and the translation from non-interacting to interacting densities. The architecture of the cGAN was optimized with respect to the internal parameters of the generator and discriminator. Moreover, the inverse problem of finding the confinement potential given the interacting density can also be approached by the <jats:monospace>pix2pix</jats:monospace> mapping, which is an important step in finding near-optimal solutions for confinement potentials.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "Miniaturizing neural networks for charge state autotuning in quantum dots",
        "doi": "10.1088/2632-2153/ac34db",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>A key challenge in scaling quantum computers is the calibration and control of multiple qubits. In solid-state quantum dots (QDs), the gate voltages required to stabilize quantized charges are unique for each individual qubit, resulting in a high-dimensional control parameter space that must be tuned automatically. Machine learning techniques are capable of processing high-dimensional data\u2014provided that an appropriate training set is available\u2014and have been successfully used for autotuning in the past. In this paper, we develop extremely small feed-forward neural networks that can be used to detect charge-state transitions in QD stability diagrams. We demonstrate that these neural networks can be trained on synthetic data produced by computer simulations, and robustly transferred to the task of tuning an experimental device into a desired charge state. The neural networks required for this task are sufficiently small as to enable an implementation in existing memristor crossbar arrays in the near future. This opens up the possibility of miniaturizing powerful control elements on low-power hardware, a significant step towards on-chip autotuning in future QD computers.</jats:p>",
        "is_referenced_by_count": 7
    },
    {
        "title": "Efficient generation of stable linear machine-learning force fields with uncertainty-aware active learning",
        "doi": "10.1088/2632-2153/ace418",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title><jats:p>Machine-learning (ML) force fields (FFs) enable an accurate and universal description of the potential energy surface of molecules and materials on the basis of a training set of<jats:italic>ab initio</jats:italic>data. However, large-scale applications of these methods rest on the possibility to train accurate ML models with a small number of<jats:italic>ab initio</jats:italic>data. In this respect, active-learning (AL) strategies, where the training set is self-generated by the model itself, combined with linear ML models are particularly promising. In this work, we explore an AL strategy based on linear regression and able to predict the model\u2019s uncertainty on predictions for molecular configurations not sampled by the training set, thus providing a straightforward recipe for the extension of the latter. We apply this strategy to the spectral neighbor analysis potential and show that only tens of<jats:italic>ab initio</jats:italic>simulations of atomic forces are required to generate FFs for room-temperature molecular dynamics at or close to chemical accuracy and which stability can be systematically improved by the user at modest computational expenses. Moreover, the method does not necessitate any conformational pre-sampling, thus requiring minimal user intervention and parametrization.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "GA-based weighted ensemble learning for multi-label aerial image classification using convolutional neural networks and vision transformers",
        "doi": "10.1088/2632-2153/ad10cf",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Multi-label classification (MLC) of aerial images is a crucial task in remote sensing image analysis. Traditional image classification methods have limitations in image feature extraction, leading to an increasing use of deep learning models, such as convolutional neural networks (CNN) and vision transformers (ViT). However, the standalone use of these models may have limitations when dealing with MLC. To enhance the generalization performance of MLC of aerial images, this paper combines two CNN and two ViT models, comparing four single deep learning models, a manually weighted ensemble learning method, and a GA-based weighted ensemble method. The experimental results using two public multi-label aerial image datasets show that the classification performance of ViT models is better than CNN models, the traditional weighted ensemble learning model performs better than a single deep learning model, and the GA-based weighted ensemble method performs better than the manually weighted ensemble learning method. The GA-based weighted ensemble method proposed in this study can achieve better MLC performance of aerial images than previous results.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Convolutional neural network based non-iterative reconstruction for accelerating neutron tomography\n                  <sup>*</sup>",
        "doi": "10.1088/2632-2153/abde8e",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Neutron computed tomography (NCT), a 3D non-destructive characterization technique, is carried out at nuclear reactor or spallation neutron source-based user facilities. Because neutrons are not severely attenuated by heavy elements and are sensitive to light elements like hydrogen, neutron radiography and computed tomography offer a complementary contrast to x-ray CT conducted at a synchrotron user facility. However, compared to synchrotron x-ray CT, the acquisition time for an NCT scan can be orders of magnitude higher due to lower source flux, low detector efficiency and the need to collect a large number of projection images for a high-quality reconstruction when using conventional algorithms. As a result of the long scan times for NCT, the number and type of experiments that can be conducted at a user facility is severely restricted. Recently, several deep convolutional neural network (DCNN) based algorithms have been introduced in the context of accelerating CT scans that can enable high quality reconstructions from sparse-view data. In this paper, we introduce DCNN algorithms to obtain high-quality reconstructions from sparse-view and low signal-to-noise ratio NCT data-sets thereby enabling accelerated scans. Our method is based on the supervised learning strategy of training a DCNN to map a low-quality reconstruction from sparse-view data to a higher quality reconstruction. Specifically, we evaluate the performance of two popular DCNN architectures\u2014one based on using patches for training and the other on using the full images for training. We observe that both the DCNN architectures offer improvements in performance over classical multi-layer perceptron as well as conventional CT reconstruction algorithms. Our results illustrate that the DCNN can be a powerful tool to obtain high-quality NCT reconstructions from sparse-view data thereby enabling accelerated NCT scans for increasing user-facility throughput or enabling high-resolution time-resolved NCT scans.</jats:p>",
        "is_referenced_by_count": 3
    },
    {
        "title": "Atomic permutationally invariant polynomials for fitting molecular force fields",
        "doi": "10.1088/2632-2153/abd51e",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We introduce and explore an approach for constructing force fields for small molecules, which combines intuitive low body order empirical force field terms with the concepts of data driven statistical fits of recent machine learned potentials. We bring these two key ideas together to bridge the gap between established empirical force fields that have a high degree of transferability on the one hand, and the machine learned potentials that are systematically improvable and can converge to very high accuracy, on the other. Our framework extends the atomic permutationally invariant polynomials (aPIP) developed for elemental materials in (2019 <jats:italic>Mach. Learn.: Sci. Technol.</jats:italic> \n                  <jats:bold>1</jats:bold> 015004) to molecular systems. The body order decomposition allows us to keep the dimensionality of each term low, while the use of an iterative fitting scheme as well as regularisation procedures improve the extrapolation outside the training set. We investigate aPIP force fields with up to generalised 4-body terms, and examine the performance on a set of small organic molecules. We achieve a high level of accuracy when fitting individual molecules, comparable to those of the many-body machine learned force fields. Fitted to a combined training set of short linear alkanes, the accuracy of the aPIP force field still significantly exceeds what can be expected from classical empirical force fields, while retaining reasonable transferability to both configurations far from the training set and to new molecules.</jats:p>",
        "is_referenced_by_count": 25
    },
    {
        "title": "Self-referencing embedded strings (SELFIES): A 100% robust molecular string representation",
        "doi": "10.1088/2632-2153/aba947",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>The discovery of novel materials and functional molecules can help to solve some of society\u2019s most urgent challenges, ranging from efficient energy harvesting and storage to uncovering novel pharmaceutical drug candidates. Traditionally matter engineering\u2013generally denoted as inverse design\u2013was based massively on human intuition and high-throughput virtual screening. The last few years have seen the emergence of significant interest in computer-inspired designs based on evolutionary or deep learning methods. The major challenge here is that the standard strings molecular representation SMILES shows substantial weaknesses in that task because large fractions of strings do not correspond to valid molecules. Here, we solve this problem at a fundamental level and introduce S<jats:sc>ELFIES</jats:sc> (SELF-referencIng Embedded Strings), a string-based representation of molecules which is 100% robust. Every S<jats:sc>ELFIES</jats:sc> string corresponds to a valid molecule, and S<jats:sc>ELFIES</jats:sc> can represent every molecule. S<jats:sc>ELFIES</jats:sc> can be directly applied in arbitrary machine learning models without the adaptation of the models; each of the generated molecule candidates is valid. In our experiments, the model\u2019s internal memory stores two orders of magnitude more diverse molecules than a similar test with SMILES. Furthermore, as all molecules are valid, it allows for explanation and interpretation of the internal working of the generative models.</jats:p>",
        "is_referenced_by_count": 262
    },
    {
        "title": "Deep-learning-based quantum vortex detection in atomic Bose\u2013Einstein condensates",
        "doi": "10.1088/2632-2153/abea6a",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Quantum vortices naturally emerge in rotating Bose\u2013Einstein condensates (BECs) and, similarly to their classical counterparts, allow the study of a range of interesting out-of-equilibrium phenomena, such as turbulence and chaos. However, the study of such phenomena requires the determination of the precise location of each vortex within a BEC, which becomes challenging when either only the density of the condensate is available or sources of noise are present, as is typically the case in experimental settings. Here, we introduce a machine-learning-based vortex detector motivated by state-of-the-art object detection methods that can accurately locate vortices in simulated BEC density images. Our model allows for robust and real-time detection in noisy and non-equilibrium configurations. Furthermore, the network can distinguish between vortices and anti-vortices if the phase profile of the condensate is also available. We anticipate that our vortex detector will be advantageous for both experimental and theoretical studies of the static and dynamic properties of vortex configurations in BECs.</jats:p>",
        "is_referenced_by_count": 11
    },
    {
        "title": "Ten years of generative adversarial nets (GANs): a survey of the state-of-the-art",
        "doi": "10.1088/2632-2153/ad1f77",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Generative adversarial networks (GANs) have rapidly emerged as powerful tools for generating realistic and diverse data across various domains, including computer vision and other applied areas, since their inception in 2014. Consisting of a discriminative network and a generative network engaged in a minimax game, GANs have revolutionized the field of generative modeling. In February 2018, GAN secured the leading spot on the \u2018Top Ten Global Breakthrough Technologies List\u2019 issued by the Massachusetts Science and Technology Review. Over the years, numerous advancements have been proposed, leading to a rich array of GAN variants, such as conditional GAN, Wasserstein GAN, cycle-consistent GAN, and StyleGAN, among many others. This survey aims to provide a general overview of GANs, summarizing the latent architecture, validation metrics, and application areas of the most widely recognized variants. We also delve into recent theoretical developments, exploring the profound connection between the adversarial principle underlying GAN and Jensen\u2013Shannon divergence while discussing the optimality characteristics of the GAN framework. The efficiency of GAN variants and their model architectures will be evaluated along with training obstacles as well as training solutions. In addition, a detailed discussion will be provided, examining the integration of GANs with newly developed deep learning frameworks such as transformers, physics-informed neural networks, large language models, and diffusion models. Finally, we reveal several issues as well as future research outlines in this field.</jats:p>",
        "is_referenced_by_count": 2
    },
    {
        "title": "Dynamics of supercooled liquids from static averaged quantities using machine learning",
        "doi": "10.1088/2632-2153/acc7e1",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We introduce a machine-learning approach to predict the complex non-Markovian dynamics of supercooled liquids from static averaged quantities. Compared to techniques based on particle propensity, our method is built upon a theoretical framework that uses as input and output system-averaged quantities, thus being easier to apply in an experimental context where particle resolved information is not available. In this work, we train a deep neural network to predict the self intermediate scattering function of binary mixtures using their static structure factor as input. While its performance is excellent for the temperature range of the training data, the model also retains some transferability in making decent predictions at temperatures lower than the ones it was trained for, or when we use it for similar systems. We also develop an evolutionary strategy that is able to construct a realistic memory function underlying the observed non-Markovian dynamics. This method lets us conclude that the memory function of supercooled liquids can be effectively parameterized as the sum of two stretched exponentials, which physically corresponds to two dominant relaxation modes.</jats:p>",
        "is_referenced_by_count": 4
    },
    {
        "title": "Multi-task graph neural networks for simultaneous prediction of global and atomic properties in ferromagnetic systems\n                  <sup>*</sup>",
        "doi": "10.1088/2632-2153/ac6a51",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We introduce a multi-tasking graph convolutional neural network, HydraGNN, to simultaneously predict <jats:italic>both global and atomic</jats:italic> physical properties and demonstrate with ferromagnetic materials. We train HydraGNN on an open-source <jats:italic>ab initio</jats:italic> density functional theory (DFT) dataset for iron-platinum with a fixed body centered tetragonal lattice structure and fixed volume to simultaneously predict the mixing enthalpy (a global feature of the system), the atomic charge transfer, and the atomic magnetic moment across configurations that span the entire compositional range. By taking advantage of underlying physical correlations between material properties, multi-task learning (MTL) with HydraGNN provides effective training even with modest amounts of data. Moreover, this is achieved with just one architecture instead of three, as required by single-task learning (STL). The first convolutional layers of the HydraGNN architecture are shared by all learning tasks and extract features common to all material properties. The following layers discriminate the features of the different properties, the results of which are fed to the separate heads of the final layer to produce predictions. Numerical results show that HydraGNN effectively captures the relation between the configurational entropy and the material properties over the entire compositional range. Overall, the accuracy of simultaneous MTL predictions is comparable to the accuracy of the STL predictions. In addition, the computational cost of training HydraGNN for MTL is much lower than the original DFT calculations and also lower than training separate STL models for each property.</jats:p>",
        "is_referenced_by_count": 8
    },
    {
        "title": "New angles on fast calorimeter shower simulation",
        "doi": "10.1088/2632-2153/acefa9",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title><jats:p>The demands placed on computational resources by the simulation requirements of high energy physics experiments motivate the development of novel simulation tools. Machine learning based generative models offer a solution that is both fast and accurate. In this work we extend the Bounded Information Bottleneck Autoencoder (BIB-AE) architecture, designed for the simulation of particle showers in highly granular calorimeters, in two key directions. First, we generalise the model to a multi-parameter conditioning scenario, while retaining a high degree of physics fidelity. In a second step, we perform a detailed study of the effect of applying a state-of-the-art particle flow-based reconstruction procedure to the generated showers. We demonstrate that the performance of the model remains high after reconstruction. These results are an important step towards creating a more general simulation tool, where maintaining physics performance after reconstruction is the ultimate target.</jats:p>",
        "is_referenced_by_count": 6
    },
    {
        "title": "Generating stable molecules using imitation and reinforcement learning",
        "doi": "10.1088/2632-2153/ac3eb4",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Chemical space is routinely explored by machine learning methods to discover interesting molecules, before time-consuming experimental synthesizing is attempted. However, these methods often rely on a graph representation, ignoring 3D information necessary for determining the stability of the molecules. We propose a reinforcement learning (RL) approach for generating molecules in Cartesian coordinates allowing for quantum chemical prediction of the stability. To improve sample-efficiency we learn basic chemical rules from imitation learning (IL) on the GDB-11 database to create an initial model applicable for all stoichiometries. We then deploy multiple copies of the model conditioned on a specific stoichiometry in a RL setting. The models correctly identify low energy molecules in the database and produce novel isomers not found in the training set. Finally, we apply the model to larger molecules to show how RL further refines the IL model in domains far from the training data.</jats:p>",
        "is_referenced_by_count": 4
    },
    {
        "title": "Hadrons, better, faster, stronger",
        "doi": "10.1088/2632-2153/ac7848",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Motivated by the computational limitations of simulating interactions of particles in highly-granular detectors, there exists a concerted effort to build fast and exact machine-learning-based shower simulators. This work reports progress on two important fronts. First, the previously investigated Wasserstein generative adversarial network and bounded information bottleneck autoencoder generative models are improved and successful learning of hadronic showers initiated by charged pions in a segment of the hadronic calorimeter of the International Large Detector is demonstrated for the first time. Second, we consider how state-of-the-art reconstruction software applied to generated shower energies affects the obtainable energy response and resolution. While many challenges remain, these results constitute an important milestone in using generative models in a realistic setting.</jats:p>",
        "is_referenced_by_count": 20
    },
    {
        "title": "A finite element-convolutional neural network model (FE-CNN) for stress field analysis around arbitrary inclusions",
        "doi": "10.1088/2632-2153/ad134a",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>This study presents a data-driven finite element-machine learning surrogate model for predicting the end-to-end full-field stress distribution and stress concentration around an arbitrary-shaped inclusion. This is important because the model\u2019s capacity to handle large datasets, consider variations in size and shape, and accurately replicate stress fields makes it a valuable tool for studying how inclusion characteristics affect material performance. An automatized dataset generation method using finite element simulation is proposed, validated, and used for attaining a dataset with one thousand inclusion shapes motivated by experimental observations and their corresponding spatially-varying stress distributions. A U-Net-based convolutional neural network (CNN) is trained using the dataset, and its performance is evaluated through quantitative and qualitative comparisons. The dataset, consisting of these stress data arrays, is directly fed into the CNN model for training and evaluation. This approach bypasses the need for converting the stress data into image format, allowing for a more direct and efficient input representation for the CNN. The model was evaluated through a series of sensitivity analyses, focusing on the impact of dataset size and model resolution on accuracy and performance. The results demonstrated that increasing the dataset size significantly improved the model\u2019s prediction accuracy, as indicated by the correlation values. Additionally, the investigation into the effect of model resolution revealed that higher resolutions led to better stress field predictions and reduced error. Overall, the surrogate model proved effective in accurately predicting the effective stress concentration in inclusions, showcasing its potential in practical applications requiring stress analysis such as structural engineering, material design, failure analysis, and multi-scale modeling.</jats:p>",
        "is_referenced_by_count": 3
    },
    {
        "title": "Prediction of 4D stress field evolution around additive manufacturing-induced porosity through progressive deep-learning frameworks",
        "doi": "10.1088/2632-2153/ad290c",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>This study investigates the application of machine learning models to predict time-evolving stress fields in complex three-dimensional structures trained with full-scale finite element simulation data. Two novel architectures, the multi-decoder CNN (MUDE-CNN) and the multiple encoder\u2013decoder model with transfer learning (MTED-TL), were introduced to address the challenge of predicting the progressive and spatial evolutional of stress distributions around defects. The MUDE-CNN leveraged a shared encoder for simultaneous feature extraction and employed multiple decoders for distinct time frame predictions, while MTED-TL progressively transferred knowledge from one encoder\u2013decoder block to another, thereby enhancing prediction accuracy through transfer learning. These models were evaluated to assess their accuracy, with a particular focus on predicting temporal stress fields around an additive manufacturing (AM)-induced isolated pore, as understanding such defects is crucial for assessing mechanical properties and structural integrity in materials and components fabricated via AM. The temporal model evaluation demonstrated MTED-TL\u2019s consistent superiority over MUDE-CNN, owing to transfer learning\u2019s advantageous initialization of weights and smooth loss curves. Furthermore, an autoregressive training framework was introduced to improve temporal predictions, consistently outperforming both MUDE-CNN and MTED-TL. By accurately predicting temporal stress fields around AM-induced defects, these models can enable real-time monitoring and proactive defect mitigation during the fabrication process. This capability ensures enhanced component quality and enhances the overall reliability of additively manufactured parts.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "Categorical representation learning: morphism is all you need",
        "doi": "10.1088/2632-2153/ac2c5d",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We provide a construction for categorical representation learning and introduce the foundations of \u2018<jats:italic>categorifier</jats:italic>\u2019. The central theme in <jats:italic>representation learning</jats:italic> is the idea of everything to vector. Every object in a dataset <jats:inline-formula>\n                     <jats:tex-math><?CDATA $\\mathcal{S}$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mrow>\n                           <mml:mi mathvariant=\"script\">S</mml:mi>\n                        </mml:mrow>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstac2c5dieqn1.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> can be represented as a vector in <jats:inline-formula>\n                     <jats:tex-math><?CDATA $\\mathbb{R}^n$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:msup>\n                           <mml:mrow>\n                              <mml:mi mathvariant=\"double-struck\">R</mml:mi>\n                           </mml:mrow>\n                           <mml:mi>n</mml:mi>\n                        </mml:msup>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstac2c5dieqn2.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> by an <jats:italic>encoding map</jats:italic> \n                  <jats:inline-formula>\n                     <jats:tex-math><?CDATA $E: \\mathcal{O}bj(\\mathcal{S})\\to\\mathbb{R}^n$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mi>E</mml:mi>\n                        <mml:mo>:</mml:mo>\n                        <mml:mrow>\n                           <mml:mi mathvariant=\"script\">O</mml:mi>\n                        </mml:mrow>\n                        <mml:mi>b</mml:mi>\n                        <mml:mi>j</mml:mi>\n                        <mml:mo stretchy=\"false\">(</mml:mo>\n                        <mml:mrow>\n                           <mml:mi mathvariant=\"script\">S</mml:mi>\n                        </mml:mrow>\n                        <mml:mo stretchy=\"false\">)</mml:mo>\n                        <mml:mo stretchy=\"false\">\u2192</mml:mo>\n                        <mml:msup>\n                           <mml:mrow>\n                              <mml:mi mathvariant=\"double-struck\">R</mml:mi>\n                           </mml:mrow>\n                           <mml:mi>n</mml:mi>\n                        </mml:msup>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstac2c5dieqn3.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>. More importantly, every morphism can be represented as a matrix <jats:inline-formula>\n                     <jats:tex-math><?CDATA $E: \\mathcal{H}om(\\mathcal{S})\\to\\mathbb{R}^{n}_{n}$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mi>E</mml:mi>\n                        <mml:mo>:</mml:mo>\n                        <mml:mrow>\n                           <mml:mi mathvariant=\"script\">H</mml:mi>\n                        </mml:mrow>\n                        <mml:mi>o</mml:mi>\n                        <mml:mi>m</mml:mi>\n                        <mml:mo stretchy=\"false\">(</mml:mo>\n                        <mml:mrow>\n                           <mml:mi mathvariant=\"script\">S</mml:mi>\n                        </mml:mrow>\n                        <mml:mo stretchy=\"false\">)</mml:mo>\n                        <mml:mo stretchy=\"false\">\u2192</mml:mo>\n                        <mml:msubsup>\n                           <mml:mrow>\n                              <mml:mi mathvariant=\"double-struck\">R</mml:mi>\n                           </mml:mrow>\n                           <mml:mrow>\n                              <mml:mi>n</mml:mi>\n                           </mml:mrow>\n                           <mml:mrow>\n                              <mml:mi>n</mml:mi>\n                           </mml:mrow>\n                        </mml:msubsup>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstac2c5dieqn4.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>. The encoding map <jats:italic>E</jats:italic> is generally modeled by a <jats:italic>deep neural network</jats:italic>. The goal of representation learning is to design appropriate tasks on the dataset to train the encoding map (assuming that an encoding is optimal if it universally optimizes the performance on various tasks). However, the latter is still a <jats:italic>set-theoretic</jats:italic> approach. The goal of the current article is to promote the representation learning to a new level via a <jats:italic>category-theoretic</jats:italic> approach. As a proof of concept, we provide an example of a text translator equipped with our technology, showing that our categorical learning model outperforms the current deep learning models by 17 times. The content of the current article is part of a US provisional patent application filed by QGNai, Inc.</jats:p>",
        "is_referenced_by_count": 3
    },
    {
        "title": "Machine learning spatio-temporal epidemiological model to evaluate Germany-county-level COVID-19 risk",
        "doi": "10.1088/2632-2153/ac0314",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>As the COVID-19 pandemic continues to ravage the world, it is critical to assess the COVID-19 risk timely on multi-scale. To implement it and evaluate the public health policies, we develop a machine learning assisted framework to predict epidemic dynamics from the reported infection data. It contains a county-level spatio-temporal epidemiological model, which combines spatial cellular automata (CA) with time sensitive-undiagnosed-infected-removed (SUIR) model, and is compatible with the existing risk prediction models. The CA-SUIR model shows the multi-scale risk to the public and reveals the transmission modes of coronavirus in different scenarios. Through transfer learning, this new toolbox is used to predict the prevalence of multi-scale COVID-19 in all 412 counties in Germany. A t-day-ahead risk forecast as well as assessment of the non-pharmaceutical intervention policies is presented. We analyzed the situation at Christmas of 2020, and found that the most serious death toll could be 34.5. However, effective policy could control it below 21thousand, which provides a quantitative basis for evaluating the public policies implemented by the government. Such intervening evaluation process would help to improve public health policies and restart the economy appropriately in pandemics.</jats:p>",
        "is_referenced_by_count": 14
    },
    {
        "title": "Tackling multimodal device distributions in inverse photonic design using invertible neural networks",
        "doi": "10.1088/2632-2153/acd619",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We show how conditional generative neural networks can be used to efficiently find nanophotonic devices with desired properties, also known as inverse photonic design. Machine learning has emerged as a promising approach to overcome limitations imposed by the dimensionality and topology of the parameter space. Importantly, traditional optimization routines assume an invertible mapping between the design parameters and response. However, different designs may have comparable or even identical performance confusing the optimization algorithm when performing inverse design. Our generative modeling approach provides the full distribution of possible solutions to the inverse design problem, including multiple solutions. We compare a commonly used conditional variational autoencoder (cVAE) and a conditional invertible neural network (cINN) on a proof-of-principle nanophotonic problem, consisting in tailoring the transmission spectrum trough a metallic film milled by subwavelength indentations. We show how cINNs have superior flexibility compared to cVAEs when dealing with multimodal device distributions.</jats:p>",
        "is_referenced_by_count": 2
    },
    {
        "title": "On the expressivity of embedding quantum kernels",
        "doi": "10.1088/2632-2153/ad2f51",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>One of the most natural connections between quantum and classical machine learning has been established in the context of kernel methods. Kernel methods rely on kernels, which are inner products of feature vectors living in large feature spaces. Quantum kernels are typically evaluated by explicitly constructing quantum feature states and then taking their inner product, here called embedding quantum kernels. Since classical kernels are usually evaluated without using the feature vectors explicitly, we wonder how expressive embedding quantum kernels are. In this work, we raise the fundamental question: can all quantum kernels be expressed as the inner product of quantum feature states? Our first result is positive: Invoking computational universality, we find that for any kernel function there always exists a corresponding quantum feature map and an embedding quantum kernel. The more operational reading of the question is concerned with efficient constructions, however. In a second part, we formalize the question of universality of efficient embedding quantum kernels. For shift-invariant kernels, we use the technique of random Fourier features to show that they are universal within the broad class of all kernels which allow a variant of efficient Fourier sampling. We then extend this result to a new class of so-called composition kernels, which we show also contains projected quantum kernels introduced in recent works. After proving the universality of embedding quantum kernels for both shift-invariant and composition kernels, we identify the directions towards new, more exotic, and unexplored quantum kernel families, for which it still remains open whether they correspond to efficient embedding quantum kernels.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Deep learning of interface structures from simulated 4D STEM data: cation intermixing vs. roughening\n                  <sup>\n                     <sup>\u2217</sup>\n                  </sup>",
        "doi": "10.1088/2632-2153/aba32d",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Interface structures in complex oxides remain an active area of condensed matter physics research, largely enabled by recent advances in scanning transmission electron microscopy (STEM). Yet the nature of the STEM contrast in which the structure is projected along the given direction precludes separation of possible structural models. Here, we utilize deep convolutional neural networks (DCNN) trained on simulated 4D STEM datasets to predict structural descriptors of interfaces. We focus on the widely studied interface between LaAlO<jats:sub>3</jats:sub> and SrTiO<jats:sub>3</jats:sub>, using dynamical diffraction theory and leveraging high performance computing to simulate thousands of possible 4D STEM datasets to train the DCNN to learn properties of the underlying structures on which the simulations are based. We test the DCNN on simulated data and show that it is possible (with &gt;95% accuracy) to identify a physically rough from a chemically diffuse interface and create a DCNN regression model to predict step positions. We quantify the applicability of the model to different thicknesses and the transferability of the approach. The method shown here is general and can be applied for any inverse imaging problem where forward models are present.</jats:p>",
        "is_referenced_by_count": 5
    },
    {
        "title": "Classification of diffraction patterns in single particle imaging experiments performed at x-ray free-electron lasers using a convolutional neural network",
        "doi": "10.1088/2632-2153/abd916",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Single particle imaging (SPI) is a promising method of native structure determination, which has undergone fast progress with the development of x-ray free-electron lasers. Large amounts of data are collected during SPI experiments, driving the need for automated data analysis. The necessary data analysis pipeline has a number of steps including binary object classification (single versus non-single hits). Classification and object detection are areas where deep neural networks currently outperform other approaches. In this work, we use the fast object detector networks YOLOv2 and YOLOv3. By exploiting transfer learning, a moderate amount of data is sufficient to train the neural network. We demonstrate here that a convolutional neural network can be successfully used to classify data from SPI experiments. We compare the results of classification for the two different networks, with different depth and architecture, by applying them to the same SPI data with different data representation. The best results are obtained for diffracted intensity represented by color images on a linear scale using YOLOv2 for classification. It shows an accuracy of about 95% with precision and recall of about 50% and 60%, respectively, in comparison to manual data classification.</jats:p>",
        "is_referenced_by_count": 13
    },
    {
        "title": "Symmetric and antisymmetric kernels for machine learning problems in quantum physics and chemistry",
        "doi": "10.1088/2632-2153/ac14ad",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We derive symmetric and antisymmetric kernels by symmetrizing and antisymmetrizing conventional kernels and analyze their properties. In particular, we compute the feature space dimensions of the resulting polynomial kernels, prove that the reproducing kernel Hilbert spaces induced by symmetric and antisymmetric Gaussian kernels are dense in the space of symmetric and antisymmetric functions, and propose a Slater determinant representation of the antisymmetric Gaussian kernel, which allows for an efficient evaluation even if the state space is high-dimensional. Furthermore, we show that by exploiting symmetries or antisymmetries the size of the training data set can be significantly reduced. The results are illustrated with guiding examples and simple quantum physics and chemistry applications.</jats:p>",
        "is_referenced_by_count": 9
    },
    {
        "title": "Laplace HypoPINN: physics-informed neural network for hypocenter localization and its predictive uncertainty",
        "doi": "10.1088/2632-2153/ac94b3",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Several techniques have been proposed over the years for automatic hypocenter localization. While those techniques have pros and cons that trade-off computational efficiency and the susceptibility of getting trapped in local minima, an alternate approach is needed that allows robust localization performance and holds the potential to make the elusive goal of real-time microseismic monitoring possible. Physics-informed neural networks (PINNs) have appeared on the scene as a flexible and versatile framework for solving partial differential equations (PDEs) along with the associated initial or boundary conditions. We develop <jats:italic>HypoPINN</jats:italic>\u2014a PINN-based inversion framework for hypocenter localization and introduce an approximate Bayesian framework for estimating its predictive uncertainties. This work focuses on predicting the hypocenter locations using HypoPINN and investigates the propagation of uncertainties from the random realizations of HypoPINN\u2019s weights and biases using the Laplace approximation. We train HypoPINN to obtain the optimized weights for predicting hypocenter location. Next, we approximate the covariance matrix at the optimized HypoPINN\u2019s weights for posterior sampling with the Laplace approximation. The posterior samples represent various realizations of HypoPINN\u2019s weights. Finally, we predict the locations of the hypocenter associated with those weights\u2019 realizations to investigate the uncertainty propagation that comes from those realizations. We demonstrate the features of this methodology through several numerical examples, including using the Otway velocity model based on the Otway project in Australia.</jats:p>",
        "is_referenced_by_count": 6
    },
    {
        "title": "A machine learning based Bayesian optimization solution to non-linear responses in dusty plasmas",
        "doi": "10.1088/2632-2153/abe7b7",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Nonlinear frequency response analysis is a widely used method for determining system dynamics in the presence of nonlinearities. In dusty plasmas, the plasma\u2013grain interaction (e.g. grain charging fluctuations) can be characterized by a single-particle non-linear response analysis, while grain\u2013grain non-linear interactions can be determined by a multi-particle non-linear response analysis. Here a machine learning-based method to determine the equation of motion in the non-linear response analysis for dust particles in plasmas is presented. Searching the parameter space in a Bayesian manner allows an efficient optimization of the parameters needed to match simulated non-linear response curves to experimentally measured non-linear response curves.</jats:p>",
        "is_referenced_by_count": 6
    },
    {
        "title": "An iterative deep learning procedure for determining electron scattering cross-sections from transport coefficients",
        "doi": "10.1088/2632-2153/ad2fed",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We propose improvements to the artificial neural network (ANN) method of determining electron scattering cross-sections from swarm data proposed by coauthors. A limitation inherent to this problem, known as the inverse swarm problem, is the non-unique nature of its solutions, particularly when there exists multiple cross-sections that each describe similar scattering processes. Considering this, prior methods leveraged existing knowledge of a particular cross-section set to reduce the solution space of the problem. To reduce the need for prior knowledge, we propose the following modifications to the ANN method. First, we propose a multi-branch ANN (MBANN) that assigns an independent branch of hidden layers to each cross-section output. We show that in comparison with an equivalent conventional ANN, the MBANN architecture enables an efficient and physics informed feature map of each cross-section. Additionally, we show that the MBANN solution can be improved upon by successive networks that are each trained using perturbations of the previous regression. Crucially, the method requires much less input data and fewer restrictive assumptions, and only assumes knowledge of energy loss thresholds and the number of cross-sections present.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Spectrally adapted physics-informed neural networks for solving unbounded domain problems",
        "doi": "10.1088/2632-2153/acd0a1",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Solving analytically intractable partial differential equations (PDEs) that involve at least one variable defined on an unbounded domain arises in numerous physical applications. Accurately solving unbounded domain PDEs requires efficient numerical methods that can resolve the dependence of the PDE on the unbounded variable over at least several orders of magnitude. We propose a solution to such problems by combining two classes of numerical methods: (i) adaptive spectral methods and (ii) physics-informed neural networks (PINNs). The numerical approach that we develop takes advantage of the ability of PINNs to easily implement high-order numerical schemes to efficiently solve PDEs and extrapolate numerical solutions at any point in space and time. We then show how recently introduced adaptive techniques for spectral methods can be integrated into PINN-based PDE solvers to obtain numerical solutions of unbounded domain problems that cannot be efficiently approximated by standard PINNs. Through a number of examples, we demonstrate the advantages of the proposed spectrally adapted PINNs in solving PDEs and estimating model parameters from noisy observations in unbounded domains.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "Gradients should stay on path: better estimators of the reverse- and forward KL divergence for normalizing flows",
        "doi": "10.1088/2632-2153/ac9455",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We show how to use the path-wise derivative estimator for both the forward reverse Kullback\u2013Leibler divergence for any practically invertible normalizing flow. The resulting path-gradient estimators are straightforward to implement, have lower variance, and lead not only to faster convergence of training but also to better overall approximation results compared to standard total gradient estimators. We also demonstrate that path-gradient training is less susceptible to mode-collapse. In light of our results, we expect that path-gradient estimators will become the new standard method to train normalizing flows for variational inference.</jats:p>",
        "is_referenced_by_count": 2
    },
    {
        "title": "Machine learning phases in swarming systems",
        "doi": "10.1088/2632-2153/acc007",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Recent years have witnessed a growing interest in using machine learning to predict and identify phase transitions (PTs) in various systems. Here we adopt convolutional neural networks (CNNs) to study the PTs of Vicsek model, solving the problem that traditional order parameters are insufficiently able to do. Within the large-scale simulations, there are four phases, and we confirm that all the PTs between two neighboring phases are first-order. We have successfully classified the phase by using CNNs with a high accuracy and identified the PT points, while traditional approaches using various order parameters fail to obtain. These results indicate the great potential of machine learning approach in understanding the complexities in collective behaviors, and in related complex systems in general.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "The reusability prior: comparing deep learning models without training",
        "doi": "10.1088/2632-2153/acc713",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Various choices can affect the performance of deep learning models. We conjecture that differences in the number of contexts for model components during training are critical. We generalize this notion by defining the reusability prior as follows: model components are forced to function in diverse contexts not only due to the training data, augmentation, and regularization choices, but also due to the model design itself. We focus on the design aspect and introduce a graph-based methodology to estimate the number of contexts for each learnable parameter. This allows a comparison of models without requiring any training. We provide supporting evidence with experiments using cross-layer parameter sharing on CIFAR-10, CIFAR-100, and Imagenet-1K benchmarks. We give examples of models that share parameters outperforming baselines that have at least 60% more parameters. The graph-analysis-based quantities we introduced for the reusability prior align well with the results, including at least two important edge cases. We conclude that the reusability prior provides a viable research direction for model analysis based on a very simple idea: counting the number of <jats:italic>contexts</jats:italic> for model parameters.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Generation model meets swin transformer for unsupervised low-dose CT reconstruction",
        "doi": "10.1088/2632-2153/ad370e",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Computed tomography (CT) has evolved into an indispensable tool for clinical diagnosis. Reducing radiation dose crucially minimizes adverse effects but may introduce noise and artifacts in reconstructed images, affecting diagnostic processes for physicians. Scholars have tackled deep learning training instability by exploring diffusion models. Given the scarcity of clinical data, we propose the unsupervised image domain score generation model (UISG) for low-dose CT reconstruction. During training, normal-dose CT images are utilized as network inputs to train a score-based generative model that captures the prior distribution of CT images. In the iterative reconstruction, the initial CT image is obtained using a filtered back-projection algorithm. Subsequently, diffusion-based prior, high-frequency convolutional sparse coding prior, and data-consistency steps are employed to obtain the high-quality reconstructed image. Given the global characteristics of noise, the score network of the diffusion model utilizes a swin transformer structure to enhance the model\u2019s ability to capture long-range dependencies. Furthermore, convolutional sparse coding is applied exclusively to the high-frequency components of the image, to prevent over-smoothing or the loss of crucial anatomical details during the denoising process. Quantitative and qualitative results indicate that UISG outperforms competing methods in terms of denoising and generalization performance.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Data-driven discovery of Koopman eigenfunctions for control",
        "doi": "10.1088/2632-2153/abf0f5",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Data-driven transformations that reformulate nonlinear systems in a linear framework have the potential to enable the prediction, estimation, and control of strongly nonlinear dynamics using linear systems theory. The Koopman operator has emerged as a principled linear embedding of nonlinear dynamics, and its eigenfunctions establish intrinsic coordinates along which the dynamics behave linearly. Previous studies have used finite-dimensional approximations of the Koopman operator for model-predictive control approaches. In this work, we illustrate a fundamental closure issue of this approach and argue that it is beneficial to first validate eigenfunctions and then construct reduced-order models in these validated eigenfunctions. These coordinates form a Koopman-invariant subspace <jats:italic>by design</jats:italic> and, thus, have improved predictive power. We show then how the control can be formulated directly in these intrinsic coordinates and discuss potential benefits and caveats of this perspective. The resulting control architecture is termed <jats:italic>Koopman Reduced Order Nonlinear Identification and Control</jats:italic> (KRONIC). It is further demonstrated that these eigenfunctions can be approximated with data-driven regression and power series expansions, based on the partial differential equation governing the infinitesimal generator of the Koopman operator. Validating discovered eigenfunctions is crucial and we show that lightly damped eigenfunctions may be faithfully extracted from EDMD or an implicit formulation. These lightly damped eigenfunctions are particularly relevant for control, as they correspond to nearly conserved quantities that are associated with persistent dynamics, such as the Hamiltonian. KRONIC is then demonstrated on a number of relevant examples, including (a) a nonlinear system with a known linear embedding, (b) a variety of Hamiltonian systems, and (c) a high-dimensional double-gyre model for ocean mixing.</jats:p>",
        "is_referenced_by_count": 81
    },
    {
        "title": "COVID-19 detection from lung CT-scan images using transfer learning approach",
        "doi": "10.1088/2632-2153/abf22c",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Since the onset of 2020, the spread of coronavirus disease (COVID-19) has rapidly accelerated worldwide into a state of severe pandemic. COVID-19 has infected more than 29 million people and caused more than 900 thousand deaths at the time of writing. Since it is highly contagious, it causes explosive community transmission. Thus, health care delivery has been disrupted and compromised by the lack of testing kits. COVID-19-infected patients show severe acute respiratory syndrome. Meanwhile, the scientific community has been involved in the implementation of deep learning (DL) techniques to diagnose COVID-19 using computed tomography (CT) lung scans, since CT is a pertinent screening tool due to its higher sensitivity in recognizing early pneumonic changes. However, large datasets of CT-scan images are not publicly available due to privacy concerns and obtaining very accurate models has become difficult. Thus, to overcome this drawback, transfer-learning pre-trained models are used in the proposed methodology to classify COVID-19 (positive) and COVID-19 (negative) patients. We describe the development of a DL framework that includes pre-trained models (DenseNet201, VGG16, ResNet50V2, and MobileNet) as its backbone, known as KarNet. To extensively test and analyze the framework, each model was trained on original (i.e. unaugmented) and manipulated (i.e. augmented) datasets. Among the four pre-trained models of KarNet, the one that used DenseNet201 demonstrated excellent diagnostic ability, with AUC scores of 1.00 and 0.99 for models trained on unaugmented and augmented data sets, respectively. Even after considerable distortion of the images (i.e. the augmented dataset) DenseNet201 achieved an accuracy of 97% for the test dataset, followed by ResNet50V2, MobileNet, and VGG16 (which achieved accuracies of 96%, 95%, and 94%, respectively).</jats:p>",
        "is_referenced_by_count": 30
    },
    {
        "title": "Deep reinforcement learning for optical systems: A case study of mode-locked lasers",
        "doi": "10.1088/2632-2153/abb6d6",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We demonstrate that deep reinforcement learning (deep RL) provides a highly effective strategy for the control and self-tuning of optical systems. Deep RL integrates the two leading machine learning architectures of deep neural networks and reinforcement learning to produce robust and stable learning for control. Deep RL is ideally suited for optical systems as the tuning and control relies on interactions with its environment with a goal-oriented objective to achieve optimal immediate or delayed rewards. This allows the optical system to recognize bi-stable structures and navigate, via trajectory planning, to optimally performing solutions, the first such algorithm demonstrated to do so in optical systems. We specifically demonstrate the deep RL architecture on a mode-locked laser, where robust self-tuning and control can be established through access of the deep RL agent to its waveplates and polarizers. We further integrate transfer learning to help the deep RL agent rapidly learn new parameter regimes and generalize its control authority. Additionally, the deep RL learning can be easily integrated with other control paradigms to provide a broad framework to control any optical system.</jats:p>",
        "is_referenced_by_count": 16
    },
    {
        "title": "Image mapping the temporal evolution of edge characteristics in tokamaks using neural networks",
        "doi": "10.1088/2632-2153/ab5639",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We propose a method for data-driven modelling of the temporal evolution of the plasma and neutral characteristics at the edge of a tokamak using neural networks. Our method proposes a novel fully convolutional network to serve as function approximators in modelling complex nonlinear phenomenon observed in the multi-physics representations of high energy physics. More specifically, we target the evolution of the temperatures, densities and parallel velocities of the electrons, ions and neutral particles at the edge. The central challenge in this context is in modelling together the different physics principles encapsulated in the evolution of plasma and the neutrals. We demonstrate that the inherent differences in nonlinear behaviour can be addressed by forking the network to process the plasma and neutral information individually before integrating as a holistic system. Our approach takes into account the spatial dependencies of the physics parameters across the grid while performing the temporal mappings, ensuring that the underlying physics is factored in and not lost to the black-box. Having used the conventional edge plasma-neutral solver code SOLPS to build the synthetic dataset, our method demonstrates a computational gain of over 5 orders of magnitude over it without a considerable compromise on accuracy.</jats:p>",
        "is_referenced_by_count": 3
    },
    {
        "title": "Machine-learning accelerated identification of exfoliable two-dimensional materials",
        "doi": "10.1088/2632-2153/ac9bca",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Two-dimensional (2D) materials have been a central focus of recent research because they host a variety of properties, making them attractive both for fundamental science and for applications. It is thus crucial to be able to identify accurately and efficiently if bulk three-dimensional (3D) materials are formed by layers held together by a weak binding energy that, thus, can be potentially exfoliated into 2D materials. In this work, we develop a machine-learning (ML) approach that, combined with a fast preliminary geometrical screening, is able to efficiently identify potentially exfoliable materials. Starting from a combination of descriptors for crystal structures, we work out a subset of them that are crucial for accurate predictions. Our final ML model, based on a random forest classifier, has a very high recall of 98%. Using a SHapely Additive exPlanations analysis, we also provide an intuitive explanation of the five most important variables of the model. Finally, we compare the performance of our best ML model with a deep neural network architecture using the same descriptors. To make our algorithms and models easily accessible, we publish an online tool on the Materials Cloud portal that only requires a bulk 3D crystal structure as input. Our tool thus provides a practical yet straightforward approach to assess whether any 3D compound can be exfoliated into 2D layers.</jats:p>",
        "is_referenced_by_count": 7
    },
    {
        "title": "Neural network field theories: non-Gaussianity, actions, and locality",
        "doi": "10.1088/2632-2153/ad17d3",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Both the path integral measure in field theory (FT) and ensembles of neural networks (NN) describe distributions over functions. When the central limit theorem can be applied in the infinite-width (infinite-<jats:italic>N</jats:italic>) limit, the ensemble of networks corresponds to a free FT. Although an expansion in <jats:inline-formula>\n                     <jats:tex-math><?CDATA $1/N$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mn>1</mml:mn>\n                        <mml:mrow>\n                           <mml:mo>/</mml:mo>\n                        </mml:mrow>\n                        <mml:mi>N</mml:mi>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstad17d3ieqn1.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> corresponds to interactions in the FT, others, such as in a small breaking of the statistical independence of network parameters, can also lead to interacting theories. These other expansions can be advantageous over the <jats:inline-formula>\n                     <jats:tex-math><?CDATA $1/N$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mn>1</mml:mn>\n                        <mml:mrow>\n                           <mml:mo>/</mml:mo>\n                        </mml:mrow>\n                        <mml:mi>N</mml:mi>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstad17d3ieqn2.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>-expansion, for example by improved behavior with respect to the universal approximation theorem. Given the connected correlators of a FT, one can systematically reconstruct the action order-by-order in the expansion parameter, using a new Feynman diagram prescription whose vertices are the connected correlators. This method is motivated by the Edgeworth expansion and allows one to derive actions for NN FT. Conversely, the correspondence allows one to engineer architectures realizing a given FT by representing action deformations as deformations of NN parameter densities. As an example, <jats:italic>\u03c6</jats:italic>\n                  <jats:sup>4</jats:sup> theory is realized as an infinite-<jats:italic>N</jats:italic> NN FT.</jats:p>",
        "is_referenced_by_count": 3
    },
    {
        "title": "Probe microscopy is all you need\n                  <sup>*</sup>",
        "doi": "10.1088/2632-2153/acccd5",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We pose that microscopy offers an ideal real-world experimental environment for the development and deployment of active Bayesian and reinforcement learning methods. Indeed, the tremendous progress achieved by machine learning (ML) and artificial intelligence over the last decade has been largely achieved via the utilization of static data sets, from the paradigmatic MNIST to the bespoke corpora of text and image data used to train large models such as GPT3, DALL\u00b7E and others. However, it is now recognized that continuous, minute improvements to state-of-the-art do not necessarily translate to advances in real-world applications. We argue that a promising pathway for the development of ML methods is via the route of domain-specific deployable algorithms in areas such as electron and scanning probe microscopy and chemical imaging. This will benefit both fundamental physical studies and serve as a test bed for more complex autonomous systems such as robotics and manufacturing. Favorable environment characteristics of scanning and electron microscopy include low risk, extensive availability of domain-specific priors and rewards, relatively small effects of exogenous variables, and often the presence of both upstream first principles as well as downstream learnable physical models for both statics and dynamics. Recent developments in programmable interfaces, edge computing, and access to application programming interfaces (APIs) facilitating microscope control, all render the deployment of ML codes on operational microscopes straightforward. We discuss these considerations and hope that these arguments will lead to create novel set of development targets for the ML community by accelerating both real world ML applications and scientific progress.</jats:p>",
        "is_referenced_by_count": 5
    },
    {
        "title": "Generation of conformational ensembles of small molecules via surrogate model-assisted molecular dynamics",
        "doi": "10.1088/2632-2153/ad3b64",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>The accurate prediction of thermodynamic properties is crucial in various fields such as drug discovery and materials design. This task relies on sampling from the underlying Boltzmann distribution, which is challenging using conventional approaches such as simulations. In this work, we introduce surrogate model-assisted molecular dynamics (SMA-MD), a new procedure to sample the equilibrium ensemble of molecules. First, SMA-MD leverages deep generative models to enhance the sampling of slow degrees of freedom. Subsequently, the generated ensemble undergoes statistical reweighting, followed by short simulations. Our empirical results show that SMA-MD generates more diverse and lower energy ensembles than conventional MD simulations. Furthermore, we showcase the application of SMA-MD for the computation of thermodynamical properties by estimating implicit solvation free energies.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Deep Learning Based Event Reconstruction for Cyclotron Radiation Emission Spectroscopy",
        "doi": "10.1088/2632-2153/ad3ee3",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>The general principle of Cyclotron Radiation Emission Spectroscopy (CRES) experiments is to build an energy spectrum by reconstructing the start frequencies of charged particle trajectories (called tracks) which leave quasilinear profiles in the time-frequency plane when exposed to a magnetic field. The Project 8 collaboration is developing the CRES technique in order to extract the unknown absolute neutrino mass value with a final sensitivity 0.04 eV/$c^2$ from the $\\beta$-decay energy spectrum of tritium. Due to the small number of events in the spectrum's endpoint region and the need for excellent instrumental energy resolution, efficient and highly accurate reconstruction methods are desired. Deep learning convolutional neural networks (CNNs) - particularly suited to deal with information-sparse data and which offer precise foreground localization - may be utilized to extract track properties from basic CRES signals with relative computational ease. In this work, we develop a novel machine learning based model which operates a CNN and a support vector machine in tandem to reconstruct simulated CRES tracks and events. As applied to simulated CRES data, we show comparable performance in accuracy of track parameter reconstruction and a relative gain of 24.1\\% in event reconstruction efficiency when compared to a traditional point-clustering based approach (baseline).</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Inception neural network for complete intersection Calabi\u2013Yau 3-folds",
        "doi": "10.1088/2632-2153/abda61",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title><jats:p>We introduce a neural network inspired by Google\u2019s Inception model to compute the Hodge number<jats:italic>h</jats:italic><jats:sup>1,1</jats:sup>of complete intersection Calabi\u2013Yau (CICY) 3-folds. This architecture improves largely the accuracy of the predictions over existing results, giving already 97% of accuracy with just 30% of the data for training. Accuracy climbs to 99% when using 80% of the data for training. This proves that neural networks are a valuable resource to study geometric aspects in both pure mathematics and string theory.</jats:p>",
        "is_referenced_by_count": 9
    },
    {
        "title": "Automated multi-layer optical design via deep reinforcement learning",
        "doi": "10.1088/2632-2153/abc327",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Optical multi-layer thin films are widely used in optical and energy applications requiring photonic designs. Engineers often design such structures based on their physical intuition. However, solely relying on human experts can be time-consuming and may lead to sub-optimal designs, especially when the design space is large. In this work, we frame the multi-layer optical design task as a sequence generation problem. A deep sequence generation network is proposed for efficiently generating optical layer sequences. We train the deep sequence generation network with proximal policy optimization to generate multi-layer structures with desired properties. The proposed method is applied to two energy applications. Our algorithm successfully discovered high-performance designs, outperforming structures designed by human experts in task 1, and a state-of-the-art memetic algorithm in task 2.</jats:p>",
        "is_referenced_by_count": 40
    },
    {
        "title": "Unsupervised machine learning of topological phase transitions from experimental data",
        "doi": "10.1088/2632-2153/abffe7",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Identifying phase transitions is one of the key challenges in quantum many-body physics. Recently, machine learning methods have been shown to be an alternative way of localising phase boundaries from noisy and imperfect data without the knowledge of the order parameter. Here, we apply different unsupervised machine learning techniques, including anomaly detection and influence functions, to experimental data from ultracold atoms. In this way, we obtain the topological phase diagram of the Haldane model in a completely unbiased fashion. We show that these methods can successfully be applied to experimental data at finite temperatures and to the data of Floquet systems when post-processing the data to a single micromotion phase. Our work provides a benchmark for the unsupervised detection of new exotic phases in complex many-body systems.</jats:p>",
        "is_referenced_by_count": 39
    },
    {
        "title": "scGMM-VGAE: a Gaussian mixture model-based variational graph autoencoder algorithm for clustering single-cell RNA-seq data",
        "doi": "10.1088/2632-2153/acd7c3",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Cell type identification using single-cell RNA sequencing data is critical for understanding disease mechanisms and drug discovery. Cell clustering analysis has been widely studied in health research for rare tumor cell detection. In this study, we propose a Gaussian mixture model-based variational graph autoencoder on scRNA-seq data (scGMM-VGAE) that integrates a statistical clustering model to a deep learning algorithm to significantly improve the cell clustering performance. This model feeds a cell-cell graph adjacency matrix and a gene feature matrix into a graph variational autoencoder (VGAE) to generate latent data. These data are then used for cell clustering by the Gaussian mixture model (GMM) module. To optimize the algorithm, a designed loss function is derived by combining parameter estimates from the GMM and VGAE. We test the proposed method on four publicly available and three simulated datasets which contain many biological and technical zeros. The scGMM-VGAE outperforms four selected baseline methods on three evaluation metrics in cell clustering. By successfully incorporating GMM into deep learning VGAE on scRNA-seq data, the proposed method shows higher accuracy in cell clustering on scRNA-seq data. This improvement has a significant impact on detecting rare cell types in health research. All source codes used in this study can be found at <jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/ericlin1230/scGMM-VGAE\" xlink:type=\"simple\">https://github.com/ericlin1230/scGMM-VGAE</jats:ext-link>.</jats:p>",
        "is_referenced_by_count": 3
    },
    {
        "title": "Data augmentation with Mobius transformations",
        "doi": "10.1088/2632-2153/abd615",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Data augmentation has led to substantial improvements in the performance and generalization of deep models, and remains a highly adaptable method to evolving model architectures and varying amounts of data\u2014in particular, extremely scarce amounts of available training data. In this paper, we present a novel method of applying M\u00f6bius transformations to augment input images during training. M\u00f6bius transformations are bijective conformal maps that generalize image translation to operate over complex inversion in pixel space. As a result, M\u00f6bius transformations can operate on the sample level and preserve data labels. We show that the inclusion of M\u00f6bius transformations during training enables improved generalization over prior sample-level data augmentation techniques such as cutout and standard crop-and-flip transformations, most notably in low data regimes.</jats:p>",
        "is_referenced_by_count": 8
    },
    {
        "title": "Classifying rock types by geostatistics and random forests in tandem",
        "doi": "10.1088/2632-2153/ad3c0f",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Rock type classification is crucial for evaluating mineral resources in ore deposits and for rock mechanics. Mineral deposits are formed in a variety of rock bodies and rock types. However, the rock type identification in drill core samples is often complicated by overprinting and weathering processes. An approach to classifying rock types from drill core data relies on whole-rock geochemical assays as features. There are few studies on rock type classification from a limited number of metal grades and dry bulk density as features. The novelty in our approach is the introduction of two sets of feature variables (proxies) at sampled data points, generated by geostatistical leave-one-out cross-validation and by kriging for removing short-scale spatial variation of the measured features. We applied our proposal to a dataset from a porphyry Cu\u2013Au deposit in Mongolia. The model performances on a testing data subset indicate that, when the training dataset is not large, the performance of the classifier (a random forest) substantially improves by incorporating the proxy features as a complement to the original measured features. At each training data point, these proxy features throw light based on the underlying spatial data correlation structure, scales of variations, sampling design, and values of features observed at neighboring points, and show the benefits of combining geostatistics with machine learning.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Reinforcement learning for semi-autonomous approximate quantum eigensolver",
        "doi": "10.1088/2632-2153/ab43b4",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>The characterization of an operator by its eigenvectors and eigenvalues allows us to know its action over any quantum state. Here, we propose a protocol to obtain an approximation of the eigenvectors of an arbitrary Hermitian quantum operator. This protocol is based on measurement and feedback processes, which characterize a reinforcement learning protocol. Our proposal is composed of two systems, a black box named environment and a quantum state named agent. The role of the environment is to change any quantum state by a unitary matrix <jats:inline-formula>\n                     <jats:tex-math>\n<?CDATA ${\\hat{U}}_{E}={{\\rm{e}}}^{-{\\rm{i}}\\tau {\\hat{{ \\mathcal O }}}_{E}}$?>\n</jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:msub>\n                           <mml:mrow>\n                              <mml:mover accent=\"true\">\n                                 <mml:mrow>\n                                    <mml:mi>U</mml:mi>\n                                 </mml:mrow>\n                                 <mml:mrow>\n                                    <mml:mo>\u02c6</mml:mo>\n                                 </mml:mrow>\n                              </mml:mover>\n                           </mml:mrow>\n                           <mml:mrow>\n                              <mml:mi>E</mml:mi>\n                           </mml:mrow>\n                        </mml:msub>\n                        <mml:mo>=</mml:mo>\n                        <mml:msup>\n                           <mml:mrow>\n                              <mml:mi mathvariant=\"normal\">e</mml:mi>\n                           </mml:mrow>\n                           <mml:mrow>\n                              <mml:mo>\u2212</mml:mo>\n                              <mml:mi mathvariant=\"normal\">i</mml:mi>\n                              <mml:mi>\u03c4</mml:mi>\n                              <mml:msub>\n                                 <mml:mrow>\n                                    <mml:mover accent=\"true\">\n                                       <mml:mrow>\n                                          <mml:mi mathvariant=\"italic\">\ue23b</mml:mi>\n                                       </mml:mrow>\n                                       <mml:mrow>\n                                          <mml:mo>\u02c6</mml:mo>\n                                       </mml:mrow>\n                                    </mml:mover>\n                                 </mml:mrow>\n                                 <mml:mrow>\n                                    <mml:mi>E</mml:mi>\n                                 </mml:mrow>\n                              </mml:msub>\n                           </mml:mrow>\n                        </mml:msup>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstab43b4ieqn1.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> where <jats:inline-formula>\n                     <jats:tex-math>\n<?CDATA ${\\hat{{ \\mathcal O }}}_{E}$?>\n</jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:msub>\n                           <mml:mrow>\n                              <mml:mover accent=\"true\">\n                                 <mml:mrow>\n                                    <mml:mi mathvariant=\"italic\">\ue23b</mml:mi>\n                                 </mml:mrow>\n                                 <mml:mrow>\n                                    <mml:mo>\u02c6</mml:mo>\n                                 </mml:mrow>\n                              </mml:mover>\n                           </mml:mrow>\n                           <mml:mrow>\n                              <mml:mi>E</mml:mi>\n                           </mml:mrow>\n                        </mml:msub>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstab43b4ieqn2.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> is a Hermitian operator, and <jats:italic>\u03c4</jats:italic> is a real parameter. The agent is a quantum state which adapts to some eigenvector of <jats:inline-formula>\n                     <jats:tex-math>\n<?CDATA ${\\hat{{ \\mathcal O }}}_{E}$?>\n</jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:msub>\n                           <mml:mrow>\n                              <mml:mover accent=\"true\">\n                                 <mml:mrow>\n                                    <mml:mi mathvariant=\"italic\">\ue23b</mml:mi>\n                                 </mml:mrow>\n                                 <mml:mrow>\n                                    <mml:mo>\u02c6</mml:mo>\n                                 </mml:mrow>\n                              </mml:mover>\n                           </mml:mrow>\n                           <mml:mrow>\n                              <mml:mi>E</mml:mi>\n                           </mml:mrow>\n                        </mml:msub>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstab43b4ieqn3.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> by repeated interactions with the environment, feedback process, and semi-random rotations. With this proposal, we can obtain an approximation of the eigenvectors of a random qubit operator with average fidelity over 90% in less than 10 iterations, and surpass 98% in less than 300 iterations. Moreover, for the two-qubit cases, the four eigenvectors are obtained with fidelities above 89% in 8000 iterations for a random operator, and fidelities of 99% for an operator with the Bell states as eigenvectors. This protocol can be useful to implement semi-autonomous quantum devices which should be capable of extracting information and deciding with minimal resources and without human intervention.</jats:p>",
        "is_referenced_by_count": 13
    },
    {
        "title": "Koopman-inspired approach for identification of exogenous anomalies in nonstationary time-series data",
        "doi": "10.1088/2632-2153/acdd50",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>In many scenarios, it is necessary to monitor a complex system via a time-series of observations and determine when anomalous exogenous events have occurred so that relevant actions can be taken. Determining whether current observations are abnormal is challenging. It requires learning an extrapolative probabilistic model of the dynamics from historical data, and using a limited number of current observations to make a classification. We leverage recent advances in long-term probabilistic forecasting, namely <jats:italic>Deep Probabilistic Koopman</jats:italic>, to build a general method for classifying anomalies in multi-dimensional time-series data. We also show how to utilize models with domain knowledge of the dynamics to reduce type I and type II error. We demonstrate our proposed method on the important real-world task of global atmospheric pollution monitoring, integrating it with NASA\u2019s Global Earth Observing System Model. The system successfully detects localized anomalies in air quality due to events such as COVID-19 lockdowns and wildfires.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Determination of latent dimensionality in international trade flow",
        "doi": "10.1088/2632-2153/aba9ee",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Currently, high-dimensional data is ubiquitous in data science, which necessitates the development of techniques to decompose and interpret such multidimensional (aka tensor) datasets. Finding a low dimensional representation of the data, that is, its inherent structure, is one of the approaches that can serve to understand the dynamics of low dimensional latent features hidden in the data. Moreover, decomposition methods with non-negative constraints are shown to extract more insightful factors. Nonnegative RESCAL is one such technique, particularly well suited to analyze self-relational data, such as dynamic networks found in international trade flows. Particularly, non-negative RESCAL computes a low dimensional tensor representation by finding the latent space containing multiple modalities. Furthermore, estimating the dimensionality of this latent space is crucial for extracting meaningful latent features. Here, to determine the dimensionality of the latent space with non-negative RESCAL, we propose a latent dimension determination method which is based on clustering of the solutions of multiple realizations of non-negative RESCAL decompositions. We demonstrate the performance of our model selection method on synthetic data. We then apply our method to decompose a network of international trade flows data from <jats:italic>International Monetary Fund</jats:italic> and shows that with a correct latent dimension determination, the resulting features are able to capture relevant empirical facts from economic literature.</jats:p>",
        "is_referenced_by_count": 3
    },
    {
        "title": "Robust detection of marine life with label-free image feature learning and probability calibration",
        "doi": "10.1088/2632-2153/ace417",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Advances in <jats:italic>in situ</jats:italic> marine life imaging have significantly increased the size and quality of available datasets, but automatic image analysis has not kept pace. Machine learning has shown promise for image processing, but its effectiveness is limited by several open challenges: the requirement for large expert-labeled training datasets, disagreement among experts, under-representation of various species and unreliable or overconfident predictions. To overcome these obstacles for automated underwater imaging, we combine and test recent developments in deep classifier networks and self-supervised feature learning. We use unlabeled images for pretraining deep neural networks to extract task-relevant image features, allowing learning algorithms to cope with scarcity in expert labels, and carefully evaluate performance in subsequent label-based tasks. Performance on rare classes is improved by applying data rebalancing together with a Bayesian correction to avoid biasing inferred <jats:italic>in situ</jats:italic> class frequencies. A divergence-based loss allows training on multiple, conflicting labels for the same image, leading to better estimates of uncertainty which we quantify with a novel accuracy measure. Together, these techniques can reduce the required label counts \u223c100-fold while maintaining the accuracy of standard supervised training, shorten training time, cope with expert disagreement and reduce overconfidence.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Achieving robustness to aleatoric uncertainty with heteroscedastic Bayesian optimisation",
        "doi": "10.1088/2632-2153/ac298c",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Bayesian optimisation is a sample-efficient search methodology that holds great promise for accelerating drug and materials discovery programs. A frequently-overlooked modelling consideration in Bayesian optimisation strategies however, is the representation of heteroscedastic aleatoric uncertainty. In many practical applications it is desirable to identify inputs with low aleatoric noise, an example of which might be a material composition which displays robust properties in response to a noisy fabrication process. In this paper, we propose a heteroscedastic Bayesian optimisation scheme capable of representing and minimising aleatoric noise across the input space. Our scheme employs a heteroscedastic Gaussian process surrogate model in conjunction with two straightforward adaptations of existing acquisition functions. First, we extend the augmented expected improvement heuristic to the heteroscedastic setting and second, we introduce the aleatoric noise-penalised expected improvement (ANPEI) heuristic. Both methodologies are capable of penalising aleatoric noise in the suggestions. In particular, the ANPEI acquisition yields improved performance relative to homoscedastic Bayesian optimisation and random sampling on toy problems as well as on two real-world scientific datasets. Code is available at: <jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/Ryan-Rhys/Heteroscedastic-BO\" xlink:type=\"simple\">https://github.com/Ryan-Rhys/Heteroscedastic-BO</jats:ext-link>\n               </jats:p>",
        "is_referenced_by_count": 7
    },
    {
        "title": "Realistic mask generation for matter-wave lithography via machine learning",
        "doi": "10.1088/2632-2153/acd988",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Fast production of large-area patterns is crucial for the established semiconductor industry and enables industrial-scale production of next-generation quantum devices. Metastable atom lithography with binary holography masks has been suggested as a higher resolution/low-cost alternative to the current state of the art: extreme ultraviolet lithography. However, it was recently shown that the interaction of the metastable atoms with the mask material (SiN) leads to a strong perturbation of the wavefront, not included in the existing mask generation theory, which is based on classical scalar waves. This means that the inverse problem (creating a mask based on the desired pattern) cannot be solved analytically, even in 1D. Here we present a machine-learning approach to mask generation targeted for metastable atoms. Our algorithm uses a combination of genetic optimisation and deep learning to obtain the mask. A novel deep neural architecture is trained to produce an initial approximation of the mask. This approximation is then used to generate the initial population of the genetic optimisation algorithm that can converge to arbitrary precision. We demonstrate the generation of arbitrary 1D patterns for system dimensions within the Fraunhofer approximation limit.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Standardizing chemical compounds with language models",
        "doi": "10.1088/2632-2153/ace878",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>With the growing amount of chemical data stored digitally, it has become crucial to represent chemical compounds accurately and consistently. Harmonized representations facilitate the extraction of insightful information from datasets, and are advantageous for machine learning applications. To achieve consistent representations throughout datasets, one relies on molecule standardization, which is typically accomplished using rule-based algorithms that modify descriptions of functional groups. Here, we present the first deep-learning model for molecular standardization. We enable custom standardization schemes based solely on data, which, as additional benefit, support standardization options that are difficult to encode into rules. Our model achieves over <jats:inline-formula>\n                     <jats:tex-math><?CDATA $98\\%$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mn>98</mml:mn>\n                        <mml:mi mathvariant=\"normal\">%</mml:mi>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstace878ieqn1.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> accuracy in learning two popular rule-based standardization protocols. We then follow a transfer learning approach to standardize metal-organic compounds (for which there is currently no automated standardization practice), based on a human-curated dataset of 1512 compounds. This model predicts the expected standardized molecular format with a test accuracy of 80.7%. As standardization can be considered, more broadly, a transformation from undesired to desired representations of compounds, the same data-driven architecture can be applied to other tasks. For instance, we demonstrate the application to compound canonicalization and to the determination of major tautomers in solution, based on computed and experimental data.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "An automated approach for determining the number of components in non-negative matrix factorization with application to mutational signature learning",
        "doi": "10.1088/2632-2153/abc60a",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Non-negative matrix factorization (NMF) is a popular method for finding a low rank approximation of a matrix, thereby revealing the latent components behind it. In genomics, NMF is widely used to interpret mutation data and derive the underlying mutational processes and their activities. A key challenge in the use of NMF is determining the number of components, or rank of the factorization. Here we propose a novel method, CV2K, to choose this number automatically from data that is based on a detailed cross validation procedure combined with a parsimony consideration. We apply our method for mutational signature analysis and demonstrate its utility on both simulated and real data sets. In comparison to previous approaches, some of which involve human assessment, CV2K leads to improved predictions across a wide range of data sets.</jats:p>",
        "is_referenced_by_count": 2
    },
    {
        "title": "Rapid parameter estimation of discrete decaying signals using autoencoder networks",
        "doi": "10.1088/2632-2153/ac1eea",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>In this work we demonstrate the use of neural networks for rapid extraction of signal parameters of discretely sampled signals. In particular, we use dense autoencoder networks to extract the parameters of interest from exponentially decaying signals and decaying oscillations. By using a three-stage training method and careful choice of the neural network size, we are able to retrieve the relevant signal parameters directly from the latent space of the autoencoder network at significantly improved rates compared to traditional algorithmic signal-analysis approaches. We show that the achievable precision and accuracy of this method of analysis is similar to conventional algorithm-based signal analysis methods, by demonstrating that the extracted signal parameters are approaching their fundamental parameter estimation limit as provided by the Cram\u00e9r\u2013Rao bound. Furthermore, we demonstrate that autoencoder networks are able to achieve signal analysis, and, hence, parameter extraction, at rates of 75 kHz, orders-of-magnitude faster than conventional techniques with similar precision. Finally, our exploration of the limitations of our approach in different computational systems suggests that analysis rates of <jats:inline-formula>\n                     <jats:tex-math><?CDATA $\\gt$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mo>&gt;</mml:mo>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstac1eeaieqn1.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>200 kHz are feasible using neural networks in systems where the transfer time between the data-acquisition system and data-analysis modules can be kept below \u223c3 <jats:italic>\u00b5</jats:italic>s.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Extending the extended dynamic mode decomposition with latent observables: the latent EDMD framework",
        "doi": "10.1088/2632-2153/acccd6",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Bernard O Koopman proposed an alternative view of dynamical systems based on linear operator theory, in which the time evolution of a dynamical system is analogous to the linear propagation of an infinite-dimensional vector of observables. In the last few years, several works have shown that finite-dimensional approximations of this operator can be extremely useful for several applications, such as prediction, control, and data assimilation. In particular, a Koopman representation of a dynamical system with a finite number of dimensions will avoid all the problems caused by nonlinearity in classical state-space models. In this work, the identification of finite-dimensional approximations of the Koopman operator and its associated observables is expressed through the inversion of an unknown augmented linear dynamical system. The proposed framework can be regarded as an extended dynamical mode decomposition that uses a collection of latent observables. The use of a latent dictionary applies to a large class of dynamical regimes, and it provides new means for deriving appropriate finite-dimensional linear approximations to high-dimensional nonlinear systems.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Data efficiency and extrapolation trends in neural network interatomic potentials",
        "doi": "10.1088/2632-2153/acf115",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Recently, key architectural advances have been proposed for neural network interatomic potentials (NNIPs), such as incorporating message-passing networks, equivariance, or many-body expansion terms. Although modern NNIP models exhibit small differences in test accuracy, this metric is still considered the main target when developing new NNIP architectures. In this work, we show how architectural and optimization choices influence the generalization of NNIPs, revealing trends in molecular dynamics (MD) stability, data efficiency, and loss landscapes. Using the 3BPA dataset, we uncover trends in NNIP errors and robustness to noise, showing these metrics are insufficient to predict MD stability in the high-accuracy regime. With a large-scale study on NequIP, MACE, and their optimizers, we show that our metric of loss entropy predicts out-of-distribution error and data efficiency despite being computed only on the training set. This work provides a deep learning justification for probing extrapolation and can inform the development of next-generation NNIPs.</jats:p>",
        "is_referenced_by_count": 4
    },
    {
        "title": "Intramolecular proton transfer reaction dynamics using machine-learned ab initio potential energy surfaces",
        "doi": "10.1088/2632-2153/acdbbc",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Hydrogen bonding interactions, which are central to various physicochemical processes, are investigated in the present study using <jats:italic>ab initio</jats:italic>-based machine learning potential energy surfaces. Abnormally strong intramolecular O\u2013H\u22efO hydrogen bonds, occurring in <jats:italic>\u03b2</jats:italic>-diketone enols of malonaldehyde and its derivatives, with substituents ranging from various electron-withdrawing to electron-donating functional groups, are studied. Machine learning force fields were constructed using a kernel-based force learning model employing <jats:italic>ab initio</jats:italic> molecular dynamics reference data. These models were used for molecular dynamics simulations at finite temperature, and dynamical properties were determined by computing proton transfer free-energy surfaces. The chemical systems studied here show progression toward barrier-less proton transfer events at an accuracy of correlated electronic structure methods. Markov state models of the conformational states indicate shorter intramolecular hydrogen bonds exhibiting higher proton transfer rates. We demonstrate how functional group substitution can modulate the strength of intramolecular hydrogen bonds by studying the thermodynamic and kinetic properties.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Conditioning Boltzmann generators for rare event sampling",
        "doi": "10.1088/2632-2153/acf55c",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title><jats:p>Understanding the dynamics of complex molecular processes is often linked to the study of infrequent transitions between long-lived stable states. The standard approach to the sampling of such rare events is to generate an ensemble of transition paths using a random walk in trajectory space. This, however, comes with the drawback of strong correlations between subsequently sampled paths and with an intrinsic difficulty in parallelizing the sampling process. We propose a transition path sampling scheme based on neural-network generated configurations. These are obtained employing normalizing flows, a neural network class able to generate statistically independent samples from a given distribution. With this approach, not only are correlations between visited paths removed, but the sampling process becomes easily parallelizable. Moreover, by conditioning the normalizing flow, the sampling of configurations can be steered towards regions of interest. We show that this approach enables the resolution of both the thermodynamics and kinetics of the transition region for systems that can be sampled using exact-likelihood generative models.</jats:p>",
        "is_referenced_by_count": 4
    },
    {
        "title": "K-means-driven Gaussian Process data collection for angle-resolved photoemission spectroscopy",
        "doi": "10.1088/2632-2153/abab61",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We propose the combination of k-means clustering with Gaussian Process (GP) regression in the analysis and exploration of 4D angle-resolved photoemission spectroscopy (ARPES) data. Using cluster labels as the driving metric on which the GP is trained, this method allows us to reconstruct the experimental phase diagram from as low as 12% of the original dataset size. In addition to the phase diagram, the GP is able to reconstruct spectra in energy-momentum space from this minimal set of data points. These findings suggest that this methodology can be used to improve the efficiency of ARPES data collection strategies for unknown samples. The practical feasibility of implementing this technology at a synchrotron beamline and the overall efficiency implications of this method are discussed with a view on enabling the collection of more samples or rapid identification of regions of interest.</jats:p>",
        "is_referenced_by_count": 7
    },
    {
        "title": "Data-centric machine learning in quantum information science",
        "doi": "10.1088/2632-2153/ac9036",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We propose a series of data-centric heuristics for improving the performance of machine learning systems when applied to problems in quantum information science. In particular, we consider how systematic engineering of training sets can significantly enhance the accuracy of pre-trained neural networks used for quantum state reconstruction without altering the underlying architecture. We find that it is not always optimal to engineer training sets to exactly match the expected distribution of a target scenario, and instead, performance can be further improved by biasing the training set to be slightly more mixed than the target. This is due to the heterogeneity in the number of free variables required to describe states of different purity, and as a result, overall accuracy of the network improves when training sets of a fixed size focus on states with the least constrained free variables. For further clarity, we also include a \u2018toy model\u2019 demonstration of how spurious correlations can inadvertently enter synthetic data sets used for training, how the performance of systems trained with these correlations can degrade dramatically, and how the inclusion of even relatively few counterexamples can effectively remedy such problems.</jats:p>",
        "is_referenced_by_count": 5
    },
    {
        "title": "Governing equation discovery based on causal graph for nonlinear dynamic systems",
        "doi": "10.1088/2632-2153/acffa4",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>The governing equations of nonlinear dynamic systems is of great significance for understanding the internal physical characteristics. In order to learn the governing equations of nonlinear systems from noisy observed data, we propose a novel method named governing equation discovery based on causal graph that combines spatio-temporal graph convolution network with governing equation modeling. The essence of our method is to first devise the causal graph encoding based on transfer entropy to obtain the adjacency matrix with causal significance between variables. Then, the spatio-temporal graph convolutional network is used to obtain approximate solutions for the system variables. On this basis, automatic differentiation is applied to obtain basic derivatives and form a dictionary of candidate algebraic terms. Finally, sparse regression is used to obtain the coefficient matrix and determine the explicit formulation of the governing equations. We also design a novel cross-combinatorial optimization strategy to learn the heterogeneous parameters that include neural network parameters and control equation coefficients. We conduct extensive experiments on seven datasets from different physical fields. The experimental results demonstrate the proposed method can automatically discover the underlying governing equation of the systems, and has great robustness.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Simulation-based inference with approximately correct parameters via maximum entropy",
        "doi": "10.1088/2632-2153/ac6286",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Inferring the input parameters of simulators from observations is a crucial challenge with applications from epidemiology to molecular dynamics. Here we show a simple approach in the regime of sparse data and approximately correct models, which is common when trying to use an existing model to infer latent variables with observed data. This approach is based on the principle of maximum entropy (MaxEnt) and provably makes the smallest change in the latent joint distribution to fit new data. This method requires no likelihood or model derivatives and its fit is insensitive to prior strength, removing the need to balance observed data fit with prior belief. The method requires the ansatz that data is fit in expectation, which is true in some settings and may be reasonable in all settings with few data points. The method is based on sample reweighting, so its asymptotic run time is independent of prior distribution dimension. We demonstrate this MaxEnt approach and compare with other likelihood-free inference methods across three systems: a point particle moving in a gravitational field, a compartmental model of epidemic spread and molecular dynamics simulation of a protein.</jats:p>",
        "is_referenced_by_count": 2
    },
    {
        "title": "Three-body renormalization group limit cycles based on unsupervised feature learning",
        "doi": "10.1088/2632-2153/ac579b",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Both the three-body system and the inverse square potential carry a special significance in the study of renormalization group limit cycles. In this work, we pursue an exploratory approach and address the question which two-body interactions lead to limit cycles in the three-body system at low energies, without imposing any restrictions upon the scattering length. For this, we train a boosted ensemble of variational autoencoders, that not only provide a severe dimensionality reduction, but also allow to generate further synthetic potentials, which is an important prerequisite in order to efficiently search for limit cycles in low-dimensional latent space. We do so by applying an elitist genetic algorithm to a population of synthetic potentials that minimizes a specially defined limit-cycle-loss. The resulting fittest individuals suggest that the inverse square potential is the only two-body potential that minimizes this limit cycle loss independent of the hyperangle.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "3D positioning and autofocus of the particle field based on the depth-from-defocus method and the deep networks",
        "doi": "10.1088/2632-2153/acdb2e",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Accurate three-dimensional positioning of particles is a critical task in microscopic particle research, with one of the main challenges being the measurement of particle depths. In this paper, we propose a method for detecting particle depths from their blurred images using the depth-from-defocus technique and a deep neural network-based object detection framework called you-only-look-once. Our method provides simultaneous lateral position information for the particles and has been tested and evaluated on various samples, including synthetic particles, polystyrene particles, blood cells, and plankton, even in a noise-filled environment. We achieved autofocus for target particles in different depths using generative adversarial networks, obtaining clear-focused images. Our algorithm can process a single multi-target image in 0.008 s, allowing real-time application. Our proposed method provides new opportunities for particle field research.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Fast reconstruction of single-shot wide-angle diffraction images through deep learning",
        "doi": "10.1088/2632-2153/abb213",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Single-shot x-ray imaging of short-lived nanostructures such as clusters and nanoparticles near a phase transition or non-crystalizing objects such as large proteins and viruses is currently the most elegant method for characterizing their structure. Using hard x-ray radiation provides scattering images that encode two-dimensional projections, which can be combined to identify the full three-dimensional object structure from multiple identical samples. Wide-angle scattering using XUV or soft x-rays, despite yielding lower resolution, provides three-dimensional structural information in a single shot and has opened routes towards the characterization of non-reproducible objects in the gas phase. The retrieval of the structural information contained in wide-angle scattering images is highly non-trivial, and currently no efficient rigorous algorithm is known. Here we show that deep learning networks, trained with simulated scattering data, allow for fast and accurate reconstruction of shape and orientation of nanoparticles from experimental images. The gain in speed compared to conventional retrieval techniques opens the route for automated structure reconstruction algorithms capable of real-time discrimination and pre-identification of nanostructures in scattering experiments with high repetition rate\u2014thus representing the enabling technology for fast femtosecond nanocrystallography.</jats:p>",
        "is_referenced_by_count": 4
    },
    {
        "title": "Autonomous victim detection system based on deep learning and multispectral imagery",
        "doi": "10.1088/2632-2153/acb6cf",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Post-disaster environments resulting from catastrophic events, leave sequels such as victims trapped in debris, which are difficult to detect by rescuers in a first inspection. Technological advances in electronics and perception have allowed the development of versatile and powerful optical sensors capable of capturing light in spectrums that humans cannot. new deep learning techniques, such as convolutional neural networks (CNNs), has allowed the generation of network models capable of autonomously detecting specific image patterns according to previous training. This work introduces an autonomous victim detection system to be deployed by using search and rescue robots. The proposed system defines new indexes based on combining the multispectral bands (Blue, Green, Red, Nir, Red Edge) to obtain new multispectral images where relevant characteristics of victims and the environment are highlighted. CNNs have been used as a second phase for automatically detecting victims in these new multispectral images. A qualitative and quantitative analysis of new indexes proposed by the authors has been carried out to evaluate their efficiency in contrast to the state-of-the-art ones. A data set has been generated to train different CNN models based on the best obtained index to analyze their effectiveness in detecting victims. The results show an efficiency of 92% in automatically detecting victims when applying the best multispectral index to new data. This method has also been contrasted with others based on thermal and RGB imagery to detect victims, where it has been proven that it generates better results in situations of outdoor environments and different weather conditions.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Learning from survey propagation: a neural network for MAX-E-3-SAT",
        "doi": "10.1088/2632-2153/ac0496",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Many natural optimization problems are NP-hard, which implies that they are probably hard to solve exactly in the worst-case. However, it suffices to get reasonably good solutions for all (or even most) instances in practice. This paper presents a new algorithm for computing approximate solutions in \u0398(<jats:italic>N</jats:italic>) for the maximum exact 3-satisfiability (MAX-E-3-SAT) problem by using supervised learning methodology. This methodology allows us to create a learning algorithm able to fix Boolean variables by using local information obtained by the Survey Propagation algorithm. By performing an accurate analysis, on random conjunctive normal form instances of the MAX-E-3-SAT with several Boolean variables, we show that this new algorithm, avoiding any decimation strategy, can build assignments better than a random one, even if the convergence of the messages is not found. Although this algorithm is not competitive with state-of-the-art maximum satisfiability solvers, it can solve substantially larger and more complicated problems than it ever saw during training.</jats:p>",
        "is_referenced_by_count": 4
    },
    {
        "title": "Establishing an evaluation metric to quantify climate change image realism\n                  <sup>*</sup>",
        "doi": "10.1088/2632-2153/ab7657",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>With success on controlled tasks, deep generative models are being increasingly applied to humanitarian applications (Nie <jats:italic>et al</jats:italic> 2017 <jats:italic>Int. Conf. on Medical Image Computing and Computer-Assisted Intervention</jats:italic> (Berlin: Springer) pp 417\u201325, Yanardag <jats:italic>et al</jats:italic> 2017 <jats:italic>Deep Empathy</jats:italic>). In this paper, we focus on the evaluation of a conditional generative model that illustrates the consequences of climate change-induced flooding to encourage public interest and awareness on the issue. Because metrics for comparing the realism of different modes in a conditional generative model do not exist, we propose several automated and human-based methods for evaluation. To do this, we adapt several existing metrics and assess the automated metrics against gold standard human evaluation. We find that using Fr\u00e9chet Inception Distance with embeddings from an intermediary Inception-v3 layer that precedes the auxiliary classifier produces results most correlated with human realism. While insufficient alone to establish a human-correlated automatic evaluation metric, we believe this work begins to bridge the gap between human and automated generative evaluation procedures, and to generate more realistic images of the future consequences of climate change.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Massively parallel fitting of Gaussian approximation potentials",
        "doi": "10.1088/2632-2153/aca743",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We present a data-parallel software package for fitting Gaussian approximation potentials (GAPs) on multiple nodes using the ScaLAPACK library with MPI and OpenMP. Until now the maximum training set size for GAP models has been limited by the available memory on a single compute node. In our new implementation, descriptor evaluation is carried out in parallel with no communication requirement. The subsequent linear solve required to determine the model coefficients is parallelised with ScaLAPACK. Our approach scales to thousands of cores, lifting the memory limitation and also delivering substantial speedups. This development expands the applicability of the GAP approach to more complex systems as well as opening up opportunities for efficiently embedding GAP model fitting within higher-level workflows such as committee models or hyperparameter optimisation.</jats:p>",
        "is_referenced_by_count": 2
    },
    {
        "title": "Automated real-space lattice extraction for atomic force microscopy images",
        "doi": "10.1088/2632-2153/acb5e0",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Analyzing atomically resolved images is a time-consuming process requiring solid experience and substantial human intervention. In addition, the acquired images contain a large amount of information such as crystal structure, presence and distribution of defects, and formation of domains, which need to be resolved to understand a material\u2019s surface structure. Therefore, machine learning techniques have been applied in scanning probe and electron microscopies during the last years, aiming for automatized and efficient image analysis. This work introduces a free and open source tool (AiSurf: Automated Identification of Surface Images) developed to inspect atomically resolved images via scale-invariant feature transform and clustering algorithms. AiSurf extracts primitive lattice vectors, unit cells, and structural distortions from the original image, with no pre-assumption on the lattice and minimal user intervention. The method is applied to various atomically resolved non-contact atomic force microscopy images of selected surfaces with different levels of complexity: anatase TiO<jats:sub>2</jats:sub>(101), oxygen deficient rutile TiO<jats:sub>2</jats:sub>(110) with and without CO adsorbates, SrTiO<jats:sub>3</jats:sub>(001) with Sr vacancies and graphene with C vacancies. The code delivers excellent results and is tested against atom misclassification and artifacts, thereby facilitating the interpretation of scanning probe microscopy images.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "A bin and hash method for analyzing reference data and descriptors in machine learning potentials",
        "doi": "10.1088/2632-2153/abe663",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>In recent years the development of machine learning potentials (MLPs) has become a very active field of research. Numerous approaches have been proposed, which allow one to perform extended simulations of large systems at a small fraction of the computational costs of electronic structure calculations. The key to the success of modern MLPs is the close-to first principles quality description of the atomic interactions. This accuracy is reached by using very flexible functional forms in combination with high-level reference data from electronic structure calculations. These data sets can include up to hundreds of thousands of structures covering millions of atomic environments to ensure that all relevant features of the potential energy surface are well represented. The handling of such large data sets is nowadays becoming one of the main challenges in the construction of MLPs. In this paper we present a method, the bin-and-hash (BAH) algorithm, to overcome this problem by enabling the efficient identification and comparison of large numbers of multidimensional vectors. Such vectors emerge in multiple contexts in the construction of MLPs. Examples are the comparison of local atomic environments to identify and avoid unnecessary redundant information in the reference data sets that is costly in terms of both the electronic structure calculations as well as the training process, the assessment of the quality of the descriptors used as structural fingerprints in many types of MLPs, and the detection of possibly unreliable data points. The BAH algorithm is illustrated for the example of high-dimensional neural network potentials using atom-centered symmetry functions for the geometrical description of the atomic environments, but the method is general and can be combined with any current type of MLP.</jats:p>",
        "is_referenced_by_count": 2
    },
    {
        "title": "Physics-enhanced neural networks for equation-of-state calculations",
        "doi": "10.1088/2632-2153/ad13b9",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Rapid access to accurate equation-of-state (EOS) data is crucial in the warm-dense matter (WDM) regime, as it is employed in various applications, such as providing input for hydrodynamic codes to model inertial confinement fusion processes. In this study, we develop neural network models for predicting the EOS based on first-principles data. The first model utilises basic physical properties, while the second model incorporates more sophisticated physical information, using output from average-atom (AA) calculations as features. AA models are often noted for providing a reasonable balance of accuracy and speed; however, our comparison of AA models and higher-fidelity calculations shows that more accurate models are required in the WDM regime. Both the neural network models we propose, particularly the physics-enhanced one, demonstrate significant potential as accurate and efficient methods for computing EOS data in WDM.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Training-free hyperparameter optimization of neural networks for electronic structures in matter",
        "doi": "10.1088/2632-2153/ac9956",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>A myriad of phenomena in materials science and chemistry rely on quantum-level simulations of the electronic structure in matter. While moving to larger length and time scales has been a pressing issue for decades, such large-scale electronic structure calculations are still challenging despite modern software approaches and advances in high-performance computing. The silver lining in this regard is the use of machine learning to accelerate electronic structure calculations\u2014this line of research has recently gained growing attention. The grand challenge therein is finding a suitable machine-learning model during a process called hyperparameter optimization. This, however, causes a massive computational overhead in addition to that of data generation. We accelerate the construction of neural network models by roughly two orders of magnitude by circumventing excessive training during the hyperparameter optimization phase. We demonstrate our workflow for Kohn\u2013Sham density functional theory, the most popular computational method in materials science and chemistry.</jats:p>",
        "is_referenced_by_count": 5
    },
    {
        "title": "BenchML: an extensible pipelining framework for benchmarking representations of materials and molecules at scale",
        "doi": "10.1088/2632-2153/ac4d11",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We introduce a machine-learning (ML) framework for high-throughput benchmarking of diverse representations of chemical systems against datasets of materials and molecules. The guiding principle underlying the benchmarking approach is to evaluate raw descriptor performance by limiting model complexity to simple regression schemes while enforcing best ML practices, allowing for unbiased hyperparameter optimization, and assessing learning progress through learning curves along series of synchronized train-test splits. The resulting models are intended as baselines that can inform future method development, in addition to indicating how easily a given dataset can be learnt. Through a comparative analysis of the training outcome across a diverse set of physicochemical, topological and geometric representations, we glean insight into the relative merits of these representations as well as their interrelatedness.</jats:p>",
        "is_referenced_by_count": 2
    },
    {
        "title": "Graph convolutional networks applied to unstructured flow field data",
        "doi": "10.1088/2632-2153/ac1fc9",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Many scientific and engineering processes produce spatially unstructured data. However, most data-driven models require a feature matrix that enforces both a set number and order of features for each sample. They thus cannot be easily constructed for an unstructured dataset. Therefore, a graph based data-driven model to perform inference on fields defined on an unstructured mesh, using a graph convolutional neural network (GCNN) is presented. The ability of the method to predict global properties from spatially irregular measurements with high accuracy is demonstrated by predicting the drag force associated with laminar flow around airfoils from scattered velocity measurements. The network can infer from field samples at different resolutions, and is invariant to the order in which the measurements within each sample are presented. The GCNN method, using inductive convolutional layers and adaptive pooling, is able to predict this quantity with a validation <jats:italic>R</jats:italic>\n                  <jats:sup>2</jats:sup> above 0.98, and a Normalized Mean Squared Error below 0.01, without relying on spatial structure.</jats:p>",
        "is_referenced_by_count": 20
    },
    {
        "title": "Artificial neural network potentials for mechanics and fracture dynamics of two-dimensional crystals\n                  <sup>**</sup>",
        "doi": "10.1088/2632-2153/accd45",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Understanding the mechanics and failure of materials at the nanoscale is critical for their engineering and applications. The accurate atomistic modeling of brittle failure with crack propagation in covalent crystals requires a quantum mechanics-based description of individual bond-breaking events. Artificial neural network potentials (NNPs) have emerged to overcome the traditional, physics-based modeling tradeoff between accuracy and accessible time and length scales. Previous studies have shown successful applications of NNPs for describing the structure and dynamics of molecular systems and amorphous or liquid phases of materials. However, their application to deformation and failure processes in materials is still uncommon. In this study, we discuss the apparent limitations of NNPs for the description of deformation and fracture under loadings and propose a way to generate and select training data for their employment in simulations of deformation and fracture simulations of crystals. We applied the proposed approach to 2D crystalline graphene, utilizing the density-functional tight-binding method for more efficient and extensive data generation in place of density functional theory. Then, we explored how the data selection affects the accuracy of the developed artificial NNPs. It revealed that NNP\u2019s reliability should not only be measured based on the total energy and atomic force comparisons for reference structures but also utilize comparisons for physical properties, e.g. stress\u2013strain curves and geometric deformation. In sharp contrast to popular reactive bond order potentials, our optimized NNP predicts straight crack propagation in graphene along both armchair and zigzag (ZZ) lattice directions, as well as higher fracture toughness of ZZ edge direction. Our study provides significant insight into crack propagation mechanisms on atomic scales and highlights strategies for NNP developments of broader materials.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "A study of transfer learning in digital rock properties measurement",
        "doi": "10.1088/2632-2153/acf117",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>The measurement of physical parameters of porous rock, which constitute reservoirs, is an essential part of hydrocarbon exploration. Typically, the measurement of these physical parameters is carried out through core analysis in a laboratory, which requires considerable time and high costs. Another approach involves using digital rock models, where the physical parameters are calculated through image processing and numerical simulations. However, this method also requires a significant amount of time for estimating the physical parameters of each rock sample. Machine learning, specifically convolutional neural network (CNN) algorithms, has been developed as an alternative method for estimating the physical parameters of porous rock in a shorter time frame. The advancement of CNN, particularly through transfer learning using pre-trained models, has contributed to rapid prediction capabilities. However, not all pre-trained models are suitable for estimating the physical parameters of porous rock. In this study, transfer learning was applied to estimate parameters of sandstones such as porosity, specific surface area, average grain size, average coordination number, and average throat radius. Six types of pre-trained models were utilized: ResNet152, DenseNet201, Xception, InceptionV3, InceptionResNetV2, and MobileNetV2. The results of this study indicate that the DenseNet201 model achieved the best performance with an error rate of 2.11%. Overall, this study highlights the potential of transfer learning to ultimately lead to more efficient and effective computation.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Theoretical characterization of uncertainty in high-dimensional linear classification",
        "doi": "10.1088/2632-2153/acd749",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title><jats:p>Being able to reliably assess not only the<jats:italic>accuracy</jats:italic>but also the<jats:italic>uncertainty</jats:italic>of models\u2019 predictions is an important endeavor in modern machine learning. Even if the model generating the data and labels is known, computing the intrinsic uncertainty after learning the model from a limited number of samples amounts to sampling the corresponding posterior probability measure. Such sampling is computationally challenging in high-dimensional problems and theoretical results on heuristic uncertainty estimators in high-dimensions are thus scarce. In this manuscript, we characterize uncertainty for learning from a limited number of samples of high-dimensional Gaussian input data and labels generated by the probit model. In this setting, the Bayesian uncertainty (i.e. the posterior marginals) can be asymptotically obtained by the approximate message passing algorithm, bypassing the canonical but costly Monte Carlo sampling of the posterior. We then provide a closed-form formula for the joint statistics between the logistic classifier, the uncertainty of the statistically optimal Bayesian classifier and the ground-truth probit uncertainty. The formula allows us to investigate the calibration of the logistic classifier learning from a limited amount of samples. We discuss how over-confidence can be mitigated by appropriately regularizing.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "Polynomial differentiation decreases the training time complexity of physics-informed neural networks and strengthens their approximation power",
        "doi": "10.1088/2632-2153/acf97a",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We present novel approximates of variational losses, being applicable for the training of physics-informed neural networks (PINNs). The formulations reflect classic Sobolev space theory for partial differential equations (PDEs) and their weak formulations. The loss approximates rest on <jats:italic>polynomial differentiation</jats:italic> realised by an extension of classic <jats:italic>Gauss\u2013Legendre cubatures</jats:italic>, we term <jats:italic>Sobolev cubatures</jats:italic>, and serve as a replacement of <jats:italic>automatic differentiation</jats:italic>. We prove the training time complexity of the resulting Sobolev -PINNs with polynomial differentiation to be less than required by PINNs relying on automatic differentiation. On top of one-to-two order of magnitude speed-up the Sobolev-PINNs are demonstrated to achieve closer solution approximations for prominent forward and inverse, linear and non-linear PDE problems compared to established PINNs.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Machine learning to predict the antimicrobial activity of cold atmospheric plasma-activated liquids",
        "doi": "10.1088/2632-2153/acc1c0",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Plasma is defined as the fourth state of matter, and non-thermal plasma can be produced at atmospheric pressure under a high electrical field. The strong and broad-spectrum antimicrobial effect of plasma-activated liquids (PALs) is now well known. The antimicrobial effects of PALs depend on many different variables, which complicates the comparison of different studies and determining the most dominant parameters for the antimicrobial effect. The proven applicability of machine learning (ML) in the medical field is encouraging for its application in the field of plasma medicine as well. Thus, ML applications on PALs could present a new perspective to better understand the influences of various parameters on their antimicrobial effects. In this paper, comparative supervised ML models are presented by using previously obtained data to predict the <jats:italic>in vitro</jats:italic> antimicrobial activity of PALs. A comprehensive literature search was performed, and 12 distinct features related to PAL-microorganism interactions were collected from 33 relevant articles to automatically predict the antimicrobial activity of PALs. After the required normalization, feature encoding, and resampling steps, two supervised ML methods, namely classification and regression, are applied to the data to obtain microbial inactivation (MI) predictions. For classification, MI is labeled in four categories, and for regression, MI is used as a continuous variable. Sixteen different classifiers and 14 regressors are implemented to predict the MI value. Two different robust cross-validation strategies are conducted for classification and regression models to evaluate the proposed method: repeated stratified <jats:italic>k</jats:italic>-fold cross-validation and <jats:italic>k</jats:italic>-fold cross-validation, respectively. We also investigate the effect of different features on models. The results demonstrated that the hyperparameter-optimized Random Forest Classifier (oRFC) and Random Forest Regressor (oRFR) provided superior performance compared to other models for classification and regression. Finally, the best test accuracy of 82.68% for oRFC and <jats:italic>R</jats:italic>\n                  <jats:sup>2</jats:sup> of 0.75 for the oRFR are obtained. Furthermore, the determined most important features of predictive models are in line with the outcomes of PALs reported in the literature. An ML framework can accurately predict the antimicrobial activity of PALs without the need for any experimental studies. To the best of our knowledge, this is the first study that investigates the antimicrobial efficacy of PALs with ML. Furthermore, ML techniques could contribute to a better understanding of plasma parameters that have a dominant role in the desired antimicrobial effect. Moreover, such findings may contribute to the definition of a plasma dose in the future.</jats:p>",
        "is_referenced_by_count": 5
    },
    {
        "title": "Application of autoencoders artificial neural network and principal component analysis for pattern extraction and spatial regionalization of global temperature data",
        "doi": "10.1088/2632-2153/ad1c34",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Spatial regionalization is instrumental in simplifying the spatial complexity of the climate system. To identify regions of significant climate variability, pattern extraction is often required prior to spatial regionalization with a clustering algorithm. In this study, the autoencoder (AE) artificial neural network was applied to extract the inherent patterns of global temperature data (from 1901 to 2021). Subsequently, Fuzzy C-means clustering was applied to the extracted patterns to classify the global temperature regions. Our analysis involved comparing AE-based and principal component analysis (PCA)-based clustering results to assess consistency. We determined the number of clusters by examining the average percentage decrease in Fuzzy Partition Coefficient (FPC) and its 95% confidence interval, seeking a balance between obtaining a high FPC and avoiding over-segmentation. This approach suggested that for a more general model, four clusters is reasonable. The Adjusted Rand Index between the AE-based and PCA-based clusters is 0.75, indicating that the AE-based and PCA-based clusters have considerable overlap. The observed difference between the AE-based clusters and PCA-based clusters is suggested to be associated with AE\u2019s capability to learn and extract complex non-linear patterns, and this attribute, for example, enabled the clustering algorithm to accurately detect the Himalayas region as the \u2018third pole\u2019 with similar temperature characteristics as the polar regions. Finally, when the analysis period is divided into two (1901\u20131960 and 1961\u20132021), the Adjusted Rand Index between the two clusters is 0.96 which suggests that historical climate change has not significantly affected the defined temperature regions over the two periods. In essence, this study indicates both AE\u2019s potential to enhance our understanding of climate variability and reveals the stability of the historical temperature regions.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Data-driven prediction of the performance of enhanced surfaces from an extensive CFD-generated parametric search space",
        "doi": "10.1088/2632-2153/acca60",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Machine learning has rapidly been adopted in virtually all areas of engineering in recent years. This paper develops a machine learning model capable of predicting the performance of parametrically generated enhanced microsurface geometries for cooling electronic and power systems. Designing this type of geometry usually involves expensive computational fluid dynamics (CFD) simulations, limiting the number of candidate geometries that may be tested. For this reason, when searching for new geometries for a given application, designs are usually restricted to a simplified subset of basic shapes to reduce the complexity and dimension of the search space. In an effort to add geometrical diversity and explore singular morphologies, we have developed an algorithm capable of characterizing almost any geometry, based on an extensive CFD database with more than 15\u2009800 geometries obtained from a Monte Carlo sampling of the space of possible geometries. With this framework, it is possible to estimate various quantities of interest, such as the heat flux in the enhanced zone and total drag, with relative errors below 10% and 2%, respectively. Thus, we establish the utility of machine learning to develop surrogate models for the rapid performance prediction of novel enhanced microsurfaces.</jats:p>",
        "is_referenced_by_count": 3
    },
    {
        "title": "Spectral density classification for environment spectroscopy",
        "doi": "10.1088/2632-2153/ad2cf1",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Spectral densities encode the relevant information characterizing the system\u2013environment interaction in an open-quantum system problem. Such information is key to determining the system\u2019s dynamics. In this work, we leverage the potential of machine learning techniques to reconstruct the features of the environment. Specifically, we show that the time evolution of a system observable can be used by an artificial neural network to infer the main features of the spectral density. In particular, for relevant examples of spin-boson models, we can classify with high accuracy the Ohmicity parameter of the environment as either Ohmic, sub-Ohmic or super-Ohmic, thereby distinguishing between different forms of dissipation.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Neural network training with highly incomplete medical datasets",
        "doi": "10.1088/2632-2153/ac7b69",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Neural network training and validation rely on the availability of large high-quality datasets. However, in many cases only incomplete datasets are available, particularly in health care applications, where each patient typically undergoes different clinical procedures or can drop out of a study. Since the data to train the neural networks need to be complete, most studies discard the incomplete datapoints, which reduces the size of the training data, or impute the missing features, which can lead to artifacts. Alas, both approaches are inadequate when a large portion of the data is missing. Here, we introduce GapNet, an alternative deep-learning training approach that can use highly incomplete datasets without overfitting or introducing artefacts. First, the dataset is split into subsets of samples containing all values for a certain cluster of features. Then, these subsets are used to train individual neural networks. Finally, this ensemble of neural networks is combined into a single neural network whose training is fine-tuned using all complete datapoints. Using two highly incomplete real-world medical datasets, we show that GapNet improves the identification of patients with underlying Alzheimer\u2019s disease pathology and of patients at risk of hospitalization due to Covid-19. Compared to commonly used imputation methods, this improvement suggests that GapNet can become a general tool to handle incomplete medical datasets.</jats:p>",
        "is_referenced_by_count": 3
    },
    {
        "title": "A method for quantifying the generalization capabilities of generative models for solving Ising models",
        "doi": "10.1088/2632-2153/ad3710",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>For Ising models with complex energy landscapes, whether the ground state can be found by neural networks depends heavily on the Hamming distance between the training datasets and the ground state. Despite the fact that various recently proposed generative models have shown good performance in solving Ising models, there is no adequate discussion on how to quantify their generalization capabilities. Here we design a Hamming distance regularizer in the framework of a class of generative models, variational autoregressive networks (VANs), to quantify the generalization capabilities of various network architectures combined with VAN. The regularizer can control the size of the overlaps between the ground state and the training datasets generated by networks, which, together with the success rates of finding the ground state, form a quantitative metric to quantify their generalization capabilities. We conduct numerical experiments on several prototypical network architectures combined with VAN, including feed-forward neural networks, recurrent neural networks, and graph neural networks, to quantify their generalization capabilities when solving Ising models. Moreover, considering the fact that the quantification of the generalization capabilities of networks on small-scale problems can be used to predict their relative performance on large-scale problems, our method is of great significance for assisting in the Neural Architecture Search field of searching for the optimal network architectures when solving large-scale Ising models.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Neural networks and quantum field theory",
        "doi": "10.1088/2632-2153/abeca3",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We propose a theoretical understanding of neural networks in terms of Wilsonian effective field theory. The correspondence relies on the fact that many asymptotic neural networks are drawn from Gaussian processes (GPs), the analog of non-interacting field theories. Moving away from the asymptotic limit yields a non-Gaussian process (NGP) and corresponds to turning on particle interactions, allowing for the computation of correlation functions of neural network outputs with Feynman diagrams. Minimal NGP likelihoods are determined by the most relevant non-Gaussian terms, according to the flow in their coefficients induced by the Wilsonian renormalization group. This yields a direct connection between overparameterization and simplicity of neural network likelihoods. Whether the coefficients are constants or functions may be understood in terms of GP limit symmetries, as expected from \u2019t Hooft\u2019s technical naturalness. General theoretical calculations are matched to neural network experiments in the simplest class of models allowing the correspondence. Our formalism is valid for any of the many architectures that becomes a GP in an asymptotic limit, a property preserved under certain types of training.</jats:p>",
        "is_referenced_by_count": 34
    },
    {
        "title": "Towards automated analysis for neutron reflectivity",
        "doi": "10.1088/2632-2153/abe7b5",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We describe a neural network-based tool for the automatic estimation of thin film thicknesses and scattering length densities from neutron reflectivity curves. The neural network sits within a data pipeline, that takes raw data from a neutron reflectometer, and outputs data and parameter estimates into a fitting program for end user analysis. Our tool deals with simple cases, predicting the number of layers and layer parameters up to three layers on a bulk substrate. This provides good accuracy in parameter estimation, while covering a large portion of the use case. By automating steps in data analysis that only require semi-expert knowledge, we lower the barrier to on-experiment data analysis, allowing better utility to be made from large scale facility experiments. Transfer learning showed that our tool works for x-ray reflectivity, and all code is freely available on GitHub (neutron-net 2020, available at: <jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://github.com/xmironov/neutron-net\" xlink:type=\"simple\">https://github.com/xmironov/neutron-net</jats:ext-link>) (Accessed: 25 June 2020).</jats:p>",
        "is_referenced_by_count": 12
    },
    {
        "title": "Estimating the probability of coincidental similarity between atomic displacement parameters with machine learning",
        "doi": "10.1088/2632-2153/ac022d",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>High-resolution diffraction studies of macromolecules incorporate the tensor form of the anisotropic displacement parameter (ADP) of atoms from their mean position. The comparison of these parameters requires a statistical framework that can handle the experimental and modeling errors linked to structure determination. Here, a Bayesian machine learning model is introduced that approximates ADPs with the random Wishart distribution. This model allows for the comparison of random samples from a distribution that is trained on experimental structures. The comparison revealed that the experimental similarity between atoms is larger than predicted by the random model for a substantial fraction of the comparisons. Different metrics between ADPs were evaluated and categorized based on how useful they are at detecting non-accidental similarity and whether they can be replaced by other metrics. The most complementary comparisons were provided by Euclidean, Riemann and Wasserstein metrics. The analysis of ADP similarity and the positional distance of atoms in bovine trypsin revealed a set of atoms with striking ADP similarity over a long physical distance, and generally the physical distance between atoms and their ADP similarity do not correlate strongly. A substantial fraction of long- and short-range ADP similarities does not form by coincidence and are reproducibly observed in different crystal structures of the same protein.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "The role of feature space in atomistic learning",
        "doi": "10.1088/2632-2153/abdaf7",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Efficient, physically-inspired descriptors of the structure and composition of molecules and materials play a key role in the application of machine-learning techniques to atomistic simulations. The proliferation of approaches, as well as the fact that each choice of features can lead to very different behavior depending on how they are used, e.g. by introducing non-linear kernels and non-Euclidean metrics to manipulate them, makes it difficult to objectively compare different methods, and to address fundamental questions on how one feature space is related to another. In this work we introduce a framework to compare different sets of descriptors, and different ways of transforming them by means of metrics and kernels, in terms of the structure of the feature space that they induce. We define diagnostic tools to determine whether alternative feature spaces contain equivalent amounts of information, and whether the common information is substantially distorted when going from one feature space to another. We compare, in particular, representations that are built in terms of <jats:italic>n</jats:italic>-body correlations of the atom density, quantitatively assessing the information loss associated with the use of low-order features. We also investigate the impact of different choices of basis functions and hyperparameters of the widely used SOAP and Behler\u2013Parrinello features, and investigate how the use of non-linear kernels, and of a Wasserstein-type metric, change the structure of the feature space in comparison to a simpler linear feature space.</jats:p>",
        "is_referenced_by_count": 25
    },
    {
        "title": "An assessment of the structural resolution of various fingerprints commonly used in machine learning",
        "doi": "10.1088/2632-2153/abb212",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Atomic environment fingerprints are widely used in computational materials science, from machine learning potentials to the quantification of similarities between atomic configurations. Many approaches to the construction of such fingerprints, also called structural descriptors, have been proposed. In this work, we compare the performance of fingerprints based on the overlap matrix, the smooth overlap of atomic positions, Behler\u2013Parrinello atom-centered symmetry functions, modified Behler\u2013Parrinello symmetry functions used in the ANI-1ccx potential and the Faber\u2013Christensen\u2013Huang\u2013Lilienfeld fingerprint under various aspects. We study their ability to resolve differences in local environments and in particular examine whether there are certain atomic movements that leave the fingerprints exactly or nearly invariant. For this purpose, we introduce a sensitivity matrix whose eigenvalues quantify the effect of atomic displacement modes on the fingerprint. Further, we check whether these displacements correlate with the variation of localized physical quantities such as forces. Finally, we extend our examination to the correlation between molecular fingerprints obtained from the atomic fingerprints and global quantities of entire molecules.</jats:p>",
        "is_referenced_by_count": 36
    },
    {
        "title": "Natural evolutionary strategies for variational quantum computation",
        "doi": "10.1088/2632-2153/abf3ac",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Natural evolutionary strategies (NES) are a family of gradient-free black-box optimization algorithms. This study illustrates their use for the optimization of randomly initialized parameterized quantum circuits (PQCs) in the region of vanishing gradients. We show that using the NES gradient estimator the exponential decrease in variance can be alleviated. We implement two specific approaches, the exponential and separable NES, for parameter optimization of PQCs and compare them against standard gradient descent. We apply them to two different problems of ground state energy estimation using variational quantum eigensolver and state preparation with circuits of varying depth and length. We also introduce batch optimization for circuits with larger depth to extend the use of ES to a larger number of parameters. We achieve accuracy comparable to state-of-the-art optimization techniques in all the above cases with a lower number of circuit evaluations. Our empirical results indicate that one can use NES as a hybrid tool in tandem with other gradient-based methods for optimization of deep quantum circuits in regions with vanishing gradients.</jats:p>",
        "is_referenced_by_count": 15
    },
    {
        "title": "Real-time semantic segmentation on FPGAs for autonomous vehicles with hls4ml",
        "doi": "10.1088/2632-2153/ac9cb5",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title><jats:p>In this paper, we investigate how field programmable gate arrays can serve as hardware accelerators for real-time semantic segmentation tasks relevant for autonomous driving. Considering compressed versions of the ENet convolutional neural network architecture, we demonstrate a fully-on-chip deployment with a latency of 4.9 ms per image, using less than 30% of the available resources on a Xilinx ZCU102 evaluation board. The latency is reduced to 3 ms per image when increasing the batch size to ten, corresponding to the use case where the autonomous vehicle receives inputs from multiple cameras simultaneously. We show, through aggressive filter reduction and heterogeneous quantization-aware training, and an optimized implementation of convolutional layers, that the power consumption and resource utilization can be significantly reduced while maintaining accuracy on the Cityscapes dataset.</jats:p>",
        "is_referenced_by_count": 5
    },
    {
        "title": "Sparse optical flow outliers elimination method based on Borda stochastic neighborhood graph",
        "doi": "10.1088/2632-2153/ad1a50",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>During the tracking of moving targets in dynamic scenes, efficiently handling outliers in the optical flow and maintaining robustness across various motion amplitudes represents a critical challenge. So far, studies have used thresholding and local consistency based approaches to deal with optical outliers. However, there is subjectivity through expert-defined thresholds or delineated regions, and therefore these methods do not perform consistently enough under different target motion amplitudes. Other studies have focused on complex statistical-mathematical modeling which, although theoretically valid, requires significant computational resources. Aiming at the above problems this paper proposes a new method to calculate the optical outliers by using stochastic neighborhood graph combined with the Borda counting method, which reduces the computation amount on the basis of objectively eliminating the outliers. Sparse optical flow (SOF) values are used as the overall population and the outlier and inlier SOF values are used as samples. Analyze the dissimilarity between SOF data points, obtaining the dissimilarity matrix, introducing the Gaussian function to smooth and reduce the dimensionality of the dissimilarity matrix, and then normalizing the smoothing matrix to generate the binding matrix, where the probability sum of each node to other nodes in the matrix is equal to 1. Stochastic neighborhood graphs are then generated based on a binding matrix to obtain the outlier probabilities of data points in different neighborhood graphs, and outlier samples are obtained based on the probability. To avoid the subjectivity of the expert thresholds, the outlier probabilities are weighted and ranked to calculate the data point Borda scores to obtain accurate optical outliers. The experimental results show that the method in this paper is robust to different amplitude motions and real scenarios, and the accuracy, precision and recall of outliers elimination are better than the current mainstream algorithms.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Improving the background of gravitational-wave searches for core collapse supernovae: a machine learning approach",
        "doi": "10.1088/2632-2153/ab527d",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Based on the prior O1\u2013O2 observing runs, about 30% of the data collected by Advanced LIGO and Virgo in the next observing runs are expected to be single-interferometer data, i.e. they will be collected at times when only one detector in the network is operating in observing mode. Searches for gravitational-wave signals from supernova events do not rely on matched filtering techniques because of the stochastic nature of the signals. If a Galactic supernova occurs during single-interferometer times, separation of its unmodelled gravitational-wave signal from noise will be even more difficult due to lack of coherence between detectors. We present a novel machine learning method to perform single-interferometer supernova searches based on the standard LIGO-Virgo coherent WaveBurst pipeline. We show that the method may be used to discriminate Galactic gravitational-wave supernova signals from noise transients, decrease the false alarm rate of the search, and improve the supernova detection reach of the detectors.</jats:p>",
        "is_referenced_by_count": 24
    },
    {
        "title": "The information of attribute uncertainties: what convolutional neural networks can learn about errors in input data",
        "doi": "10.1088/2632-2153/ad0285",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Errors in measurements are key to weighting the value of data, but are often neglected in machine learning (ML). We show how convolutional neural networks (CNNs) are able to learn about the context and patterns of signal and noise, leading to improvements in the performance of classification methods. We construct a model whereby two classes of objects follow an underlying Gaussian distribution, and where the features (the input data) have varying, but known, levels of noise\u2014in other words, each data point has a different error bar. This model mimics the nature of scientific data sets, such as those from astrophysical surveys, where noise arises as a realization of random processes with known underlying distributions. The classification of these objects can then be performed using standard statistical techniques (e.g. least squares minimization), as well as ML techniques. This allows us to take advantage of a maximum likelihood approach to object classification, and to measure the amount by which the ML methods are incorporating the information in the input data uncertainties. We show that, when each data point is subject to different levels of noise (i.e. noises with different distribution functions, which is typically the case in scientific data sets), that information can be learned by the CNNs, raising the ML performance to at least the same level of the least squares method\u2014and sometimes even surpassing it. Furthermore, we show that, with varying noise levels, the confidence of the ML classifiers serves as a proxy for the underlying cumulative distribution function, but only if the information about specific input data uncertainties is provided to the CNNs.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Direct prediction of inelastic neutron scattering spectra from the crystal structure*",
        "doi": "10.1088/2632-2153/acb315",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Inelastic neutron scattering (INS) is a powerful technique to study vibrational dynamics of materials with several unique advantages. However, analysis and interpretation of INS spectra often require advanced modeling that needs specialized computing resources and relevant expertise. This difficulty is compounded by the limited experimental resources available to perform INS measurements. In this work, we develop a machine-learning based predictive framework which is capable of directly predicting both one-dimensional INS spectra and two-dimensional INS spectra with additional momentum resolution. By integrating symmetry-aware neural networks with autoencoders, and using a large scale synthetic INS database, high-dimensional spectral data are compressed into a latent-space representation, and a high-quality spectra prediction is achieved by using only atomic coordinates as input. Our work offers an efficient approach to predict complex multi-dimensional neutron spectra directly from simple input; it allows for improved efficiency in using the limited INS measurement resources, and sheds light on building structure-property relationships in a variety of on-the-fly experimental data analysis scenarios.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "A hybrid quantum regression model for the prediction of molecular atomization energies",
        "doi": "10.1088/2632-2153/abd486",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Quantum machine learning is a relatively new research field that aims to combine the dramatic performance advantage offered by quantum computing and the ability of machine learning algorithms to learn complex distributions of high-dimensional data. The primary focus of this domain is the implementation of classical machine learning algorithms in the quantum mechanical domain and study of the speedup due to quantum parallelism, which could enable the development of novel techniques for solving problems such as quantum phase recognition and quantum error correction optimization. In this paper, we propose a hybrid quantum machine learning pipeline for predicting the atomization energies of various molecules using the nuclear charges and atomic positions of the constituent atoms. Firstly, we will be using a deep convolutional auto-encoder model for the feature extraction of data constructed from the eigenvalues and eigenvector centralities of the pairwise distance matrix calculated from atomic positions and the unrolled upper triangle of each Coulomb matrix calculated from nuclear charges, and we will then be using a quantum regression algorithm such as quantum linear regression, quantum radial basis function neural network and, a quantum neural network for estimating the atomization energy. The hybrid quantum neural network models do not seem to provide any speedup over their classical counterparts. Before implementing a quantum algorithm, we will also be using state-of-the-art classical machine learning and deep learning models such as XGBoost, multilayer perceptron, deep convolutional neural network, and a long short-term memory network to study the correlation between the extracted features and corresponding atomization energies of molecules.</jats:p>",
        "is_referenced_by_count": 6
    },
    {
        "title": "Calibrated uncertainty for molecular property prediction using ensembles of message passing neural networks",
        "doi": "10.1088/2632-2153/ac3eb3",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Data-driven methods based on machine learning have the potential to accelerate computational analysis of atomic structures. In this context, reliable uncertainty estimates are important for assessing confidence in predictions and enabling decision making. However, machine learning models can produce badly calibrated uncertainty estimates and it is therefore crucial to detect and handle uncertainty carefully. In this work we extend a message passing neural network designed specifically for predicting properties of molecules and materials with a calibrated probabilistic predictive distribution. The method presented in this paper differs from previous work by considering both aleatoric and epistemic uncertainty in a unified framework, and by recalibrating the predictive distribution on unseen data. Through computer experiments, we show that our approach results in accurate models for predicting molecular formation energies with well calibrated uncertainty in and out of the training data distribution on two public molecular benchmark datasets, QM9 and PC9. The proposed method provides a general framework for training and evaluating neural network ensemble models that are able to produce accurate predictions of properties of molecules with well calibrated uncertainty estimates.</jats:p>",
        "is_referenced_by_count": 16
    },
    {
        "title": "Development of use-specific high-performance cyber-nanomaterial optical detectors by effective choice of machine learning algorithms",
        "doi": "10.1088/2632-2153/ab8967",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Due to their inherent variabilities, nanomaterials-based sensors are challenging to translate into real-world applications, where reliability and reproducibility are key. Machine learning can be a powerful approach for obtaining reliable inferences from data generated by such sensors. Here, we show that the best choice of ML algorithm in a cyber-nanomaterial detector is largely determined by the specific use-considerations, including accuracy, computational cost, speed, and resilience against drifts and long-term ageing effects. When sufficient data and computing resources are provided, the highest sensing accuracy can be achieved by the k-nearest neighbors (kNNs) and Bayesian inference algorithms, however, these algorithms can be computationally expensive for real-time applications. In contrast, artificial neural networks (ANNs) are computationally expensive to train (off-line), but they provide the fastest result under testing conditions (on-line) while remaining reasonably accurate. When access to data is limited, support vector machines (SVMs) can perform well even with small training sample sizes, while other algorithms show considerable reduction in accuracy if data is scarce, hence, setting a lower limit on the size of required training data. We also show by tracking and modeling the long-term drifts of the detector performance over a one year time-frame, it is possible to dramatically improve the predictive accuracy without any re-calibration. Our research shows for the first time that if the ML algorithm is chosen specific to the use-case, low-cost solution-processed cyber-nanomaterial detectors can be practically implemented under diverse operational requirements, despite their inherent variabilities.</jats:p>",
        "is_referenced_by_count": 9
    },
    {
        "title": "Fast modeling and understanding fluid dynamics systems with encoder\u2013decoder networks",
        "doi": "10.1088/2632-2153/abd1cf",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Is a deep learning model capable of representing systems governed by certain first principle physics laws by only observing the system\u2019s output? In an effort to simulate two-dimensional subsurface fluid dynamics in porous media, we found that an accurate deep-learning-based proxy model can be taught efficiently by a computationally expensive finite-volume-based simulator. We pose the problem as an image-to-image regression, running the simulator with different input parameters to furnish a synthetic training dataset upon which we fit the deep learning models. Since the data is spatiotemporal, we compare the performance of three alternative treatments of time; a convolutional LSTM, an autoencoder network that treats time as a direct input and an echo state network. Adversarial methods are adopted to address the sharp spatial gradient in the fluid dynamics problem. Compared to traditional simulation, the proposed deep learning approach enables much faster forward computation, which allows us to explore more scenarios with a much larger parameter space given the same time. It is shown that the improved forward computation efficiency is particularly valuable in solving inversion problems, where the physics model has unknown parameters to be determined by history matching. By computing the pixel-level attention of the trained model, we quantify the sensitivity of the deep learning model to key physical parameters and hence demonstrate that the inverse problem can be solved with great acceleration. We assess the efficacy of the machine learning surrogate in terms of its training speed and accuracy. The network can be trained within minutes using limited training data and achieve accuracy that scales desirably with the amount of training data supplied.</jats:p>",
        "is_referenced_by_count": 4
    },
    {
        "title": "Spherical convolutions on molecular graphs for protein model quality assessment",
        "doi": "10.1088/2632-2153/abf856",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Processing information on three-dimensional (3D) objects requires methods stable to rigid-body transformations, in particular rotations, of the input data. In image processing tasks, convolutional neural networks achieve this property using rotation-equivariant operations. However, contrary to images, graphs generally have irregular topology. This makes it challenging to define a rotation-equivariant convolution operation on these structures. In this work, we propose spherical graph convolutional network that processes 3D models of proteins represented as molecular graphs. In a protein molecule, individual amino acids have common topological elements. This allows us to unambiguously associate each amino acid with a local coordinate system and construct rotation-equivariant spherical filters that operate on angular information between graph nodes. Within the framework of the protein model quality assessment problem, we demonstrate that the proposed spherical convolution method significantly improves the quality of model assessment compared to the standard message-passing approach. It is also comparable to state-of-the-art methods, as we demonstrate on critical assessment of structure prediction benchmarks. The proposed technique operates only on geometric features of protein 3D models. This makes it universal and applicable to any other geometric-learning task where the graph structure allows constructing local coordinate systems. The method is available at <jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://team.inria.fr/nano-d/software/s-gcn/\" xlink:type=\"simple\">https://team.inria.fr/nano-d/software/s-gcn/</jats:ext-link>.</jats:p>",
        "is_referenced_by_count": 9
    },
    {
        "title": "Importance nested sampling with normalising flows",
        "doi": "10.1088/2632-2153/acd5aa",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We present an improved version of the nested sampling algorithm <jats:monospace>nessai</jats:monospace> in which the core algorithm is modified to use importance weights. In the modified algorithm, samples are drawn from a mixture of normalising flows and the requirement for samples to be independently and identically distributed (i.i.d.) according to the prior is relaxed. Furthermore, it allows for samples to be added in any order, independently of a likelihood constraint, and for the evidence to be updated with batches of samples. We call the modified algorithm <jats:monospace>i-nessai</jats:monospace>. We first validate <jats:monospace>i-nessai</jats:monospace> using analytic likelihoods with known Bayesian evidences and show that the evidence estimates are unbiased in up to 32 dimensions. We compare <jats:monospace>i-nessai</jats:monospace> to standard <jats:monospace>nessai</jats:monospace> for the analytic likelihoods and the Rosenbrock likelihood, the results show that <jats:monospace>i-nessai</jats:monospace> is consistent with <jats:monospace>nessai</jats:monospace> whilst producing more precise evidence estimates. We then test <jats:monospace>i-nessai</jats:monospace> on 64 simulated gravitational-wave signals from binary black hole coalescence and show that it produces unbiased estimates of the parameters. We compare our results to those obtained using standard <jats:monospace>nessai</jats:monospace> and <jats:monospace>dynesty</jats:monospace> and find that <jats:monospace>i-nessai</jats:monospace> requires 2.68 and 13.3 times fewer likelihood evaluations to converge, respectively. We also test <jats:monospace>i-nessai</jats:monospace> of an 80\u2009s simulated binary neutron star signal using a reduced-order-quadrature basis and find that, on average, it converges in 24\u2009min, whilst only requiring <jats:inline-formula>\n                     <jats:tex-math><?CDATA $1.01 \\times 10^{6}$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mn>1.01</mml:mn>\n                        <mml:mo>\u00d7</mml:mo>\n                        <mml:msup>\n                           <mml:mn>10</mml:mn>\n                           <mml:mrow>\n                              <mml:mn>6</mml:mn>\n                           </mml:mrow>\n                        </mml:msup>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstacd5aaieqn1.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> likelihood evaluations compared to <jats:inline-formula>\n                     <jats:tex-math><?CDATA $1.42 \\times 10^{6}$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mn>1.42</mml:mn>\n                        <mml:mo>\u00d7</mml:mo>\n                        <mml:msup>\n                           <mml:mn>10</mml:mn>\n                           <mml:mrow>\n                              <mml:mn>6</mml:mn>\n                           </mml:mrow>\n                        </mml:msup>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstacd5aaieqn2.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> for <jats:monospace>nessai</jats:monospace> and <jats:inline-formula>\n                     <jats:tex-math><?CDATA $4.30 \\times 10^{7}$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mn>4.30</mml:mn>\n                        <mml:mo>\u00d7</mml:mo>\n                        <mml:msup>\n                           <mml:mn>10</mml:mn>\n                           <mml:mrow>\n                              <mml:mn>7</mml:mn>\n                           </mml:mrow>\n                        </mml:msup>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstacd5aaieqn3.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> for <jats:monospace>dynesty</jats:monospace>. These results demonstrate that <jats:monospace>i-nessai</jats:monospace> is consistent with <jats:monospace>nessai</jats:monospace> and <jats:monospace>dynesty</jats:monospace> whilst also being more efficient.</jats:p>",
        "is_referenced_by_count": 5
    },
    {
        "title": "Kernel charge equilibration: efficient and accurate prediction of molecular dipole moments with a machine-learning enhanced electron density model",
        "doi": "10.1088/2632-2153/ac568d",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>State-of-the-art machine learning (ML) interatomic potentials use local representations of atomic environments to ensure linear scaling and size-extensivity. This implies a neglect of long-range interactions, most prominently related to electrostatics. To overcome this limitation, we herein present a ML framework for predicting charge distributions and their interactions termed kernel charge equilibration (kQEq). This model is based on classical charge equilibration (QEq) models expanded with an environment-dependent electronegativity. In contrast to previously reported neural network models with a similar concept, kQEq takes advantage of the linearity of both QEq and Kernel Ridge Regression to obtain a closed-form linear algebra expression for training the models. Furthermore, we avoid the ambiguity of charge partitioning schemes by using dipole moments as reference data. As a first application, we show that kQEq can be used to generate accurate and highly data-efficient models for molecular dipole moments.</jats:p>",
        "is_referenced_by_count": 15
    },
    {
        "title": "Deep learning of chaos classification",
        "doi": "10.1088/2632-2153/abb6d3",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We train an artificial neural network which distinguishes chaotic and regular dynamics of the two-dimensional Chirikov standard map. We use finite length trajectories and compare the performance with traditional numerical methods which need to evaluate the Lyapunov exponent (LE). The neural network has superior performance for short periods with length down to 10 Lyapunov times on which the traditional LE computation is far from converging. We show the robustness of the neural network to varying control parameters, in particular we train with one set of control parameters, and successfully test in a complementary set. Furthermore, we use the neural network to successfully test the dynamics of discrete maps in different dimensions, e.g. the one-dimensional logistic map and a three-dimensional discrete version of the Lorenz system. Our results demonstrate that a convolutional neural network can be used as an excellent chaos indicator.</jats:p>",
        "is_referenced_by_count": 11
    },
    {
        "title": "Robust errant beam prognostics with conditional modeling for particle accelerators",
        "doi": "10.1088/2632-2153/ad2e18",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Particle accelerators are complex and comprise thousands of components, with many pieces of equipment running at their peak power. Consequently, they can fault and abort operations for numerous reasons, lowering efficiency and science output. To avoid these faults, we apply anomaly detection techniques to predict unusual behavior and perform preemptive actions to improve the total availability. Supervised machine learning (ML) techniques such as siamese neural network models can outperform the often-used unsupervised or semi-supervised approaches for anomaly detection by leveraging the label information. One of the challenges specific to anomaly detection for particle accelerators is the data\u2019s variability due to accelerator configuration changes within a production run of several months. ML models fail at providing accurate predictions when data changes due to changes in the configuration. To address this challenge, we include the configuration settings into our models and training to improve the results. Beam configurations are used as a conditional input for the model to learn any cross-correlation between the data from different conditions and retain its performance. We employ conditional siamese neural network (CSNN) models and conditional variational auto encoder (CVAE) models to predict errant beam pulses at the spallation neutron source under different system configurations and compare their performance. We demonstrate that CSNNs outperform CVAEs in our application.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Online meta-learned gradient norms for active learning in science and technology",
        "doi": "10.1088/2632-2153/ad2e17",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Acquisition of scientific data can be expensive and time-consuming. Active learning is a solution to reduce costs and time by guiding the selection of scientific experiments. Autonomous and automatic identification of the most essential samples to annotate by active learning can also help to mitigate human bias. Previous research has demonstrated that unlabelled samples causing the largest gradient norms of neural network models can promote active learning in classification. However, gradient norm estimation in regression is non-trivial because the continuous one-dimensional output of regression significantly differs from classification. In this study, we propose a new active learning method that uses meta-learning to estimate the gradient norm of the unlabelled sample in regression. Specifically, we use a separate model to be a selector that learns knowledge from the previous active learning results and is used to predict the gradient norms of unlabelled samples. In each active learning iteration, we estimate and select unlabelled samples with the largest gradient norms to annotate. Our method is evaluated on six regression data sets in various domains, which include costly scientific data.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "WATUNet: a deep neural network for segmentation of volumetric sweep imaging ultrasound",
        "doi": "10.1088/2632-2153/ad2e15",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Limited access to breast cancer diagnosis globally leads to delayed treatment. Ultrasound, an effective yet underutilized method, requires specialized training for sonographers, which hinders its widespread use. Volume sweep imaging (VSI) is an innovative approach that enables untrained operators to capture high-quality ultrasound images. Combined with deep learning, like convolutional neural networks, it can potentially transform breast cancer diagnosis, enhancing accuracy, saving time and costs, and improving patient outcomes. The widely used UNet architecture, known for medical image segmentation, has limitations, such as vanishing gradients and a lack of multi-scale feature extraction and selective region attention. In this study, we present a novel segmentation model known as Wavelet_Attention_UNet (WATUNet). In this model, we incorporate wavelet gates and attention gates between the encoder and decoder instead of a simple connection to overcome the limitations mentioned, thereby improving model performance. Two datasets are utilized for the analysis: the public \u2018Breast Ultrasound Images\u2019 dataset of 780 images and a private VSI dataset of 3818 images, captured at the University of Rochester by the authors. Both datasets contained segmented lesions categorized into three types: no mass, benign mass, and malignant mass. Our segmentation results show superior performance compared to other deep networks. The proposed algorithm attained a Dice coefficient of 0.94 and an F1 score of 0.94 on the VSI dataset and scored 0.93 and 0.94 on the public dataset, respectively. Moreover, our model significantly outperformed other models in McNemar\u2019s test with false discovery rate correction on a 381-image VSI set. The experimental findings demonstrate that the proposed WATUNet model achieves precise segmentation of breast lesions in both standard-of-care and VSI images, surpassing state-of-the-art models. Hence, the model holds considerable promise for assisting in lesion identification, an essential step in the clinical diagnosis of breast lesions.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Coherent optical communications enhanced by machine intelligence",
        "doi": "10.1088/2632-2153/ab9c3d",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Accuracy in discriminating between different received coherent signals is integral to the operation of many free-space communications protocols, and is often difficult when the receiver measures a weak signal. Here we design an optical communication scheme that uses balanced homodyne detection in combination with an unsupervised generative machine learning and convolutional neural network (CNN) system, and demonstrate its efficacy in a realistic simulated coherent quadrature phase shift keyed (QPSK) communications system. Additionally, we design the neural network system such that it autonomously learns to correct for the noise associated with a weak QPSK signal, which is distributed to the receiver prior to the implementation of the communications. We find that the scheme significantly reduces the overall error probability of the communications system, achieving the classical optimal limit. We anticipate that these results will allow for a significant enhancement of current classical and quantum coherent optical communications technologies.</jats:p>",
        "is_referenced_by_count": 5
    },
    {
        "title": "End-to-end AI framework for interpretable prediction of molecular and crystal properties",
        "doi": "10.1088/2632-2153/acd434",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We introduce an end-to-end computational framework that allows for hyperparameter optimization using the <jats:monospace>DeepHyper</jats:monospace> library, accelerated model training, and interpretable AI inference. The framework is based on state-of-the-art AI models including <jats:monospace>CGCNN</jats:monospace>, <jats:monospace>PhysNet</jats:monospace>, <jats:monospace>SchNet</jats:monospace>, <jats:monospace>MPNN</jats:monospace>, <jats:monospace>MPNN-transformer</jats:monospace>, and <jats:monospace>TorchMD-NET</jats:monospace>. We employ these AI models along with the benchmark <jats:monospace>QM9</jats:monospace>, <jats:monospace>hMOF</jats:monospace>, and <jats:monospace>MD17</jats:monospace> datasets to showcase how the models can predict user-specified material properties within modern computing environments. We demonstrate transferable applications in the modeling of small molecules, inorganic crystals and nanoporous metal organic frameworks with a unified, standalone framework. We have deployed and tested this framework in the ThetaGPU supercomputer at the Argonne Leadership Computing Facility, and in the Delta supercomputer at the National Center for Supercomputing Applications to provide researchers with modern tools to conduct accelerated AI-driven discovery in leadership-class computing environments. We release these digital assets as open source scientific software in GitLab, and ready-to-use Jupyter notebooks in Google Colab.</jats:p>",
        "is_referenced_by_count": 2
    },
    {
        "title": "Evidence Networks: simple losses for fast, amortized, neural Bayesian model comparison",
        "doi": "10.1088/2632-2153/ad1a4d",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Evidence Networks can enable Bayesian model comparison when state-of-the-art methods (e.g. nested sampling) fail and even when likelihoods or priors are intractable or unknown. Bayesian model comparison, i.e. the computation of Bayes factors or evidence ratios, can be cast as an optimization problem. Though the Bayesian interpretation of optimal classification is well-known, here we change perspective and present classes of loss functions that result in fast, amortized neural estimators that directly estimate convenient functions of the Bayes factor. This mitigates numerical inaccuracies associated with estimating individual model probabilities. We introduce the leaky parity-odd power (l-POP) transform, leading to the novel \u2018l-POP-Exponential\u2019 loss function. We explore neural density estimation for data probability in different models, showing it to be less accurate and scalable than Evidence Networks. Multiple real-world and synthetic examples illustrate that Evidence Networks are explicitly independent of dimensionality of the parameter space and scale mildly with the complexity of the posterior probability density function. This simple yet powerful approach has broad implications for model inference tasks. As an application of Evidence Networks to real-world data we compute the Bayes factor for two models with gravitational lensing data of the Dark Energy Survey. We briefly discuss applications of our methods to other, related problems of model comparison and evaluation in implicit inference settings.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "Developing novel machine-learning-based fire weather indices",
        "doi": "10.1088/2632-2153/acc008",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Accurate wildfire risk estimation is an essential yet challenging task. As the frequency of extreme fire weather and wildfires is on the rise, forest managers and firefighters require accurate wildfire risk estimations to successfully implement forest management and firefighting strategies. Wildfire risk depends on non-linear interactions between multiple factors; therefore, the performance of linear models in its estimation is limited. To date, several traditional fire weather indices (FWIs) have been commonly used by weather services, such as the Canadian FWI.@Traditional FWIs are primarily based on empirical and statistical analyses. In this paper, we propose a novel FWI that was developed using machine learning\u2014the machine learning based fire weather index (MLFWI). We present the performance of the MLFWI and compare it with various traditional FWIs. We find that the MLFWI significantly outperforms traditional indices in predicting wildfire occurrence, achieving an area under the curve score of 0.99 compared to 0.62\u20130.80. We recommend applying the MLFWI in wildfire warning systems.</jats:p>",
        "is_referenced_by_count": 3
    },
    {
        "title": "Robust simulation-based inference in cosmology with Bayesian neural networks",
        "doi": "10.1088/2632-2153/acbb53",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Simulation-based inference (SBI) is rapidly establishing itself as a standard machine learning technique for analyzing data in cosmological surveys. Despite continual improvements to the quality of density estimation by learned models, applications of such techniques to real data are entirely reliant on the generalization power of neural networks far outside the training distribution, which is mostly unconstrained. Due to the imperfections in scientist-created simulations, and the large computational expense of generating all possible parameter combinations, SBI methods in cosmology are vulnerable to such generalization issues. Here, we discuss the effects of both issues, and show how using a Bayesian neural network framework for training SBI can mitigate biases, and result in more reliable inference outside the training set. We introduce <jats:monospace>cosmoSWAG</jats:monospace>, the first application of stochastic weight averaging to cosmology, and apply it to SBI trained for inference on the cosmic microwave background.</jats:p>",
        "is_referenced_by_count": 5
    },
    {
        "title": "Comparison of neural network architectures for feature extraction from binary black hole merger waveforms",
        "doi": "10.1088/2632-2153/ad2972",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We evaluate several neural-network architectures, both convolutional and recurrent, for gravitational-wave time-series feature extraction by performing point parameter estimation on noisy waveforms from binary-black-hole mergers. We build datasets of 100\u2009000 elements for each of four different waveform models (or approximants) in order to test how approximant choice affects feature extraction. Our choices include <jats:monospace>SEOBNRv4P</jats:monospace> and <jats:monospace>IMRPhenomPv3</jats:monospace>, which contain only the dominant quadrupole emission mode, alongside <jats:monospace>IMRPhenomPv3HM</jats:monospace> and <jats:monospace>NRHybSur3dq8</jats:monospace>, which also account for high-order modes. Each dataset element is injected into detector noise corresponding to the third observing run of the LIGO-Virgo-KAGRA (LVK) collaboration. We identify the temporal convolutional network architecture as the overall best performer in terms of training and validation losses and absence of overfitting to data. Comparison of results between datasets shows that the choice of waveform approximant for the creation of a dataset conditions the feature extraction ability of a trained network. Hence, care should be taken when building a dataset for the training of neural networks, as certain approximants may result in better network convergence of evaluation metrics. However, this performance does not necessarily translate to data which is more faithful to numerical relativity simulations. We also apply this network on actual signals from LVK runs, finding that its feature-extracting performance can be effective on real data.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Extending the relative seriality formalism for interpretable deep learning of normal tissue complication probability models",
        "doi": "10.1088/2632-2153/ac6932",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We formally demonstrate that the relative seriality (RS) model of normal tissue complication probability (NTCP) can be recast as a simple neural network with one convolutional and one pooling layer. This approach enables us to systematically construct deep relative seriality networks (DRSNs), a new class of mechanistic generalizations of the RS model with radiobiologically interpretable parameters amenable to deep learning. To demonstrate the utility of this formulation, we analyze a simplified example of xerostomia due to irradiation of the parotid gland during alpha radiopharmaceutical therapy. Using a combination of analytical calculations and numerical simulations, we show for both the RS and DRSN cases that the ability of the neural network to generalize without overfitting is tied to \u2018stiff\u2019 and \u2018sloppy\u2019 directions in the parameter space of the mechanistic model. These results serve as proof-of-concept for radiobiologically interpretable deep learning of NTCP, while simultaneously yielding insight into how such techniques can robustly generalize beyond the training set despite uncertainty in individual parameters.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "FINETUNA: fine-tuning accelerated molecular simulations",
        "doi": "10.1088/2632-2153/ac8fe0",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Progress towards the energy breakthroughs needed to combat climate change can be significantly accelerated through the efficient simulation of atomistic systems. However, simulation techniques based on first principles, such as density functional theory (DFT), are limited in their practical use due to their high computational expense. Machine learning approaches have the potential to approximate DFT in a computationally efficient manner, which could dramatically increase the impact of computational simulations on real-world problems. However, they are limited by their accuracy and the cost of generating labeled data. Here, we present an online active learning framework for accelerating the simulation of atomic systems efficiently and accurately by incorporating prior physical information learned by large-scale pre-trained graph neural network models from the Open Catalyst Project. Accelerating these simulations enables useful data to be generated more cheaply, allowing better models to be trained and more atomistic systems to be screened. We also present a method of comparing local optimization techniques on the basis of both their speed and accuracy. Experiments on 30 benchmark adsorbate-catalyst systems show that our method of transfer learning to incorporate prior information from pre-trained models accelerates simulations by reducing the number of DFT calculations by 91%, while meeting an accuracy threshold of 0.02\u2009eV 93% of the time. Finally, we demonstrate a technique for leveraging the interactive functionality built in to Vienna <jats:italic>ab initio</jats:italic> Simulation Package (VASP) to efficiently compute single point calculations within our online active learning framework without the significant startup costs. This allows VASP to work in tandem with our framework while requiring 75% fewer self-consistent cycles than conventional single point calculations. The online active learning implementation, and examples using the VASP interactive code, are available in the open source <jats:italic>FINETUNA</jats:italic> package on Github.</jats:p>",
        "is_referenced_by_count": 13
    },
    {
        "title": "Learning to unknot",
        "doi": "10.1088/2632-2153/abe91f",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We introduce natural language processing into the study of knot theory, as made natural by the braid word representation of knots. We study the UNKNOT problem of determining whether or not a given knot is the unknot. After describing an algorithm to randomly generate <jats:italic>N</jats:italic>-crossing braids and their knot closures and discussing the induced prior on the distribution of knots, we apply binary classification to the UNKNOT decision problem. We find that the Reformer and shared-QK Transformer network architectures outperform fully-connected networks, though all perform at <jats:inline-formula>\n                     <jats:tex-math><?CDATA $\\gtrsim$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mo>\u2273</mml:mo>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstabe91fieqn1.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>95% accuracy. Perhaps surprisingly, we find that accuracy increases with the length of the braid word, and that the networks learn a direct correlation between the confidence of their predictions and the degree of the Jones polynomial. Finally, we utilize reinforcement learning (RL) to find sequences of Markov moves and braid relations that simplify knots and can identify unknots by explicitly giving the sequence of unknotting actions. Trust region policy optimization (TRPO) performs consistently well, reducing <jats:inline-formula>\n                     <jats:tex-math><?CDATA $\\gtrsim$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mo>\u2273</mml:mo>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstabe91fieqn2.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula>80% of the unknots with up to 96 crossings we tested to the empty braid word, and thoroughly outperformed other RL algorithms and random walkers. Studying these actions, we find that braid relations are more useful in simplifying to the unknot than one of the Markov moves.</jats:p>",
        "is_referenced_by_count": 19
    },
    {
        "title": "Machine learning the computational cost of quantum chemistry",
        "doi": "10.1088/2632-2153/ab6ac4",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Computational quantum mechanics based molecular and materials design campaigns consume increasingly more high-performance computer resources, making improved job scheduling efficiency desirable in order to reduce carbon footprint or wasteful spending. We introduce quantum machine learning (QML) models of the computational cost of common quantum chemistry tasks. For 2D nonlinear toy systems, single point, geometry optimization, and transition state calculations the out of sample prediction error of QML models of wall times decays systematically with training set size. We present numerical evidence for a toy system containing two functions and three commonly used optimizer and for thousands of organic molecular systems including closed and open shell equilibrium structures, as well as transition states. Levels of electronic structure theory considered include B3LYP/def2-TZVP, MP2/6-311G(d), local CCSD(T)/VTZ-F12, CASSCF/VDZ-F12, and MRCISD+Q-F12/VDZ-F12. In comparison to conventional indiscriminate job treatment, QML based wall time predictions significantly improve job scheduling efficiency for all tasks after training on just thousands of molecules. Resulting reductions in CPU time overhead range from 10% to 90%.</jats:p>",
        "is_referenced_by_count": 25
    },
    {
        "title": "Fractional deep neural network via constrained optimization",
        "doi": "10.1088/2632-2153/aba8e7",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>This paper introduces a novel algorithmic framework for a deep neural network (DNN), which in a mathematically rigorous manner, allows us to incorporate history (or memory) into the network\u2014it ensures all layers are connected to one another. This DNN, called Fractional-DNN, can be viewed as a time-discretization of a fractional in time non-linear ordinary differential equation (ODE). The learning problem then is a minimization problem subject to that fractional ODE as constraints. We emphasize that an analogy between the existing DNN and ODEs, with standard time derivative, is well-known by now. The focus of our work is the Fractional-DNN. Using the Lagrangian approach, we provide a derivation of the backward propagation and the design equations. We test our network on several datasets for classification problems. Fractional-DNN offers various advantages over the existing DNN. The key benefits are a significant improvement to the vanishing gradient issue due to the memory effect, and better handling of nonsmooth data due to the network\u2019s ability to approximate non-smooth functions.</jats:p>",
        "is_referenced_by_count": 5
    },
    {
        "title": "Recipes for when physics fails: recovering robust learning of physics informed neural networks",
        "doi": "10.1088/2632-2153/acb416",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Physics-informed neural networks (PINNs) have been shown to be effective in solving partial differential equations by capturing the physics induced constraints as a part of the training loss function. This paper shows that a PINN can be sensitive to errors in training data and overfit itself in dynamically propagating these errors over the domain of the solution of the PDE. It also shows how physical regularizations based on continuity criteria and conservation laws fail to address this issue and rather introduce problems of their own causing the deep network to converge to a physics-obeying local minimum instead of the global minimum. We introduce Gaussian process (GP) based smoothing that recovers the performance of a PINN and promises a robust architecture against noise/errors in measurements. Additionally, we illustrate an inexpensive method of quantifying the evolution of uncertainty based on the variance estimation of GPs on boundary data. Robust PINN performance is also shown to be achievable by choice of sparse sets of inducing points based on sparsely induced GPs. We demonstrate the performance of our proposed methods and compare the results from existing benchmark models in literature for time-dependent Schr\u00f6dinger and Burgers\u2019 equations.</jats:p>",
        "is_referenced_by_count": 4
    },
    {
        "title": "Noise-aware physics-informed machine learning for robust PDE discovery",
        "doi": "10.1088/2632-2153/acb1f0",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>This work is concerned with discovering the governing partial differential equation (PDE) of a physical system. Existing methods have demonstrated the PDE identification from finite observations but failed to maintain satisfying results against noisy data, partly owing to suboptimal estimated derivatives and found PDE coefficients. We address the issues by introducing a noise-aware physics-informed machine learning framework to discover the governing PDE from data following arbitrary distributions. We propose training a couple of neural networks, namely solver and preselector, in a multi-task learning paradigm, which yields important scores of basis candidates that constitute the hidden physical constraint. After they are jointly trained, the solver network estimates potential candidates, e.g. partial derivatives, for the sparse regression to initially unveil the most likely parsimonious PDE, decided according to information criterion. Denoising physics-informed neural networks, based on discrete Fourier transform, is proposed to deliver the optimal PDE coefficients respecting the noise-reduced variables. Extensive experiments on five canonical PDEs affirm that the proposed framework presents a robust and interpretable approach for PDE discovery, leading to a new automatic PDE selection algorithm established on minimization of the information criterion decay rate.</jats:p>",
        "is_referenced_by_count": 4
    },
    {
        "title": "PyXtal_FF: a python library for automated force field generation",
        "doi": "10.1088/2632-2153/abc940",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We present PyXtal_FF\u2014a package based on Python programming language\u2014for developing machine learning potentials (MLPs). The aim of PyXtal_FF is to promote the application of atomistic simulations through providing several choices of atom-centered descriptors and machine learning regressions in one platform. Based on the given choice of descriptors (including the atom-centered symmetry functions, embedded atom density, SO4 bispectrum, and smooth SO3 power spectrum), PyXtal_FF can train MLPs with either generalized linear regression or neural network models, by simultaneously minimizing the errors of energy/forces/stress tensors in comparison with the data from <jats:italic>ab-initio</jats:italic> simulations. The trained MLP model from PyXtal_FF is interfaced with the Atomic Simulation Environment (ASE) package, which allows different types of light-weight simulations such as geometry optimization, molecular dynamics simulation, and physical properties prediction. Finally, we will illustrate the performance of PyXtal_FF by applying it to investigate several material systems, including the bulk SiO<jats:sub>2</jats:sub>, high entropy alloy NbMoTaW, and elemental Pt for general purposes. Full documentation of PyXtal_FF is available at <jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://pyxtal-ff.readthedocs.io \" xlink:type=\"simple\">https://pyxtal-ff.readthedocs.io</jats:ext-link>.</jats:p>",
        "is_referenced_by_count": 18
    },
    {
        "title": "Solving quantum statistical mechanics with variational autoregressive networks and quantum circuits",
        "doi": "10.1088/2632-2153/aba19d",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We extend the ability of an unitary quantum circuit by interfacing it with a classical autoregressive neural network. The combined model parametrizes a variational density matrix as a classical mixture of quantum pure states, where the autoregressive network generates bitstring samples as input states to the quantum circuit. We devise an efficient variational algorithm to jointly optimize the classical neural network and the quantum circuit to solve quantum statistical mechanics problems. One can obtain thermal observables such as the variational free energy, entropy, and specific heat. As a byproduct, the algorithm also gives access to low energy excitation states. We demonstrate applications of the approach to thermal properties and excitation spectra of the quantum Ising model with resources that are feasible on near-term quantum computers.</jats:p>",
        "is_referenced_by_count": 25
    },
    {
        "title": "Quantum machine learning of large datasets using randomized measurements",
        "doi": "10.1088/2632-2153/acb0b4",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Quantum computers promise to enhance machine learning for practical applications. Quantum machine learning for real-world data has to handle extensive amounts of high-dimensional data. However, conventional methods for measuring quantum kernels are impractical for large datasets as they scale with the square of the dataset size. Here, we measure quantum kernels using randomized measurements. The quantum computation time scales linearly with dataset size and quadratic for classical post-processing. While our method scales in general exponentially in qubit number, we gain a substantial speed-up when running on intermediate-sized quantum computers. Further, we efficiently encode high-dimensional data into quantum computers with the number of features scaling linearly with the circuit depth. The encoding is characterized by the quantum Fisher information metric and is related to the radial basis function kernel. Our approach is robust to noise via a cost-free error mitigation scheme. We demonstrate the advantages of our methods for noisy quantum computers by classifying images with the IBM quantum computer. To achieve further speedups we distribute the quantum computational tasks between different quantum computers. Our method enables benchmarking of quantum machine learning algorithms with large datasets on currently available quantum computers.</jats:p>",
        "is_referenced_by_count": 12
    },
    {
        "title": "Inverting the Kohn\u2013Sham equations with physics-informed machine learning",
        "doi": "10.1088/2632-2153/ad3159",
        "year": 2024,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Electronic structure theory calculations offer an understanding of matter at the quantum level, complementing experimental studies in materials science and chemistry. One of the most widely used methods, density functional theory, maps a set of real interacting electrons to a set of fictitious non-interacting electrons that share the same probability density. Ensuring that the density remains the same depends on the exchange-correlation (XC) energy and, by a derivative, the XC potential. Inversions provide a method to obtain exact XC potentials from target electronic densities, in hopes of gaining insights into accuracy-boosting approximations. Neural networks provide a new avenue to perform inversions by learning the mapping from density to potential. In this work, we learn this mapping using physics-informed machine learning methods, namely physics informed neural networks and Fourier neural operators. We demonstrate the capabilities of these two methods on a dataset of one-dimensional atomic and molecular models. The capabilities of each approach are discussed in conjunction with this proof-of-concept presentation. The primary finding of our investigation is that the combination of both approaches has the greatest potential for inverting the Kohn\u2013Sham equations at scale.</jats:p>",
        "is_referenced_by_count": 0
    },
    {
        "title": "Physics-informed neural networks for solving forward and inverse Vlasov\u2013Poisson equation via fully kinetic simulation",
        "doi": "10.1088/2632-2153/ad03d5",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>The Vlasov\u2013Poisson equation is one of the most fundamental models in plasma physics. It has been widely used in areas such as confined plasmas in thermonuclear research and space plasmas in planetary magnetospheres. In this study, we explore the feasibility of the physics-informed neural networks for solving forward and inverse Vlasov\u2013Poisson equation (PINN-Vlasov). The PINN-Vlasov method employs a multilayer perceptron (MLP) to represent the solution of the Vlasov\u2013Poisson equation. The training dataset comprises the randomly sampled time, space, and velocity coordinates and the corresponding distribution function. We generate training data using the fully kinetic PIC simulation rather than the analytical solution to the Vlasov\u2013Poisson equation to eliminate the correlation between data and equations. The Vlasov equation and Poisson equation are concurrently integrated into the PINN-Vlasov framework using automatic differentiation and the trapezoidal rule, respectively. By minimizing the residuals between the reconstructed distribution function and labeled data, and the physically constrained residuals of the Vlasov\u2013Poisson equation, the PINN-Vlasov method is capable of dealing with both forward and inverse problems. For forward problems, the PINN-Vlasov method can solve the Vlasov\u2013Poisson equation with given initial and boundary conditions. For inverse problems, the completely unknown electric field and equation coefficients can be predicted with the PINN-Vlasov method using little particle distribution data.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "A differentiable programming method for quantum control",
        "doi": "10.1088/2632-2153/ab9802",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Optimal control is highly desirable in many current quantum systems, especially to realize tasks in quantum information processing. We introduce a method based on differentiable programming to leverage explicit knowledge of the differential equations governing the dynamics of the system. In particular, a control agent is represented as a neural network that maps the state of the system at a given time to a control pulse. The parameters of this agent are optimized via gradient information obtained by direct differentiation through both the neural network <jats:italic>and</jats:italic> the differential equation of the system. This fully differentiable reinforcement learning approach ultimately yields time-dependent control parameters optimizing a desired figure of merit. We demonstrate the method\u2019s viability and robustness to noise in eigenstate preparation tasks for three systems: a single qubit, a chain of qubits, and a quantum parametric oscillator.</jats:p>",
        "is_referenced_by_count": 31
    },
    {
        "title": "RG-Flow: a hierarchical and explainable flow model based on renormalization group and sparse prior",
        "doi": "10.1088/2632-2153/ac8393",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Flow-based generative models have become an important class of unsupervised learning approaches. In this work, we incorporate the key ideas of renormalization group (RG) and sparse prior distribution to design a hierarchical flow-based generative model, RG-Flow, which can separate information at different scales of images and extract disentangled representations at each scale. We demonstrate our method on synthetic multi-scale image datasets and the CelebA dataset, showing that the disentangled representations enable semantic manipulation and style mixing of the images at different scales. To visualize the latent representations, we introduce receptive fields for flow-based models and show that the receptive fields of RG-Flow are similar to those of convolutional neural networks. In addition, we replace the widely adopted isotropic Gaussian prior distribution by the sparse Laplacian distribution to further enhance the disentanglement of representations. From a theoretical perspective, our proposed method has <jats:inline-formula>\n                     <jats:tex-math><?CDATA $O(\\log L)$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mrow>\n                           <mml:mi>O</mml:mi>\n                           <mml:mo stretchy=\"false\">(</mml:mo>\n                           <mml:mi>log</mml:mi>\n                           <mml:mi>L</mml:mi>\n                           <mml:mo stretchy=\"false\">)</mml:mo>\n                        </mml:mrow>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstac8393ieqn1.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> complexity for inpainting of an image with edge length <jats:italic>L</jats:italic>, compared to previous generative models with <jats:inline-formula>\n                     <jats:tex-math><?CDATA $O(L^2)$?></jats:tex-math>\n                     <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" overflow=\"scroll\">\n                        <mml:mi>O</mml:mi>\n                        <mml:mo stretchy=\"false\">(</mml:mo>\n                        <mml:msup>\n                           <mml:mi>L</mml:mi>\n                           <mml:mn>2</mml:mn>\n                        </mml:msup>\n                        <mml:mo stretchy=\"false\">)</mml:mo>\n                     </mml:math>\n                     <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"mlstac8393ieqn2.gif\" xlink:type=\"simple\" />\n                  </jats:inline-formula> complexity.</jats:p>",
        "is_referenced_by_count": 5
    },
    {
        "title": "An end-to-end trainable hybrid classical-quantum classifier",
        "doi": "10.1088/2632-2153/ac104d",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We introduce a hybrid model combining a quantum-inspired tensor network and a variational quantum circuit to perform supervised learning tasks. This architecture allows for the classical and quantum parts of the model to be trained simultaneously, providing an end-to-end training framework. We show that compared to the principal component analysis, a tensor network based on the matrix product state with low bond dimensions performs better as a feature extractor for the input data of the variational quantum circuit in the binary and ternary classification of MNIST and Fashion-MNIST datasets. The architecture is highly adaptable and the classical-quantum boundary can be adjusted according to the availability of the quantum resource by exploiting the correspondence between tensor networks and quantum circuits.</jats:p>",
        "is_referenced_by_count": 20
    },
    {
        "title": "Introducing Machine Learning: Science and Technology",
        "doi": "10.1088/2632-2153/ab6d5d",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Due to the remarkable progress of ever-growing digitalisation and computing capabilities, data has become increasingly abundant, and machine learning has emerged as a key ingredient in many enabling technologies within modern society. Its potential for pushing the frontiers of science is now also clear and has been demonstrated in various domains extending from novel materials design, quantum physics and the simulation of molecules and chemical systems, to particle physics, medical imaging, space science, climate science and drug discovery. Conceived in close consultation with the community, <jats:italic>Machine Learning: Science and Technology</jats:italic> has been launched as a unique multidisciplinary, open access journal that will bridge the application of machine learning across the natural sciences with new conceptual advances in machine learning methods as motivated by physical insights.</jats:p>",
        "is_referenced_by_count": 11
    },
    {
        "title": "Neural network Gaussian processes as efficient models of potential energy surfaces for polyatomic molecules",
        "doi": "10.1088/2632-2153/ad0652",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Kernel models of potential energy surfaces (PESs) for polyatomic molecules are often restricted by a specific choice of the kernel function. This can be avoided by optimizing the complexity of the kernel function. For regression problems with very expensive data, the functional form of the model kernels can be optimized in the Gaussian process (GP) setting through compositional function search guided by the Bayesian information criterion. However, the compositional kernel search is computationally demanding and relies on greedy strategies, which may yield sub-optimal kernels. An alternative strategy of increasing complexity of GP kernels treats a GP as a Bayesian neural network (NN) with a variable number of hidden layers, which yields NNGP models. Here, we present a direct comparison of GP models with composite kernels and NNGP models for applications aiming at the construction of global PES for polyatomic molecules. We show that NNGP models of PES can be trained much more efficiently and yield better generalization accuracy without relying on any specific form of the kernel function. We illustrate that NNGP models trained by distributions of energy points at low energies produce accurate predictions of PES at high energies. We also illustrate that NNGP models can extrapolate in the input variable space by building the free energy surface of the Heisenberg model trained in the paramagnetic phase and validated in the ferromagnetic phase. By construction, composite kernels yield more accurate models than kernels with a fixed functional form. Therefore, by illustrating that NNGP models outperform GP models with composite kernels, our work suggests that NNGP models should be a preferred choice of kernel models for PES.</jats:p>",
        "is_referenced_by_count": 1
    },
    {
        "title": "Randomized CP tensor decomposition",
        "doi": "10.1088/2632-2153/ab8240",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>The <jats:italic>CANDECOMP/PARAFAC</jats:italic> (CP) tensor decomposition is a popular dimensionality-reduction method for multiway data. Dimensionality reduction is often sought after since many high-dimensional tensors have low intrinsic rank relative to the dimension of the ambient measurement space. However, the emergence of \u2018big data\u2019 poses significant computational challenges for computing this fundamental tensor decomposition. By leveraging modern randomized algorithms, we demonstrate that coherent structures can be learned from a smaller representation of the tensor in a fraction of the time. Thus, this simple but powerful algorithm enables one to compute the approximate CP decomposition even for massive tensors. The approximation error can thereby be controlled via oversampling and the computation of power iterations. In addition to theoretical results, several empirical results demonstrate the performance of the proposed algorithm.</jats:p>",
        "is_referenced_by_count": 15
    },
    {
        "title": "Constraints on parameter choices for successful time-series prediction with echo-state networks",
        "doi": "10.1088/2632-2153/aca1f6",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Echo-state networks are simple models of discrete dynamical systems driven by a time series. By selecting network parameters such that the dynamics of the network is contractive, characterized by a negative maximal Lyapunov exponent, the network may synchronize with the driving signal. Exploiting this synchronization, the echo-state network may be trained to autonomously reproduce the input dynamics, enabling time-series prediction. However, while synchronization is a necessary condition for prediction, it is not sufficient. Here, we study what other conditions are necessary for successful time-series prediction. We identify two key parameters for prediction performance, and conduct a parameter sweep to find regions where prediction is successful. These regions differ significantly depending on whether full or partial phase space information about the input is provided to the network during training. We explain how these regions emerge.</jats:p>",
        "is_referenced_by_count": 2
    },
    {
        "title": "Methods for comparing uncertainty quantifications for material property predictions",
        "doi": "10.1088/2632-2153/ab7e1a",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Data science and informatics tools have been proliferating recently within the computational materials science and catalysis fields. This proliferation has spurned the creation of various frameworks for automated materials screening, discovery, and design. Underpinning these frameworks are surrogate models with uncertainty estimates on their predictions. These uncertainty estimates are instrumental for determining which materials to screen next, but the computational catalysis field does not yet have a standard procedure for judging the quality of such uncertainty estimates. Here we present a suite of figures and performance metrics derived from the machine learning community that can be used to judge the quality of such uncertainty estimates. This suite probes the accuracy, calibration, and sharpness of a model quantitatively. We then show a case study where we judge various methods for predicting density-functional-theory-calculated adsorption energies. Of the methods studied here, we find that the best performer is a model where a convolutional neural network is used to supply features to a Gaussian process regressor, which then makes predictions of adsorption energies along with corresponding uncertainty estimates.</jats:p>",
        "is_referenced_by_count": 73
    },
    {
        "title": "Neural network analysis of neutron and x-ray reflectivity data: pathological cases, performance and perspectives",
        "doi": "10.1088/2632-2153/abf9b1",
        "year": 2021,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Neutron and x-ray reflectometry (NR and XRR) are powerful techniques to investigate the structural, morphological and even magnetic properties of solid and liquid thin films. While neutrons and x-rays behave similarly in many ways and can be described by the same general theory, they fundamentally differ in certain specific aspects. These aspects can be exploited to investigate different properties of a system, depending on which particular questions need to be answered. Having demonstrated the general applicability of neural networks to analyze XRR and NR data before (Greco <jats:italic>et al</jats:italic> 2019 <jats:italic>J. Appl. Cryst.</jats:italic> \n                  <jats:bold>52</jats:bold> 1342), this study discusses challenges arising from certain pathological cases as well as performance issues and perspectives. These cases include a low signal-to-noise ratio, a high background signal (e.g. from incoherent scattering), as well as a potential lack of a total reflection edge (TRE). By dynamically modifying the training data after every mini batch, a fully-connected neural network was trained to determine thin film parameters from reflectivity curves. We show that noise and background intensity pose no significant problem as long as they do not affect the TRE. However, for curves without strong features the prediction accuracy is diminished. Furthermore, we compare the prediction accuracy for different scattering length density combinations. The results are demonstrated using simulated data of a single-layer system while also discussing challenges for multi-component systems.</jats:p>",
        "is_referenced_by_count": 13
    },
    {
        "title": "A duality connecting neural network and cosmological dynamics",
        "doi": "10.1088/2632-2153/ac87e9",
        "year": 2022,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>We demonstrate that the dynamics of neural networks (NNs) trained with gradient descent and the dynamics of scalar fields in a flat, vacuum energy dominated Universe are structurally profoundly related. This duality provides the framework for synergies between these systems, to understand and explain NN dynamics and new ways of simulating and describing early Universe models. Working in the continuous-time limit of NNs, we analytically match the dynamics of the mean background and the dynamics of small perturbations around the mean field, highlighting potential differences in separate limits. We perform empirical tests of this analytic description and quantitatively show the dependence of the effective field theory parameters on hyperparameters of the NN. As a result of this duality, the cosmological constant is matched inversely to the learning rate in the gradient descent update.</jats:p>",
        "is_referenced_by_count": 2
    },
    {
        "title": "Bayesian renormalization",
        "doi": "10.1088/2632-2153/ad0102",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>In this note we present a fully information theoretic approach to renormalization inspired by Bayesian statistical inference, which we refer to as Bayesian renormalization. The main insight of Bayesian renormalization is that the Fisher metric defines a correlation length that plays the role of an emergent renormalization group (RG) scale quantifying the distinguishability between nearby points in the space of probability distributions. This RG scale can be interpreted as a proxy for the maximum number of unique observations that can be made about a given system during a statistical inference experiment. The role of the Bayesian renormalization scheme is subsequently to prepare an effective model for a given system up to a precision which is bounded by the aforementioned scale. In applications of Bayesian renormalization to physical systems, the emergent information theoretic scale is naturally identified with the maximum energy that can be probed by current experimental apparatus, and thus Bayesian renormalization coincides with ordinary renormalization. However, Bayesian renormalization is sufficiently general to apply even in circumstances in which an immediate physical scale is absent, and thus provides an ideal approach to renormalization in data science contexts. To this end, we provide insight into how the Bayesian renormalization scheme relates to existing methods for data compression and data generation such as the information bottleneck and the diffusion learning paradigm. We conclude by designing an explicit form of Bayesian renormalization inspired by Wilson\u2019s momentum shell renormalization scheme in quantum field theory. We apply this Bayesian renormalization scheme to a simple neural network and verify the sense in which it organizes the parameters of the model according to a hierarchy of information theoretic importance.</jats:p>",
        "is_referenced_by_count": 2
    },
    {
        "title": "Enhancing wildfire spread modelling by building a gridded fuel moisture content product with machine learning",
        "doi": "10.1088/2632-2153/aba480",
        "year": 2020,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>Wildland fire decision support systems require accurate predictions of wildland fire spread. Fuel moisture content (FMC) is one of the important parameters controlling the rate of spread of wildland fire. However, dead FMC measurements are provided by a relatively sparse network of remote automatic weather stations (RAWS), while live FMC is relatively infrequently measured manually. We developed a high resolution, gridded, real-time FMC data sets that did not previously exist for assimilation into operational wildland fire prediction systems based on ML. We used surface observations of live and dead FMC to train machine learning models to estimate FMC based on satellite observations. Moderate Resolution Imaging Spectrometer Terra and Aqua reflectances are used to predict the live and dead FMC measured by the Wildland Fire Assessment System and RAWS). We evaluate multiple machine learning methods including multiple linear regression, random forests (RFs), gradient boosted regression and artificial neural networks. The models are trained to learn the relationships between the satellite reflectances, surface weather and soil moisture observations and FMC. After training on data corresponding to the temporally and spatially nearest grid points to the irregularly spaced surface FMC observations, the machine learning models could be applied to all grid cells for a gridded product over the Conterminous United States (CONUS). The results show generally that the rule-based approaches have the lowest errors likely due to the sharp decision boundaries among the predictors, and the RF approach that utilizes bagging to avoid over-fitting has the lowest error on the test dataset. The errors are typically between 25%\u221233% the typical variability of the FMC data, which indicate the skill of the RF in estimating the FMC based on satellite data and surface characteristics. The FMC gridded product based on the RF runs operationally daily over CONUS and can be assimilated into WRF-Fire for more accurate wildland fire spread predictions.</jats:p>",
        "is_referenced_by_count": 13
    },
    {
        "title": "Probability flow solution of the Fokker\u2013Planck equation",
        "doi": "10.1088/2632-2153/ace2aa",
        "year": 2023,
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>The method of choice for integrating the time-dependent Fokker\u2013Planck equation (FPE) in high-dimension is to generate samples from the solution via integration of the associated stochastic differential equation (SDE). Here, we study an alternative scheme based on integrating an ordinary differential equation that describes the flow of probability. Acting as a transport map, this equation deterministically pushes samples from the initial density onto samples from the solution at any later time. Unlike integration of the stochastic dynamics, the method has the advantage of giving direct access to quantities that are challenging to estimate from trajectories alone, such as the probability current, the density itself, and its entropy. The probability flow equation depends on the gradient of the logarithm of the solution (its \u2018score\u2019), and so is <jats:italic>a-priori</jats:italic> unknown. To resolve this dependence, we model the score with a deep neural network that is learned on-the-fly by propagating a set of samples according to the instantaneous probability current. We show theoretically that the proposed approach controls the Kullback\u2013Leibler (KL) divergence from the learned solution to the target, while learning on external samples from the SDE does not control either direction of the KL divergence. Empirically, we consider several high-dimensional FPEs from the physics of interacting particle systems. We find that the method accurately matches analytical solutions when they are available as well as moments computed via Monte-Carlo when they are not. Moreover, the method offers compelling predictions for the global entropy production rate that out-perform those obtained from learning on stochastic trajectories, and can effectively capture non-equilibrium steady-state probability currents over long time intervals.</jats:p>",
        "is_referenced_by_count": 1
    }
]